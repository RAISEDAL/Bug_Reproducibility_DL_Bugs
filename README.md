## Bug Reproducibility for Deep Learning Systems

This repository is the replication package for the project "Enhancing the Reproducibility of Deep Learning Bugs: An Empirical Study". This study is conducted under the supervision and guidance of Dr. Masud Rahman and Dr. Foutse Khomh.

### Abstract
Deep learning has made remarkable progress in various sectors in recent years, significantly impacting people's daily lives. It has revolutionized healthcare, autonomous vehicles, and cybersecurity. However, like typical software systems, deep learning systems are susceptible to bugs, some of which can have a severe impact, as evidenced by fatal incidents involving Tesla's Autopilot technology. Despite the substantial advancements in deep learning techniques, little research has focused on the problem of reproducing bugs in these systems. This lack of attention is concerning, as non-reproducible bugs can hinder bug-fixing. Existing literature suggests that only 3% of machine learning and deep learning bugs are reproducible, underscoring the need for further research to tackle this issue. In this project, we thus conduct an empirical study focusing on the reproducibility of bugs in deep learning systems. Firstly, we constructed a dataset of different types of deep-learning bugs from Stack Overflow posts. This dataset comprises 123 Model, 204 Tensor, 103 Training, 110 GPU and 28 API Bugs. Secondly, we determined the reproducibility status of these bugs (e.g., reproducible, non-reproducible) by attempting to reproduce them using the bug descriptions, source code, and complementary information. During reproduction, we identify editing actions that can reproduce deep learning bugs and the critical information in bug reports that makes these bugs reproducible. Finally, we identify the edit actions required for reproducing specific types of deep learning bugs using the Apriori algorithm. In this paper, we successfully reproduce 85 deep learning bugs and identify 10 edit actions that can be used to reproduce the deep learning bugs. Furthermore, we identify the critical edit operations for different categories of deep learning bugs and the critical information in bug reports which helps the reproducibility of these bugs. Thus, our findings offer important insights for future research targeting the reproducibility of bugs in deep learning systems.

### Materials Included
* Analysis Folder: This folder contains Jupyter notebooks focused on dataset analysis. The notebooks include code for implementing the Apriori algorithm, which is used to identify critical edit actions. These actions are essential for gathering the necessary information required to reproduce bugs.
* Dataset Folder: Within this directory, you'll find various datasets, including those for PyTorch, TensorFlow (TF), and Keras Posts. The folder also contains queries used to filter the data and retrieve specific posts. Additionally, reproducibility results are included, along with corresponding edit actions and vital bug report details.
* Bugs Folder In this folder, a collection of bugs is organized, alongside their original code snippets sourced from Stack Overflow. Completed code snippets associated with each bug are also provided. Each specific bug folder contains the following elements:
  - `main.py`: Finalized code snippet.
  - `original_code_snippet.py`: Original code snippet from Stack Overflow.
  - Output files: Logs containing output information.
  - `requirements.txt` file is generated to facilitate the installation of necessary dependencies for each specific bug.
