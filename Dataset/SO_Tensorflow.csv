Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense,Link
47068709,1,47227886,,2017-11-02 06:10:46,,768,646342,"
<p>I have recently installed tensorflow (Windows CPU version) and received the following message:</p>
<blockquote>
<p>Successfully installed tensorflow-1.4.0 tensorflow-tensorboard-0.4.0rc2</p>
</blockquote>
<p>Then when I tried to run</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
sess.run(hello)
'Hello, TensorFlow!'
a = tf.constant(10)
b = tf.constant(32)
sess.run(a + b)
42
sess.close()
</code></pre>
<p>(which I found through <a href=""https://github.com/tensorflow/tensorflow"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow</a>)</p>
<p>I received the following message:</p>
<blockquote>
<p>2017-11-02 01:56:21.698935: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2</p>
</blockquote>
<p>But when I ran</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))
</code></pre>
<p>it ran as it should and output <code>Hello, TensorFlow!</code>, which indicates that the installation was successful indeed but there is something else that is wrong.</p>
<p>Do you know what the problem is and how to fix it?</p>
",8977639.0,,17905764.0,,2022-01-26 18:37:03,2023-03-16 20:18:09,Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2,<python><tensorflow><cpu><avx>,11,6,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47068709
33759623,1,50852627,,2015-11-17 14:37:26,,656,484223,"<p>After you train a model in Tensorflow: </p>

<ol>
<li>How do you save the trained model?</li>
<li>How do you later restore this saved model?</li>
</ol>
",1978504.0,,792066.0,,2021-05-28 11:05:01,2022-07-16 17:28:15,How to save/restore a model after training?,<python><tensorflow>,29,5,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/33759623
34240703,1,34243720,,2015-12-12 14:03:27,,470,236670,"<p>In the <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#softmax"" rel=""noreferrer"">tensorflow API docs</a> they use a keyword called <code>logits</code>. What is it? A lot of methods are written like:</p>
<pre><code>tf.nn.softmax(logits, name=None)
</code></pre>
<p>If <code>logits</code> is just a generic <code>Tensor</code> input, why is it named <code>logits</code>?</p>
<hr />
<p>Secondly, what is the difference between the following two methods?</p>
<pre><code>tf.nn.softmax(logits, name=None)
tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)
</code></pre>
<p>I know what <code>tf.nn.softmax</code> does, but not the other. An example would be really helpful.</p>
",4341948.0,,4561314.0,,2021-06-26 02:05:22,2022-07-14 23:03:36,What are logits? What is the difference between softmax and softmax_cross_entropy_with_logits?,<python><machine-learning><tensorflow>,8,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/34240703
38009682,1,38019608,,2016-06-24 09:14:23,,437,793210,"<p>I have installed tensorflow in my ubuntu 16.04 using the second answer <a href=""https://devtalk.nvidia.com/default/topic/936429/-solved-tensorflow-with-gpu-in-anaconda-env-ubuntu-16-04-cuda-7-5-cudnn-/"" rel=""noreferrer"">here</a> with ubuntu's builtin apt cuda installation.</p>

<p>Now my question is how can I test if tensorflow is really using gpu? I have a gtx 960m gpu. When I <code>import tensorflow</code> this is the output</p>

<pre><code>I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
</code></pre>

<p>Is this output enough to check if tensorflow is using gpu ? </p>
",2270136.0,,3650983.0,,2020-01-08 22:58:28,2022-12-20 08:57:23,How to tell if tensorflow is using gpu acceleration from inside python shell?,<python><tensorflow><ubuntu><gpu>,31,8,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38009682
37674306,1,37675359,,2016-06-07 08:32:16,,429,399642,"<p>What is the difference between 'SAME' and 'VALID' padding in <code>tf.nn.max_pool</code> of <code>tensorflow</code>?</p>

<p>In my opinion, 'VALID' means there will be no zero padding outside the edges when we do max pool. </p>

<p>According to <a href=""https://arxiv.org/pdf/1603.07285v1.pdf"">A guide to convolution arithmetic for deep learning</a>, it says that there will be no padding in pool operator, i.e. just use 'VALID' of <code>tensorflow</code>.
But what is 'SAME' padding of max pool in <code>tensorflow</code>?</p>
",5651936.0,,5950520.0,,2016-06-07 08:40:07,2022-12-03 02:24:39,What is the difference between 'SAME' and 'VALID' padding in tf.nn.max_pool of tensorflow?,<python><tensorflow><deep-learning>,16,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37674306
38549253,1,38549357,,2016-07-24 06:06:04,,382,1180192,"<p>I need to find which version of TensorFlow I have installed. I'm using Ubuntu 16.04 Long Term Support.  </p>
",5709404.0,,472495.0,,2020-01-29 22:35:19,2022-11-26 09:36:03,How to find which version of TensorFlow is installed in my system?,<python><ubuntu><tensorflow><command-line><version>,19,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38549253
34199233,1,34200194,,2015-12-10 10:19:51,,368,265390,"<p>I work in an environment in which computational resources are shared, i.e., we have a few server machines equipped with a few Nvidia Titan X GPUs each.</p>
<p>For small to moderate size models, the 12 GB of the Titan X is usually enough for 2–3 people to run training concurrently on the same GPU. If the models are small enough that a single model does not take full advantage of all the computational units of the GPU, this can actually result in a speedup compared with running one training process after the other. Even in cases where the concurrent access to the GPU does slow down the individual training time, it is still nice to have the flexibility of having multiple users simultaneously train on the GPU.</p>
<p>The problem with TensorFlow is that, by default, it allocates the full amount of available GPU memory when it is launched. Even for a small two-layer neural network, I see that all 12 GB of the GPU memory is used up.</p>
<p>Is there a way to make TensorFlow only allocate, say, 4 GB of GPU memory, if one knows that this is enough for a given model?</p>
",1841986.0,,6117017.0,,2020-08-28 09:55:36,2021-10-10 07:56:33,How to prevent tensorflow from allocating the totality of a GPU memory?,<python><tensorflow><tensorflow2.0><tensorflow2.x><nvidia-titan>,16,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/34199233
48720833,1,51831928,,2018-02-10 12:35:44,,366,843564,"<p>I installed the latest version of Python <code>(3.6.4 64-bit)</code> and the latest version of <code>PyCharm (2017.3.3 64-bit)</code>. Then I installed some modules in PyCharm (Numpy, Pandas, etc), but when I tried installing Tensorflow it didn't install, and I got the error message: </p>

<blockquote>
  <p>Could not find a version that satisfies the requirement TensorFlow (from versions: )
      No matching distribution found for TensorFlow.</p>
</blockquote>

<p>Then I tried installing TensorFlow from the command prompt and I got the same error message.
I did however successfully install tflearn. </p>

<p>I also installed Python 2.7, but I got the same error message again. I googled the error and tried some of the things which were suggested to other people, but nothing worked (this included installing Flask). </p>

<p>How can I install Tensorflow? Thanks.</p>
",5538535.0,,,user11717381,2020-02-09 18:02:30,2023-04-08 07:29:16,Could not find a version that satisfies the requirement tensorflow,<python><python-3.x><python-2.7><tensorflow><pip>,25,9,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48720833
34097281,1,56554855,,2015-12-04 20:55:54,,322,847933,"<p>How to convert a tensor into a numpy array when using Tensorflow with Python bindings?</p>
",1978504.0,,4909087.0,,2020-10-21 20:59:15,2023-01-09 16:06:40,Convert a tensor to numpy array in Tensorflow?,<python><numpy><tensorflow>,14,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/34097281
50622525,1,50622526,,2018-05-31 10:48:09,,316,508267,"<p>I have noticed that some newer TensorFlow versions are incompatible with older CUDA and cuDNN versions. Does an overview of the compatible versions or even a list of officially tested combinations exist? I can't find it in the TensorFlow documentation. </p>
",7353970.0,,7353970.0,,2018-07-31 14:00:21,2022-11-10 06:46:01,Which TensorFlow and CUDA version combinations are compatible?,<tensorflow><cuda><version><compatibility><cudnn>,7,8,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50622525
33633370,1,33633839,,2015-11-10 15:19:58,,308,604179,"<p>I have been using the introductory example of matrix multiplication in TensorFlow.</p>

<pre><code>matrix1 = tf.constant([[3., 3.]])
matrix2 = tf.constant([[2.],[2.]])
product = tf.matmul(matrix1, matrix2)
</code></pre>

<p>When I print the product, it is displaying it as a <code>Tensor</code> object:</p>

<pre><code>&lt;tensorflow.python.framework.ops.Tensor object at 0x10470fcd0&gt;
</code></pre>

<p>But how do I know the value of <code>product</code>?</p>

<p>The following doesn't help:</p>

<pre><code>print product
Tensor(""MatMul:0"", shape=TensorShape([Dimension(1), Dimension(1)]), dtype=float32)
</code></pre>

<p>I know that graphs run on <code>Sessions</code>, but isn't there any way I can check the output of a <code>Tensor</code> object without running the graph in a <code>session</code>?</p>
",4993513.0,,8233320.0,,2019-05-21 12:02:08,2021-02-13 00:40:41,How to print the value of a Tensor object in TensorFlow?,<python><tensorflow><tensor>,24,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33633370
35919020,1,37534656,,2016-03-10 14:19:55,,297,108889,"<p>What's the differences between these functions?</p>

<blockquote>
  <p><code>tf.variable_op_scope(values, name, default_name, initializer=None)</code></p>
  
  <p>Returns a context manager for defining an op that creates variables.
  This context manager validates that the given values are from the same graph, ensures that that graph is the default graph, and pushes a name scope and a variable scope.</p>
</blockquote>

<hr>

<blockquote>
  <p><code>tf.op_scope(values, name, default_name=None)</code></p>
  
  <p>Returns a context manager for use when defining a Python op.
  This context manager validates that the given values are from the same graph, ensures that that graph is the default graph, and pushes a name scope.            </p>
</blockquote>

<hr>

<blockquote>
  <p><code>tf.name_scope(name)</code></p>
  
  <p>Wrapper for <code>Graph.name_scope()</code> using the default graph.
  See <code>Graph.name_scope()</code> for more details.</p>
</blockquote>

<hr>

<blockquote>
  <p><code>tf.variable_scope(name_or_scope, reuse=None, initializer=None)</code></p>
  
  <p>Returns a context for variable scope.
  Variable scope allows to create new variables and to share already created ones while providing checks to not create or share by accident. For details, see the Variable Scope How To, here we present only a few basic examples.  </p>
</blockquote>
",2886263.0,,3924118.0,,2017-11-11 17:56:22,2020-11-13 09:52:36,What's the difference of name scope and a variable scope in tensorflow?,<tensorflow>,8,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35919020
39691902,1,40295999,,2016-09-25 21:12:23,,236,159479,"<p><em>The original question was in regard to TensorFlow implementations specifically. However, the answers are for implementations in general. This general answer is also the correct answer for TensorFlow.</em></p>

<p>When using batch normalization and dropout in TensorFlow (specifically using the contrib.layers) do I need to be worried about the ordering?</p>

<p>It seems possible that if I use dropout followed immediately by batch normalization there might be trouble. For example, if the shift in the batch normalization trains to the larger scale numbers of the training outputs, but then that same shift is applied to the smaller (due to the compensation for having more outputs) scale numbers without dropout during testing, then that shift may be off. Does the TensorFlow batch normalization layer automatically compensate for this? Or does this not happen for some reason I'm missing?</p>

<p>Also, are there other pitfalls to look out for in when using these two together? For example, assuming I'm using them in the correct order in regards to the above (assuming there <em>is</em> a correct order), could there be trouble with using both batch normalization and dropout on multiple successive layers? I don't immediately see a problem with that, but I might be missing something.</p>

<p>Thank you much!</p>

<p><strong>UPDATE:</strong></p>

<p>An experimental test <em>seems</em> to suggest that ordering <em>does</em> matter. I ran the same network twice with only the batch norm and dropout reverse. When the dropout is before the batch norm, validation loss seems to be going up as training loss is going down. They're both going down in the other case. But in my case the movements are slow, so things may change after more training and it's just a single test. A more definitive and informed answer would still be appreciated.</p>
",1191087.0,,1191087.0,,2019-02-03 21:14:55,2022-06-16 12:41:45,Ordering of batch normalization and dropout?,<python><neural-network><tensorflow><conv-neural-network>,8,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/39691902
38559755,1,38580201,,2016-07-25 04:30:38,,232,397773,"<p>I have a plan to use distributed TensorFlow, and I saw TensorFlow can use GPUs for training and testing. In a cluster environment, each machine could have 0 or 1 or more GPUs, and I want to run my TensorFlow graph into GPUs on as many machines as possible.</p>

<p>I found that when running <code>tf.Session()</code> TensorFlow gives information about GPU in the log messages like below:</p>

<pre><code>I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
</code></pre>

<p>My question is how do I get information about current available GPU from TensorFlow? I can get loaded GPU information from the log, but I want to do it in a more sophisticated, programmatic way.
I also could restrict GPUs intentionally using the CUDA_VISIBLE_DEVICES environment variable, so I don't want to know a way of getting GPU information from OS kernel.</p>

<p>In short, I want a function like <code>tf.get_available_gpus()</code> that will return <code>['/gpu:0', '/gpu:1']</code> if there are two GPUs available in the machine. How can I implement this?</p>
",2728425.0,,3574081.0,,2016-07-26 02:37:25,2023-03-30 09:21:24,How to get current available GPUs in tensorflow?,<python><gpu><tensorflow>,16,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38559755
33610685,1,33610914,,2015-11-09 13:52:52,,223,127133,"<p>TensorFlow has two ways to evaluate part of graph: <code>Session.run</code> on a list of variables and <code>Tensor.eval</code>.  Is there a difference between these two?</p>
",16480.0,,3204551.0,,2015-11-14 00:10:50,2020-02-20 10:17:10,"In TensorFlow, what is the difference between Session.run() and Tensor.eval()?",<python><tensorflow>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33610685
33620794,1,62245422,,2015-11-10 00:18:33,,210,164211,"<p>I'm really eager to start using Google's new Tensorflow library in C++. The website and docs are just really unclear in terms of how to build the project's C++ API and I don't know where to start. </p>

<p>Can someone with more experience help by discovering and sharing a guide to using tensorflow's C++ API?  </p>
",3499258.0,,3204551.0,,2015-11-14 00:15:03,2022-10-20 14:53:54,How to build and use Google TensorFlow C++ api,<c++><tensorflow>,13,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33620794
37660312,1,37660913,,2016-06-06 14:41:56,,195,259201,"<p>I have installed the GPU version of tensorflow on an Ubuntu 14.04.</p>

<p>I am on a GPU server where tensorflow can access the available GPUs.</p>

<p>I want to run tensorflow on the CPUs.</p>

<p>Normally I can use <code>env CUDA_VISIBLE_DEVICES=0</code> to run on GPU no. 0.</p>

<p>How can I pick between the CPUs instead?</p>

<p>I am not intersted in rewritting my code with <code>with tf.device(""/cpu:0""):</code></p>
",4233809.0,,4958717.0,,2018-02-07 13:45:39,2022-04-16 18:25:29,How to run Tensorflow on CPU,<python><tensorflow>,13,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37660312
35677724,1,35678837,,2016-02-28 01:40:08,,174,81465,"<p>I recently started studying deep learning and other ML techniques, and I started searching for frameworks that simplify the process of build a net and training it, then I found TensorFlow, having little experience in the field, for me, it seems that speed is a big factor for making a big ML system even more if working with deep learning, so why python was chosen by Google to make TensorFlow? Wouldn't it be better to make it over an language that can be compiled and not interpreted?</p>

<p>What are the advantages of using Python over a language like C++ for machine learning?</p>
",2473294.0,,1090562.0,,2017-07-16 03:45:37,2020-06-18 20:35:01,"TensorFlow, why was python the chosen language?",<python><c++><machine-learning><tensorflow>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35677724
34870614,1,34877590,,2016-01-19 07:14:40,,173,77126,"<pre><code>tf.nn.embedding_lookup(params, ids, partition_strategy='mod', name=None)
</code></pre>

<p>I cannot understand the duty of this function. Is it like a lookup table? Which means to return the parameters corresponding to each id (in ids)?</p>

<p>For instance, in the <code>skip-gram</code> model if we use <code>tf.nn.embedding_lookup(embeddings, train_inputs)</code>, then for each <code>train_input</code> it finds the correspond embedding?</p>
",5808490.0,,2956066.0,,2018-07-13 12:19:33,2022-08-26 13:05:01,What does tf.nn.embedding_lookup function do?,<python><tensorflow><deep-learning><word-embedding><nlp>,9,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34870614
42315202,1,42318280,,2017-02-18 12:35:35,,165,58992,"<p>It is really straightforward to see and understand the scalar values in TensorBoard. However, it's not clear how to understand histogram graphs. </p>

<p>For example, they are the histograms of my network weights.</p>

<p><a href=""https://i.stack.imgur.com/IttNH.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/RVOA5.jpg"" alt=""enter image description here""></a></p>

<p>(After fixing a bug thanks to sunside)
<a href=""https://i.stack.imgur.com/IttNH.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/IttNH.jpg"" alt=""enter image description here""></a>
What is the best way to interpret these? Layer 1 weights look mostly flat, what does this mean?</p>

<p>I added the network construction code here.</p>

<pre><code>X = tf.placeholder(tf.float32, [None, input_size], name=""input_x"")
x_image = tf.reshape(X, [-1, 6, 10, 1])
tf.summary.image('input', x_image, 4)

# First layer of weights
with tf.name_scope(""layer1""):
    W1 = tf.get_variable(""W1"", shape=[input_size, hidden_layer_neurons],
                         initializer=tf.contrib.layers.xavier_initializer())
    layer1 = tf.matmul(X, W1)
    layer1_act = tf.nn.tanh(layer1)
    tf.summary.histogram(""weights"", W1)
    tf.summary.histogram(""layer"", layer1)
    tf.summary.histogram(""activations"", layer1_act)

# Second layer of weights
with tf.name_scope(""layer2""):
    W2 = tf.get_variable(""W2"", shape=[hidden_layer_neurons, hidden_layer_neurons],
                         initializer=tf.contrib.layers.xavier_initializer())
    layer2 = tf.matmul(layer1_act, W2)
    layer2_act = tf.nn.tanh(layer2)
    tf.summary.histogram(""weights"", W2)
    tf.summary.histogram(""layer"", layer2)
    tf.summary.histogram(""activations"", layer2_act)

# Third layer of weights
with tf.name_scope(""layer3""):
    W3 = tf.get_variable(""W3"", shape=[hidden_layer_neurons, hidden_layer_neurons],
                         initializer=tf.contrib.layers.xavier_initializer())
    layer3 = tf.matmul(layer2_act, W3)
    layer3_act = tf.nn.tanh(layer3)

    tf.summary.histogram(""weights"", W3)
    tf.summary.histogram(""layer"", layer3)
    tf.summary.histogram(""activations"", layer3_act)

# Fourth layer of weights
with tf.name_scope(""layer4""):
    W4 = tf.get_variable(""W4"", shape=[hidden_layer_neurons, output_size],
                         initializer=tf.contrib.layers.xavier_initializer())
    Qpred = tf.nn.softmax(tf.matmul(layer3_act, W4)) # Bug fixed: Qpred = tf.nn.softmax(tf.matmul(layer3, W4))
    tf.summary.histogram(""weights"", W4)
    tf.summary.histogram(""Qpred"", Qpred)

# We need to define the parts of the network needed for learning a policy
Y = tf.placeholder(tf.float32, [None, output_size], name=""input_y"")
advantages = tf.placeholder(tf.float32, name=""reward_signal"")

# Loss function
# Sum (Ai*logp(yi|xi))
log_lik = -Y * tf.log(Qpred)
loss = tf.reduce_mean(tf.reduce_sum(log_lik * advantages, axis=1))
tf.summary.scalar(""Q"", tf.reduce_mean(Qpred))
tf.summary.scalar(""Y"", tf.reduce_mean(Y))
tf.summary.scalar(""log_likelihood"", tf.reduce_mean(log_lik))
tf.summary.scalar(""loss"", loss)

# Learning
train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)
</code></pre>
",364772.0,,364772.0,,2017-02-19 02:08:58,2021-01-19 08:05:59,Understanding TensorBoard (weight) histograms,<tensorflow><histogram><tensorboard>,2,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42315202
34619177,1,44103248,,2016-01-05 18:51:56,,152,90620,"<p>I was looking at the docs of tensorflow about <code>tf.nn.conv2d</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/conv2d"" rel=""noreferrer"">here</a>. But I can't understand what it does or what it is trying to achieve. It says on the docs,</p>
<blockquote>
<p>#1 : Flattens the filter to a 2-D matrix with shape</p>
<p><code>[filter_height * filter_width * in_channels, output_channels]</code>.</p>
</blockquote>
<p>Now what does that do? Is that element-wise multiplication or just plain matrix multiplication? I also could not understand the other two points mentioned in the docs. I have written them below :</p>
<blockquote>
<p># 2: Extracts image patches from the the input tensor to form a virtual tensor of shape</p>
<p><code>[batch, out_height, out_width, filter_height * filter_width * in_channels]</code>.</p>
<p># 3: For each patch, right-multiplies the filter matrix and the image patch vector.</p>
</blockquote>
<p>It would be really helpful if anyone could give an example, a piece of code (extremely helpful) maybe and explain what is going on there and why the operation is like this.</p>
<p>I've tried coding a small portion and printing out the shape of the operation. Still, I can't understand.</p>
<p>I tried something like this:</p>
<pre class=""lang-python prettyprint-override""><code>op = tf.shape(tf.nn.conv2d(tf.random_normal([1,10,10,10]), 
              tf.random_normal([2,10,10,10]), 
              strides=[1, 2, 2, 1], padding='SAME'))

with tf.Session() as sess:
    result = sess.run(op)
    print(result)
</code></pre>
<p>I understand bits and pieces of convolutional neural networks. I studied them <a href=""http://cs231n.github.io/convolutional-networks/"" rel=""noreferrer"">here</a>. But the implementation on tensorflow is not what I expected. So it raised the question.</p>
<p><strong>EDIT</strong>:
So, I implemented a much simpler code. But I can't figure out what's going on. I mean how the results are like this. It would be extremely helpful if anyone could tell me what process yields this output.</p>
<pre class=""lang-python prettyprint-override""><code>input = tf.Variable(tf.random_normal([1,2,2,1]))
filter = tf.Variable(tf.random_normal([1,1,1,1]))

op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME')
init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)

    print(&quot;input&quot;)
    print(input.eval())
    print(&quot;filter&quot;)
    print(filter.eval())
    print(&quot;result&quot;)
    result = sess.run(op)
    print(result)
</code></pre>
<p>output</p>
<pre><code>input
[[[[ 1.60314465]
   [-0.55022103]]

  [[ 0.00595062]
   [-0.69889867]]]]
filter
[[[[-0.59594476]]]]
result
[[[[-0.95538563]
   [ 0.32790133]]

  [[-0.00354624]
   [ 0.41650501]]]]
</code></pre>
",4341948.0,,-1.0,,2020-06-20 09:12:55,2021-05-02 09:48:50,What does tf.nn.conv2d do in tensorflow?,<neural-network><tensorflow>,7,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34619177
49083680,1,69079804,,2018-03-03 11:34:03,,150,4809,"<p>I'm having a bit of trouble understanding the new <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/summary"" rel=""nofollow noreferrer""><code>tf.contrib.summary</code></a> API. In the old one, it seemed that all one was supposed to do was to run <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/merge_all"" rel=""nofollow noreferrer""><code>tf.summary.merge_all()</code></a> and run that as an op.</p>
<p>But now we have things like <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/summary/record_summaries_every_n_global_steps"" rel=""nofollow noreferrer""><code>tf.contrib.summary.record_summaries_every_n_global_steps</code></a>, which can be used like this:</p>
<pre><code>import tensorflow.contrib.summary as tfsum

summary_writer = tfsum.create_file_writer(logdir, flush_millis=3000)
summaries = []

# First we create one summary which runs every n global steps
with summary_writer.as_default(), tfsum.record_summaries_every_n_global_steps(30):
    summaries.append(tfsum.scalar(&quot;train/loss&quot;, loss))

# And then one that runs every single time?
with summary_writer.as_default(), tfsum.always_record_summaries():
    summaries.append(tfsum.scalar(&quot;train/accuracy&quot;, accuracy))

# Then create an optimizer which uses a global step
step = tf.create_global_step()
train = tf.train.AdamOptimizer().minimize(loss, global_step=step)
</code></pre>
<p>And now come a few questions:</p>
<ol>
<li>If we just run <code>session.run(summaries)</code> in a loop, I assume that the accuracy summary would get written every single time, while the loss one wouldn't, because it only gets written if the global step is divisible by 30?</li>
<li>Assuming the summaries automatically evaluate their dependencies, I never need to run <code>session.run([accuracy, summaries])</code> but can just run, <code>session.run(summaries)</code> since they have a dependency in the graph, right?</li>
<li>If 2) is true, can't I just add a control dependency to the training step so that the summaries are written on every train run? Or is this a bad practice?</li>
<li>Is there any downside to using control dependencies in general for things that are going to be evaluated at the same time anyway?</li>
<li>Why does <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/summary/scalar"" rel=""nofollow noreferrer""><code>tf.contrib.summary.scalar</code></a> (and others) take in a <code>step</code> parameter?</li>
</ol>
<p>By adding a control dependency in 3) I mean doing this:</p>
<pre><code>tf.control_dependencies(summaries):
    train = tf.train.AdamOptimizer().minimize(loss, global_step=step)
</code></pre>
",72583.0,,72583.0,,2021-09-06 20:05:39,2021-09-06 20:06:03,How are the new tf.contrib.summary summaries in TensorFlow evaluated?,<python><tensorflow><tensorboard>,1,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/49083680
36883949,1,36893840,,2016-04-27 08:08:29,,141,162850,"<p>I am creating neural nets with <code>Tensorflow</code> and <code>skflow</code>; for some reason I want to get the values of some inner tensors for a given input, so I am using <code>myClassifier.get_layer_value(input, ""tensorName"")</code>, <code>myClassifier</code> being a <code>skflow.estimators.TensorFlowEstimator</code>. </p>

<p>However, I find it difficult to find the correct syntax of the tensor name, even knowing its name (and I'm getting confused between operation and tensors), so I'm using tensorboard to plot the graph and look for the name.</p>

<p>Is there a way to enumerate all the tensors in a graph without using tensorboard?</p>
",2902280.0,,,,,2021-02-09 12:45:55,"In Tensorflow, get the names of all the Tensors in a graph",<python><tensorflow><tensorboard><skflow>,10,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36883949
41265035,1,41273348,,2016-12-21 14:23:58,,136,96212,"<p>Having read the <a href=""https://www.tensorflow.org/how_tos/variables/#saving_and_restoring"" rel=""noreferrer"">docs</a>, I saved a model in <code>TensorFlow</code>, here is my demo code:</p>

<pre class=""lang-py prettyprint-override""><code># Create some variables.
v1 = tf.Variable(..., name=""v1"")
v2 = tf.Variable(..., name=""v2"")
...
# Add an op to initialize the variables.
init_op = tf.global_variables_initializer()

# Add ops to save and restore all the variables.
saver = tf.train.Saver()

# Later, launch the model, initialize the variables, do some work, save the
# variables to disk.
with tf.Session() as sess:
  sess.run(init_op)
  # Do some work with the model.
  ..
  # Save the variables to disk.
  save_path = saver.save(sess, ""/tmp/model.ckpt"")
  print(""Model saved in file: %s"" % save_path)
</code></pre>

<p>but after that, I found there are 3 files</p>

<pre><code>model.ckpt.data-00000-of-00001
model.ckpt.index
model.ckpt.meta
</code></pre>

<p>And I can't restore the model by restore the <code>model.ckpt</code> file, since there is no such file. Here is my code</p>

<pre class=""lang-py prettyprint-override""><code>with tf.Session() as sess:
  # Restore variables from disk.
  saver.restore(sess, ""/tmp/model.ckpt"")
</code></pre>

<p>So, why there are 3 files?</p>
",5046896.0,,5046896.0,,2018-05-21 01:19:57,2021-03-21 13:52:03,"TensorFlow, why there are 3 files after saving the model?",<tensorflow>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41265035
37098546,1,37102908,,2016-05-08 09:57:28,,135,44522,"<p>As far as I know, <code>Variable</code> is the default operation for making a variable, and <code>get_variable</code> is mainly used for weight sharing.</p>

<p>On the one hand, there are some people suggesting using <code>get_variable</code> instead of the primitive <code>Variable</code> operation whenever you need a variable. On the other hand, I merely see any use of <code>get_variable</code> in TensorFlow's official documents and demos.</p>

<p>Thus I want to know some rules of thumb on how to correctly use these two mechanisms. Are there any ""standard"" principles?</p>
",4794308.0,,134077.0,,2018-03-16 21:02:29,2019-10-21 18:38:57,Difference between Variable and get_variable in TensorFlow,<python><tensorflow>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37098546
39517431,1,39526318,,2016-09-15 17:54:15,,131,102182,"<p>I'm training a network for image localization with Adam optimizer, and someone suggest me to use exponential decay. I don't want to try that because Adam optimizer itself decays learning rate. But that guy insists and he said he did that before. So should I do that and is there any theory behind your suggestion?</p>
",6417085.0,,9678047.0,,2019-10-10 10:53:36,2022-08-25 14:32:10,Should we do learning rate decay for adam optimizer,<neural-network><tensorflow>,7,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/39517431
46444018,1,47025850,,2017-09-27 09:18:35,,129,76939,"<p>As per TensorFlow <a href=""https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset#prefetch"" rel=""noreferrer"">documentation</a> , the <code>prefetch</code> and <code>map</code> methods of <code>tf.contrib.data.Dataset</code> class, both have a parameter called <code>buffer_size</code>.</p>
<p>For <code>prefetch</code> method, the parameter is known as <code>buffer_size</code> and according to documentation :</p>
<blockquote>
<p>buffer_size: A tf.int64 scalar tf.Tensor, representing the maximum
number elements that will be buffered when prefetching.</p>
</blockquote>
<p>For the <code>map</code> method, the parameter is known as <code>output_buffer_size</code> and according to documentation :</p>
<blockquote>
<p>output_buffer_size: (Optional.) A tf.int64 scalar tf.Tensor,
representing the maximum number of processed elements that will be
buffered.</p>
</blockquote>
<p>Similarly for the <code>shuffle</code> method, the same quantity appears and according to documentation :</p>
<blockquote>
<p>buffer_size: A tf.int64 scalar tf.Tensor, representing the number of
elements from this dataset from which the new dataset will sample.</p>
</blockquote>
<p>What is the relation between these parameters ?</p>
<p>Suppose I create a<code>Dataset</code> object as follows :</p>
<pre><code> tr_data = TFRecordDataset(trainfilenames)
    tr_data = tr_data.map(providefortraining, output_buffer_size=10 * trainbatchsize, num_parallel_calls\
=5)
    tr_data = tr_data.shuffle(buffer_size= 100 * trainbatchsize)
    tr_data = tr_data.prefetch(buffer_size = 10 * trainbatchsize)
    tr_data = tr_data.batch(trainbatchsize)
</code></pre>
<p>What role is being played by the <code>buffer</code> parameters in the above snippet ?</p>
",8530591.0,,7964098.0,,2020-07-02 09:30:00,2021-08-06 08:58:05,"Meaning of buffer_size in Dataset.map , Dataset.prefetch and Dataset.shuffle",<tensorflow><tensorflow-datasets>,6,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/46444018
34642595,1,34643081,,2016-01-06 20:56:26,,126,48252,"<p>I am trying to understand the <strong>strides</strong> argument in tf.nn.avg_pool, tf.nn.max_pool, tf.nn.conv2d. </p>

<p>The <a href=""https://www.tensorflow.org/versions/master/api_docs/python/nn.html#max_pool"" rel=""noreferrer"">documentation</a> repeatedly says </p>

<blockquote>
  <p>strides: A list of ints that has length >= 4. The stride of the sliding window for each dimension of the input tensor.</p>
</blockquote>

<p>My questions are:</p>

<ol>
<li>What do each of the 4+ integers represent?</li>
<li>Why must they have strides[0] = strides[3] = 1 for convnets?</li>
<li>In <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3%20-%20Neural%20Networks/convolutional_network.ipynb"" rel=""noreferrer"">this example</a> we see <code>tf.reshape(_X,shape=[-1, 28, 28, 1])</code>. Why -1?</li>
</ol>

<p>Sadly the examples in the docs for reshape using -1 don't translate too well to this scenario.</p>
",3908247.0,,,,,2018-11-12 08:51:30,Tensorflow Strides Argument,<python><neural-network><convolution><tensorflow><conv-neural-network>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34642595
37312421,1,37317322,,2016-05-19 01:15:32,,125,65675,"<p>I recently came across <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits"" rel=""noreferrer"">tf.nn.sparse_softmax_cross_entropy_with_logits</a> and I can not figure out what the difference is compared to <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits"" rel=""noreferrer"">tf.nn.softmax_cross_entropy_with_logits</a>.</p>

<p>Is the only difference that training vectors <code>y</code> have to be <a href=""http://www.cs.toronto.edu/~guerzhoy/321/lec/W04/onehot.pdf"" rel=""noreferrer"">one-hot encoded</a> when using <code>sparse_softmax_cross_entropy_with_logits</code>?</p>

<p>Reading the API, I was unable to find any other difference compared to <code>softmax_cross_entropy_with_logits</code>. But why do we need the extra function then?</p>

<p>Shouldn't <code>softmax_cross_entropy_with_logits</code> produce the same results as <code>sparse_softmax_cross_entropy_with_logits</code>, if it is supplied with one-hot encoded training data/vectors?  </p>
",3314143.0,,3924118.0,,2018-07-08 23:00:53,2018-07-08 23:00:53,What's the difference between sparse_softmax_cross_entropy_with_logits and softmax_cross_entropy_with_logits?,<neural-network><tensorflow><softmax><cross-entropy>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/37312421
37383812,1,49690207,,2016-05-23 06:20:20,,125,297823,"<p>I've been trying to use tensorflow for two days now installing and reinstalling it over and over again in python2.7 and 3.4.  No matter what I do, I get this error message when trying to use tensorflow.placeholder()</p>

<p>It's very boilerplate code:</p>

<pre><code>tf_in = tf.placeholder(""float"", [None, A]) # Features
</code></pre>

<p>No matter what I do I always get the trace back:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/willim/PycharmProjects/tensorflow/tensorflow.py"", line 2, in &lt;module&gt;
    import tensorflow as tf
  File ""/home/willim/PycharmProjects/tensorflow/tensorflow.py"", line 53, in &lt;module&gt;
    tf_in = tf.placeholder(""float"", [None, A]) # Features
AttributeError: 'module' object has no attribute 'placeholder'
</code></pre>

<p>Anyone know how I can fix this?</p>
",3023715.0,,3297613.0,,2016-05-23 06:24:38,2023-03-14 03:38:27,"TensorFlow, ""'module' object has no attribute 'placeholder'""",<python><machine-learning><tensorflow>,22,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37383812
41567895,1,41568439,,2017-01-10 11:37:23,,115,163035,"<p>Reading implementation of scikit-learn in TensorFlow: <a href=""http://learningtensorflow.com/lesson6/"" rel=""noreferrer"">http://learningtensorflow.com/lesson6/</a> and scikit-learn: <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"" rel=""noreferrer"">http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a> I'm struggling to decide which implementation to use.</p>
<p>scikit-learn is installed as part of the tensorflow docker container so can use either implementation.</p>
<p>Reason to use scikit-learn :</p>
<blockquote>
<p>scikit-learn contains less boilerplate than the tensorflow
implementation.</p>
</blockquote>
<p>Reason to use tensorflow :</p>
<blockquote>
<p>If running on Nvidia GPU the algorithm will be run against in parallel
, I'm not sure if scikit-learn will utilize all available GPUs?</p>
</blockquote>
<p>Reading <a href=""https://www.quora.com/What-are-the-main-differences-between-TensorFlow-and-SciKit-Learn"" rel=""noreferrer"">https://www.quora.com/What-are-the-main-differences-between-TensorFlow-and-SciKit-Learn</a></p>
<blockquote>
<p>TensorFlow is more  low-level; basically, the Lego bricks that help
you to implement machine learning algorithms whereas scikit-learn
offers you off-the-shelf algorithms, e.g., algorithms for
classification such as SVMs, Random Forests, Logistic Regression, and
many, many more. TensorFlow shines if you want to implement
deep learning algorithms, since it allows you to take advantage of
GPUs for more efficient training.</p>
</blockquote>
<p>This statement re-enforces my assertion that &quot;scikit-learn contains less boilerplate than the tensorflow implementation&quot; but also suggests scikit-learn will not utilize all available GPUs?</p>
",470184.0,,10972216.0,,2021-09-23 10:23:45,2022-02-16 10:10:43,Will scikit-learn utilize GPU?,<python><tensorflow><scikit-learn><k-means><neuraxle>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41567895
65298241,1,65333085,,2020-12-15 00:05:16,,114,184951,"<p>I just installed tensorflow v2.3 on anaconda python. I tried to test out the installation using the python command below;</p>
<pre><code>$ python -c &quot;import tensorflow as tf; x = [[2.]]; print('tensorflow version', tf.__version__); print('hello, {}'.format(tf.matmul(x, x)))&quot;
</code></pre>
<p>I got the following message;</p>
<pre><code>2020-12-15 07:59:12.411952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
hello, [[4.]]
</code></pre>
<p>From the message, it seems that the installation was installed successfully. But what does <code>This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2</code> mean exactly?</p>
<p>Am I using a tensorflow version with some limited features? Any side effects?</p>
<p>I am using Windows 10.</p>
",7518091.0,,,,,2023-04-16 18:51:49,What does this tensorflow message mean? Any side effect? Was the installation successful?,<python><tensorflow><anaconda>,7,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/65298241
33919948,1,33922859,,2015-11-25 15:08:58,,112,113408,"<p>I am using TensorFlow to train a neural network. This is how I am initializing the <code>GradientDescentOptimizer</code>:</p>

<pre><code>init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)

mse        = tf.reduce_mean(tf.square(out - out_))
train_step = tf.train.GradientDescentOptimizer(0.3).minimize(mse)
</code></pre>

<p>The thing here is that I don't know how to set an update rule for the learning rate or a decay value for that. </p>

<p>How can I use an adaptive learning rate here?</p>
",826983.0,,,,,2019-06-05 17:37:20,How to set adaptive learning rate for GradientDescentOptimizer?,<python><tensorflow>,5,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33919948
47818822,1,48468512,,2017-12-14 17:14:36,,109,80794,"<p>Is there any way to use TensorBoard when training a TensorFlow model on Google Colab?</p>
",3915600.0,,6729010.0,,2020-10-13 03:18:26,2023-01-03 07:00:52,Can I use TensorBoard with Google Colab?,<tensorflow><tensorboard><google-colaboratory>,22,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47818822
38947658,1,38950073,,2016-08-14 23:53:27,,108,44167,"<p>From what I've gathered so far, there are several different ways of dumping a TensorFlow graph into a file and then loading it into another program, but I haven't been able to find clear examples/information on how they work. What I already know is this:</p>

<ol>
<li>Save the model's variables into a checkpoint file (.ckpt) using a <code>tf.train.Saver()</code> and restore them later (<a href=""https://www.tensorflow.org/versions/r0.10/how_tos/variables/index.html"" rel=""noreferrer"">source</a>)</li>
<li>Save a model into a .pb file and load it back in using <code>tf.train.write_graph()</code> and <code>tf.import_graph_def()</code> (<a href=""https://github.com/tensorflow/tensorflow/issues/616"" rel=""noreferrer"">source</a>)</li>
<li>Load in a model from a .pb file, retrain it, and dump it into a new .pb file using Bazel (<a href=""https://petewarden.com/2016/02/28/tensorflow-for-poets/"" rel=""noreferrer"">source</a>)</li>
<li>Freeze the graph to save the graph and weights together (<a href=""https://www.tensorflow.org/versions/r0.9/how_tos/tool_developers/index.html#freezing"" rel=""noreferrer"">source</a>)</li>
<li>Use <code>as_graph_def()</code> to save the model, and for weights/variables, map them into constants (<a href=""https://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow"">source</a>)</li>
</ol>

<p>However, I haven't been able to clear up several questions regarding these different methods:</p>

<ol>
<li>Regarding checkpoint files, do they only save the trained weights of a model? Could checkpoint files be loaded into a new program, and be used to run the model, or do they simply serve as ways to save the weights in a model at a certain time/stage?</li>
<li>Regarding <code>tf.train.write_graph()</code>, are the weights/variables saved as well?</li>
<li>Regarding Bazel, can it only save into/load from .pb files for retraining? Is there a simple Bazel command just to dump a graph into a .pb?</li>
<li>Regarding freezing, can a frozen graph be loaded in using <code>tf.import_graph_def()</code>?</li>
<li>The Android demo for TensorFlow loads in Google's Inception model from a .pb file. If I wanted to substitute my own .pb file, how would I go about doing that? Would I need to change any native code/methods?</li>
<li>In general, what exactly is the difference between all these methods? Or more broadly, what is the difference between <code>as_graph_def()</code>/.ckpt/.pb?</li>
</ol>

<p>In short, what I'm looking for is a method to save both a graph (as in, the various operations and such) and its weights/variables into a file, which can then be used to load the graph and weights into another program, for use (not necessarily continuing/retraining).</p>

<p>Documentation about this topic isn't very straightforward, so any answers/information would be greatly appreciated.</p>
",1908727.0,,-1.0,,2017-05-23 11:47:11,2018-10-01 13:18:33,TensorFlow saving into/loading a graph from a file,<python><tensorflow><protocol-buffers>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38947658
41166681,1,41167447,,2016-12-15 14:32:18,,104,62062,"<p>In this is <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py"" rel=""noreferrer"">tutorial code</a> from TensorFlow website,</p>
<ol>
<li><p>could anyone help explain what does <code>global_step</code> mean?</p>
<p>I found on the Tensorflow website written that <em>global step is used count training steps</em>, but I don't quite get what exactly it means.</p>
</li>
<li><p>Also, what does the number 0 mean when setting up <code>global_step</code>?</p>
</li>
</ol>
<pre class=""lang-py prettyprint-override""><code>    def training(loss,learning_rate):
        tf.summary.scalar('loss',loss)
        optimizer = tf.train.GradientDescentOptimizer(learning_rate)
        
        # Why 0 as the first parameter of the global_step tf.Variable?
        global_step = tf.Variable(0, name='global_step',trainable=False)

        train_op = optimizer.minimize(loss, global_step=global_step)
    
        return train_op
</code></pre>
<p>According to Tensorflow doc <em>global_step: increment by one after the variables have been updated</em>. Does that mean after one update <code>global_step</code> becomes 1?</p>
",6733064.0,,-1.0,,2020-06-20 09:12:55,2019-10-03 11:27:28,What does global_step mean in Tensorflow?,<tensorflow><deep-learning>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41166681
40666316,1,40666375,,2016-11-17 22:37:28,,103,143493,"<p>Suppose I have a Tensorflow tensor. How do I get the dimensions (shape) of the tensor as integer values? I know there are two methods, <code>tensor.get_shape()</code> and <code>tf.shape(tensor)</code>, but I can't get the shape values as integer <code>int32</code> values.</p>

<p>For example, below I've created a 2-D tensor, and I need to get the number of rows and columns as <code>int32</code> so that I can call <code>reshape()</code> to create a tensor of shape <code>(num_rows * num_cols, 1)</code>. However, the method <code>tensor.get_shape()</code> returns values as <code>Dimension</code> type, not <code>int32</code>.</p>

<pre><code>import tensorflow as tf
import numpy as np

sess = tf.Session()    
tensor = tf.convert_to_tensor(np.array([[1001,1002,1003],[3,4,5]]), dtype=tf.float32)

sess.run(tensor)    
# array([[ 1001.,  1002.,  1003.],
#        [    3.,     4.,     5.]], dtype=float32)

tensor_shape = tensor.get_shape()    
tensor_shape
# TensorShape([Dimension(2), Dimension(3)])    
print tensor_shape    
# (2, 3)

num_rows = tensor_shape[0] # ???
num_cols = tensor_shape[1] # ???

tensor2 = tf.reshape(tensor, (num_rows*num_cols, 1))    
# Traceback (most recent call last):
#   File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
#   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1750, in reshape
#     name=name)
#   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 454, in apply_op
#     as_ref=input_arg.is_ref)
#   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 621, in convert_to_tensor
#     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
#   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 180, in _constant_tensor_conversion_function
#     return constant(v, dtype=dtype, name=name)
#   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 163, in constant
#     tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
#   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 353, in make_tensor_proto
#     _AssertCompatible(values, dtype)
#   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 290, in _AssertCompatible
#     (dtype.name, repr(mismatch), type(mismatch).__name__))
# TypeError: Expected int32, got Dimension(6) of type 'Dimension' instead.
</code></pre>
",4561314.0,,9619186.0,,2019-01-29 20:23:54,2020-07-06 20:15:31,How to get Tensorflow tensor dimensions (shape) as int values?,<python><tensorflow><machine-learning><artificial-intelligence>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40666316
34236252,1,34237210,,2015-12-12 00:21:08,,103,90119,"<p>In the <a href=""https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html"" rel=""noreferrer"">MNIST beginner tutorial</a>, there is the statement </p>

<pre><code>accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
</code></pre>

<p><code>tf.cast</code> basically changes the type of tensor the object is, but what is the difference between <a href=""https://www.tensorflow.org/api_docs/python/tf/reduce_mean"" rel=""noreferrer""><code>tf.reduce_mean</code></a> and <a href=""https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.mean.html"" rel=""noreferrer""><code>np.mean</code></a>? </p>

<p>Here is the doc on <a href=""https://www.tensorflow.org/api_docs/python/tf/reduce_mean"" rel=""noreferrer""><code>tf.reduce_mean</code></a>:</p>

<blockquote>
  <p><code>reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None)</code></p>
  
  <p><code>input_tensor</code>: The tensor to reduce. Should have numeric type.</p>
  
  <p><code>reduction_indices</code>: The dimensions to reduce. If <code>None</code> (the defaut), reduces all dimensions.</p>

<pre><code># 'x' is [[1., 1. ]]
#         [2., 2.]]
tf.reduce_mean(x) ==&gt; 1.5
tf.reduce_mean(x, 0) ==&gt; [1.5, 1.5]
tf.reduce_mean(x, 1) ==&gt; [1.,  2.]
</code></pre>
</blockquote>

<p>For a 1D vector, it looks like <code>np.mean == tf.reduce_mean</code>, but I don't understand what's happening in <code>tf.reduce_mean(x, 1) ==&gt; [1.,  2.]</code>. <code>tf.reduce_mean(x, 0) ==&gt; [1.5, 1.5]</code> kind of makes sense, since mean of <code>[1, 2]</code> and <code>[1, 2]</code> is <code>[1.5, 1.5]</code>, but what's going on with <code>tf.reduce_mean(x, 1)</code>?</p>
",678572.0,O.rka,3924118.0,,2019-10-25 13:58:53,2021-01-05 15:25:21,What is the difference between np.mean and tf.reduce_mean?,<python><numpy><machine-learning><mean><tensorflow>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/34236252
35687678,1,35688187,,2016-02-28 20:11:43,,101,60211,"<p>I've recently reviewed an interesting implementation for <a href=""http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/"">convolutional text classification</a>. However all TensorFlow code I've reviewed uses a random (not pre-trained) embedding vectors like the following:</p>

<pre><code>with tf.device('/cpu:0'), tf.name_scope(""embedding""):
    W = tf.Variable(
        tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),
        name=""W"")
    self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)
    self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)
</code></pre>

<p>Does anybody know how to use the results of Word2vec or a GloVe pre-trained word embedding instead of a random one?</p>
",3147590.0,,3574081.0,,2016-02-28 21:02:15,2021-09-08 08:18:13,Using a pre-trained word embedding (word2vec or Glove) in TensorFlow,<python><numpy><tensorflow><deep-learning>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35687678
47034888,1,47034889,,2017-10-31 11:59:49,,100,61966,"<p>Classification problems, such as logistic regression or multinomial
logistic regression, optimize a <strong>cross-entropy</strong> loss.
Normally, the cross-entropy layer follows the <strong>softmax</strong> layer,
which produces probability distribution.</p>

<p>In tensorflow, there are at least a <strong>dozen of different cross-entropy loss functions</strong>:</p>

<ul>
<li><code>tf.losses.softmax_cross_entropy</code></li>
<li><code>tf.losses.sparse_softmax_cross_entropy</code></li>
<li><code>tf.losses.sigmoid_cross_entropy</code></li>
<li><code>tf.contrib.losses.softmax_cross_entropy</code></li>
<li><code>tf.contrib.losses.sigmoid_cross_entropy</code></li>
<li><code>tf.nn.softmax_cross_entropy_with_logits</code></li>
<li><code>tf.nn.sigmoid_cross_entropy_with_logits</code></li>
<li>...</li>
</ul>

<p>Which one works only for binary classification and which are suitable for multi-class problems? When should you use <code>sigmoid</code> instead of <code>softmax</code>? How are <code>sparse</code> functions different from others and why is it only <code>softmax</code>?</p>

<p>Related (more math-oriented) discussion: <a href=""https://stackoverflow.com/q/44674847/712995"">What are the differences between all these cross-entropy losses in Keras and TensorFlow?</a>. </p>
",712995.0,,10908375.0,,2020-01-06 21:20:58,2021-03-15 13:58:25,How to choose cross-entropy loss in TensorFlow?,<python><tensorflow><neural-network><logistic-regression><cross-entropy>,3,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47034888
61922334,1,61961016,,2020-05-20 20:28:10,,100,115171,"<p>I encountered it while executing <code>from object_detection.utils import label_map_util</code> in jupyter notebook. It is actually the tensorflow object detection tutorial notebook(it comes with the tensorflow object detection api)
The complete error log:</p>
<pre class=""lang-none prettyprint-override""><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-7-7035655b948a&gt; in &lt;module&gt;
      1 from object_detection.utils import ops as utils_ops
----&gt; 2 from object_detection.utils import label_map_util
      3 from object_detection.utils import visualization_utils as vis_util

~\AppData\Roaming\Python\Python37\site-packages\object_detection\utils\label_map_util.py in &lt;module&gt;
     25 import tensorflow as tf
     26 from google.protobuf import text_format
---&gt; 27 from object_detection.protos import string_int_label_map_pb2
     28 
     29 

~\AppData\Roaming\Python\Python37\site-packages\object_detection\protos\string_int_label_map_pb2.py in &lt;module&gt;
     19   syntax='proto2',
     20   serialized_options=None,
---&gt; 21   create_key=_descriptor._internal_create_key,
     22   serialized_pb=b'\n2object_detection/protos/string_int_label_map.proto\x12\x17object_detection.protos\&quot;\xc0\x01\n\x15StringIntLabelMapItem\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02id\x18\x02 \x01(\x05\x12\x14\n\x0c\x64isplay_name\x18\x03 \x01(\t\x12M\n\tkeypoints\x18\x04 \x03(\x0b\x32:.object_detection.protos.StringIntLabelMapItem.KeypointMap\x1a(\n\x0bKeypointMap\x12\n\n\x02id\x18\x01 \x01(\x05\x12\r\n\x05label\x18\x02 \x01(\t\&quot;Q\n\x11StringIntLabelMap\x12&lt;\n\x04item\x18\x01 \x03(\x0b\x32..object_detection.protos.StringIntLabelMapItem'
     23 )

AttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key'
</code></pre>
",13283462.0,,6372809.0,,2021-02-11 20:41:12,2022-08-17 06:53:37,"How to solve ""AttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key""?",<python><tensorflow><protocol-buffers><object-detection-api><proto>,10,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/61922334
37893755,1,37901914,,2016-06-18 05:55:39,,98,243184,"<p>I have two GPUs and would like to run two different networks via ipynb simultaneously, however the first notebook always allocates both GPUs. </p>

<p>Using CUDA_VISIBLE_DEVICES, I can hide devices for python files, however I am unsure of how to do so within a notebook.</p>

<p>Is there anyway to hide different GPUs in to notebooks running on the same server?</p>
",200663.0,,,,,2021-02-18 17:40:22,Tensorflow set CUDA_VISIBLE_DEVICES within jupyter,<python><environment-variables><tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37893755
37107223,1,37143333,,2016-05-09 03:04:56,,96,84849,"<p>I found in many available neural network code implemented using TensorFlow that regularization terms are often implemented by manually adding an additional term to loss value.</p>

<p>My questions are:</p>

<ol>
<li><p>Is there a more elegant or recommended way of regularization than doing it manually?</p></li>
<li><p>I also find that <code>get_variable</code> has an argument <code>regularizer</code>. How should it be used? According to my observation, if we pass a regularizer to it (such as <code>tf.contrib.layers.l2_regularizer</code>, a tensor representing regularized term will be computed and added to a graph collection named <code>tf.GraphKeys.REGULARIZATOIN_LOSSES</code>. Will that collection be automatically used by TensorFlow (e.g. used by optimizers when training)? Or is it expected that I should use that collection by myself?</p></li>
</ol>
",4794308.0,,4304503.0,,2016-10-31 15:07:28,2022-12-25 01:04:46,How to add regularizations in TensorFlow?,<python><neural-network><tensorflow><deep-learning>,10,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37107223
52357542,1,52359348,,2018-09-16 19:09:44,,94,201118,"<p>How can I fix this error I downloaded this code from GitHub.</p>

<pre><code>predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].numpy()
</code></pre>

<p>throws the error </p>

<pre><code>AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>

<p>Please help me fix this!</p>

<p>I used:</p>

<pre><code>sess = tf.Session()
    with sess.as_default():
       predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].eval()
</code></pre>

<p>And i get this error. Someone help me i just want it to work why is this so hard?</p>

<pre><code>D:\Python&gt;python TextGenOut.py
  File ""TextGenOut.py"", line 72
    predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].eval()
    ^
IndentationError: unexpected indent

D:\Python&gt;python TextGenOut.py
2018-09-16 21:50:57.008663: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-09-16 21:50:57.272973: W T:\src\github\tensorflow\tensorflow\core\framework\op_kernel.cc:1275] OP_REQUIRES failed at resource_variable_ops.cc:480 : Not found: Container localhost does not exist. (Could not find resource: localhost/model/embedding/embeddings)
Traceback (most recent call last):
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\client\session.py"", line 1278, in _do_call
    return fn(*args)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\client\session.py"", line 1263, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\client\session.py"", line 1350, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable model/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/model/dense/kernel)
         [[Node: model/dense/MatMul/ReadVariableOp = ReadVariableOp[dtype=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](model/dense/kernel)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""TextGenOut.py"", line 72, in &lt;module&gt;
    predicted_id = tf.multinomial(tf.exp(predictions), num_samples=1)[0][0].eval()
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\framework\ops.py"", line 680, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\framework\ops.py"", line 4951, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\client\session.py"", line 877, in run
    run_metadata_ptr)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\client\session.py"", line 1100, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\client\session.py"", line 1272, in _do_run
    run_metadata)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\client\session.py"", line 1291, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable model/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/model/dense/kernel)
         [[Node: model/dense/MatMul/ReadVariableOp = ReadVariableOp[dtype=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](model/dense/kernel)]]

Caused by op 'model/dense/MatMul/ReadVariableOp', defined at:
  File ""TextGenOut.py"", line 66, in &lt;module&gt;
    predictions, hidden = model(input_eval, hidden)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 736, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""TextGenOut.py"", line 39, in call
    x = self.fc(output)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 736, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\keras\layers\core.py"", line 943, in call
    outputs = gen_math_ops.mat_mul(inputs, self.kernel)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 4750, in mat_mul
    name=name)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\framework\op_def_library.py"", line 510, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\framework\ops.py"", line 1094, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 1045, in _dense_var_to_tensor
    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 1000, in _dense_var_to_tensor
    return self.value()
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 662, in value
    return self._read_variable_op()
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\ops\resource_variable_ops.py"", line 745, in _read_variable_op
    self._dtype)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\ops\gen_resource_variable_ops.py"", line 562, in read_variable_op
    ""ReadVariableOp"", resource=resource, dtype=dtype, name=name)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\util\deprecation.py"", line 454, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\framework\ops.py"", line 3155, in create_op
    op_def=op_def)
  File ""C:\Users\fried\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\framework\ops.py"", line 1717, in __init__
    self._traceback = tf_stack.extract_stack()

FailedPreconditionError (see above for traceback): Error while reading resource variable model/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/model/dense/kernel)
         [[Node: model/dense/MatMul/ReadVariableOp = ReadVariableOp[dtype=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](model/dense/kernel)]]
</code></pre>
",9800348.0,,1805756.0,,2019-10-07 11:39:17,2022-11-06 23:35:11,AttributeError: 'Tensor' object has no attribute 'numpy',<python><numpy><tensorflow><attributeerror><tensor>,9,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52357542
49579684,1,49579995,,2018-03-30 18:40:59,,94,47455,"<p>I have a dataset represented as a NumPy matrix of shape <code>(num_features, num_examples)</code> and I wish to convert it to TensorFlow type <code>tf.Dataset</code>.</p>

<p>I am struggling trying to understand the difference between these two methods: <code>Dataset.from_tensors</code> and <code>Dataset.from_tensor_slices</code>. What is the right one and why?</p>

<p>TensorFlow documentation (<a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset"" rel=""noreferrer"">link</a>) says that both method accept a nested structure of tensor although when using <code>from_tensor_slices</code> the tensor should have same size in the 0-th dimension. </p>
",5291026.0,,3924118.0,,2019-10-29 21:38:56,2021-08-07 08:57:59,What is the difference between Dataset.from_tensors and Dataset.from_tensor_slices?,<python><tensorflow><tensorflow-datasets>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/49579684
53514495,1,53517848,,2018-11-28 07:47:03,,92,57109,"<p>I'm currently learning TensorFlow but I came across a confusion in the below code snippet:</p>
<pre><code>dataset = dataset.shuffle(buffer_size = 10 * batch_size) 
dataset = dataset.repeat(num_epochs).batch(batch_size)
return dataset.make_one_shot_iterator().get_next()
</code></pre>
<p>I know that first the dataset will hold all the data but what <code>shuffle()</code>,<code>repeat()</code>, and <code>batch()</code> do to the dataset?
Please help me with an example and explanation.</p>
",10492790.0,,10730632.0,,2021-01-05 09:40:49,2022-12-18 11:08:27,"What does batch, repeat, and shuffle do with TensorFlow Dataset?",<tensorflow><dataset>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53514495
33640581,1,55334946,,2015-11-10 22:07:54,,89,107903,"<p>I'm porting my Caffe network over to TensorFlow but it doesn't seem to have xavier initialization. I'm using <code>truncated_normal</code> but this seems to be making it a lot harder to train.</p>
",230987.0,,249341.0,,2015-12-19 22:25:10,2020-10-21 00:22:14,How to do Xavier initialization on TensorFlow,<python><tensorflow>,10,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33640581
36182380,1,36188682,,2016-03-23 15:31:58,,89,79663,"<p>TensorBoard seems to have a feature to display multiple different runs and toggle them. </p>

<p><a href=""https://i.stack.imgur.com/5E3eQ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/5E3eQ.png"" alt=""enter image description here""></a></p>

<p>How can I make multiple runs show up here and how can assign a name to them to differentiate them?</p>
",349760.0,,,,,2022-12-29 18:31:15,How do display different runs in TensorBoard?,<tensorflow><tensorboard>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36182380
37091899,1,37093142,,2016-05-07 17:57:38,,89,51946,"<p>I'm relatively new to the world of TensorFlow, and pretty perplexed by how you'd <strong><em>actually</em></strong> read CSV data into a usable example/label tensors in TensorFlow. The example from the <a href=""https://www.tensorflow.org/versions/r0.7/how_tos/reading_data/index.html#reading-from-files"" rel=""noreferrer"">TensorFlow tutorial on reading CSV data</a> is pretty fragmented and only gets you part of the way to being able to train on CSV data.</p>

<p>Here's my code that I've pieced together, based off that CSV tutorial:</p>

<pre><code>from __future__ import print_function
import tensorflow as tf

def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i + 1

filename = ""csv_test_data.csv""

# setup text reader
file_length = file_len(filename)
filename_queue = tf.train.string_input_producer([filename])
reader = tf.TextLineReader(skip_header_lines=1)
_, csv_row = reader.read(filename_queue)

# setup CSV decoding
record_defaults = [[0],[0],[0],[0],[0]]
col1,col2,col3,col4,col5 = tf.decode_csv(csv_row, record_defaults=record_defaults)

# turn features back into a tensor
features = tf.stack([col1,col2,col3,col4])

print(""loading, "" + str(file_length) + "" line(s)\n"")
with tf.Session() as sess:
  tf.initialize_all_variables().run()

  # start populating filename queue
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)

  for i in range(file_length):
    # retrieve a single instance
    example, label = sess.run([features, col5])
    print(example, label)

  coord.request_stop()
  coord.join(threads)
  print(""\ndone loading"")
</code></pre>

<p>And here is an brief example from the CSV file I'm loading - pretty basic data - 4 feature columns, and 1 label column:</p>

<pre><code>0,0,0,0,0
0,15,0,0,0
0,30,0,0,0
0,45,0,0,0
</code></pre>

<p>All the code above does is <strong>print each example from the CSV file, one by one</strong>, which, while nice, is pretty darn useless for training.</p>

<p>What I'm struggling with here is how you'd actually turn those individual examples, loaded one-by-one, into a training dataset. For example, <a href=""https://github.com/rringham/deep-learning-notebooks/blob/master/notMNIST_four_hidden_layers.ipynb"" rel=""noreferrer"">here's a notebook</a> I was working on in the Udacity Deep Learning course. I basically want to take the CSV data I'm loading, and plop it into something like <strong>train_dataset</strong> and <strong>train_labels</strong>:</p>

<pre><code>def reformat(dataset, labels):
  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)
  # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]
  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)
  return dataset, labels
train_dataset, train_labels = reformat(train_dataset, train_labels)
valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)
test_dataset, test_labels = reformat(test_dataset, test_labels)
print('Training set', train_dataset.shape, train_labels.shape)
print('Validation set', valid_dataset.shape, valid_labels.shape)
print('Test set', test_dataset.shape, test_labels.shape)
</code></pre>

<p>I've tried using <code>tf.train.shuffle_batch</code>, like this, but it just inexplicably hangs:</p>

<pre><code>  for i in range(file_length):
    # retrieve a single instance
    example, label = sess.run([features, colRelevant])
    example_batch, label_batch = tf.train.shuffle_batch([example, label], batch_size=file_length, capacity=file_length, min_after_dequeue=10000)
    print(example, label)
</code></pre>

<p>So to sum up, here are my questions:</p>

<ul>
<li><strong>What am I missing about this process?</strong>

<ul>
<li>It feels like there is some key intuition that I'm missing about how to properly build an input pipeline.</li>
</ul></li>
<li><strong>Is there a way to avoid having to know the length of the CSV file?</strong>

<ul>
<li>It feels pretty inelegant to have to know the number of lines you want to process (the <code>for i in range(file_length)</code> line of code above)</li>
</ul></li>
</ul>

<hr>

<p><strong>Edit:</strong>
As soon as Yaroslav pointed out that I was likely mixing up imperative and graph-construction parts here, it started to become clearer. I was able to pull together the following code, which I think is closer to what would typically done when training a model from CSV (excluding any model training code):</p>

<pre><code>from __future__ import print_function
import numpy as np
import tensorflow as tf
import math as math
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('dataset')
args = parser.parse_args()

def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i + 1

def read_from_csv(filename_queue):
  reader = tf.TextLineReader(skip_header_lines=1)
  _, csv_row = reader.read(filename_queue)
  record_defaults = [[0],[0],[0],[0],[0]]
  colHour,colQuarter,colAction,colUser,colLabel = tf.decode_csv(csv_row, record_defaults=record_defaults)
  features = tf.stack([colHour,colQuarter,colAction,colUser])  
  label = tf.stack([colLabel])  
  return features, label

def input_pipeline(batch_size, num_epochs=None):
  filename_queue = tf.train.string_input_producer([args.dataset], num_epochs=num_epochs, shuffle=True)  
  example, label = read_from_csv(filename_queue)
  min_after_dequeue = 10000
  capacity = min_after_dequeue + 3 * batch_size
  example_batch, label_batch = tf.train.shuffle_batch(
      [example, label], batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  return example_batch, label_batch

file_length = file_len(args.dataset) - 1
examples, labels = input_pipeline(file_length, 1)

with tf.Session() as sess:
  tf.initialize_all_variables().run()

  # start populating filename queue
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)

  try:
    while not coord.should_stop():
      example_batch, label_batch = sess.run([examples, labels])
      print(example_batch)
  except tf.errors.OutOfRangeError:
    print('Done training, epoch reached')
  finally:
    coord.request_stop()

  coord.join(threads) 
</code></pre>
",18505.0,,1913888.0,,2018-01-20 15:18:53,2020-01-20 11:28:39,How to *actually* read CSV data in TensorFlow?,<python><csv><tensorflow>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37091899
34220532,1,34220750,,2015-12-11 09:51:46,,88,115414,"<p>I am trying to assign a new value to a tensorflow variable in python.</p>

<pre><code>import tensorflow as tf
import numpy as np

x = tf.Variable(0)
init = tf.initialize_all_variables()
sess = tf.InteractiveSession()
sess.run(init)

print(x.eval())

x.assign(1)
print(x.eval())
</code></pre>

<p>But the output I get is</p>

<pre><code>0
0
</code></pre>

<p>So the value has not changed. What am I missing?</p>
",3537687.0,,5096199.0,,2018-01-29 11:24:11,2019-12-13 18:33:53,How to assign a value to a TensorFlow variable?,<python><tensorflow><neural-network><deep-learning><variable-assignment>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34220532
33711556,1,33713962,,2015-11-14 18:00:57,,86,108343,"<p>I followed the given mnist tutorials and was able to train a model and evaluate its accuracy. However, the tutorials don't show how to make predictions given a model. I'm not interested in accuracy, I just want to use the model to predict a new example and in the output see all the results (labels), each with its assigned score (sorted or not).</p>
",247866.0,,1090562.0,,2015-11-14 21:39:36,2020-01-21 09:06:05,Making predictions with a TensorFlow model,<tensorflow>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33711556
54665842,1,54708388,,2019-02-13 08:43:40,,86,135346,"<p>I have installed Ancaconda3 and Tensorflow. When I try to import Tensorflow in python shell I receive the following error:</p>
<blockquote>
<p>ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
ImportError: numpy.core.multiarray failed to import</p>
<p>The above exception was the direct cause of the following exception:</p>
<p>Traceback (most recent call last):   File &quot;&quot;, line 980, in _find_and_load SystemError:
&lt;class '_frozen_importlib._ModuleLockManager'&gt; returned a result with
an error set ImportError: numpy.core._multiarray_umath failed to
import ImportError: numpy.core.umath failed to import</p>
</blockquote>
<p>I am not sure what the problem is as numpy is installed on my system and can be successfully imported in python.
I am using Windows10.</p>
",6104563.0,,11107541.0,,2022-12-24 19:44:16,2023-05-18 02:10:25,"When importing tensorflow, I get the following error: No module named 'numpy.core._multiarray_umath'",<python-3.x><numpy><tensorflow><anaconda>,5,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54665842
53953099,1,53995313,,2018-12-28 02:39:47,,85,43764,"<p>I watched the Tensorflow Developer's summit video on Eager Execution in Tensorflow, and the presenter gave an introduction to ""Gradient Tape."" Now I understand that Gradient Tape tracks the automatic differentiation that occurs in a TF model.</p>

<p>I was trying to understand why I would use Gradient Tape? Can anyone explain how Gradient Tape is used as a diagnostic tool? Why would someone use Gradient Tape versus just Tensorboard visualization of weights. </p>

<p>So I get that the automatic differentiation that occurs with a model is to compute the gradients of each node--meaning the adjustment of the weights and biases at each node, given some batch of data. So that is the learning process. But I was under the impression that I can actually use a <code>tf.keras.callback.TensorBoard()</code> call to see the tensorboard visualization of training--so I can watch the weights on each node and determine if there are any dead or oversaturated nodes.</p>

<p>Is the use of Gradient Tape only to see if some gradients go to zero or get really big, etc? Or is there some other use of the Gradient Tape?</p>
",1610428.0,,,,,2020-11-15 02:54:48,What is the purpose of the Tensorflow Gradient Tape?,<tensorflow><eager-execution>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53953099
42394585,1,42402484,,2017-02-22 14:41:48,,83,65110,"<p>I have a <code>.tfrecord</code> but I don't know how it is structured. How can I inspect the schema to understand what the <code>.tfrecord</code> file contains?</p>

<p>All Stackoverflow answers or documentation seem to assume I know the structure of the file.</p>

<pre><code>reader = tf.TFRecordReader()
file = tf.train.string_input_producer(""record.tfrecord"")
_, serialized_record = reader.read(file)

...HOW TO INSPECT serialized_record...
</code></pre>
",1501285.0,,1501285.0,,2021-04-20 09:11:56,2022-07-30 15:45:58,How to inspect a Tensorflow .tfrecord file?,<python><tensorflow><tfrecord>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42394585
36193553,1,36193677,,2016-03-24 04:58:58,,79,107040,"<p>I have trained a ConvNet model with TensorFlow, and I want to get a particular weight in layer. For example in torch7 I would simply access <code>model.modules[2].weights</code>. to get the weights of layer 2. How would I do the same thing in TensorFlow?</p>
",3106889.0,,3574081.0,,2016-03-24 06:08:22,2021-12-18 22:35:23,Get the value of some weights in a model trained by TensorFlow,<tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36193553
42217059,1,42218732,,2017-02-14 02:52:26,,78,67852,"<p>I have used tensorflow for ONE day,but there comes some troubles,when I import tensorflow, there would be AttributeError: 'module' object has no attribute 'XXXXXX'</p>

<h2>Environment</h2>

<p>I use ubuntu14.04, python2.7, CUDA toolkit 8.0 and CuDNN v5.
And versions of my six and protobuf are:
Name: six
Version: 1.10.0
Location: /usr/local/lib/python2.7/dist-packages
Requires: 
Name: protobuf
Version: 3.2.0
Location: /usr/local/lib/python2.7/dist-packages
Requires: six, setuptools</p>

<p>here is my test code:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>import tensorflow as tf
a = tf.placeholder(tf.int16)
b = tf.placeholder(tf.int16)
add = tf.add(a, b)
mul = tf.mul(a, b)
with tf.Session() as sess:
    # Run every operation with variable input
    print ""Addition with variables: %i"" % sess.run(add, feed_dict={a: 2, b: 3})
    print ""Multiplication with variables: %i"" % sess.run(mul, feed_dict={a: 2, b: 3})</code></pre>
</div>
</div>
</p>

<p>I get this output:</p>

<p><a href=""https://i.stack.imgur.com/LCHw1.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/LCHw1.png"" alt=""enter image description here""></a></p>

<p>Is there any problem with the tensorflow installation? or any other problems?</p>
",7560632.0,,5633071.0,,2017-03-05 00:53:50,2020-01-29 09:11:50,tensorflow:AttributeError: 'module' object has no attribute 'mul',<python><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42217059
33949786,1,33950177,,2015-11-27 03:17:52,,78,91379,"<p>I would like to use <em>batch normalization</em> in TensorFlow. I found the related C++ source code in <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/nn_ops.cc"" rel=""noreferrer""><code>core/ops/nn_ops.cc</code></a>. However, I did not find it documented on tensorflow.org.</p>

<p>BN has different semantics in MLP and CNN, so I am not sure what exactly this BN does.</p>

<p>I did not find a method called <code>MovingMoments</code> either.</p>
",3090897.0,,3924118.0,,2018-07-08 14:42:24,2018-07-11 17:34:39,How could I use batch normalization in TensorFlow?,<python><tensorflow>,8,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/33949786
34293714,1,34297960,,2015-12-15 15:57:34,,77,46807,"<p>I know I can measure the execution time of a call to <code>sess.run()</code>, but is it possible to get a finer granularity and measure the execution time of individual operations?</p>
",3559888.0,,562769.0,,2016-12-20 22:01:28,2022-03-09 13:25:06,Can I measure the execution time of individual operations with TensorFlow?,<tensorflow>,10,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34293714
37337728,1,39353693,,2016-05-20 04:00:45,,76,62816,"<p>When I run <code>sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})</code> I get <code>InternalError: Blas SGEMM launch failed</code>. Here is the full error and stack trace:</p>

<pre><code>InternalErrorTraceback (most recent call last)
&lt;ipython-input-9-a3261a02bdce&gt; in &lt;module&gt;()
      1 batch_xs, batch_ys = mnist.train.next_batch(100)
----&gt; 2 sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    338     try:
    339       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 340                          run_metadata_ptr)
    341       if run_metadata:
    342         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    562     try:
    563       results = self._do_run(handle, target_list, unique_fetches,
--&gt; 564                              feed_dict_string, options, run_metadata)
    565     finally:
    566       # The movers are no longer used. Delete them.

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    635     if handle is None:
    636       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--&gt; 637                            target_list, options, run_metadata)
    638     else:
    639       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
    657       # pylint: disable=protected-access
    658       raise errors._make_specific_exception(node_def, op, error_message,
--&gt; 659                                             e.code)
    660       # pylint: enable=protected-access
    661 

InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 10), m=100, n=10, k=784
     [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_4, Variable/read)]]
Caused by op u'MatMul', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py"", line 3, in &lt;module&gt;
    app.launch_new_instance()
  File ""/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py"", line 596, in launch_instance
    app.start()
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py"", line 442, in start
    ioloop.IOLoop.instance().start()
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py"", line 883, in start
    handler_func(fd_obj, events)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 391, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py"", line 199, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2825, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""&lt;ipython-input-4-d7414c4b6213&gt;"", line 4, in &lt;module&gt;
    y = tf.nn.softmax(tf.matmul(x, W) + b)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 1036, in matmul
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 911, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()
</code></pre>

<p>Stack: EC2 g2.8xlarge machine, Ubuntu 14.04</p>
",1930168.0,,,,,2020-01-30 05:30:48,TensorFlow: InternalError: Blas SGEMM launch failed,<tensorflow><blas>,16,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37337728
41791469,1,41791644,,2017-01-22 13:27:47,,76,35726,"<p>In which cases should <code>tf.Session()</code> and <code>tf.InteractiveSession()</code> be considered for what purpose?</p>

<p>When I tried to use the former one, some functions (for example, <code>.eval()</code>) didn't work, and when I changed to the later one, it worked.</p>
",7457101.0,,3924118.0,,2017-10-22 12:30:52,2018-08-13 15:13:19,What's the difference between tf.Session() and tf.InteractiveSession()?,<tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41791469
36162180,1,44225502,,2016-03-22 18:16:38,,76,36275,"<p>I'm studying <em>TensorFlow</em> and how to use it, even if I'm not an expert of neural networks and deep learning (just the basics).</p>

<p>Following tutorials, I don't understand the real and practical differences between the three optimizers for loss. I look at the <a href=""https://www.tensorflow.org/versions/r0.7/api_docs/python/train.html#optimizers"" rel=""noreferrer"">API</a> and I understand the principles, but my questions are:</p>

<p><strong>1. When is it preferable to use one instead of the others ?</strong></p>

<p><strong>2. Are there important differences to know ?</strong></p>
",859453.0,,1075708.0,,2018-04-12 02:56:38,2019-04-12 17:38:07,Gradient Descent vs Adagrad vs Momentum in TensorFlow,<tensorflow><deep-learning>,3,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36162180
51726203,1,51727268,,2018-08-07 11:56:03,,76,112893,"<p>I'm trying to install tensorflow onto a Mac with Python3.7. However, I'm getting the error:</p>

<pre><code>$ pip3 -v install tensorflow
...    
    Skipping link https://files.pythonhosted.org/packages/56/7a/c6bca0fe52a94ca508731d8b139e7dbd5a36cddc64c19f422f97e5a853e8/tensorflow-1.10.0rc1-cp36-cp36m-win_amd64.whl#sha256=3ab24374888d6a13d55ce2e3cf4ba0c9cd6f824723313db5322512087525cb78 (from https://pypi.org/simple/tensorflow/); it is not compatible with this Python
  Could not find a version that satisfies the requirement tensorflow (from versions: )
Cleaning up...
Removed build tracker '/private/var/folders/4n/9342s4wd3jv0qzwjz8rxrygr0000gp/T/pip-req-tracker-3p60r2lo'

No matching distribution found for tensorflow
</code></pre>

<p>From what I can gather this is happening because tensorflow doesn't yet support Python3.7. As a workaround I want to install Python3.6 alongside 3.7 and then install tensorflow to that version. However, I'm new to Mac and not sure of the correct way to do this without potentially messing with the preexisting Python version. </p>

<p>I've tried using brew, but it looks like Python3 is as specific as it gets. What is the correct way to do what I'm after?</p>
",1997195.0,,,,,2020-09-04 16:35:10,Installing Python3.6 alongside Python3.7 on Mac,<macos><tensorflow><python-3.6><python-3.7>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51726203
38160940,1,38161314,,2016-07-02 13:55:11,,74,61660,"<p>Is there a function call or another way to count the total number of parameters in a tensorflow model?</p>

<p>By parameters I mean: an N dim vector of trainable variables has N parameters, a <code>NxM</code> matrix has <code>N*M</code> parameters, etc. So essentially I'd like to sum the product of the shape dimensions of all the trainable variables in a tensorflow session.</p>
",5765409.0,,5765409.0,,2018-11-06 17:56:40,2022-08-19 09:49:19,How to count total number of trainable parameters in a tensorflow model?,<neural-network><tensorflow>,9,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38160940
57381430,1,57382914,,2019-08-06 17:43:46,,74,67204,"<p>I installed TensorFlow 1.10.1 but when I tried to import TensorFlow it said that I need TensorFlow version 1.10.0. Thus, I installed it and now I get the following warnings:</p>

<pre><code>&gt;&gt;&gt; import tensorflow
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
C:\Users\PC\Anaconda3\envs\tut\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
</code></pre>
",11423611.0,,9805238.0,,2019-08-07 09:32:42,2022-12-20 18:49:28,"""synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'."" problem in TensorFlow",<python><python-3.x><numpy><tensorflow><artificial-intelligence>,8,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/57381430
34454721,1,37411464,,2015-12-24 15:10:54,,73,55449,"<p>I'm testing different hyperparameters for a cnn model I built, but I'm having a small annoyance when viewing the summaries in Tensorboard. The problem seems to be that the data is just ""added"" in consecutive runs, so the functions result in a weird superposition unless I see the information as ""relative"" instead of ""by step"". See here:</p>

<p><a href=""https://i.stack.imgur.com/hZDiS.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/hZDiS.png"" alt=""X Type: Step""></a></p>

<p><a href=""https://i.stack.imgur.com/kef2k.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/kef2k.png"" alt=""X Type: Relative""></a></p>

<p>I've tried killing tensorboard's process and erasing the log files, but it seems it is not enough.</p>

<p><strong>So the question is, how do I reset this information?</strong></p>

<p>Thanks!!</p>
",1978504.0,,,,,2020-12-09 09:12:27,"How to ""reset"" tensorboard data after killing tensorflow instance",<tensorflow><tensorboard>,8,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34454721
33681517,1,33682213,,2015-11-12 21:16:01,,72,86632,"<p>Does tensorflow have something similar to scikit learn's <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"">one hot encoder</a> for processing categorical data?  Would using a placeholder of tf.string behave as categorical data?</p>

<p>I realize I can manually pre-process the data before sending it to tensorflow, but having it built in is very convenient.</p>
",276310.0,,610569.0,,2015-11-13 18:04:33,2020-04-01 17:34:40,Tensorflow One Hot Encoder?,<python><machine-learning><neural-network><tensorflow>,15,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33681517
39758094,1,44842044,,2016-09-28 21:38:34,,72,140516,"<p>I've trained 3 models and am now running code that loads each of the 3 checkpoints in sequence and runs predictions using them. I'm using the GPU.</p>

<p>When the first model is loaded it pre-allocates the entire GPU memory (which I want for working through the first batch of data). But it doesn't unload memory when it's finished. When the second model is loaded, using both <code>tf.reset_default_graph()</code> and <code>with tf.Graph().as_default()</code> the GPU memory still is fully consumed from the first model, and the second model is then starved of memory.</p>

<p>Is there a way to resolve this, other than using Python subprocesses or multiprocessing to work around the problem (the only solution I've found on via google searches)?</p>
",4790871.0,,,,,2022-11-02 15:57:16,Clearing Tensorflow GPU memory after model execution,<python><tensorflow><gpu>,9,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39758094
35833011,1,35833133,,2016-03-06 21:47:46,,71,58120,"<p>Let's say I have following code:</p>

<pre><code>x = tf.placeholder(""float32"", shape=[None, ins_size**2*3], name = ""x_input"")
condition = tf.placeholder(""int32"", shape=[1, 1], name = ""condition"")
W = tf.Variable(tf.zeros([ins_size**2*3,label_option]), name = ""weights"")
b = tf.Variable(tf.zeros([label_option]), name = ""bias"")

if condition &gt; 0:
    y = tf.nn.softmax(tf.matmul(x, W) + b)
else:
    y = tf.nn.softmax(tf.matmul(x, W) - b)  
</code></pre>

<p>Would the <code>if</code> statement work in the calculation (I do not think so)? If not, how can I add an <code>if</code> statement into the TensorFlow calculation graph? </p>
",5948325.0,,1735003.0,,2017-07-12 18:20:45,2019-06-16 13:03:24,How to add if condition in a TensorFlow graph?,<python><if-statement><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35833011
34877523,1,34881060,,2016-01-19 13:01:41,,70,44838,"<p>I've seen <code>tf.identity</code> used in a few places, such as the official CIFAR-10 tutorial and the batch-normalization implementation on stackoverflow, but I don't see why it's necessary.</p>

<p>What's it used for? Can anyone give a use case or two?</p>

<p>One proposed answer is that it can be used for transfer between the CPU and GPU. This is not clear to me. Extension to the question, based on <a href=""https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py"" rel=""noreferrer"">this</a>: <code>loss = tower_loss(scope)</code> is under the GPU block, which suggests to me that all operators defined in <code>tower_loss</code> are mapped to the GPU. Then, at the end of <code>tower_loss</code>, we see <code>total_loss = tf.identity(total_loss)</code> before it's returned. Why? What would be the flaw with not using <code>tf.identity</code> here?</p>
",1441121.0,,249341.0,,2019-01-12 04:11:02,2019-05-24 13:51:35,"In TensorFlow, what is tf.identity used for?",<python><tensorflow>,8,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34877523
41402409,1,41530102,,2016-12-30 20:37:30,,70,150145,"<p>I've tried tensorflow on both cuda 7.5 and 8.0, w/o cudnn (my GPU is old, cudnn doesn't support it). </p>

<p>When I execute <code>device_lib.list_local_devices()</code>, there is no gpu in the output. Theano sees my gpu, and works fine with it, and examples in /usr/share/cuda/samples work fine as well. </p>

<p>I installed tensorflow through pip install. Is my gpu too old for tf to support it? gtx 460</p>
",7091875.0,,,,,2023-05-02 11:37:42,Tensorflow doesn't seem to see my gpu,<tensorflow>,10,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41402409
44560549,1,44563055,,2017-06-15 06:51:27,,69,69282,"<p>I'm trying to train a network with an unbalanced data. I have A (198 samples), B (436 samples), C (710 samples), D (272 samples) and I have read about the &quot;weighted_cross_entropy_with_logits&quot; but all the examples I found are for binary classification so I'm not very confident in how to set those weights.</p>
<p>Total samples: 1616</p>
<p>A_weight: 198/1616 = 0.12?</p>
<p>The idea behind, if I understood, is to penalize the errors of the majority class and value more positively the hits in the minority one, right?</p>
<p>My piece of code:</p>
<pre><code>weights = tf.constant([0.12, 0.26, 0.43, 0.17])
cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=pred, targets=y, pos_weight=weights))
</code></pre>
<p>I have read <a href=""https://stackoverflow.com/questions/40698709/tensorflow-interpretation-of-weight-in-weighted-cross-entropy"">this one</a> and others examples with binary classification but still not very clear.</p>
",1405024.0,,11107541.0,,2022-12-29 03:34:01,2022-12-29 03:34:01,Unbalanced data and weighted cross entropy,<python><machine-learning><tensorflow><deep-learning>,3,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44560549
37304461,1,37359199,,2016-05-18 15:48:30,,69,75215,"<p>I've run several training sessions with different graphs in TensorFlow. The summaries I set up show interesting results in the training and validation. Now, I'd like to take the data I've saved in the summary logs and perform some statistical analysis and in general plot and look at the summary data in different ways. Is there any existing way to easily access this data?</p>

<p>More specifically, is there any built in way to read a TFEvent record back into Python?</p>

<p>If there is no simple way to do this, <a href=""https://www.tensorflow.org/versions/r0.8/how_tos/tool_developers/index.html#protocol-buffers"" rel=""noreferrer"">TensorFlow states that all its file formats are protobuf files</a>. From my understanding of protobufs (which is limited), I think I'd be able to extract this data if I have the TFEvent protocol specification. Is there an easy way to get ahold of this? Thank you much.</p>
",1191087.0,,,,,2021-12-01 13:11:18,TensorFlow - Importing data from a TensorBoard TFEvent file?,<python><tensorflow><tensorboard>,9,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37304461
33765336,1,33768179,,2015-11-17 19:24:07,,69,77702,"<p>When working with the default global graph, is it possible to remove nodes after they've been added, or alternatively to reset the default graph to empty? When working with TF interactively in IPython, I find myself having to restart the kernel repeatedly. I would like to be able to experiment with graphs more easily if possible.</p>
",2615676.0,,249341.0,,2017-04-29 20:25:33,2020-04-16 16:21:57,Remove nodes from graph or reset entire default graph,<python><tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33765336
33712178,1,33713196,,2015-11-14 19:01:58,,68,69895,"<p>I'm using TensorFlow and I modified the <a href=""http://tensorflow.org/tutorials/mnist/pros/index.md"">tutorial</a> example to take my RGB images.</p>

<p>The algorithm works flawlessly out of the box on the new image set, until suddenly (still converging, it's around 92% accuracy usually), it crashes with the error that ReluGrad received non-finite values. Debugging shows that nothing unusual happens with the numbers until very suddenly, for unknown reason, the error is thrown. Adding</p>

<pre><code>print ""max W vales: %g %g %g %g""%(tf.reduce_max(tf.abs(W_conv1)).eval(),tf.reduce_max(tf.abs(W_conv2)).eval(),tf.reduce_max(tf.abs(W_fc1)).eval(),tf.reduce_max(tf.abs(W_fc2)).eval())
print ""max b vales: %g %g %g %g""%(tf.reduce_max(tf.abs(b_conv1)).eval(),tf.reduce_max(tf.abs(b_conv2)).eval(),tf.reduce_max(tf.abs(b_fc1)).eval(),tf.reduce_max(tf.abs(b_fc2)).eval())
</code></pre>

<p>as debug code to each loop, yields the following output:</p>

<pre><code>Step 8600
max W vales: 0.759422 0.295087 0.344725 0.583884
max b vales: 0.110509 0.111748 0.115327 0.124324
Step 8601
max W vales: 0.75947 0.295084 0.344723 0.583893
max b vales: 0.110516 0.111753 0.115322 0.124332
Step 8602
max W vales: 0.759521 0.295101 0.34472 0.5839
max b vales: 0.110521 0.111747 0.115312 0.124365
Step 8603
max W vales: -3.40282e+38 -3.40282e+38 -3.40282e+38 -3.40282e+38
max b vales: -3.40282e+38 -3.40282e+38 -3.40282e+38 -3.40282e+38
</code></pre>

<p>Since none of my values is very high, the only way a NaN can happen is by a badly handled 0/0, but since this tutorial code doesn't do any divisions or similar operations, I see no other explanation than that this comes from the internal TF code. </p>

<p>I'm clueless on what to do with this. Any suggestions? The algorithm is converging nicely, its accuracy on my validation set was steadily climbing and just reached 92.5% at iteration 8600.</p>
",1111929.0,,1090562.0,,2015-11-14 21:41:00,2020-11-09 23:17:21,Tensorflow NaN bug?,<nan><tensorflow>,15,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33712178
38189119,1,55028643,,2016-07-04 16:33:32,,68,52150,"<p>The official way to visualize a TensorFlow graph is with TensorBoard, but sometimes I just want a quick look at the graph when I'm working in Jupyter.</p>

<p>Is there a quick solution, ideally based on TensorFlow tools, or standard SciPy packages (like matplotlib), but if necessary based on 3rd party libraries?</p>
",38626.0,,,,,2021-12-05 22:09:37,Simple way to visualize a TensorFlow graph in Jupyter?,<tensorflow><jupyter><graph-visualization><tensorboard>,8,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38189119
35551326,1,35556485,,2016-02-22 10:31:45,,68,81912,"<p>Is there a way to change the default port (<code>6006</code>) on TensorBoard so we could open multiple TensorBoards? Maybe an option like <code>--port=&quot;8008&quot;</code>?</p>
",4190832.0,,5524090.0,,2020-11-05 14:22:05,2020-11-05 14:22:05,Tensorflow Tensorboard default port,<python><tensorflow><tensorboard>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/35551326
47220595,1,47220765,,2017-11-10 10:25:06,,67,36078,"<p>I've hacked a deep feed forward NN from scratch in R, and it seems more stable with ""hard sigmoid"" activations - max(0,min(1,x)) - than ReLU. Trying to port it to TensorFlow, and noticed that they don't have this activation function built in, only relu6, which uses an upper cutoff at 6. Is there a reason for this? 
(I realize that you could do relu6(x*6)/6, but if the TF guys put the 6 there for a good reason, I'd like to know.)
Also, I'd like to know if others have explosion problems with ReLU in feed forward nets (I'm aware of RNN issues).</p>
",8918908.0,,,,,2020-10-02 16:45:17,Why the 6 in relu6?,<tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47220595
42785026,1,42932979,,2017-03-14 11:41:17,,67,37022,"<p>Is there any advantage in using <code>tf.nn.*</code> over <code>tf.layers.*</code>?</p>

<p>Most of the examples in the doc use <code>tf.nn.conv2d</code>, for instance, but it is not clear why they do so.</p>
",326849.0,,,,,2019-10-27 01:54:30,tf.nn.conv2d vs tf.layers.conv2d,<python><tensorflow>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42785026
38286717,1,38287616,,2016-07-09 22:00:33,,67,79585,"<p>I am playing with a ANN which is part of Udacity DeepLearning course.</p>

<p>I have an assignment which involves introducing generalization to the network with one hidden ReLU layer using L2 loss. I wonder how to properly introduce it so that ALL weights are penalized, not only weights of the output layer.</p>

<p>Code for network <em>without</em> generalization is at the bottom of the post (code to actually run the training is out of the scope of the question).</p>

<p>Obvious way of introducing the L2 is to replace the loss calculation with something like this (if beta is 0.01):</p>

<pre><code>loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(out_layer, tf_train_labels) + 0.01*tf.nn.l2_loss(out_weights))
</code></pre>

<p>But in such case it will take into account values of output layer's weights. I am not sure, how do we properly penalize the weights which come INTO the hidden ReLU layer. Is it needed at all or introducing penalization of output layer will somehow keep the hidden weights in check also?</p>

<pre><code>#some importing
from __future__ import print_function
import numpy as np
import tensorflow as tf
from six.moves import cPickle as pickle
from six.moves import range

#loading data
pickle_file = '/home/maxkhk/Documents/Udacity/DeepLearningCourse/SourceCode/tensorflow/examples/udacity/notMNIST.pickle'

with open(pickle_file, 'rb') as f:
  save = pickle.load(f)
  train_dataset = save['train_dataset']
  train_labels = save['train_labels']
  valid_dataset = save['valid_dataset']
  valid_labels = save['valid_labels']
  test_dataset = save['test_dataset']
  test_labels = save['test_labels']
  del save  # hint to help gc free up memory
  print('Training set', train_dataset.shape, train_labels.shape)
  print('Validation set', valid_dataset.shape, valid_labels.shape)
  print('Test set', test_dataset.shape, test_labels.shape)


#prepare data to have right format for tensorflow
#i.e. data is flat matrix, labels are onehot

image_size = 28
num_labels = 10

def reformat(dataset, labels):
  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)
  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]
  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)
  return dataset, labels
train_dataset, train_labels = reformat(train_dataset, train_labels)
valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)
test_dataset, test_labels = reformat(test_dataset, test_labels)
print('Training set', train_dataset.shape, train_labels.shape)
print('Validation set', valid_dataset.shape, valid_labels.shape)
print('Test set', test_dataset.shape, test_labels.shape)


#now is the interesting part - we are building a network with
#one hidden ReLU layer and out usual output linear layer

#we are going to use SGD so here is our size of batch
batch_size = 128

#building tensorflow graph
graph = tf.Graph()
with graph.as_default():
      # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size))
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))
  tf_valid_dataset = tf.constant(valid_dataset)
  tf_test_dataset = tf.constant(test_dataset)

  #now let's build our new hidden layer
  #that's how many hidden neurons we want
  num_hidden_neurons = 1024
  #its weights
  hidden_weights = tf.Variable(
    tf.truncated_normal([image_size * image_size, num_hidden_neurons]))
  hidden_biases = tf.Variable(tf.zeros([num_hidden_neurons]))

  #now the layer itself. It multiplies data by weights, adds biases
  #and takes ReLU over result
  hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)

  #time to go for output linear layer
  #out weights connect hidden neurons to output labels
  #biases are added to output labels  
  out_weights = tf.Variable(
    tf.truncated_normal([num_hidden_neurons, num_labels]))  

  out_biases = tf.Variable(tf.zeros([num_labels]))  

  #compute output  
  out_layer = tf.matmul(hidden_layer,out_weights) + out_biases
  #our real output is a softmax of prior result
  #and we also compute its cross-entropy to get our loss
  loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(out_layer, tf_train_labels))

  #now we just minimize this loss to actually train the network
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

  #nice, now let's calculate the predictions on each dataset for evaluating the
  #performance so far
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(out_layer)
  valid_relu = tf.nn.relu(  tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)
  valid_prediction = tf.nn.softmax( tf.matmul(valid_relu, out_weights) + out_biases) 

  test_relu = tf.nn.relu( tf.matmul( tf_test_dataset, hidden_weights) + hidden_biases)
  test_prediction = tf.nn.softmax(tf.matmul(test_relu, out_weights) + out_biases)
</code></pre>
",3633250.0,,,,,2020-03-19 11:10:56,"TensorFlow - regularization with L2 loss, how to apply to all weights, not just last one?",<machine-learning><neural-network><tensorflow><deep-learning><regularized>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38286717
35953210,1,35963479,,2016-03-12 02:55:20,,67,98575,"<p>I have just reinstalled latest tensorflow on ubuntu:</p>

<pre><code>$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
[sudo] password for ubuntu: 
The directory '/home/ubuntu/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/home/ubuntu/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Collecting tensorflow==0.7.1 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
  Downloading https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl (13.8MB)
    100% |████████████████████████████████| 13.8MB 32kB/s 
Requirement already up-to-date: six&gt;=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.7.1)
Requirement already up-to-date: protobuf==3.0.0b2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.7.1)
Requirement already up-to-date: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.7.1)
Requirement already up-to-date: numpy&gt;=1.8.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.7.1)
Requirement already up-to-date: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf==3.0.0b2-&gt;tensorflow==0.7.1)
Installing collected packages: tensorflow
  Found existing installation: tensorflow 0.7.1
    Uninstalling tensorflow-0.7.1:
      Successfully uninstalled tensorflow-0.7.1
Successfully installed tensorflow-0.7.1
</code></pre>

<p>When following the directions to test it fails with <strong>cannot import name pywrap_tensorflow</strong>:</p>

<pre><code>$ ipython

/git/tensorflow/tensorflow/__init__.py in &lt;module&gt;()
     21 from __future__ import print_function
     22 
---&gt; 23 from tensorflow.python import *

/git/tensorflow/tensorflow/python/__init__.py in &lt;module&gt;()
     43 _default_dlopen_flags = sys.getdlopenflags()
     44 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---&gt; 45 from tensorflow.python import pywrap_tensorflow
     46 sys.setdlopenflags(_default_dlopen_flags)
     47 

ImportError: cannot import name pywrap_tensorflow
</code></pre>

<p>Is there an additional change needed to my python or ubuntu/bash environment?</p>
",1056563.0,,5703820.0,,2018-08-18 12:48:02,2021-03-15 12:12:02,Error running basic tensorflow example,<python><ubuntu><tensorflow>,11,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35953210
49919300,1,49919516,,2018-04-19 10:53:33,,66,53926,"<p>I'm new into the AI world, I've start doing some stuff using Python &amp; OpenCV for face detection and so on. I know that with the implementation of some algorithms I can develop AI system using Python &amp; OpenCV. So my question is : What is the position of Tensorflow here? Can I say Tensorflow is an alternative to OpenCV? as I can say Python is an alternative programming language to Java (for example).</p>
",1739137.0,,,,,2018-10-04 15:53:32,Tensorflow vs OpenCV,<opencv><tensorflow><artificial-intelligence>,1,0,0.0,2018-04-20 20:18:11,,CC BY-SA 3.0,https://stackoverflow.com/q/49919300
33849617,1,33862568,,2015-11-21 22:57:47,,65,71772,"<p>I have training data that is a directory of jpeg images and a corresponding text file containing the file name and the associated category label.  I am trying to convert this training data into a tfrecords file as described in the tensorflow documentation. I have spent quite some time trying to get this to work but there are no examples in tensorflow that demonstrate how to use any of the readers to read in jpeg files and add them to a tfrecord using tfrecordwriter</p>
",5590385.0,,7446770.0,,2020-05-18 20:11:24,2022-01-18 15:03:18,How do I convert a directory of jpeg images to TFRecords file in tensorflow?,<tensorflow><tfrecord>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33849617
40782271,1,40782339,,2016-11-24 09:20:03,,65,137552,"<p>I have installed tensorflow version r0.11. </p>

<p>In my file name <code>cartpole.py</code> I have imported <code>tensorflow</code>:</p>

<pre><code> import tensorflow as tf  
</code></pre>

<p>and use it:</p>

<pre><code> tf.reset_default_graph()
</code></pre>

<p>Trying to run my project in PyCharm I get this error:</p>

<pre><code>in &lt;module&gt;
tf.reset_default_graph()
AttributeError: module 'tensorflow' has no attribute 'reset_default_graph'
</code></pre>

<p>How can I fix this error?</p>
",7204252.0,,18665.0,,2016-11-27 10:41:35,2022-11-07 07:36:49,AttributeError: module 'tensorflow' has no attribute 'reset_default_graph',<python><tensorflow><pycharm>,12,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40782271
55870127,1,55872941,,2019-04-26 14:53:01,,65,261529,"<p>I am trying to train my own custom object detector using Tensorflow Object-Detection-API </p>

<p>I installed the tensorflow using ""pip install tensorflow"" in my google compute engine. Then I followed all the instructions on this site: <a href=""https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html"" rel=""noreferrer"">https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html</a> </p>

<p>When I try to use train.py I am getting this error message:</p>

<blockquote>
  <p>Traceback (most recent call last):
  File ""train.py"", line 49, in 
   from object_detection.builders import dataset_builder
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1->py3.6.egg/object_detection/builders/dataset_builder.py"", line 27, in 
  from object_detection.data_decoders import tf_example_decoder
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/data_decoders/tf_example_decoder.py"", line 27, in 
      slim_example_decoder = tf.contrib.slim.tfexample_decoder
  AttributeError: module 'tensorflow' has no attribute 'contrib'</p>
</blockquote>

<p>Also I am getting different results when I try to learn version of tensorflow.</p>

<blockquote>
  <p>python3 -c 'import tensorflow as tf; print(tf.<strong>version</strong>)' : 2.0.0-dev20190422</p>
</blockquote>

<p>and when I use</p>

<blockquote>
  <p>pip3 show tensorflow: </p>
  
  <p>Name: tensorflow
  Version: 1.13.1
  Summary: TensorFlow is an open source machine learning framework for everyone.
  Home-page: <a href=""https://www.tensorflow.org/"" rel=""noreferrer"">https://www.tensorflow.org/</a>
  Author: Google Inc.
  Author-email: opensource@google.com
  License: Apache 2.0
  Location: /usr/local/lib/python3.6/dist-packages
  Requires: gast, astor, absl-py, tensorflow-estimator, keras-preprocessing, grpcio, six, keras-applications, wheel, numpy, tensorboard, protobuf, termcolor
  Required-by: </p>
</blockquote>

<pre><code>    sudo python3 train.py --logtostderr --train_dir=training/ -- 
    pipeline_config_path=training/ssd_inception_v2_coco.config
</code></pre>

<p>What should I do to solve this problem? I couldn't find anything about this error message except this: <a href=""https://stackoverflow.com/questions/38238192/tensorflow-module-object-has-no-attribute-contrib"">tensorflow &#39;module&#39; object has no attribute &#39;contrib&#39;</a></p>
",10025471.0,,,,,2023-01-13 09:44:30,Module 'tensorflow' has no attribute 'contrib',<tensorflow>,10,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55870127
50737192,1,50737863,,2018-06-07 09:03:22,,65,96861,"<p>Let's say I have defined a dataset in this way:</p>

<pre><code>filename_dataset = tf.data.Dataset.list_files(""{}/*.png"".format(dataset))
</code></pre>

<p>how can I get the number of elements that are inside the dataset (hence, the number of single elements that compose an epoch)?</p>

<p>I know that <code>tf.data.Dataset</code> already knows the dimension of the dataset, because the <code>repeat()</code> method allows repeating the input pipeline for a specified number of epochs. So it must be a way to get this information.</p>
",2891324.0,,6941952.0,,2022-05-11 05:24:59,2022-12-20 08:57:06,tf.data.Dataset: how to get the dataset size (number of elements in an epoch)?,<python><python-3.x><tensorflow><tensorflow-datasets>,18,9,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50737192
37085430,1,37085824,,2016-05-07 06:47:17,,65,114723,"<p>I define a tensor like this:</p>

<p><code>x = tf.get_variable(""x"", [100])</code></p>

<p>But when I try to print shape of tensor :</p>

<p><code>print( tf.shape(x) )</code></p>

<p>I get <strong>Tensor(""Shape:0"", shape=(1,), dtype=int32)</strong>, why the result of output should not be shape=(100)</p>
",1303432.0,,2956066.0,,2017-12-11 21:43:07,2020-02-14 10:46:11,tf.shape() get wrong shape in tensorflow,<python><python-3.x><tensorflow><tensor>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37085430
35336648,1,35337827,,2016-02-11 10:24:57,,65,89820,"<p>The graph object in Tensorflow has a method called ""get_tensor_by_name(name)"". Is there anyway to get a list of valid tensor names?</p>

<p>If not, does anyone know the valid names for the pretrained model inception-v3 <a href=""https://www.tensorflow.org/versions/v0.6.0/tutorials/image_recognition/index.html"">from here</a>? From their example, pool_3, is one valid tensor but a list of all of them would be nice. I looked at <a href=""http://arxiv.org/abs/1512.00567"">the paper referred to</a> and some of the layers seems to correspond to the sizes in table 1 but not all of them.</p>
",2372357.0,,,,,2019-11-13 22:11:04,List of tensor names in graph in Tensorflow,<python><tensorflow>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35336648
37096225,1,37096395,,2016-05-08 04:31:00,,64,41487,"<p>In <a href=""https://www.tensorflow.org/versions/r0.8/resources/faq.html#tensor-shapes"">TensorFlow FAQ</a>, it says:</p>

<blockquote>
  <p>In TensorFlow, a tensor has both a static (inferred) shape and a
  dynamic (true) shape. The static shape can be read using the
  tf.Tensor.get_shape() method: this shape is inferred from the
  operations that were used to create the tensor, and may be partially
  complete. If the static shape is not fully defined, the dynamic shape
  of a Tensor t can be determined by evaluating tf.shape(t).</p>
</blockquote>

<p>But I still cannot fully understand the relationship between static shape and dynamic shape. Are there any examples showing their differences? Thanks.</p>
",4794308.0,,2952723.0,,2016-05-08 04:56:11,2020-09-04 10:09:52,How to understand static shape and dynamic shape in TensorFlow?,<tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37096225
51306862,1,51307381,,2018-07-12 13:23:55,,64,286109,"<p>How do I use <strong>TensorFlow GPU</strong> version instead of <strong>CPU</strong> version in Python 3.6 x64?</p>
<pre><code>import tensorflow as tf
</code></pre>
<p>Python is using my <strong>CPU</strong> for calculations. <br/>
I can notice it because I have an error:</p>
<blockquote>
<p>Your CPU supports instructions that this TensorFlow binary was not
compiled to use: AVX2</p>
</blockquote>
<p>I have installed tensorflow and tensorflow-gpu.</p>
<p>How do I switch to GPU version?</p>
",9822809.0,,10908375.0,,2020-07-25 12:38:55,2023-02-20 18:44:06,How do I use TensorFlow GPU?,<python><tensorflow><gpu>,10,7,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51306862
42326748,1,42652258,,2017-02-19 11:36:37,,63,120483,"<blockquote>
  <p>Note : this question was initially <a href=""https://github.com/tensorflow/tensorflow/issues/7648#issuecomment-280866214"" rel=""noreferrer"">asked on github</a>, but it was asked to be here instead</p>
</blockquote>

<p>I'm having trouble running tensorflow on gpu, and it does not seems to be the usual cuda's configuration problem, because everything seems to indicate cuda is properly setup.</p>

<p>The main symptom: when running tensorflow, my gpu is not detected (<a href=""https://gist.github.com/oelmekki/cafda411bf5c2ea695d984fa98e0995b"" rel=""noreferrer"">the code being run</a>, and <a href=""https://gist.github.com/oelmekki/77235c6b0dde99b3438f190eb557f40f"" rel=""noreferrer"">its output</a>).</p>

<p>What differs from usual issues is that cuda seems properly installed and running <code>./deviceQuery</code> from cuda samples is successful (<a href=""https://gist.github.com/oelmekki/fe65a15daec45aa90ec33b10b51d3aae"" rel=""noreferrer"">output</a>).</p>

<p>I have two graphical cards:</p>

<ul>
<li>an old GTX 650 used for my monitors (I don't want to use that one with tensorflow)</li>
<li>a GTX 1060 that I want to dedicate to tensorflow</li>
</ul>

<p>I use:</p>

<ul>
<li><a href=""https://pypi.python.org/pypi/tensorflow"" rel=""noreferrer"">tensorflow-1.0.0</a></li>
<li>cuda-8.0 (<a href=""https://gist.github.com/oelmekki/6e5e9d7d1ea871e1d73efae307efe9ce"" rel=""noreferrer"">ls -l /usr/local/cuda/lib64/libcud*</a>)</li>
<li>cudnn-5.1.10</li>
<li>python-2.7.12</li>
<li>nvidia-drivers-375.26 (this was installed by cuda and replaced my distro driver package)</li>
</ul>

<p>I've tried:</p>

<ul>
<li>adding <code>/usr/local/cuda/bin/</code> to <code>$PATH</code></li>
<li>forcing gpu placement in tensorflow script using <code>with tf.device('/gpu:1'):</code> (and <code>with tf.device('/gpu:0'):</code> when it failed, for good measure)</li>
<li>whitelisting the gpu I wanted to use with <code>CUDA_VISIBLE_DEVICES</code>, in case the presence of my old unsupported card did cause problems</li>
<li>running the script with sudo (because why not)</li>
</ul>

<p>Here are the outputs of <a href=""https://gist.github.com/oelmekki/7bdcb5cc2f791cea561a60f8b21e87b5"" rel=""noreferrer"">nvidia-smi</a> and <a href=""https://gist.github.com/oelmekki/b83a5a0a72e8924aeb44b70b3598f9b4"" rel=""noreferrer"">nvidia-debugdump -l</a>, in case it's useful.</p>

<p>At this point, I feel like I have followed all the breadcrumbs and have no idea what I could try else. I'm not even sure if I'm contemplating a bug or a configuration problem. Any advice about how to debug this would be greatly appreciated. Thanks!</p>

<p><strong>Update</strong>: with the help of Yaroslav on github, I gathered more debugging info by raising log level, but it doesn't seem to say much about the device selection : <a href=""https://gist.github.com/oelmekki/760a37ca50bf58d4f03f46d104b798bb"" rel=""noreferrer"">https://gist.github.com/oelmekki/760a37ca50bf58d4f03f46d104b798bb</a></p>

<p><strong>Update 2</strong>: Using theano detects gpu correctly, but interestingly it complains about cuDNN being too recent, then fallback to cpu (<a href=""https://gist.github.com/oelmekki/34b6e41a0ff2b17ff9f39bcf56d0635a"" rel=""noreferrer"">code ran</a>, <a href=""https://gist.github.com/oelmekki/11626d6b34058337dae64f1915e5a9fe"" rel=""noreferrer"">output</a>). Maybe that could be the problem with tensorflow as well?</p>
",1268771.0,,1268771.0,,2017-02-19 15:48:53,2021-07-15 12:00:50,"tensorflow on GPU: no known devices, despite cuda's deviceQuery returning a ""PASS"" result",<tensorflow>,8,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42326748
33634008,1,33634101,,2015-11-10 15:48:57,,62,160561,"<p>How do I install TensorFlow's tensorboard?</p>
",363455.0,,3924118.0,,2018-07-02 16:25:03,2019-12-19 19:17:41,How do I install TensorFlow's tensorboard?,<tensorflow><tensorboard>,12,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/33634008
34685947,1,34686952,,2016-01-08 20:58:51,,62,38115,"<p>I feel embarrassed asking this, but how do you adjust a single value within a tensor? Suppose you want to add '1' to only one value within your tensor?</p>

<p>Doing it by indexing doesn't work:</p>

<pre><code>TypeError: 'Tensor' object does not support item assignment
</code></pre>

<p>One approach would be to build an identically shaped tensor of 0's. And then adjusting a 1 at the position you want. Then you would add the two tensors together. Again this runs into the same problem as before.</p>

<p>I've read through the API docs several times and can't seem to figure out how to do this. Thanks in advance! </p>
",5451067.0,,,,,2021-12-07 11:53:52,Adjust Single Value within Tensor -- TensorFlow,<indexing><addition><tensorflow>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34685947
44906317,1,46901051,,2017-07-04 12:42:38,,61,36665,"<p>I have successfully trained an object detection model with TensorFlow with the sample configurations given here: <a href=""https://github.com/tensorflow/models/tree/master/object_detection/samples/configs"" rel=""noreferrer"">https://github.com/tensorflow/models/tree/master/object_detection/samples/configs</a></p>

<p>Now I want to fine tune my configuration to get better results. One of the promising options I see in there is ""data_augmentation_options"" under ""train_config"". Currently, it looks like this: </p>

<pre><code>train_config: {
  batch_size: 1
  ...
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}
</code></pre>

<p>Are there other options to do random scaling, cropping or tweaking of brightness?</p>
",2730201.0,,,,,2021-07-12 18:43:46,What are possible values for data_augmentation_options in the TensorFlow Object Detection pipeline configuration?,<tensorflow><configuration><object-detection>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44906317
34945554,1,34948185,,2016-01-22 11:22:10,,61,33018,"<p>I am wondering if there is a way that I can use different learning rate for different layers like what is in Caffe. I am trying to modify a pre-trained model and use it for other tasks. What I want is to speed up the training for new added layers and keep the trained layers at low learning rate in order to prevent them from being distorted. for example, I have a 5-conv-layer pre-trained model. Now I add a new conv layer and fine tune it. The first 5 layers would have learning rate of 0.00001 and the last one would have 0.001. Any idea how to achieve this?</p>
",5825952.0,,,,,2022-10-13 11:58:01,How to set layer-wise learning rate in Tensorflow?,<python><deep-learning><tensorflow>,7,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34945554
40069883,1,41024999,,2016-10-16 11:47:58,,61,135657,"<p>I want to specify the gpu to run my process. And I set it as follows:</p>

<pre><code>import tensorflow as tf
with tf.device('/gpu:0'):
    a = tf.constant(3.0)
with tf.Session() as sess:
    while True:
        print sess.run(a)
</code></pre>

<p>However it still allocate memory in both my two gpus. </p>

<pre><code>|    0      7479    C   python                         5437MiB 
|    1      7479    C   python                         5437MiB 
</code></pre>
",4696856.0,,3323084.0,,2017-07-08 12:10:05,2022-12-13 17:32:24,How to set specific gpu in tensorflow?,<tensorflow>,9,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40069883
33616094,1,33618580,,2015-11-09 18:51:41,,61,22701,"<p>I haven't seen anything about Windows compatibility -- is this on the way or currently available somewhere if I put forth some effort? (I have a Mac and an Ubuntu box but the Windows machine is the one with the discrete graphics card that I currently use with theano).</p>
",4389216.0,,472495.0,,2016-12-05 08:19:52,2020-01-28 09:11:25,Is Tensorflow compatible with a Windows workflow?,<python><windows><tensorflow>,7,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33616094
33622613,1,33635645,,2015-11-10 03:56:32,,60,155303,"<p>when I try to install TensorFlow by cloning from Git, I run into the error &quot;no module named copyreg,&quot; so I tried installing using a <a href=""http://pypi.python.org/pypi/virtualenv"" rel=""nofollow noreferrer"">virtualenv</a>. However, I then run into this error:</p>
<pre class=""lang-none prettyprint-override""><code>pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl

tensorflow-0.5.0-py2-none-any.whl is not a supported wheel on this platform.
</code></pre>
<p>I don't see this under the common problems section.</p>
<p>I am using <a href=""https://en.wikipedia.org/wiki/OS_X_Yosemite"" rel=""nofollow noreferrer"">OS X v10.10.5</a> (Yosemite) and Python 3.4.3, but I also have Python 2.7 (I am unsure if pip differentiates between these or how to switch between them).</p>
",3775886.0,,63550.0,,2022-02-05 18:30:27,2022-11-07 13:13:32,Tensorflow installation error: not a supported wheel on this platform,<installation><pip><python-wheel><tensorflow>,15,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/33622613
55224016,1,55238537,,2019-03-18 14:46:31,,59,180796,"<p>I have installed Cuda 10.1 and cudnn on Ubuntu 18.04 and it seems to be installed properly as type nvcc and nvidia-smi, I get proper response:</p>
<pre><code>user:~$ nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:17_PST_2019
Cuda compilation tools, release 10.1, V10.1.105
user:~$ nvidia-smi 
Mon Mar 18 14:36:47 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.43       Driver Version: 418.43       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Quadro K5200        Off  | 00000000:03:00.0  On |                  Off |
| 26%   39C    P8    14W / 150W |    225MiB /  8118MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1538      G   /usr/lib/xorg/Xorg                            32MiB |
|    0      1583      G   /usr/bin/gnome-shell                           5MiB |
|    0      3008      G   /usr/lib/xorg/Xorg                           100MiB |
|    0      3120      G   /usr/bin/gnome-shell                          82MiB |
+-----------------------------------------------------------------------------+
</code></pre>
<p>I have installed tensorflow using:
<code>user:~$ sudo pip3 install --upgrade tensorflow-gpu</code></p>
<pre><code>The directory '/home/amin/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/home/amin/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Requirement already up-to-date: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (1.13.1)
Requirement already satisfied, skipping upgrade: keras-applications&gt;=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)
Requirement already satisfied, skipping upgrade: protobuf&gt;=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.6.1)
Requirement already satisfied, skipping upgrade: wheel&gt;=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.32.3)
Requirement already satisfied, skipping upgrade: absl-py&gt;=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.0)
Requirement already satisfied, skipping upgrade: keras-preprocessing&gt;=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)
Requirement already satisfied, skipping upgrade: gast&gt;=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)
Requirement already satisfied, skipping upgrade: termcolor&gt;=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)
Requirement already satisfied, skipping upgrade: grpcio&gt;=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.0)
Requirement already satisfied, skipping upgrade: tensorflow-estimator&lt;1.14.0rc0,&gt;=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)
Requirement already satisfied, skipping upgrade: six&gt;=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow-gpu) (1.11.0)
Requirement already satisfied, skipping upgrade: numpy&gt;=1.13.3 in /usr/lib/python3/dist-packages (from tensorflow-gpu) (1.13.3)
Requirement already satisfied, skipping upgrade: astor&gt;=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)
Requirement already satisfied, skipping upgrade: tensorboard&lt;1.14.0,&gt;=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)
Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications&gt;=1.0.6-&gt;tensorflow-gpu) (2.9.0)
Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&gt;=3.6.1-&gt;tensorflow-gpu) (40.6.3)
Requirement already satisfied, skipping upgrade: mock&gt;=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator&lt;1.14.0rc0,&gt;=1.13.0-&gt;tensorflow-gpu) (2.0.0)
Requirement already satisfied, skipping upgrade: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;1.14.0,&gt;=1.13.0-&gt;tensorflow-gpu) (0.14.1)
Requirement already satisfied, skipping upgrade: markdown&gt;=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard&lt;1.14.0,&gt;=1.13.0-&gt;tensorflow-gpu) (3.0.1)
Requirement already satisfied, skipping upgrade: pbr&gt;=0.11 in /usr/local/lib/python3.6/dist-packages (from mock&gt;=2.0.0-&gt;tensorflow-estimator&lt;1.14.0rc0,&gt;=1.13.0-&gt;tensorflow-gpu) (5.1.1)
</code></pre>
<p>However when I am trying to import tensorflow I am getting error about  libcublas.so.10.0:</p>
<pre><code>user:~$ python3
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import tensorflow as tf
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py&quot;, line 58, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 28, in &lt;module&gt;
    _pywrap_tensorflow_internal = swig_import_helper()
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File &quot;/usr/lib/python3.6/imp.py&quot;, line 243, in load_module
    return load_dynamic(name, filename, file)
  File &quot;/usr/lib/python3.6/imp.py&quot;, line 343, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py&quot;, line 24, in &lt;module&gt;
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py&quot;, line 49, in &lt;module&gt;
    from tensorflow.python import pywrap_tensorflow
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py&quot;, line 74, in &lt;module&gt;
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py&quot;, line 58, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 28, in &lt;module&gt;
    _pywrap_tensorflow_internal = swig_import_helper()
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File &quot;/usr/lib/python3.6/imp.py&quot;, line 243, in load_module
    return load_dynamic(name, filename, file)
  File &quot;/usr/lib/python3.6/imp.py&quot;, line 343, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
</code></pre>
<p>What I am missing? and How can I resolve this?</p>
<p>Thanks</p>
",3468778.0,,7122272.0,,2020-11-30 12:33:31,2023-05-17 22:33:57,ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory,<tensorflow><ubuntu-18.04>,14,5,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55224016
50304156,1,51367588,,2018-05-12 08:09:09,,59,122562,"<p>Using ResNet50 pre-trained Weights I am trying to build a classifier. The code base is fully implemented in Keras high-level Tensorflow API. The complete code is posted in the below GitHub Link.</p>
<p>Source Code: <a href=""https://gist.github.com/Madhivarman/676650f71ec35a5f2802631fcfa0ff73"" rel=""noreferrer"">Classification Using RestNet50 Architecture</a></p>
<p>The file size of the pre-trained model is <strong>94.7mb</strong>.</p>
<p>I loaded the pre-trained file</p>
<pre><code>new_model = Sequential()

new_model.add(ResNet50(include_top=False,
                pooling='avg',
                weights=resnet_weight_paths))
</code></pre>
<p>and fit the model</p>
<pre><code>train_generator = data_generator.flow_from_directory(
    'path_to_the_training_set',
    target_size = (IMG_SIZE,IMG_SIZE),
    batch_size = 12,
    class_mode = 'categorical'
    )

validation_generator = data_generator.flow_from_directory(
    'path_to_the_validation_set',
    target_size = (IMG_SIZE,IMG_SIZE),
    class_mode = 'categorical'
    )

#compile the model

new_model.fit_generator(
    train_generator,
    steps_per_epoch = 3,
    validation_data = validation_generator,
    validation_steps = 1
)
</code></pre>
<p>and in the Training dataset, I have two folders dog and cat, each holder almost 10,000 images. When  I compiled the script, I get the following error</p>
<blockquote>
<p>Epoch 1/1 2018-05-12 13:04:45.847298: W
tensorflow/core/framework/allocator.cc:101] Allocation of 38535168
exceeds 10% of system memory. 2018-05-12 13:04:46.845021: W
tensorflow/core/framework/allocator.cc:101] Allocation of 37171200
exceeds 10% of system memory. 2018-05-12 13:04:47.552176: W
tensorflow/core/framework/allocator.cc:101] Allocation of 37171200
exceeds 10% of system memory. 2018-05-12 13:04:48.199240: W
tensorflow/core/framework/allocator.cc:101] Allocation of 37171200
exceeds 10% of system memory. 2018-05-12 13:04:48.918930: W
tensorflow/core/framework/allocator.cc:101] Allocation of 37171200
exceeds 10% of system memory. 2018-05-12 13:04:49.274137: W
tensorflow/core/framework/allocator.cc:101] Allocation of 19267584
exceeds 10% of system memory. 2018-05-12 13:04:49.647061: W
tensorflow/core/framework/allocator.cc:101] Allocation of 19267584
exceeds 10% of system memory. 2018-05-12 13:04:50.028839: W
tensorflow/core/framework/allocator.cc:101] Allocation of 19267584
exceeds 10% of system memory. 2018-05-12 13:04:50.413735: W
tensorflow/core/framework/allocator.cc:101] Allocation of 19267584
exceeds 10% of system memory.</p>
</blockquote>
<p>Any ideas to optimize the way to load the pre-trained model (or) get rid of this warning message?</p>
<p>Thanks!</p>
",9044016.0,,-1.0,,2020-06-20 09:12:55,2023-02-28 11:54:37,Tensorflow Allocation Memory: Allocation of 38535168 exceeds 10% of system memory,<python><tensorflow><memory><keras-layer><resnet>,10,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50304156
37901047,1,39440218,,2016-06-18 19:51:05,,59,43689,"<p>In MNIST LSTM examples, I don't understand what ""hidden layer"" means. Is it the imaginary-layer formed when you represent an unrolled RNN over time? </p>

<p>Why is the <code>num_units = 128</code> in most cases ? </p>
",6253584.0,,6253584.0,,2020-04-29 08:39:43,2021-10-27 14:42:16,What is num_units in tensorflow BasicLSTMCell?,<tensorflow><neural-network><lstm><recurrent-neural-network>,11,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/37901047
51278213,1,51281809,,2018-07-11 06:00:50,,58,108177,"<p>I am using some implementation for creating a face recognition which uses <a href=""https://drive.google.com/file/d/0B5MzpY9kBtDVZ2RpVDYwWmxoSUk"" rel=""noreferrer"">this file</a>:</p>

<p>""facenet.load_model(""20170512-110547/20170512-110547.pb"")""</p>

<p>What is the use of this file? I am not sure how it works.</p>

<p>console log :</p>

<pre><code>Model filename: 20170512-110547/20170512-110547.pb
distance = 0.72212267
</code></pre>

<p>Github link of the actual owner of the code
<a href=""https://github.com/arunmandal53/facematch"" rel=""noreferrer"">https://github.com/arunmandal53/facematch</a></p>
",7820277.0,,7820277.0,,2019-10-15 11:22:24,2021-06-17 12:39:35,What is the use of a *.pb file in TensorFlow and how does it work?,<tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51278213
39921607,1,39921608,,2016-10-07 16:08:19,,58,29230,"<p>Suppose you need to make an activation function which is not possible using only pre-defined tensorflow building-blocks, what can you do?</p>

<p>So in Tensorflow it is possible to make your own activation function. But it is quite complicated, you have to write it in C++ and recompile the whole of tensorflow <a href=""https://www.quora.com/Is-it-possible-to-add-new-activation-functions-to-TensorFlow-Theano-Torch-How"" rel=""noreferrer"">[1]</a> <a href=""https://www.tensorflow.org/versions/r0.11/how_tos/adding_an_op/index.html"" rel=""noreferrer"">[2]</a>.</p>

<p>Is there a simpler way?</p>
",3990607.0,,3990607.0,,2018-01-11 09:30:16,2018-06-12 06:53:01,How to make a custom activation function with only Python in Tensorflow?,<python><tensorflow><neural-network><deep-learning><activation-function>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39921607
37146614,1,37156491,,2016-05-10 18:48:09,,58,39196,"<p>Is there a way to plot both the training losses and validation losses on the <em>same</em> graph?</p>

<p>It's easy to have two separate scalar summaries for each of them individually, but this puts them on separate graphs. If both are displayed in the same graph it's much easier to see the gap between them and whether or not they have begin to diverge due to overfitting.</p>

<p>Is there a built in way to do this? If not, a work around way? Thank you much!</p>
",1191087.0,,4794308.0,,2017-11-07 21:34:22,2022-03-24 12:42:18,TensorBoard - Plot training and validation losses on the same graph?,<machine-learning><tensorflow><tensorboard>,9,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37146614
35298326,1,35304001,,2016-02-09 17:26:36,,57,45359,"<p>I am trying to implement <a href=""http://arxiv.org/abs/1406.2661"">Adversarial NN</a>, which requires to 'freeze' one or the other part of the graph during alternating training minibatches. I.e. there two sub-networks: G and D.</p>

<pre><code>G( Z ) -&gt;  Xz
D( X ) -&gt;  Y
</code></pre>

<p>where loss function of <code>G</code> depends on <code>D[G(Z)], D[X]</code>.</p>

<p>First I need to train parameters in D with all G parameters fixed, and then parameters in G with parameters in D fixed. Loss function in first case will be negative loss function in the second case and the update will have to apply to the parameters of whether first or second subnetwork.</p>

<p>I saw that tensorflow has <code>tf.stop_gradient</code> function. For purpose of training the D (downstream) subnetwork I can use this function to block the gradient flow to </p>

<pre><code> Z -&gt; [ G ] -&gt; tf.stop_gradient(Xz) -&gt; [ D ] -&gt; Y
</code></pre>

<p>The <code>tf.stop_gradient</code> is very succinctly annotated with no in-line example (and example <code>seq2seq.py</code> is too long and not that easy to read), but looks like it must be called during the graph creation. <strong>Does it imply that if I want to block/unblock gradient flow in alternating batches, I need to re-create and re-initialize the graph model?</strong> </p>

<p>Also it seems that <strong>one cannot block the gradient flowing through the G (upstream) network by means of <code>tf.stop_gradient</code>, right?</strong></p>

<p>As an alternative I saw that one can pass the list of variables to the optimizer call as <code>opt_op = opt.minimize(cost, &lt;list of variables&gt;)</code>, which would be an easy solution if one could get all variables in the scopes of each subnetwork. <strong>Can one get a <code>&lt;list of variables&gt;</code> for a tf.scope?</strong></p>
",1716733.0,,4105359.0,,2016-02-26 15:48:35,2017-02-06 05:38:44,"""freeze"" some variables/scopes in tensorflow: stop_gradient vs passing variables to minimize",<python><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35298326
48014769,1,48450068,,2017-12-28 21:46:58,,57,224034,"<p>I want to install TensorFlow following these instructions: <a href=""https://web.archive.org/web/20170627102751/https://www.tensorflow.org/versions/r0.12/get_started/os_setup#pip_installation"" rel=""noreferrer"">https://web.archive.org/web/20170627102751/https://www.tensorflow.org/versions/r0.12/get_started/os_setup#pip_installation</a></p>
<p>But when I try this code on terminal, it returns an error.</p>
<pre><code>$ sudo pip3 install --upgrade $TF_BINARY_URL
sudo: pip3: command not found
</code></pre>
<p>So I installed Homebrew and tried to uninstall and reinstall python3-pip, but didn't work.</p>
<pre><code>MakotonoMacBook-ea:~ makotomiyazaki$ brew uninstall python3-pip
Error: No such keg: /usr/local/Cellar/python3-pip

MakotonoMacBook-ea:~ makotomiyazaki$ brew install python3-pip
Error: No available formula with the name &quot;python3-pip&quot; 
==&gt; Searching for a previously deleted formula...
Warning: homebrew/core is shallow clone. To get complete history run:
  git -C &quot;$(brew --repo homebrew/core)&quot; fetch --unshallow
</code></pre>
<p>What should I do for getting pip3?
My OS is macOS High Sierra, and I have Python 3.6.2 already installed.</p>
<p>EDIT: I tried</p>
<pre><code>python3 -m pip
</code></pre>
<p>and what's returned was this:</p>
<pre><code>The directory '/Users/makotomiyazaki/Library/Caches/pip/http' or its 
parent directory is not owned by the current user and the cache has 
been disabled. Please check the permissions and owner of that 
directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/Users/makotomiyazaki/Library/Caches/pip' or its parent 
directory is not owned by the current user and caching wheels has been 
disabled. check the permissions and owner of that directory. If 
executing pip with sudo, you may want sudo's -H flag.
You must give at least one requirement to install (see &quot;pip help 
install&quot;)
</code></pre>
<p>I also tried which pip3, but just I don't know if it worked...</p>
<pre><code>MakotonoMacBook-ea:~ makotomiyazaki$ sudo which pip3 install --upgrade $TF_BINARY_URL
/usr/bin/install
</code></pre>
",8876025.0,,7503963.0,,2022-08-30 06:49:10,2023-04-05 12:10:33,pip3: command not found,<python><tensorflow><pip><homebrew>,7,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48014769
47529792,1,47529907,,2017-11-28 10:54:10,,56,225535,"<p>I am running the following pixel recurrent neural network (RNN) code using Python 3.6</p>

<pre><code>import os
import logging

import numpy as np
from tqdm import trange
import tensorflow as tf

from utils import *
from network import Network
from statistic import Statistic
</code></pre>

<p>However, there was an error:</p>

<pre><code>ModuleNotFoundError: No module named 'tqdm'
</code></pre>

<p>Does anyone know how to solve it?</p>
",9003390.0,,,,,2022-05-02 16:20:35,No module named 'tqdm',<python><tensorflow><pixel><recurrent-neural-network><tqdm>,6,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47529792
55318273,1,55492909,,2019-03-23 20:54:18,,55,69531,"<p>When using </p>

<pre><code>model.compile(optimizer = tf.train.AdamOptimizer(),
              loss = 'sparse_categorical_crossentropy',
              metrics=['accuracy'])
</code></pre>

<p>in my Jupyter Notebook the following Error pops up:</p>

<p><strong>module 'tensorflow._api.v2.train' has no attribute 'AdamOptimizer'</strong></p>

<p>Tensorflow Version: <strong>2.0.0-alpha0</strong></p>

<hr>

<p>Do you think the only possibility is to downgrade the TF version?</p>
",5720357.0,,,,,2022-07-24 13:58:16,Tensorflow._api.v2.train has no attribute 'AdamOptimizer',<python><tensorflow>,7,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55318273
33636925,1,33642903,,2015-11-10 18:23:38,,55,55091,"<p>I've installed the tensorflow docker container on an ubuntu machine.  The tensorflow docker <a href=""http://www.tensorflow.org/get_started/os_setup.md"" rel=""noreferrer"">setup instructions</a> specify:</p>

<pre><code>docker run -it b.gcr.io/tensorflow/tensorflow
</code></pre>

<p>This puts me into the docker container terminal, and I can run python and execute the Hello World example.  I can also manually run .\run_jupyter.sh to start the jupyter notebook. However, I can't reach the notebook from host.</p>

<p>How do I start the jupyter notebook such that I can use the notebook from the host machine? Ideally I would like to use docker to launch the container and start jupyter in a single command.</p>
",276310.0,,3885376.0,,2017-07-23 15:41:25,2019-10-28 15:59:25,How do I start tensorflow docker jupyter notebook,<docker><jupyter><tensorflow>,10,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33636925
44433438,1,44434099,,2017-06-08 10:38:21,,55,37868,"<p>I would like to understand what <code>tf.global_variables_initializer</code> does in a bit more detail.
A <a href=""https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer"" rel=""noreferrer"">sparse description is given here</a>:</p>

<blockquote>
  <p>Returns an Op that initializes global variables.</p>
</blockquote>

<p>But that doesn't really help me. I know that the op is necessary to initialize the graph, but what does that actually mean? Is this the step where the graph is complied? </p>
",3747801.0,,3924118.0,,2019-10-27 22:09:43,2022-08-24 11:58:06,What is the purpose of tf.global_variables_initializer?,<tensorflow><deep-learning>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44433438
43839431,1,43948872,,2017-05-08 03:43:38,,54,26464,"<p>I would like to replace or modify the gradient of an op or portion of the graph in tensorflow.  It would be ideal if I can use the existing gradient in the calculation.</p>

<p>In some ways this is the opposite to what <code>tf.stop_gradient()</code> does: instead of adding a calculation which is ignored when calculating gradients, I want a calculation which is only used when calculating gradients.</p>

<p>A simple example would be something which simply scales gradients by multiplying them with a constant (but does not multiply the forward calculation by a constant).  Another example would be something which clips the gradients to a given range.</p>
",1828289.0,,1828289.0,,2017-05-08 15:29:50,2020-07-15 18:32:16,Tensorflow: How to replace or modify gradient?,<python><tensorflow><neural-network>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43839431
38287772,1,42187104,,2016-07-10 01:21:34,,54,40235,"<p>In <a href=""https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html#vector-representations-of-words"" rel=""noreferrer"">this</a> page, it is said that: </p>

<blockquote>
  <p>[...] skip-gram inverts contexts and targets, and tries to predict each context word from its target word [...]</p>
</blockquote>

<p>However, looking at the training dataset it produces, the content of the X and Y pair seems to be interexchangeable, as those two pairs of (X, Y): </p>

<blockquote>
  <p><code>(quick, brown), (brown, quick)</code></p>
</blockquote>

<p>So, why distinguish that much between context and targets if it is the same thing in the end? </p>

<p>Also, doing <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/5_word2vec.ipynb"" rel=""noreferrer"">Udacity's Deep Learning course exercise on word2vec</a>, I wonder why they seem to do the difference between those two approaches that much in this problem: </p>

<blockquote>
  <p>An alternative to skip-gram is another Word2Vec model called CBOW (Continuous Bag of Words). In the CBOW model, instead of predicting a context word from a word vector, you predict a word from the sum of all the word vectors in its context. Implement and evaluate a CBOW model trained on the text8 dataset.</p>
</blockquote>

<p>Would not this yields the same results?</p>
",2476920.0,,,,,2022-01-20 14:12:40,CBOW v.s. skip-gram: why invert context and target words?,<nlp><tensorflow><deep-learning><word2vec><word-embedding>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38287772
36927607,1,37026818,,2016-04-29 00:28:24,,54,99928,"<p>I ran the MNIST demo in TensorFlow with 2 conv layers and a full-conect layer, I got an message that 'ran out of memeory trying to allocate 2.59GiB' , but it shows that total memory is 4.69GiB, and free memory is 3.22GiB, how can it stop with 2.59GiB? And with larger network, how can I manage  gpu memory? I concern only how to make best use of the gpu memory and wanna know how it happened,  not how to pre-allocating memory</p>
",5545794.0,,5545794.0,,2016-04-29 06:11:13,2022-09-24 19:50:58,How can I solve 'ran out of gpu memory' in TensorFlow,<tensorflow>,11,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36927607
59529804,1,59940352,,2019-12-30 11:07:41,,54,64894,"<p>Till date, I have been using <strong>Tensorflow-GPU</strong> by installing it using <strong>pip</strong> and the Cuda related software and Nvidia softwares/drivers from <strong>Nvidia's website</strong>. Recently, I found that using <code>conda install tensorflow-gpu</code> also installs <strong>cudatoolkit</strong> and <strong>cudnn</strong>. </p>

<p>So, how are these(the ones provided by conda) different from the ones that I downloaded from Nvidia's website?</p>

<p>In my first (previous) environment, <code>conda list</code> showed that I have installed only TensorFlow(from PyPi) and no cudnn/cudatoolkit, but still everything worked. <a href=""https://i.stack.imgur.com/DVAIZ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DVAIZ.png"" alt="" This is my base environment where I installed Tensorflow-GPU using pip""></a></p>

<p>Also, in a new environment in which I ran <code>conda install tensorflow-gpu</code>, <code>conda list</code> showed me <strong>tensorflow-gpu</strong> has been installed along with <strong>cudatoolkit</strong> and <strong>cudnn</strong> by <strong>Anaconda</strong>. And in this environment also, everything worked fine.<a href=""https://i.stack.imgur.com/49OaA.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/49OaA.png"" alt=""This is a new environment where I used conda to install tensorflow-gpu""></a> </p>

<p>So does this mean, that downloading and installing Cuda from Nvidia's website is <strong>only</strong> necessary if I use pip to install TensorFlow?</p>
",9895768.0,,9895768.0,,2019-12-30 11:14:27,2022-06-22 03:41:18,Nvidia Cudatoolkit vs Conda Cudatoolkit,<python><tensorflow><anaconda><conda>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59529804
34340489,1,36947632,,2015-12-17 17:14:59,,54,44745,"<p>I am building a standard image classification model with Tensorflow. For this I have input images, each assigned with a label (number in {0,1}). The Data can hence be stored in a list using the following format:</p>

<pre><code>/path/to/image_0 label_0
/path/to/image_1 label_1
/path/to/image_2 label_2
...
</code></pre>

<p>I want to use TensorFlow's queuing system to read my data and feed it to my model. Ignoring the labels, one can easily achieve this by using <code>string_input_producer</code> and <code>wholeFileReader</code>. Here the code:</p>

<pre><code>def read_my_file_format(filename_queue):
  reader = tf.WholeFileReader()
  key, value = reader.read(filename_queue)
  example = tf.image.decode_png(value)
  return example

#removing label, obtaining list containing /path/to/image_x
image_list = [line[:-2] for line in image_label_list]

input_queue = tf.train.string_input_producer(image_list)                                                     
input_images = read_my_file_format(input_queue)
</code></pre>

<p>However, the labels are lost in that process as the image data is purposely shuffled as part of the input pipeline. What is the easiest way of pushing the labels together with the image data through the input queues?</p>
",2594660.0,,464273.0,,2016-04-29 05:56:41,2017-07-03 21:33:11,Tensorflow read images with labels,<python><tensorflow>,3,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34340489
61233004,1,61235696,,2020-04-15 15:50:26,,53,43646,"<p>I cannot get a satisfying answer to this question. As I understand it, TensorFlow is a library for numerical computations, often used in deep learning applications, and Scikit-learn is a framework for general machine learning. </p>

<p>But what is the exact difference between them, what is the purpose and function of TensorFlow? Can I use them together, and does it make any sense?</p>
",5082740.0,,,,,2023-04-24 06:41:08,What's the difference between scikit-learn and tensorflow? Is it possible to use them together?,<python><tensorflow><machine-learning><scikit-learn>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/61233004
41117740,1,42894528,,2016-12-13 09:38:13,,53,48408,"<p>I'm running tensorflow-gpu on Windows 10 using a simple MINST neural network program. When it tries to run, it encounters a <code>CUBLAS_STATUS_ALLOC_FAILED</code> error. A google search doesn't turn up anything.</p>

<pre><code>I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 970
major: 5 minor: 2 memoryClockRate (GHz) 1.253
pciBusID 0000:0f:00.0
Total memory: 4.00GiB
Free memory: 3.31GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 970, pci bus id: 0000:0f:00.0)
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support
Traceback (most recent call last):
  File ""C:\Users\Anonymous\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1021, in _do_call
    return fn(*args)
  File ""C:\Users\Anonymous\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1003, in _run_fn
    status, run_metadata)
  File ""C:\Users\Anonymous\AppData\Local\Programs\Python\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\Users\Anonymous\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(100, 784), b.shape=(784, 256), m=100, n=256, k=784
         [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_Placeholder_0/_7, Variable/read)]]
         [[Node: Mean/_15 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_35_Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
</code></pre>
",211159.0,,10685378.0,,2020-01-02 08:59:22,2022-02-26 04:06:13,Tensorflow crashes with CUBLAS_STATUS_ALLOC_FAILED,<tensorflow><windows-10><mnist><cublas>,10,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41117740
39614938,1,39616491,,2016-09-21 11:11:28,,53,18957,"<p>What is the purpose of:</p>

<pre><code>with tf.Graph().as_default()
</code></pre>

<p>I have some tensorflow code that uses the above.
However, the code has only one graph, so why do we need this?</p>
",6857504.0,,,,,2016-09-21 16:38:33,Why do we need TensorFlow tf.Graph?,<tensorflow>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39614938
37900780,1,37901852,,2016-06-18 19:19:27,,53,29765,"<p>In tensorflow tutorials, I see both codes like <code>tf.add(tf.matmul(X, W), b)</code> and <code>tf.matmul(X, W) + b</code>, what is the difference between using the math function <code>tf.add()</code>, <code>tf.assign()</code>, etc and the operators <code>+</code> and <code>=</code>, etc, in precision or other aspects? </p>
",1429955.0,,,,,2019-02-23 06:39:55,In tensorflow what is the difference between tf.add and operator (+)?,<tensorflow>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37900780
44232898,1,44233285,,2017-05-28 23:16:09,,52,68843,"<p>I am using  tensor flow version :</p>

<blockquote>
  <p>0.12.1</p>
</blockquote>

<p>Cuda tool set version is 8.</p>

<pre><code>lrwxrwxrwx  1 root root   19 May 28 17:27 cuda -&gt; /usr/local/cuda-8.0
</code></pre>

<p>As documented  <a href=""https://www.tensorflow.org/versions/r0.10/get_started/os_setup#optional_install_cuda_gpus_on_linux"" rel=""noreferrer"">here</a> I have downloaded and installed cuDNN. But while execeting following line from my python script I am getting error messages mentioned in header:</p>

<pre><code>  model.fit_generator(train_generator,
   steps_per_epoch= len(train_samples),
   validation_data=validation_generator, 
   validation_steps=len(validation_samples),
   epochs=9)
</code></pre>

<p>Detailed error message is as follows:</p>

<pre><code>Using TensorFlow backend. 
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally 
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally 
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally 
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally 
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally 
Epoch 1/9 Exception in thread Thread-1: Traceback (most recent call last):   File "" lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()   File "" lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)   File "" lib/python3.5/site-packages/keras/engine/training.py"", line 612, in data_generator_task
    generator_output = next(self._generator) StopIteration

I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), 
 but there must be at least one NUMA node, so returning NUMA node zero 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] 
Found device 0 with properties: name: GRID K520 major: 3 minor: 0 memoryClockRate (GHz) 0.797 pciBusID 0000:00:03.0 Total memory: 3.94GiB Free memory:
3.91GiB 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] 
 Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0) 
Traceback (most recent call last):   File ""model_new.py"", line 82, in &lt;module&gt;
    model.fit_generator(train_generator, steps_per_epoch= len(train_samples),validation_data=validation_generator, validation_steps=len(validation_samples),epochs=9)   File "" lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 88, in wrapper
    return func(*args, **kwargs)   File "" lib/python3.5/site-packages/keras/models.py"", line 1110, in fit_generator
    initial_epoch=initial_epoch)   File "" lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 88, in wrapper
    return func(*args, **kwargs)   File "" lib/python3.5/site-packages/keras/engine/training.py"", line 1890, in fit_generator
    class_weight=class_weight)   File "" lib/python3.5/site-packages/keras/engine/training.py"", line 1633, in train_on_batch
    outputs = self.train_function(ins)   File "" lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2229, in __call__
    feed_dict=feed_dict)   File "" lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)   File "" lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 937, in _run
    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)   File "" lib/python3.5/site-packages/numpy/core/numeric.py"", line 531, in asarray
    return array(a, dtype, copy=False, order=order) MemoryError
</code></pre>

<p>If any suggestion to resolve this error is appreciated.</p>

<p><strong>EDIT:</strong>
Issue is fatal. </p>

<pre><code>uname -a
Linux ip-172-31-76-109 4.4.0-78-generic #99-Ubuntu SMP
Thu Apr 27 15:29:09 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

sudo lshw -short
[sudo] password for carnd:
H/W path    Device  Class      Description
==========================================
                    system     HVM domU
/0                  bus        Motherboard
/0/0                memory     96KiB BIOS
/0/401              processor  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz
/0/402              processor  CPU
/0/403              processor  CPU
/0/404              processor  CPU
/0/405              processor  CPU
/0/406              processor  CPU
/0/407              processor  CPU
/0/408              processor  CPU
/0/1000             memory     15GiB System Memory
/0/1000/0           memory     15GiB DIMM RAM
/0/100              bridge     440FX - 82441FX PMC [Natoma]
/0/100/1            bridge     82371SB PIIX3 ISA [Natoma/Triton II]
/0/100/1.1          storage    82371SB PIIX3 IDE [Natoma/Triton II]
/0/100/1.3          bridge     82371AB/EB/MB PIIX4 ACPI
/0/100/2            display    GD 5446
/0/100/3            display    GK104GL [GRID K520]
/0/100/1f           generic    Xen Platform Device
/1          eth0    network    Ethernet interface
</code></pre>

<p><strong>EDIT 2:</strong></p>

<p>This is an EC2 instance in Amazon cloud.  And all the files holding value -1.</p>

<pre><code>:/sys$ find . -name numa_node -exec cat '{}' \;
find: ‘./fs/fuse/connections/39’: Permission denied
-1
-1
-1
-1
-1
-1
-1
find: ‘./kernel/debug’: Permission denied
</code></pre>

<p><strong>EDIT3:</strong>
After updating the numa_nod files NUMA related error is disappeared.  But all other previous errors listed above is remaining. And again I got a fatal error.</p>

<pre><code>Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
Epoch 1/9
Exception in thread Thread-1:
Traceback (most recent call last):
  File "" lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File "" lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "" lib/python3.5/site-packages/keras/engine/training.py"", line 612, in data_generator_task
    generator_output = next(self._generator)
StopIteration

I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 3.94GiB
Free memory: 3.91GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
Traceback (most recent call last):
  File ""model_new.py"", line 85, in &lt;module&gt;
    model.fit_generator(train_generator, steps_per_epoch= len(train_samples),validation_data=validation_generator, validation_steps=len(validation_samples),epochs=9)
  File "" lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 88, in wrapper
    return func(*args, **kwargs)
  File "" lib/python3.5/site-packages/keras/models.py"", line 1110, in fit_generator
    initial_epoch=initial_epoch)
  File "" lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 88, in wrapper
    return func(*args, **kwargs)
  File "" lib/python3.5/site-packages/keras/engine/training.py"", line 1890, in fit_generator
    class_weight=class_weight)
  File "" lib/python3.5/site-packages/keras/engine/training.py"", line 1633, in train_on_batch
    outputs = self.train_function(ins)
  File "" lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2229, in __call__
    feed_dict=feed_dict)
  File "" lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File "" lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 937, in _run
    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)
  File "" lib/python3.5/site-packages/numpy/core/numeric.py"", line 531, in asarray
    return array(a, dtype, copy=False, order=order)
MemoryError
</code></pre>
",1144157.0,,681865.0,,2017-05-29 04:29:28,2022-03-21 12:33:58,"MemoryError in TensorFlow; and ""successful NUMA node read from SysFS had negative value (-1)"" with xen",<python-3.x><tensorflow><deep-learning>,3,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44232898
41704484,1,44585250,,2017-01-17 18:32:57,,52,30014,"<p><code>tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)</code> outputs random values from a normal distribution.</p>

<p><code>tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)</code> outputs random values from a truncated normal distribution.</p>

<p>I tried googling 'truncated normal distribution'. But didn't understand much.</p>
",5708247.0,,1090562.0,,2017-06-16 09:10:02,2021-09-10 13:24:25,What is difference between tf.truncated_normal and tf.random_normal?,<math><machine-learning><tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41704484
36007883,1,36016117,,2016-03-15 09:55:38,,51,107955,"<p>I am trying to implement multivariate linear regression in Python using TensorFlow, but have run into some logical and implementation issues. My code throws the following error:</p>

<pre><code>Attempting to use uninitialized value Variable
Caused by op u'Variable/read'
</code></pre>

<p>Ideally the <code>weights</code> output should be <code>[2, 3]</code></p>

<pre><code>def hypothesis_function(input_2d_matrix_trainingexamples,
                        output_matrix_of_trainingexamples,
                        initial_parameters_of_hypothesis_function,
                        learning_rate, num_steps):
    # calculate num attributes and num examples
    number_of_attributes = len(input_2d_matrix_trainingexamples[0])
    number_of_trainingexamples = len(input_2d_matrix_trainingexamples)

    #Graph inputs
    x = []
    for i in range(0, number_of_attributes, 1):
        x.append(tf.placeholder(""float""))
    y_input = tf.placeholder(""float"")

    # Create Model and Set Model weights
    parameters = []
    for i in range(0, number_of_attributes, 1):
        parameters.append(
            tf.Variable(initial_parameters_of_hypothesis_function[i]))

    #Contruct linear model
    y = tf.Variable(parameters[0], ""float"")
    for i in range(1, number_of_attributes, 1):
        y = tf.add(y, tf.multiply(x[i], parameters[i]))

    # Minimize the mean squared errors
    loss = tf.reduce_mean(tf.square(y - y_input))
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    train = optimizer.minimize(loss)

    #Initialize the variables
    init = tf.initialize_all_variables()

    # launch the graph
    session = tf.Session()
    session.run(init)
    for step in range(1, num_steps + 1, 1):
        for i in range(0, number_of_trainingexamples, 1):
            feed = {}
            for j in range(0, number_of_attributes, 1):
                array = [input_2d_matrix_trainingexamples[i][j]]
                feed[j] = array
            array1 = [output_matrix_of_trainingexamples[i]]
            feed[number_of_attributes] = array1
            session.run(train, feed_dict=feed)

    for i in range(0, number_of_attributes - 1, 1):
        print (session.run(parameters[i]))

array = [[0.0, 1.0, 2.0], [0.0, 2.0, 3.0], [0.0, 4.0, 5.0]]
hypothesis_function(array, [8.0, 13.0, 23.0], [1.0, 1.0, 1.0], 0.01, 200)
</code></pre>
",3940080.0,,281545.0,,2017-05-13 19:05:37,2019-04-22 16:52:35,"TensorFlow: ""Attempting to use uninitialized value"" in variable initialization",<python><machine-learning><linear-regression><tensorflow>,6,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36007883
33788989,1,33846659,,2015-11-18 19:45:42,,51,117742,"<p>I am experimenting with some simple models in tensorflow, including one that looks very similar to the first <a href=""http://www.tensorflow.org/tutorials/mnist/beginners/index.md"">MNIST for ML Beginners example</a>, but with a somewhat larger dimensionality. I am able to use the gradient descent optimizer with no problems, getting good enough convergence. When I try to use the ADAM optimizer, I get errors like this:</p>

<pre><code>tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value Variable_21/Adam
     [[Node: Adam_2/update_Variable_21/ApplyAdam = ApplyAdam[T=DT_FLOAT, use_locking=false, _device=""/job:localhost/replica:0/task:0/cpu:0""](Variable_21, Variable_21/Adam, Variable_21/Adam_1, beta1_power_2, beta2_power_2, Adam_2/learning_rate, Adam_2/beta1, Adam_2/beta2, Adam_2/epsilon, gradients_11/add_10_grad/tuple/control_dependency_1)]]
</code></pre>

<p>where the specific variable that complains about being uninitialized changes depending on the run. What does this error mean? And what does it suggest is wrong? It seems to occur regardless of the learning rate I use.</p>
",189456.0,,,,,2017-11-28 23:23:44,Tensorflow: Using Adam optimizer,<python><tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33788989
37697747,1,37706972,,2016-06-08 08:55:20,,51,93681,"<p>I try to run this code:</p>

<pre><code>outputs, states = rnn.rnn(lstm_cell, x, initial_state=initial_state, sequence_length=real_length)

tensor_shape = outputs.get_shape()
for step_index in range(tensor_shape[0]):
    word_index = self.x[:, step_index]
    word_index = tf.reshape(word_index, [-1,1])
    index_weight = tf.gather(word_weight, word_index)
    outputs[step_index,  :,  :]=tf.mul(outputs[step_index,  :,  :] , index_weight)
</code></pre>

<p>But I get error on last line: 
<code>TypeError: 'Tensor' object does not support item assignment</code>
It seems I can not assign to tensor, how can I fix it?</p>
",1303432.0,,826983.0,,2018-09-28 10:31:11,2022-08-11 23:50:51,TypeError: 'Tensor' object does not support item assignment in TensorFlow,<python><tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37697747
34194151,1,34199902,,2015-12-10 05:12:12,,50,54560,"<p>What is the most efficient way to flatten a 2D tensor which is actually a horizontal or vertical vector into a 1D tensor? </p>

<p>Is there a difference in terms of performance between:</p>

<pre><code>tf.reshape(w, [-1])
</code></pre>

<p>and</p>

<pre><code>tf.squeeze(w)
</code></pre>

<p>?</p>
",1576602.0,,,,,2020-01-30 12:39:21,Best way to flatten a 2D tensor containing a vector in TensorFlow?,<python><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34194151
37689423,1,37689717,,2016-06-07 21:10:13,,50,53987,"<p>What is the best way to convert a tensor from NHWC format to NCHW format, and vice versa?</p>

<p>Is there an op specifically that does this, or will I need to use some combination of the split/concat type operations?</p>
",2989201.0,,,,,2022-07-20 17:52:45,Convert between NHWC and NCHW in TensorFlow,<tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37689423
34785414,1,34788819,,2016-01-14 09:06:14,,50,46982,"<p>I am starting to work with TensorFlow library for deep learning, <a href=""https://www.tensorflow.org/"">https://www.tensorflow.org/</a>. </p>

<p>I found a explicit guide to work on it on linux and Mac but I did not find how to work with it under Windows. I try over the net, but the information are lacking. </p>

<p>I use Visual Studio 2015 for my projects, and I am trying to compile the library with Visual studio Compiler VC14.</p>

<p>How to install it and to use it under Windows?</p>

<p>Can I use <a href=""https://github.com/dslomov/bazel-windows"">Bazel for Windows </a> for production use?</p>
",4564882.0,,4564882.0,,2016-01-14 11:02:05,2017-09-17 09:59:55,How to install TensorFlow on Windows?,<c++><windows><visual-studio><machine-learning><tensorflow>,11,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34785414
36612512,1,36784246,,2016-04-14 01:56:13,,50,84174,"<p>I'm having trouble recovering a tensor by name, I don't even know if it's possible.</p>

<p>I have a function that creates my graph:</p>

<pre><code>def create_structure(tf, x, input_size,dropout):    
 with tf.variable_scope(""scale_1"") as scope:
  W_S1_conv1 = deep_dive.weight_variable_scaling([7,7,3,64], name='W_S1_conv1')
  b_S1_conv1 = deep_dive.bias_variable([64])
  S1_conv1 = tf.nn.relu(deep_dive.conv2d(x_image, W_S1_conv1,strides=[1, 2, 2, 1], padding='SAME') + b_S1_conv1, name=""Scale1_first_relu"")
.
.
.
return S3_conv1,regularizer
</code></pre>

<p>I want to access the variable S1_conv1 outside this function. I tried:</p>

<pre><code>with tf.variable_scope('scale_1') as scope_conv: 
 tf.get_variable_scope().reuse_variables()
 ft=tf.get_variable('Scale1_first_relu')
</code></pre>

<p>But that is giving me an error:</p>

<p>ValueError: Under-sharing: Variable scale_1/Scale1_first_relu does not exist, disallowed. Did you mean to set reuse=None in VarScope?</p>

<p>But this works:</p>

<pre><code>with tf.variable_scope('scale_1') as scope_conv: 
 tf.get_variable_scope().reuse_variables()
 ft=tf.get_variable('W_S1_conv1')
</code></pre>

<p>I can get around this with</p>

<pre><code>return S3_conv1,regularizer, S1_conv1
</code></pre>

<p>but I don't want to do that.</p>

<p>I think my problem is that S1_conv1 is not really a variable, it's just a tensor. Is there a way to do what I want?</p>
",3618299.0,,,,,2020-11-29 11:11:15,Tensorflow: How to get a tensor by name?,<python><scope><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36612512
37340129,1,37343690,,2016-05-20 07:07:40,,50,69096,"<p>I am new to TensorFlow. I am looking for the help on the image recognition where I can <strong>train my own image</strong> dataset.</p>

<p>Is there any example for training the new dataset?</p>
",6343552.0,,6053728.0,,2018-02-05 04:42:55,2021-11-07 11:14:41,TensorFlow: training on my own image,<python><tensorflow><conv-neural-network><tensorflow-datasets>,4,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37340129
48340392,1,48544614,,2018-01-19 11:46:34,,49,56985,"<p>After updating my <code>Numpy</code> and <code>Tensorflow</code> I am getting these kind of warnings. I had already tried <a href=""https://github.com/scikit-learn/scikit-learn/issues/9673"" rel=""noreferrer"">these</a>, but nothing works, every suggestion will be appreciated.</p>

<pre><code>FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2018-01-19 17:11:38.695932: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
</code></pre>
",4786793.0,,5098368.0,,2018-01-29 02:05:08,2020-02-06 14:36:29,FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated,<python><numpy><tensorflow>,11,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48340392
38235555,1,38244353,,2016-07-06 23:43:31,,48,49354,"<p>I have some data represented by <code>input_x</code>. It is a tensor of unknown size (should be inputted by batch) and each item there is of size <code>n</code>. <code>input_x</code> undergoes <code>tf.nn.embedding_lookup</code>, so that <code>embed</code> now has dimensions <code>[?, n, m]</code> where <code>m</code> is the embedding size and <code>?</code> refers to the unknown batch size. </p>

<p>This is described here:</p>

<pre><code>input_x = tf.placeholder(tf.int32, [None, n], name=""input_x"") 
embed = tf.nn.embedding_lookup(W, input_x)
</code></pre>

<p>I'm now trying to multiply each sample in my input data (which is now expanded by embedding dimension) by a matrix variable, <code>U</code>, and I can't seem to get how to do that.</p>

<p>I first tried using <code>tf.matmul</code> but it gives an error due to mismatch in shapes. I then tried the following, by expanding the dimension of <code>U</code> and applying <code>batch_matmul</code> (I also tried the function from <code>tf.nn.math_ops.</code>, the result was the same):</p>

<pre><code>U = tf.Variable( ... )    
U1 = tf.expand_dims(U,0)
h=tf.batch_matmul(embed, U1)
</code></pre>

<p>This passes the initial compilation, but then when actual data is applied, I get the following error:</p>

<p><code>In[0].dim(0) and In[1].dim(0) must be the same: [64,58,128] vs [1,128,128]</code></p>

<p>I also know why this is happening - I replicated the dimension of <code>U</code> and it is now <code>1</code>, but the minibatch size, <code>64</code>, doesn't fit. </p>

<p>How can I do that matrix multiplication on my tensor-matrix input correctly (for unknown batch size)?</p>
",635622.0,,6637663.0,,2018-03-13 07:27:13,2018-11-01 13:50:12,Tensorflow - matmul of input matrix with batch data,<python><tensorflow>,5,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38235555
70537488,1,70538761,,2021-12-30 22:55:22,,48,66275,"<p>I got below error message when I run <code>model_main_tf2.py</code> on Object Detection API:</p>
<pre><code>Traceback (most recent call last):
  File &quot;/content/models/research/object_detection/model_main_tf2.py&quot;, line 32, in &lt;module&gt;
    from object_detection import model_lib_v2
  File &quot;/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py&quot;, line 29, in &lt;module&gt;
    from object_detection import eval_util
  File &quot;/usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py&quot;, line 36, in &lt;module&gt;
    from object_detection.metrics import lvis_evaluation
  File &quot;/usr/local/lib/python3.7/dist-packages/object_detection/metrics/lvis_evaluation.py&quot;, line 23, in &lt;module&gt;
    from lvis import results as lvis_results
  File &quot;/usr/local/lib/python3.7/dist-packages/lvis/__init__.py&quot;, line 5, in &lt;module&gt;
    from lvis.vis import LVISVis
  File &quot;/usr/local/lib/python3.7/dist-packages/lvis/vis.py&quot;, line 1, in &lt;module&gt;
    import cv2
  File &quot;/usr/local/lib/python3.7/dist-packages/cv2/__init__.py&quot;, line 9, in &lt;module&gt;
    from .cv2 import _registerMatType
ImportError: cannot import name '_registerMatType' from 'cv2.cv2' (/usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so)
</code></pre>
<p>The weird thing is I run the same code before, it worked well but now it gives me an error.</p>
",16422667.0,,651246.0,,2022-01-17 22:24:06,2022-04-22 09:55:57,cannot import name '_registerMatType' from 'cv2.cv2',<python><tensorflow><object-detection-api>,8,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/70537488
55318626,1,55318851,,2019-03-23 21:34:58,,48,64843,"<p>I'm trying to run a tensorflow code in v2.0 and I'mg getting the following error</p>

<pre><code>AttributeError: module 'tensorflow' has no attribute 'logging'
</code></pre>

<p>I don't want to simply remove it from the code.</p>

<ul>
<li>why this code has been removed?</li>
<li>why should I do instead?</li>
</ul>
",3604079.0,,,,,2020-10-27 06:38:31,module 'tensorflow' has no attribute 'logging',<tensorflow><tensorflow2.0>,2,0,,,,CC BY-SA 4.0,https://stackoverflow.com/q/55318626
35164529,1,35164992,,2016-02-02 21:55:18,,48,42998,"<p>The standard way of initializing variables in TensorFlow is</p>

<pre><code>init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)
</code></pre>

<p>After running some learning for a while I create a new set of variables but once I initialize them it resets all my existing variables. At the moment my way around this is to save all the variable I need and then reapply them after the tf.initalize_all_variables call. This works but is a bit ugly and clunky. I cannot find anything like this in the docs...</p>

<p>Does anyone know of any good way to just initialize the uninitialized variables?   </p>
",2245776.0,,249341.0,,2016-07-24 00:02:26,2020-11-20 09:01:30,In TensorFlow is there any way to just initialize uninitialised variables?,<python><tensorflow>,7,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35164529
42281844,1,49357445,,2017-02-16 18:24:30,,48,22318,"<p>I presume it is some kind of moving average, but the valid range is between 0 and 1.</p>
",49530.0,,,,,2023-03-13 22:32:52,"What is the mathematics behind the ""smoothing"" parameter in TensorBoard's scalar graphs?",<tensorflow><tensorboard>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42281844
34343259,1,34343517,,2015-12-17 20:01:06,,47,29522,"<p>I am looking at <a href=""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android"" rel=""noreferrer"">Google's example</a> on how to deploy and use a pre-trained Tensorflow graph (model) on Android. This example uses a <code>.pb</code> file at: </p>

<blockquote>
  <p><a href=""https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip"" rel=""noreferrer"">https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip</a></p>
</blockquote>

<p><em>which is a link to a file that downloads automatically</em>.</p>

<p>The example shows how to load the <code>.pb</code> file to a Tensorflow session and use it to perform classification, but it doesn't seem to mention how to generate such a <code>.pb</code> file, after a graph is trained (e.g., in Python).</p>

<p>Are there any examples on how to do that?</p>
",2116766.0,,3924118.0,,2018-07-09 13:24:43,2018-07-09 13:24:43,Is there an example on how to generate protobuf files holding trained TensorFlow graphs,<protocol-buffers><tensorflow>,6,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/34343259
60368298,1,60368453,,2020-02-24 00:42:51,,47,86600,"<p>I am trying to normally import the TensorFlow python package, but I get the following error:</p>

<p><a href=""https://i.stack.imgur.com/pRcNd.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/pRcNd.png"" alt=""enter image description here""></a></p>

<p>Here is the text from the above terminal image:</p>

<pre><code>2020-02-23 19:01:06.163940: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-23 19:01:06.164019: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-23 19:01:06.164030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
&lt;module 'tensorflow_core._api.v2.version' from '/home/saman/miniconda3/envs/testconda/lib/python3.7/site-packages/tensorflow_core/_api/v2/version/__init__.py'
</code></pre>
",9408163.0,,6622587.0,,2020-02-24 01:20:22,2022-12-13 15:34:07,Could not load dynamic library 'libnvinfer.so.6',<python><linux><tensorflow><pip><dynamic-library>,6,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/60368298
35226428,1,35227842,,2016-02-05 14:21:24,,47,45798,"<p>The feature I'm after is to be able to tell what the gradient of a given variable is with respect to my error function given some data.</p>

<p>One way to do this would be to see how much the variable has changed after a call to train, but obviously that can vary massively based on the learning algorithm (for example it would be almost impossible to tell with something like RProp) and just isn't very clean.</p>

<p>Thanks in advance.</p>
",2245776.0,,3574081.0,,2016-02-05 16:56:10,2020-10-02 02:23:16,How do I get the gradient of the loss at a TensorFlow variable?,<tensorflow>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35226428
34598371,1,34599220,,2016-01-04 19:26:24,,47,46049,"<p>I understand that <code>tf.where</code> will return the locations of <code>True</code> values, so that I could use the result's <code>shape[0]</code> to get the number of <code>True</code>s. </p>

<p>However, when I try and use this, the dimension is unknown (which makes sense as it needs to be computed at runtime). So my question is, how can I access a dimension and use it in an operation like a sum?</p>

<p>For example:</p>

<pre><code>myOtherTensor = tf.constant([[True, True], [False, True]])
myTensor = tf.where(myOtherTensor)
myTensor.get_shape() #=&gt; [None, 2]
sum = 0
sum += myTensor.get_shape().as_list()[0] # Well defined at runtime but considered None until then.
</code></pre>
",4975126.0,,3710490.0,,2016-01-04 19:50:32,2017-11-16 08:18:35,"Count number of ""True"" values in boolean Tensor",<python><tensorflow>,4,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34598371
52346254,1,52353715,,2018-09-15 15:44:47,,47,86659,"<p>I'm starting my adventure with Tensorflow. I think I installed everything correctly, but when running this code, PyCharm returns an error:</p>

<pre><code>Traceback (most recent call last):
  File ""C:/Users/tymot/Desktop/myenv3/env/Tensorflow/all_good.py"", line 15, in &lt;module&gt;
    import matplotlib.pyplot as plt
  File ""C:\Users\tymot\Anaconda1\lib\site-packages\matplotlib\pyplot.py"", line 115, in &lt;module&gt;
    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()
  File ""C:\Users\tymot\Anaconda1\lib\site-packages\matplotlib\backends\__init__.py"", line 62, in pylab_setup
    [backend_name], 0)
  File ""C:\Users\tymot\Anaconda1\lib\site-packages\matplotlib\backends\backend_qt5agg.py"", line 15, in &lt;module&gt;
    from .backend_qt5 import (
  File ""C:\Users\tymot\Anaconda1\lib\site-packages\matplotlib\backends\backend_qt5.py"", line 19, in &lt;module&gt;
    import matplotlib.backends.qt_editor.figureoptions as figureoptions
  File ""C:\Users\tymot\Anaconda1\lib\site-packages\matplotlib\backends\qt_editor\figureoptions.py"", line 20, in &lt;module&gt;
    import matplotlib.backends.qt_editor.formlayout as formlayout
  File ""C:\Users\tymot\Anaconda1\lib\site-packages\matplotlib\backends\qt_editor\formlayout.py"", line 54, in &lt;module&gt;
    from matplotlib.backends.qt_compat import QtGui, QtWidgets, QtCore
  File ""C:\Users\tymot\Anaconda1\lib\site-packages\matplotlib\backends\qt_compat.py"", line 158, in &lt;module&gt;
    raise ImportError(""Failed to import any qt binding"")
ImportError: Failed to import any qt binding
</code></pre>

<p>My code which I am trying to run:</p>

<pre><code>import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

num_features = 2
num_iter = 10000
display_step = int(num_iter / 10)
learning_rate = 0.01

num_input = 2          # units in the input layer 28x28 images
num_hidden1 = 2        # units in the first hidden layer
num_output = 1         # units in the output, only one output 0 or 1

#%% mlp function

def multi_layer_perceptron_xor(x, weights, biases):

    hidden_layer1 = tf.add(tf.matmul(x, weights['w_h1']), biases['b_h1'])
    hidden_layer1 = tf.nn.sigmoid(hidden_layer1)

    out_layer = tf.add(tf.matmul(hidden_layer1, weights['w_out']), biases['b_out'])

    return out_layer

#%%
x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], np.float32)  # 4x2, input
y = np.array([0, 1, 1, 0], np.float32)                      # 4, correct output, AND operation
y = np.reshape(y, [4,1])                                    # convert to 4x1

# trainum_inputg data and labels
X = tf.placeholder('float', [None, num_input])     # training data
Y = tf.placeholder('float', [None, num_output])    # labels

# weights and biases
weights = {
    'w_h1' : tf.Variable(tf.random_normal([num_input, num_hidden1])), # w1, from input layer to hidden layer 1
    'w_out': tf.Variable(tf.random_normal([num_hidden1, num_output])) # w2, from hidden layer 1 to output layer
}
biases = {
    'b_h1' : tf.Variable(tf.zeros([num_hidden1])),
    'b_out': tf.Variable(tf.zeros([num_output]))
}

model = multi_layer_perceptron_xor(X, weights, biases)

'''
- cost function and optimization
- sigmoid cross entropy -- single output
- softmax cross entropy -- multiple output, normalized
'''
loss_func = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=model, labels=Y))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss_func)

sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)

for k in range(num_iter):
    tmp_cost, _ = sess.run([loss_func, optimizer], feed_dict={X: x, Y: y})
    if k % display_step == 0:
        #print('output: ', sess.run(model, feed_dict={X:x}))
        print('loss= ' + ""{:.5f}"".format(tmp_cost))

# separates the input space
W = np.squeeze(sess.run(weights['w_h1']))   # 2x2
b = np.squeeze(sess.run(biases['b_h1']))    # 2,

sess.close()

#%%
# Now plot the fitted line. We need only two points to plot the line
plot_x = np.array([np.min(x[:, 0] - 0.2), np.max(x[:, 1]+0.2)])
plot_y =  -1 / W[1, 0] * (W[0, 0] * plot_x + b[0])
plot_y = np.reshape(plot_y, [2, -1])
plot_y = np.squeeze(plot_y)

plot_y2 = -1 / W[1, 1] * (W[0, 1] * plot_x + b[1])
plot_y2 = np.reshape(plot_y2, [2, -1])
plot_y2 = np.squeeze(plot_y2)

plt.scatter(x[:, 0], x[:, 1], c=y, s=100, cmap='viridis')
plt.plot(plot_x, plot_y, color='k', linewidth=2)    # line 1
plt.plot(plot_x, plot_y2, color='k', linewidth=2)   # line 2
plt.xlim([-0.2, 1.2]); plt.ylim([-0.2, 1.25]);
#plt.text(0.425, 1.05, 'XOR', fontsize=14)
plt.xticks([0.0, 0.5, 1.0]); plt.yticks([0.0, 0.5, 1.0])
plt.show()

#%%
</code></pre>

<p>I think it follows another version of python. How can I run the code without error. 
I installed qt-binding and added tensorflow to my PyCharm. </p>

<p>Any help will be appreciated.</p>
",9989779.0,,,,,2023-04-18 06:05:48,"ImportError: Failed to import any qt binding, Python - Tensorflow",<python><tensorflow>,7,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52346254
44552585,1,44552793,,2017-06-14 18:55:04,,47,62797,"<p>Is there a way to run TensorFlow purely on the CPU. All of the memory on my machine is hogged by a separate process running TensorFlow. I have tried setting the per_process_memory_fraction to 0, unsuccessfully.</p>
",3220264.0,,,,,2020-04-06 18:51:22,Prevent TensorFlow from accessing the GPU?,<python><tensorflow>,2,0,0.0,2017-06-15 18:28:57,,CC BY-SA 3.0,https://stackoverflow.com/q/44552585
36966316,1,36967015,,2016-05-01 11:49:43,,46,155834,"<p>I am trying an Op that is not behaving as expected.</p>

<pre><code>graph = tf.Graph()
with graph.as_default():
  train_dataset = tf.placeholder(tf.int32, shape=[128, 2])
  embeddings = tf.Variable(
    tf.random_uniform([50000, 64], -1.0, 1.0))
  embed = tf.nn.embedding_lookup(embeddings, train_dataset)
  embed = tf.reduce_sum(embed, reduction_indices=0)
</code></pre>

<p>So I need to know the dimensions of the Tensor <code>embed</code>. I know that it can be done at the run time but it's too much work for such a simple operation. What's the easier way to do it?</p>
",3274693.0,,2956066.0,,2018-01-18 20:25:43,2022-03-28 14:39:28,How to get the dimensions of a tensor (in TensorFlow) at graph construction time?,<python><tensorflow><deep-learning><tensor>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36966316
52943489,1,58487325,,2018-10-23 07:32:41,,46,41308,"<p>I can list gpu devices sing the following tensorflow code:</p>
<pre><code>import tensorflow as tf
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
</code></pre>
<p>The result is:</p>
<pre><code>[name: &quot;/device:CPU:0&quot;
 device_type: &quot;CPU&quot;
 memory_limit: 268435456
 locality {
 }
 incarnation: 17897160860519880862, name: &quot;/device:XLA_GPU:0&quot;
 device_type: &quot;XLA_GPU&quot;
 memory_limit: 17179869184
 locality {
 }
 incarnation: 9751861134541508701
 physical_device_desc: &quot;device: XLA_GPU device&quot;, name: &quot;/device:XLA_CPU:0&quot;
 device_type: &quot;XLA_CPU&quot;
 memory_limit: 17179869184
 locality {
 }
 incarnation: 5368380567397471193
 physical_device_desc: &quot;device: XLA_CPU device&quot;, name: &quot;/device:GPU:0&quot;
 device_type: &quot;GPU&quot;
 memory_limit: 21366299034
 locality {
   bus_id: 1
   links {
     link {
       device_id: 1
       type: &quot;StreamExecutor&quot;
       strength: 1
     }
   }
 }
 incarnation: 7110958745101815531
 physical_device_desc: &quot;device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1&quot;, name: &quot;/device:GPU:1&quot;
 device_type: &quot;GPU&quot;
 memory_limit: 17336821351
 locality {
   bus_id: 1
   links {
     link {
       type: &quot;StreamExecutor&quot;
       strength: 1
     }
   }
 }
 incarnation: 3366465227705362600
 physical_device_desc: &quot;device: 1, name: Tesla P40, pci bus id: 0000:03:00.0, compute capability: 6.1&quot;, name: &quot;/device:GPU:2&quot;
 device_type: &quot;GPU&quot;
 memory_limit: 22590563943
 locality {
   bus_id: 2
   numa_node: 1
   links {
     link {
       device_id: 3
       type: &quot;StreamExecutor&quot;
       strength: 1
     }
   }
 }
 incarnation: 8774017944003495680
 physical_device_desc: &quot;device: 2, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1&quot;, name: &quot;/device:GPU:3&quot;
 device_type: &quot;GPU&quot;
 memory_limit: 22590563943
 locality {
   bus_id: 2
   numa_node: 1
   links {
     link {
       device_id: 2
       type: &quot;StreamExecutor&quot;
       strength: 1
     }
   }
 }
 incarnation: 2007348906807258050
 physical_device_desc: &quot;device: 3, name: Tesla P40, pci bus id: 0000:84:00.0, compute capability: 6.1&quot;]
</code></pre>
<p>I want to know what is <code>XLA_GPU</code> and <code>XLA_CPU</code>?</p>
",988709.0,,4139143.0,,2020-10-06 10:37:54,2020-10-06 10:37:54,what is XLA_GPU and XLA_CPU for tensorflow,<python><tensorflow><gpu>,1,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52943489
66977227,1,69302029,,2021-04-06 22:23:10,,46,57257,"<p>Note: there are many similar questions but for different versions of ubuntu and somewhat different specific libraries.  I have not been able to figure out what combination of symbolic links, additional environment variables such as <code>LD_LIBRARY_PATH</code> would work</p>
<p>Here is my <em>nvidia</em> configuration</p>
<pre><code>$ nvidia-smi
Tue Apr  6 11:35:54 2021
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce RTX 2070    Off  | 00000000:01:00.0 Off |                  N/A |
| 18%   25C    P8     9W / 175W |     25MiB /  7982MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1081      G   /usr/lib/xorg/Xorg                 20MiB |
|    0   N/A  N/A      1465      G   /usr/bin/gnome-shell                3MiB |
+-----------------------------------------------------------------------------+
</code></pre>
<p>When running a TF program the following happened:</p>
<pre><code>2021-04-06 14:35:01.589906: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2021-04-06 14:35:01.589914: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
</code></pre>
<p>Has anyone seen this particular mix and how did you resolve it?</p>
<p>Here is one of the additional fixes attempted, but with no change:</p>
<pre><code>conda install cudatoolkit=11.0
</code></pre>
",1056563.0,,681865.0,,2021-04-06 22:35:54,2023-03-08 20:31:22,"""Could not load dynamic library 'libcudnn.so.8'"" when running tensorflow on ubuntu 20.04",<python><tensorflow>,3,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/66977227
40430186,1,40430291,,2016-11-04 19:10:36,,46,119106,"<p>I am new to TensorFlow and machine learning. I am trying to classify two objects a cup and a pendrive (jpeg images). I have trained and exported a model.ckpt successfully. Now I am trying to restore the saved model.ckpt for prediction. Here is the script: </p>

<pre><code>import tensorflow as tf
import math
import numpy as np
from PIL import Image
from numpy import array


# image parameters
IMAGE_SIZE = 64
IMAGE_CHANNELS = 3
NUM_CLASSES = 2

def main():
    image = np.zeros((64, 64, 3))
    img = Image.open('./IMG_0849.JPG')

    img = img.resize((64, 64))
    image = array(img).reshape(64,64,3)

    k = int(math.ceil(IMAGE_SIZE / 2.0 / 2.0 / 2.0 / 2.0)) 
    # Store weights for our convolution and fully-connected layers
    with tf.name_scope('weights'):
        weights = {
            # 5x5 conv, 3 input channel, 32 outputs each
            'wc1': tf.Variable(tf.random_normal([5, 5, 1 * IMAGE_CHANNELS, 32])),
            # 5x5 conv, 32 inputs, 64 outputs
            'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),
            # 5x5 conv, 64 inputs, 128 outputs
            'wc3': tf.Variable(tf.random_normal([5, 5, 64, 128])),
            # 5x5 conv, 128 inputs, 256 outputs
            'wc4': tf.Variable(tf.random_normal([5, 5, 128, 256])),
            # fully connected, k * k * 256 inputs, 1024 outputs
            'wd1': tf.Variable(tf.random_normal([k * k * 256, 1024])),
            # 1024 inputs, 2 class labels (prediction)
            'out': tf.Variable(tf.random_normal([1024, NUM_CLASSES]))
        }

    # Store biases for our convolution and fully-connected layers
    with tf.name_scope('biases'):
        biases = {
            'bc1': tf.Variable(tf.random_normal([32])),
            'bc2': tf.Variable(tf.random_normal([64])),
            'bc3': tf.Variable(tf.random_normal([128])),
            'bc4': tf.Variable(tf.random_normal([256])),
            'bd1': tf.Variable(tf.random_normal([1024])),
            'out': tf.Variable(tf.random_normal([NUM_CLASSES]))
        }

   saver = tf.train.Saver()
   with tf.Session() as sess:
       saver.restore(sess, ""./model.ckpt"")
       print ""...Model Loaded...""   
       x_ = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE , IMAGE_SIZE , IMAGE_CHANNELS])
       y_ = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES])
       keep_prob = tf.placeholder(tf.float32)

       init = tf.initialize_all_variables()

       sess.run(init)
       my_classification = sess.run(tf.argmax(y_, 1), feed_dict={x_:image})
       print 'Neural Network predicted', my_classification[0], ""for your image""


if __name__ == '__main__':
     main()
</code></pre>

<p>When I run the above script for prediction I get the following error:</p>

<pre><code>ValueError: Cannot feed value of shape (64, 64, 3) for Tensor u'Placeholder:0', which has shape '(?, 64, 64, 3)' 
</code></pre>

<p>What am I doing wrong? And how do I fix the shape of numpy array?</p>
",6438307.0,,3714940.0,,2017-08-21 12:00:52,2022-02-26 11:36:00,"TensorFlow ValueError: Cannot feed value of shape (64, 64, 3) for Tensor u'Placeholder:0', which has shape '(?, 64, 64, 3)'",<python><numpy><tensorflow><deep-learning>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40430186
55970686,1,55970819,,2019-05-03 13:20:14,,46,33252,"<p>I want to run tensorboard in jupyter using the latest tensorflow 2.0.0a0. 
With the tensorboard version 1.13.1, and python 3.6. </p>

<p>using </p>

<p><code>...
%tensorboard --logdir {logs_base_dir}</code></p>

<p>I get the error :</p>

<p><code>UsageError: Line magic function %tensorboard not found</code></p>

<p>Do you have an idea what the problem could be? It seems that all versions are up to date and the command seems correct too. </p>

<p>Thanks</p>
",6510273.0,,5154274.0,,2020-10-27 07:21:48,2022-06-04 03:12:21,Tensorboard not found as magic function in jupyter,<python><tensorflow><tensorflow2.0><tensorboard><tensorflow2.x>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55970686
60299967,1,60300019,,2020-02-19 12:03:49,,46,57653,"<p>I'm using Google Colab for deep learning and I'm aware that they randomly allocate GPU's to users. I'd like to be able to see which GPU I've been allocated in any given session. Is there a way to do this in Google Colab notebooks?</p>

<p>Note that I am using Tensorflow if that helps.</p>
",4391249.0,,,,,2021-01-20 03:38:51,How to get allocated GPU spec in Google Colab,<python><tensorflow><gpu><google-colaboratory>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/60299967
39373230,1,39373603,,2016-09-07 14:55:18,,46,36874,"<p>The documentation for the <code>conv2d_transpose()</code> operation does not clearly explain what it does:</p>

<blockquote>
  <p>The transpose of conv2d.</p>
  
  <p>This operation is sometimes called ""deconvolution"" after
  <a href=""http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf"" rel=""noreferrer"">Deconvolutional Networks</a>, but is actually the transpose (gradient) of
  conv2d rather than an actual deconvolution.</p>
</blockquote>

<p>I went through the paper that the doc points to, but it did not help.</p>

<p>What does this operation do and what are examples of why you would want to use it?</p>
",38626.0,,,,,2020-11-07 20:48:24,What does TensorFlow's `conv2d_transpose()` operation do?,<tensorflow><conv-neural-network>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39373230
45276830,1,46460129,,2017-07-24 09:23:56,,46,12910,"<p>I try to build tensorflow-serving using bazel but I've encountered some errors during the building </p>

<pre><code>ERROR:/private/var/tmp/_bazel_Kakadu/3f0c35881c95d2c43f04614911c03a57/external/local_config_cc/BUILD:49:5: in apple_cc_toolchain rule @local_config_cc//:cc-compiler-darwin_x86_64: Xcode version must be specified to use an Apple CROSSTOOL.

ERROR: Analysis of target '//tensorflow_serving/sources/storage_path:file_system_storage_path_source_proto' failed; build aborted.
</code></pre>

<p>I've already tried to use <code>bazel clean</code> and <code>bazel clean --expunge</code> but it didn't help and still Bazel doesn't see my xcode (I suppose) but it's completely installed. I even reinstalled it to make sure that all works fine but the error didn't disappeared </p>

<p>My Bazel version is </p>

<pre><code>Build label: 0.5.2-homebrew
Build target: bazel-out/darwin_x86_64-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jul 13 12:29:40 2017 (1499948980)
Build timestamp: 1499948980
Build timestamp as int: 1499948980
KakaduDevs-Mac-mini:serving Kakadu$ 
</code></pre>

<p>OS is MacOS Sierra version 10.12.5</p>

<p>What should I do to specify Xcode version in bazel to avoid this error? It seems that the error is common but I haven't found how I can make the bazel build.
P.S I'm trying to install tensorflow-serving the way it's explained here.
<a href=""https://tensorflow.github.io/serving/setup"" rel=""noreferrer"">https://tensorflow.github.io/serving/setup</a></p>
",7574860.0,,7574860.0,,2019-07-24 14:28:39,2019-07-24 14:28:39,Xcode version must be specified to use an Apple CROSSTOOL,<tensorflow><bazel><tensorflow-serving>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45276830
38212205,1,38212561,,2016-07-05 20:31:08,,45,39692,"<p>I have a tensor of shape <code>(30, 116, 10)</code>, and I want to swap the first two dimensions, so that I have a tensor of shape <code>(116, 30, 10)</code></p>

<p>I saw that numpy as such a function implemented (<code>np.swapaxes</code>) and I searched for something similar in tensorflow but I found nothing.</p>

<p>Do you have any idea?</p>
",5048273.0,,3924118.0,,2019-04-27 14:56:02,2022-07-07 00:08:22,How do I swap tensor's axes in TensorFlow?,<tensorflow><axis><swap><axes><permute>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38212205
33655731,1,33699100,,2015-11-11 16:58:54,,45,76211,"<p>I have installed the Tensorflow bindings with python successfully. But when I try to import Tensorflow, I get the follwoing error.</p>

<pre><code>ImportError: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.17' not found (required by /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so)
</code></pre>

<p>I have tried to update GLIBC_2.15 to 2.17, but no luck.</p>
",5551505.0,,9190768.0,,2018-07-04 03:45:36,2019-08-25 02:25:50,Error while importing Tensorflow in Python 2.7 in Ubuntu 12.04. 'GLIBC_2.17 not found',<python><ubuntu><glibc><tensorflow>,14,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/33655731
33616732,1,33616733,,2015-11-09 19:32:04,,45,96055,"<p>just installed tensorflow using pip with the command:</p>

<p><code>$ pip install tensorflow</code></p>

<p>On the <a href=""http://tensorflow.org/get_started/os_setup.md"">""Getting Started"" for Tensorflow</a> they have an example for convolutional neural networks</p>

<p><code>$ python tensorflow/models/image/mnist/convolutional.py</code></p>

<p>Where is that directory located when installing with pip?</p>
",3767229.0,,,,,2020-07-13 03:30:29,"Where is the folder for Installing tensorflow with pip, Mac OSX?",<python><macos><tensorflow>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33616732
42816124,1,42817280,,2017-03-15 16:56:50,,45,27424,"<p>I am going through TensorFlow <a href=""https://www.tensorflow.org/get_started/get_started"" rel=""nofollow noreferrer"">get started tutorial</a>. In the <code>tf.contrib.learn</code> example, these are two lines of code:</p>

<pre><code>input_fn = tf.contrib.learn.io.numpy_input_fn({""x"":x}, y, batch_size=4, num_epochs=1000)
estimator.fit(input_fn=input_fn, steps=1000)
</code></pre>

<p>I am wondering what is the difference between argument <code>steps</code> in the call to <code>fit</code> function and <code>num_epochs</code> in the <code>numpy_input_fn</code> call. Shouldn't there be just one argument? How are they connected? </p>

<p>I have found that code is somehow taking the <code>min</code> of these two as the number of steps in the toy example of the tutorial.</p>

<p>At least, one of the two parameters either <code>num_epochs</code> or <code>steps</code> has to be redundant. We can calculate one from the other. Is there a way I can know how many steps (number of times parameters get updated) my algorithm actually took? </p>

<p>I am curious about which one takes precedence. And does it depend on some other parameters?</p>
",1953366.0,,3924118.0,,2019-10-29 16:46:17,2019-10-29 16:46:17,What is the relationship between steps and epochs in TensorFlow?,<tensorflow>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42816124
34715055,1,34715397,,2016-01-11 05:57:40,,45,73966,"<p>Is there any noticeable difference in TensorFlow performance if using Quadro GPUs vs GeForce GPUs? </p>

<p><strong>e.g. does it use double precision operations or something else that would cause a drop in GeForce cards?</strong></p>

<p>I am about to buy a GPU for TensorFlow, and wanted to know if a GeForce would be ok. Thanks and appreciate your help</p>
",2771184.0,,,user359135,2016-11-30 14:20:10,2018-01-31 04:27:33,Choosing between GeForce or Quadro GPUs to do machine learning via TensorFlow,<machine-learning><gpu><gpgpu><tensorflow>,1,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34715055
34875944,1,37573411,,2016-01-19 11:44:35,,45,66566,"<p>I am new to <code>tensorflow</code>. I want to write my own custom loss function. Is there any tutorial about this? For example, the hinge loss or a sum_of_square_loss(though this is already in tf)?
Can I do it directly in python or I have to write the cpp code?</p>
",5576325.0,,5576325.0,,2016-01-19 11:56:30,2021-03-19 09:35:06,How to write a custom loss function in Tensorflow?,<tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34875944
36584907,1,56436392,,2016-04-12 22:06:22,,44,47090,"<p>Having installed tensorflow GPU (running on a measly NVIDIA GeForce 950), I would like to compare performance with the CPU. </p>

<p>I am running the tensorFlow MNIST tutorial code, and have noticed a dramatic increase in speed--estimated anyways (I ran the CPU version 2 days ago on a laptop i7 with a batch size of 100, and this on a desktop GPU, batch size of 10)--between the CPU and the GPU when I switched...but I only noticed the speed increase when I lowered the batch size on the GPU to 10 from 100...</p>

<p>Now I lack an objective measure for what I am gaining.  </p>

<p>Is there a way to toggle between the CPU and GPU tensor flows?</p>
",3834415.0,,,,,2020-12-13 05:39:26,Tensor flow toggle between CPU/GPU,<tensorflow>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36584907
35361467,1,35367161,,2016-02-12 11:28:07,,44,37954,"<p>I want to compare the predicted values <code>yp</code> from my neural network in a pairwise fashion, and so I was using (back in my old numpy implementation):</p>

<pre><code>idx = np.repeat(np.arange(len(yp)), len(yp))
jdx = np.tile(np.arange(len(yp)), len(yp))
s = yp[[idx]] - yp[[jdx]]
</code></pre>

<p>This basically create a indexing mesh which I then use. <code>idx=[0,0,0,1,1,1,...]</code> while <code>jdx=[0,1,2,0,1,2...]</code>. I do not know if there is a simpler manner of doing it...</p>

<p>Anyhow, TensorFlow has a <code>tf.tile()</code>, but it seems to be lacking a <code>tf.repeat()</code>.</p>

<pre><code>idx = np.repeat(np.arange(n), n)
v2 = v[idx]
</code></pre>

<p>And I get the error:</p>

<pre><code>TypeError: Bad slice index [  0   0   0 ..., 215 215 215] of type &lt;type 'numpy.ndarray'&gt;
</code></pre>

<p>It also does not work to use a TensorFlow constant for the indexing:</p>

<pre><code>idx = tf.constant(np.repeat(np.arange(n), n))
v2 = v[idx]
</code></pre>

<p>-</p>

<pre><code>TypeError: Bad slice index Tensor(""Const:0"", shape=TensorShape([Dimension(46656)]), dtype=int64) of type &lt;class 'tensorflow.python.framework.ops.Tensor'&gt;
</code></pre>

<p>The idea is to convert my <a href=""http://research.microsoft.com/en-us/um/people/cburges/papers/ICML_ranking.pdf"" rel=""noreferrer"">RankNet</a> implementation to TensorFlow.</p>
",2680707.0,,2680707.0,,2016-02-12 17:06:42,2022-10-27 12:52:35,TensorFlow: numpy.repeat() alternative,<tensorflow>,11,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35361467
43558707,1,43568508,,2017-04-22 11:32:58,,44,75913,"<p>I'm having problems in importing tensorflow in python3:</p>

<pre><code>&gt;&gt;&gt; import tensorflow as tf
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py"", line 24, in &lt;module&gt;
    from tensorflow.python import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py"", line 51, in &lt;module&gt;
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in &lt;module&gt;
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
</code></pre>

<p>I am using Nvidia drivers version 381.09 beta, as version 375 has this bug: <a href=""https://askubuntu.com/questions/896221/strange-artifacts-along-window-borders-after-waking-computer-from-sleep-mode?noredirect=1&amp;lq=1"">https://askubuntu.com/questions/896221/strange-artifacts-along-window-borders-after-waking-computer-from-sleep-mode?noredirect=1&amp;lq=1</a></p>

<p>I have install CUDA 8.0 and cuDNN-v6.0:</p>

<pre><code>rharish@rharish-GL552VW:~$ cd /usr/local
rharish@rharish-GL552VW:/usr/local$ ls
bin         cuda      etc    include  man   share
computecpp  cuda-8.0  games  lib      sbin  src
</code></pre>

<p>Also, libcusolver.so.8.0 exists in /usr/local/cuda/lib64/:</p>

<p><a href=""https://i.stack.imgur.com/ul5x4.jpg"" rel=""noreferrer"">libcusolver.so.8.0 in 'ls' output</a></p>

<p>I have uninstalled and reinstalled CUDA, cuDNN, and built tensorflow from sources. This problem has been occuring since updating the Nvidia drivers to version 381.09 beta. Any help?</p>
",7905483.0,,681865.0,,2017-04-22 12:28:59,2019-10-14 18:36:52,Tensorflow: ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory,<tensorflow>,5,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43558707
52624703,1,52627105,,2018-10-03 10:11:44,,43,39819,"<p>Recently, I wanted to move my Python libraries to a pendrive to keep all the libraries constant while switching between my workstation and laptop. (Also so that if I update one, it's updated on other also.)</p>
<p>For this, I have installed a tensorflow-gpu version on my pendrive (my laptop doesn't have a GPU). Everything works fine without a problem on both PC (it detects and uses my GPU without a problem) and laptop (it automatically uses my CPU).</p>
<p>That's where my question lies. What is the difference between a</p>
<pre><code>tensorflow-gpu 
</code></pre>
<p>AND just</p>
<pre><code>tensorflow
</code></pre>
<p>? (Because when no GPU is found, tensorflow-gpu automatically uses the CPU version.)</p>
<p>Does the difference lie only in the GPU support? Then why at all have a non GPU version of tensorflow?</p>
<p>Also, is it alright to proceed like this? Or should I create virtual environments to keep separate installations for CPU and GPU?</p>
<p>The closest answer I can find is
<a href=""https://stackoverflow.com/questions/45290326/how-to-develope-for-tensor-flow-with-gpu-without-a-gpu"">How to develop for tensor flow with gpu without a gpu</a>.</p>
<p>But it only specifies that it's completely okay to use tensorflow-gpu on a CPU platform, but it still does not answer my first question. Also, the answer might be outdated as tensorflow keeps releasing new updates.</p>
<p>I had installed the tensorflow-gpu version on my workstation with GTX 1070 (Thus a successful install).</p>
<p>Also I understand the difference is that <code>pip install tensorflow-gpu</code> will require CUDA enabled device to install, but my question is more towards the usage of the libraries because I am not getting any problems when using the <code>tensorflow-gpu</code> version on my laptop (with no GPU) and all my scripts run without any error.</p>
<p>(Also removed pip install from above to avoid confusion)</p>
<p>Also, isn't running <code>tensorflow-gpu</code> on a system with no GPU the same as setting <code>CUDA_VISIBLE_DEVICES=-1</code>?</p>
",5937211.0,,3964927.0,,2021-04-23 01:22:02,2021-04-23 01:22:02,Difference between installation libraries of Tensorflow GPU vs CPU,<python><tensorflow>,3,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52624703
58012741,1,58064287,,2019-09-19 13:59:03,,43,62657,"<p>I am running this simple code on Spyder 3.3 with Python 3.7 and Tensorlow 2.0:</p>

<pre><code>import tensorflow as tf
print(tf.__version__)
</code></pre>

<p>When I try to run it again in the same IPython console, I get the following error:</p>

<blockquote>
  <p>File ""/home/rodrigo/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/monitoring.py"", line 121, in <strong>init</strong>
      self._metric = self._metric_methods[self._label_length].create(*args)</p>
  
  <p>AlreadyExistsError: Another metric with the same name already exists.</p>
</blockquote>

<p>If I close the IPython console, and then open it again, it works fine. I am getting this error in every code that imports Tensorflow. <strong>Does anyone know how to solve this?</strong></p>

<p>System configuration:</p>

<ul>
<li>Ubuntu 19.04 </li>
<li>Spyder 3.3.2</li>
<li>Python 3.7.3</li>
<li>IPython 5.8.0</li>
<li>TensorFlow 2.0.0-rc2</li>
</ul>
",8682939.0,,,,,2022-11-03 19:08:22,"Error importing tensorflow ""AlreadyExistsError: Another metric with the same name already exists.""",<python><tensorflow>,17,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58012741
45544928,1,45552938,,2017-08-07 10:37:50,,43,17467,"<p>I was following <a href=""https://medium.com/towards-data-science/how-to-deploy-machine-learning-models-with-tensorflow-part-2-containerize-it-db0ad7ca35a7"" rel=""noreferrer"">this</a> tutorial to use <code>tensorflow serving</code> using my object detection model. I am using <a href=""https://github.com/tensorflow/models/tree/master/object_detection"" rel=""noreferrer"">tensorflow object detection</a> for generating the model. I have created a frozen model using <a href=""https://github.com/tensorflow/models/blob/master/object_detection/g3doc/exporting_models.md"" rel=""noreferrer"">this</a> exporter (the generated frozen model <strong>works</strong> using python script).</p>
<p>The frozen graph directory has following contents ( nothing on <code>variables</code> directory)</p>
<blockquote>
<p>variables/</p>
<p>saved_model.pb</p>
</blockquote>
<p>Now when I try to serve the model using the following command,</p>
<pre><code>tensorflow_model_server --port=9000 --model_name=ssd --model_base_path=/serving/ssd_frozen/
</code></pre>
<p>It always shows me</p>
<blockquote>
<p>...</p>
<p>tensorflow_serving/model_servers/server_core.cc:421]  (Re-)adding
model: ssd 2017-08-07 10:22:43.892834: W
tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:262]
No versions of servable ssd found under base path /serving/ssd_frozen/
2017-08-07 10:22:44.892901: W
tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:262]
No versions of servable ssd found under base path /serving/ssd_frozen/</p>
<p>...</p>
</blockquote>
",5330223.0,,-1.0,,2020-06-20 09:12:55,2021-01-25 17:15:52,Tensorflow serving No versions of servable <MODEL> found under base path,<tensorflow><deep-learning><object-detection><tensorflow-serving>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45544928
34597316,1,34597667,,2016-01-04 18:17:25,,43,15260,"<p>I can't understand why dropout works like this in tensorflow. The blog of <a href=""http://cs231n.github.io/neural-networks-2/"">CS231n</a> says that, <code>""dropout is implemented by only keeping a neuron active with some probability p (a hyperparameter), or setting it to zero otherwise.""</code> Also you can see this from picture(Taken from the same site)
<a href=""https://i.stack.imgur.com/SbXq1.jpg""><img src=""https://i.stack.imgur.com/SbXq1.jpg"" alt=""enter image description here""></a></p>

<p>From tensorflow site, <code>With probability keep_prob, outputs the input element scaled up by 1 / keep_prob, otherwise outputs 0.</code></p>

<p>Now, why the input element is scaled up by <code>1/keep_prob</code>? Why not keep the input element as it is with probability and not scale it with <code>1/keep_prob</code>? </p>
",4341948.0,,2838606.0,,2016-01-05 01:40:40,2022-03-08 09:47:43,Why input is scaled in tf.nn.dropout in tensorflow?,<machine-learning><neural-network><deep-learning><tensorflow>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34597316
37902705,1,37915182,,2016-06-19 00:02:23,,43,24265,"<p>I often want to log python variables --as opposed to tf tensors.</p>

<p>In the docs it says that ""you can pass a <code>tf.Summary</code> protocol buffer that you populate with your own data"" but there is no docs for <code>tf.Summary</code> and i could not figure out how to use it.</p>

<p>Anyone knows how to create a Scalar summary this way?</p>
",6108836.0,,,,,2018-05-13 18:29:00,How to manually create a tf.Summary(),<tensorflow>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37902705
49083984,1,49087542,,2018-03-03 12:14:42,,43,66505,"<p>I tried to replace the training and validation data with local images. But when running the training code, it came up with the error : </p>

<blockquote>
  <p>ValueError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].</p>
</blockquote>

<p>I don't know how to fix it up. There is no visible variable in the model definition code. The code was modified from TensorFlow tutorial. The images are jpgs. </p>

<p>Here is the detail Error message:</p>

<pre><code>INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_is_chief': True, '_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_session_config': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_service': None, '_keep_checkpoint_max': 5, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x00000288088D50F0&gt;, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_master': '', '_save_summary_steps': 100, '_num_ps_replicas': 0, '_task_id': 0}
Traceback (most recent call last):
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\tf_exe_5_make_image_lables\cnn_mnist.py"", line 214, in &lt;module&gt;
    tf.app.run()
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\platform\app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""D:\tf_exe_5_make_image_lables\cnn_mnist.py"", line 203, in main
    hooks=[logging_hook])
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 314, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 743, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 725, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""D:\tf_exe_5_make_image_lables\cnn_mnist.py"", line 67, in cnn_model_fn
    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\losses\losses_impl.py"", line 790, in sparse_softmax_cross_entropy
    labels, logits, weights, expected_rank_diff=1)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\losses\losses_impl.py"", line 720, in _remove_squeezable_dimensions
    labels, predictions, expected_rank_diff=expected_rank_diff)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\confusion_matrix.py"", line 76, in remove_squeezable_dimensions
    labels = array_ops.squeeze(labels, [-1])
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 2490, in squeeze
    return gen_array_ops._squeeze(input, axis, name)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 7049, in _squeeze
    ""Squeeze"", input=input, squeeze_dims=axis, name=name)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 3162, in create_op
    compute_device=compute_device)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 3208, in _create_op_helper
    set_shapes_for_outputs(op)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2427, in set_shapes_for_outputs
    return _set_shapes_for_outputs(op)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2400, in _set_shapes_for_outputs
    shapes = shape_func(op)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2330, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""C:\Users\ASUS\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [100,3].
&gt;&gt;&gt; 
</code></pre>

<p>Here is my code:</p>

<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

#imports
import numpy as np
import tensorflow as tf
import glob
import cv2
import random
import matplotlib.pylab as plt
import pandas as pd
import sys as system
from mlxtend.preprocessing import one_hot
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder


tf.logging.set_verbosity(tf.logging.INFO)

def cnn_model_fn(features, labels, mode):
    """"""Model function for CNN""""""
    #Input Layer
    input_layer = tf.reshape(features[""x""], [-1,320,320,3])
    #Convolutional Layer #1
    conv1 = tf.layers.conv2d(
        inputs = input_layer,
        filters = 32,
        kernel_size=[5,5],
        padding = ""same"",
        activation=tf.nn.relu)

    #Pooling Layer #1
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2,2], strides=2)

    #Convolutional Layer #2 and Pooling Layer #2
    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=64,
        kernel_size=[5,5],
        padding=""same"",
        activation=tf.nn.relu)
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2,2], strides=2)

    #Dense Layer
    pool2_flat = tf.reshape(pool2, [-1,80*80*64])
    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
    dropout = tf.layers.dropout(
        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

    #Logits Layer
    logits = tf.layers.dense(inputs=dropout, units=3)

    predictions = {
        #Generate predictions (for PREDICT and EVAL mode)
        ""classes"": tf.argmax(input=logits, axis=1),
        #Add 'softmax_tensor' to the graph. It is used for PREDICT and by the
        #'logging_hook'
        ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")
    }

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    # Calculate Loss (for both TRAIN and EVAL modes
    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)


# Configure the Training Op (for TRAIN mode)
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(
            loss=loss,
            global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

    # Add evaluation metrics (for EVAL mode)
    eval_metric_ops = {
        ""accuracy"": tf.metrics.accuracy(
            labels=labels, predictions=predictions[""classes""])}
    return tf.estimator.EstimatorSpec(
        mode=mode, loss=loss,eval_metric_ops=eval_metric_ops)

def main(unused_argv):
    '''
    #Load training and eval data
    mnist = tf.contrib.learn.datasets.load_dataset(""mnist"")
    train_data = mnist.train.images
    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
    eval_data = mnist.test.images
    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)
    '''
    #Load cats, dogs and cars image in local folder
    X_data = []
    files = glob.glob(""data/cats/*.jpg"")
    for myFile in files:
        image = cv2.imread (myFile)
        imgR = cv2.resize(image, (320, 320))
        imgNR = imgR/255
        X_data.append(imgNR)

    files = glob.glob(""data/dogs/*.jpg"")
    for myFile in files:
        image = cv2.imread (myFile)
        imgR = cv2.resize(image, (320, 320))
        imgNR = imgR/255
        X_data.append(imgNR)

    files = glob.glob (""data/cars/*.jpg"")
    for myFile in files:
        image = cv2.imread (myFile)
        imgR = cv2.resize(image, (320, 320))
        imgNR = imgR/255
        X_data.append (imgNR)
    #print('X_data count:', len(X_data))

    X_data_Val = []
    files = glob.glob (""data/Validation/cats/*.jpg"")
    for myFile in files:
        image = cv2.imread (myFile)
        imgR = cv2.resize(image, (320, 320))
        imgNR = imgR/255
        X_data_Val.append (imgNR)

    files = glob.glob (""data/Validation/dogs/*.jpg"")
    for myFile in files:
        image = cv2.imread (myFile)
        imgR = cv2.resize(image, (320, 320))
        imgNR = imgR/255
        X_data_Val.append (imgNR)

    files = glob.glob (""data/Validation/cars/*.jpg"")
    for myFile in files:
        image = cv2.imread (myFile)
        imgR = cv2.resize(image, (320, 320))
        imgNR = imgR/255
        X_data_Val.append (imgNR)


    #Feed One hot lables
    Y_Label = np.zeros(shape=(300,1))
    for el in range(0,100):
        Y_Label[el]=[0]
    for el in range(101,200):
        Y_Label[el]=[1]
    for el in range(201,300):
        Y_Label[el]=[2]
    onehot_encoder = OneHotEncoder(sparse=False)
    #Y_Label_RS = Y_Label.reshape(len(Y_Label), 1)
    Y_Label_Encode = onehot_encoder.fit_transform(Y_Label)

    #print('Y_Label_Encode shape:', Y_Label_Encode.shape)


    Y_Label_Val = np.zeros(shape=(30,1))
    for el in range(0, 10):
        Y_Label_Val[el]=[0]
    for el in range(11, 20):
        Y_Label_Val[el]=[1]
    for el in range(21, 30):
        Y_Label_Val[el]=[2]

    #Y_Label_Val_RS = Y_Label_Val.reshape(len(Y_Label_Val), 1)
    Y_Label_Val_Encode = onehot_encoder.fit_transform(Y_Label_Val)

    #print('Y_Label_Val_Encode shape:', Y_Label_Val_Encode.shape)

    train_data = np.array(X_data)
    train_data = train_data.astype(np.float32)
    train_labels = np.asarray(Y_Label_Encode, dtype=np.int32)

    eval_data = np.array(X_data_Val)
    eval_data = eval_data.astype(np.float32)
    eval_labels = np.asarray(Y_Label_Val_Encode, dtype=np.int32)

    print(train_data.shape)
    print(train_labels.shape)

    #Create the Estimator
    mnist_classifier = tf.estimator.Estimator(
        model_fn=cnn_model_fn, model_dir=""/tmp/mnist_convnet_model"")
    # Set up logging for predictions
    tensor_to_log = {""probabilities"": ""softmax_tensor""}
    logging_hook = tf.train.LoggingTensorHook(
        tensors=tensor_to_log, every_n_iter=50)


    # Train the model
    train_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": train_data},
        y=train_labels,
        batch_size=100,
        num_epochs=None,
        shuffle=True)



    mnist_classifier.train(
        input_fn=train_input_fn,
        #original steps are 20000
        steps=1, 
        hooks=[logging_hook])
    # Evaluate the model and print results
    eval_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": eval_data},
        y=eval_labels,
        num_epochs=1,
        shuffle=False)
    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
    print(eval_results)

if __name__ == ""__main__"":
    tf.app.run()
</code></pre>
",9418182.0,,7248342.0,,2018-03-03 12:38:11,2021-02-28 14:27:46,"ValueError: Can not squeeze dim[1], expected a dimension of 1, got 3 for 'sparse_softmax_cross_entropy_loss",<python><tensorflow>,7,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49083984
51797280,1,51797601,,2018-08-11 06:57:58,,42,17204,"<p>I've recently started coding with Machine learning techniques and had been going back and forth between Machine learning implemented in different platforms. The frameworks i worked a lot with were <strong>Tensorflow</strong> (Python), <strong>Tensorflow.js</strong> and <strong>Brain.js</strong>. And i've got couple of doubts about them.</p>

<ol>
<li>Why do most of them prefer Tensorflow (Python) over Tensorflow.js. What does Tensorflow has that Tensorflow.js doesn't which makes it special?</li>
<li>Most people i've seen in the internet prefer working with Tensorflow.js than brain.js, even though brain.js uses JSON objects which doesnt put the developer in a hassle to create Tensors and make memory management and stuff. Why do people prefer working with Tensorflow.js even though brain.js is easy to implement?</li>
<li>If i'm making a web site which uses Node.js as a backend, which would be the preferable library to be implemented for Machine Learning in a long run? Tensorflow.js or Brain.js? or should i use Tensorflow separately for just Machine learning things?</li>
</ol>

<p>I've been searching a lot on these topics. And i haven't got a nice explanation for my doubts yet. So expecting a clear and detail exaplanation :)</p>
",,user10140016,4685471.0,,2018-08-11 09:49:05,2018-08-11 09:49:05,Machine Learning : Tensorflow v/s Tensorflow.js v/s Brain.js,<tensorflow><machine-learning><tensorflow.js><brain.js>,1,1,0.0,2018-08-11 18:45:27,,CC BY-SA 4.0,https://stackoverflow.com/q/51797280
38545362,1,38895052,,2016-07-23 18:52:32,,42,57004,"<p>I want a piece of code that creates a variable within a scope if it doesn't exist, and access the variable if it already exists. I need it to be the <strong>same</strong> code since it will be called multiple times. </p>

<p>However, Tensorflow needs me to specify whether I want to create or reuse the variable, like this:</p>

<pre><code>with tf.variable_scope(""foo""): #create the first time
    v = tf.get_variable(""v"", [1])

with tf.variable_scope(""foo"", reuse=True): #reuse the second time
    v = tf.get_variable(""v"", [1])
</code></pre>

<p>How can I get it to figure out whether to create or reuse it automatically? I.e., I want the above two blocks of code to be the <strong>same</strong> and have the program run. </p>
",2430739.0,,5140223.0,,2018-12-17 17:30:05,2018-12-17 17:30:05,Tensorflow variable scope: reuse if variable exists,<python><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38545362
35365007,1,43960730,,2016-02-12 14:26:17,,42,70678,"<p>I would like to know if there is a way to implement the different score function from the scikit learn package like this one :</p>

<pre><code>from sklearn.metrics import confusion_matrix
confusion_matrix(y_true, y_pred)
</code></pre>

<p>into a tensorflow model to get the different score.</p>

<pre><code>with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
init = tf.initialize_all_variables()
sess.run(init)
for epoch in xrange(1):
        avg_cost = 0.
        total_batch = len(train_arrays) / batch_size
        for batch in range(total_batch):
                train_step.run(feed_dict = {x: train_arrays, y: train_labels})
                avg_cost += sess.run(cost, feed_dict={x: train_arrays, y: train_labels})/total_batch
        if epoch % display_step == 0:
                print ""Epoch:"", '%04d' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost)

print ""Optimization Finished!""
correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
# Calculate accuracy
accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
print ""Accuracy:"", batch, accuracy.eval({x: test_arrays, y: test_labels})
</code></pre>

<p>Will i have to run the session again to get the prediction ?</p>
",4190832.0,,,,,2020-03-20 10:12:22,Tensorflow Precision / Recall / F1 score and Confusion matrix,<python><machine-learning><scikit-learn><tensorflow>,5,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35365007
36150834,1,36156697,,2016-03-22 09:40:16,,42,15561,"<p>I wonder if this is the correct understanding: </p>

<p>All tensors are derived from some operation, and operations are either given a name in the constructor, or given the default name for a particular kind of operation. If the name is not unique, TensorFlow automatically handles this by appending <code>""_1""</code>, <code>""_2""</code>, etc. An operation with n tensor outputs name these tensors <code>""op_name:0""</code>, <code>""op_name:1""</code>, ..., <code>""op_name:n-1""</code>.</p>

<p>One problem seems to arise: if <code>x</code> is a <code>tf.Variable</code>, then <code>x.name</code> gives <code>""variable_name:0""</code>. This is confusing: to what does <code>""variable_name""</code> refer?</p>
",6093883.0,,3924118.0,,2018-01-03 20:09:12,2018-10-05 09:54:40,How does TensorFlow name tensors?,<tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36150834
33648167,1,33648339,,2015-11-11 10:01:41,,41,12260,"<p>In some of the places, I saw the syntax, where variables are initialized with names, sometimes without names. For example:</p>

<pre><code># With name
var = tf.Variable(0, name=""counter"")

# Without
one = tf.constant(1)
</code></pre>

<p>What is the point of naming the variable <code>var</code> <code>""counter""</code>?</p>
",4165313.0,,3924118.0,,2017-11-13 17:49:28,2018-08-23 19:30:35,Why do we name variables in Tensorflow?,<python><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33648167
36533723,1,36536063,,2016-04-10 18:24:01,,41,65299,"<p>I have some variables created within a certain scope like this:</p>

<pre><code>with tf.variable_scope(""my_scope""):
  createSomeVariables()
  ...
</code></pre>

<p>I then want to get the list of all the variables in ""my_scope"" so I can pass it to an optimizer. What is the right way to do this?</p>
",1595417.0,,,,,2017-11-17 20:07:32,Tensorflow get all variables in scope,<tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36533723
40879504,1,40881670,,2016-11-30 03:00:39,,41,59996,"<p>Drop-Out is regularization techniques. And I want to apply it to notMNIST data to reduce over-fitting to finish my Udacity Deep Learning Course Assignment.I have read the <a href=""https://www.tensorflow.org/versions/r0.12/tutorials/mnist/pros/index.html"" rel=""noreferrer"">docs of tensorflow</a> on how to call the <code>tf.nn.dropout</code>. And here is my code</p>

<pre class=""lang-py prettyprint-override""><code># before proceeding further.
from __future__ import print_function
import numpy as np  
import tensorflow as tf
from six.moves import cPickle as pickle


pickle_file = 'notMNIST.pickle'

with open(pickle_file, 'rb') as f:
    save = pickle.load(f)
    train_dataset = save['train_dataset']
    train_labels = save['train_labels']
    valid_dataset = save['valid_dataset']
    valid_labels = save['valid_labels']
    test_dataset = save['test_dataset']
    test_labels = save['test_labels']
    del save  # hint to help gc free up memory
    print('Training set', train_dataset.shape, train_labels.shape)
    print('Validation set', valid_dataset.shape, valid_labels.shape)
    print('Test set', test_dataset.shape, test_labels.shape)


image_size = 28
num_labels = 10

def reformat(dataset, labels):
    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)
    # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]
    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)
    return dataset, labels

    train_dataset, train_labels = reformat(train_dataset, train_labels)
    valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)
    test_dataset, test_labels = reformat(test_dataset, test_labels)
    print('Training set', train_dataset.shape, train_labels.shape)
    print('Validation set', valid_dataset.shape, valid_labels.shape)
    print('Test set', test_dataset.shape, test_labels.shape)

    def accuracy(predictions, labels):
        return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))  / predictions.shape[0])


# ReLU neuron
# param
training_epochs = 30
batch_size = 521
display_step = 1
n_input = 784 # img shape: 28*28
n_classes = 10 # MNIST total classes (0-9 digits)

# hyper-parameter
n_hidden_1 = 256 
learning_rate = 0.05
lambda_term = 0.01


graph = tf.Graph()
with graph.as_default():
    # init weights
    weights_hiden =  tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=np.sqrt(n_input)))
    weights_out = tf.Variable(tf.random_normal([n_hidden_1, n_classes], stddev=np.sqrt(n_hidden_1)))

    biases_hidden = tf.Variable(tf.random_normal([n_hidden_1]))
    biases_out = tf.Variable(tf.random_normal([n_classes]))

    x = tf.placeholder(""float"", [None, n_input])
    y = tf.placeholder(""float"", [None, n_classes])

    def model(x, weights_hiden, weights_out, biases_hidden, biases_out):
        # hidden layer with RELU activation
        layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights_hiden), biases_hidden))
        # apply DropOut to hidden layer
        keep_prob = tf.placeholder(tf.float32)  # DROP-OUT here
        drop_out = tf.nn.dropout(layer_1, keep_prob)  # DROP-OUT here
        # output layer with linear activation
        out_layer = tf.matmul(layer_1, weights_out) + biases_out
        return out_layer

    # Construct model
    pred = model(x, weights_hiden, weights_out, biases_hidden, biases_out)

    # Define loss and optimizer
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y) +
                          lambda_term * tf.nn.l2_loss(weights_hiden) + 
                          lambda_term * tf.nn.l2_loss(weights_out) +
                          lambda_term * tf.nn.l2_loss(biases_hidden) + 
                          lambda_term * tf.nn.l2_loss(biases_out))
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)


# run the graph
with tf.Session(graph=graph) as sess:
    tf.initialize_all_variables().run()
    print('Initialized')
    # Training cycle
    for epoch in range(training_epochs):
        avg_cost = 0.
        total_batch = int(train_dataset.shape[0]/batch_size)
        # Loop over all batches
        for i in range(total_batch):
            batch_x = train_dataset[(i*batch_size):((i*batch_size) + batch_size), :]
            batch_y = train_labels[(i*batch_size):((i*batch_size) + batch_size), :]
            # Run optimization op (backprop) and cost op (to get loss value)
            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})
            # Compute average loss
            avg_cost += c / total_batch
        # Display logs per epoch step
        if epoch % display_step == 0:
            print(""Epoch:"", '%04d' % (epoch+1), ""cost="", ""{:.9f}"".format(avg_cost))
    print(""Optimization Finished!"")

    # Test model
    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
    # Calculate accuracy
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
    print(""Test data accuracy:"", accuracy.eval({x: test_dataset, y: test_labels}))
    print(""Valid data accuracy:"", accuracy.eval({x: valid_dataset, y: valid_labels}))
</code></pre>

<p>The <code>tf.nn.dropout</code> is called in function <code>model()</code>, but after I applied the DropOut technique to the neural network, the accuracy did seem any change, here is the result:</p>

<pre><code>Epoch: 0001 cost= 579980.086977807
Epoch: 0002 cost= 238859.802382506
Epoch: 0003 cost= 90672.733752856
Epoch: 0004 cost= 32649.040985028
Epoch: 0005 cost= 11325.878361874
Epoch: 0006 cost= 3866.805511076
Epoch: 0007 cost= 1357.785540469
Epoch: 0008 cost= 519.381747333
Epoch: 0009 cost= 225.359804119
Epoch: 0010 cost= 110.099476707
Epoch: 0011 cost= 55.212384386
Epoch: 0012 cost= 28.469241683
Epoch: 0013 cost= 14.511494627
Epoch: 0014 cost= 6.567228943
Epoch: 0015 cost= 3.186372240
Epoch: 0016 cost= 1.701917576
Epoch: 0017 cost= 1.041632473
Epoch: 0018 cost= 0.843376874
Epoch: 0019 cost= 0.786183911
Epoch: 0020 cost= 0.775412846
Epoch: 0021 cost= 0.782965020
Epoch: 0022 cost= 0.796788171
Epoch: 0023 cost= 0.814522117
Epoch: 0024 cost= 0.832090579
Epoch: 0025 cost= 0.849197715
Epoch: 0026 cost= 0.867473578
Epoch: 0027 cost= 0.889561496
Epoch: 0028 cost= 0.921837020
Epoch: 0029 cost= 16.655304543
Epoch: 0030 cost= 1.421570476
Optimization Finished!
Test data accuracy: 0.8775
Valid data accuracy: 0.8069
</code></pre>

<p>How can I apply DropOut by Tensorflow to improve the accuracy of the network? Thank you!</p>
",5046896.0,,5046896.0,,2017-07-19 01:08:30,2017-08-01 13:54:17,How to apply Drop Out in Tensorflow to improve the accuracy of neural network?,<neural-network><tensorflow><deep-learning>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40879504
40910857,1,40911592,,2016-12-01 12:35:24,,41,30754,"<p>I have run deep learning models(CNN's) using tensorflow. Many times during the epoch, i have observed that both loss and accuracy have increased, or both have decreased. My understanding was that both are always inversely related. What could be scenario where both increase or decrease simultaneously.</p>
",3898714.0,,,,,2021-11-16 10:16:28,How to interpret increase in both loss and accuracy,<tensorflow><deep-learning><loss>,5,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40910857
37009647,1,37040451,,2016-05-03 16:36:35,,41,22035,"<p>I want to compute the pairwise square distance of a batch of feature in Tensorflow. I have a simple implementation using + and * operations by
tiling the original tensor :</p>

<pre><code>def pairwise_l2_norm2(x, y, scope=None):
    with tf.op_scope([x, y], scope, 'pairwise_l2_norm2'):
        size_x = tf.shape(x)[0]
        size_y = tf.shape(y)[0]
        xx = tf.expand_dims(x, -1)
        xx = tf.tile(xx, tf.pack([1, 1, size_y]))

        yy = tf.expand_dims(y, -1)
        yy = tf.tile(yy, tf.pack([1, 1, size_x]))
        yy = tf.transpose(yy, perm=[2, 1, 0])

        diff = tf.sub(xx, yy)
        square_diff = tf.square(diff)

        square_dist = tf.reduce_sum(square_diff, 1)

        return square_dist
</code></pre>

<p>This function takes as input two matrices of size (m,d) and (n,d) and compute the squared distance between each row vector. The output is a matrix of size (m,n) with element 'd_ij = dist(x_i, y_j)'.</p>

<p>The problem is that I have a large batch and high dim features 'm, n, d' replicating the tensor consume a lot of memory. 
I'm looking for another way to implement this without increasing the memory usage and just only store the final distance tensor. Kind of double looping the original tensor.</p>
",1259390.0,,1259390.0,,2016-05-04 06:54:12,2018-07-05 12:47:39,Compute pairwise distance in a batch without replicating tensor in Tensorflow?,<python><tensorflow>,4,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37009647
47859924,1,49193660,,2017-12-17 22:05:57,,41,31749,"<p>So I installed the GPU version of TensorFlow on a Windows 10 machine with a <code>GeForce GTX 980</code> graphics card on it.</p>

<p>Admittedly, I know very little about graphics cards, but according to dxdiag it does have:</p>

<p><code>4060MB</code> of dedicated memory (VRAM) and;</p>

<p><code>8163MB</code> of shared memory</p>

<p>for a total of about <code>12224MB</code>.</p>

<p>What I noticed, though, is that this ""shared"" memory seems to be pretty much useless. When I start training a model, the VRAM will fill up and if the memory requirement exceeds these <code>4GB</code>, TensorFlow will crash with a ""resource exhausted"" error message.</p>

<p>I CAN, of course, prevent reaching that point by choosing the batch size suitably low, but I do wonder if there's a way to make use of these ""extra"" <code>8GB</code> of RAM, or if that's it and TensorFlow requires the memory to be dedicated.</p>
",3322533.0,,6296561.0,,2018-03-07 15:23:41,2022-05-28 11:44:40,Use shared GPU memory with TensorFlow?,<tensorflow><shared-memory><vram>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47859924
46513923,1,47982699,,2017-10-01 15:33:02,,41,15790,"<p>I have a few questions regarding the <code>SavedModel</code> API, whose <a href=""https://www.tensorflow.org/programmers_guide/saved_model#overview_of_saving_and_restoring_models"" rel=""noreferrer"">documentation</a> I find leaves a lot of details unexplained.</p>

<p>The first three questions are about what to pass to the arguments of the <code>add_meta_graph_and_variables()</code> method of <code>tf.saved_model.builder.SavedModelBuilder</code>, while the fourth question is about why to use the <code>SavedModel</code> API over <code>tf.train.Saver</code>.</p>

<ol>
<li><p>What is the format of the <code>signature_def_map</code> argument? Do I normally need to set this argument when saving a model?</p></li>
<li><p>Similarly, What is the format of the <code>assets_collection</code> argument?</p></li>
<li><p>Why do you save a list of tags with a metagraph as opposed to just giving it a name (i.e. attaching just one unique tag to it)? Why would I add multiple tags to a given metagraph? What if I try to load a metagrpah from a <code>pb</code> by a certain tag, but multiple metagraphs in that <code>pb</code> match that tag?</p></li>
<li><p>The documentation argues that it is recommended to use <code>SavedModel</code> to save entire models (as opposed to variables only) in self-contained files. But <code>tf.train.Saver</code> also saves the graph in addition to the variables in a <code>.meta</code> file. So what are the advantages of using <code>SavedModel</code>? The documentation says</p></li>
</ol>

<blockquote>
  <p>When you want to save and load variables, the graph, and the graph's
  metadata--basically, when you want to save or restore your model--we
  recommend using SavedModel. SavedModel is a language-neutral,
  recoverable, hermetic serialization format. SavedModel enables
  higher-level systems and tools to produce, consume, and transform
  TensorFlow models.</p>
</blockquote>

<p>but this explanation is quite abstract and doesn't really help me understand what the advantages of <code>SavedModel</code> are. What would be concrete examples where <code>SavedModel</code> (as opposed to <code>tf.train.Saver</code>) would be better to use?</p>

<p>Please note that my question is not a duplicate of <a href=""https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model"">this question</a>. I'm not asking how to save a model, I am asking very specific questions about the properties of <code>SavedModel</code>, which is only one of multiple mechanisms TensorFlow provides to save and load models. None of the answers in the linked question touch on the <code>SavedModel</code> API (which, once again, is not the same as <code>tf.train.Saver</code>).</p>
",7517192.0,,7517192.0,,2017-10-02 14:52:31,2019-02-17 21:18:23,TensorFlow: How and why to use SavedModel,<python><tensorflow>,1,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46513923
34594198,1,34596212,,2016-01-04 15:14:04,,41,14989,"<p>I am trying to prefetch training data to hide I/O latency. I would like to write custom Python code that loads data from disk and preprocesses the data (e.g. by adding a context window). In other words, one thread does data preprocessing and the other does training. Is this possible in TensorFlow?</p>

<p>Update: I have a working example based on @mrry's example.</p>

<pre><code>import numpy as np
import tensorflow as tf
import threading

BATCH_SIZE = 5
TRAINING_ITERS = 4100

feature_input = tf.placeholder(tf.float32, shape=[128])
label_input = tf.placeholder(tf.float32, shape=[128])

q = tf.FIFOQueue(200, [tf.float32, tf.float32], shapes=[[128], [128]])
enqueue_op = q.enqueue([label_input, feature_input])

label_batch, feature_batch = q.dequeue_many(BATCH_SIZE)
c = tf.reshape(feature_batch, [BATCH_SIZE, 128]) + tf.reshape(label_batch, [BATCH_SIZE, 128])

sess = tf.Session()

def load_and_enqueue(sess, enqueue_op, coord):
  with open('dummy_data/features.bin') as feature_file, open('dummy_data/labels.bin') as label_file:
    while not coord.should_stop():
      feature_array = np.fromfile(feature_file, np.float32, 128)
      if feature_array.shape[0] == 0:
        print('reach end of file, reset using seek(0,0)')
        feature_file.seek(0,0)
        label_file.seek(0,0)
        continue
      label_value = np.fromfile(label_file, np.float32, 128)

      sess.run(enqueue_op, feed_dict={feature_input: feature_array,
                                      label_input: label_value})

coord = tf.train.Coordinator()
t = threading.Thread(target=load_and_enqueue, args=(sess,enqueue_op, coord))
t.start()

for i in range(TRAINING_ITERS):
  sum = sess.run(c)
  print('train_iter='+str(i))
  print(sum)

coord.request_stop()
coord.join([t])
</code></pre>
",1104696.0,,1104696.0,,2016-01-05 20:51:55,2017-07-21 14:28:21,How to prefetch data using a custom python function in tensorflow,<python><multithreading><latency><tensorflow><prefetch>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34594198
51125266,1,51126863,,2018-07-01 17:00:30,,41,47501,"<p>I have a tensorflow dataset based on one .tfrecord file. How do I split the dataset into test and train datasets? E.g. 70% Train and 30% test?</p>

<p>Edit:</p>

<p>My Tensorflow Version: 1.8
I've checked, there is no ""split_v"" function as mentioned in the possible duplicate. Also I am working with a tfrecord file.</p>
",5240684.0,,5240684.0,,2018-07-01 17:13:30,2020-12-30 01:31:08,How do I split Tensorflow datasets?,<tensorflow><tensorflow-datasets>,2,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51125266
40788785,1,40806185,,2016-11-24 14:22:10,,40,13926,"<p>Assuming I have a bunch of summaries defined like:</p>

<pre class=""lang-py prettyprint-override""><code>loss = ...
tf.scalar_summary(""loss"", loss)
# ...
summaries = tf.merge_all_summaries()
</code></pre>

<p>I can evaluate the <code>summaries</code> tensor every few steps on the training data and pass the result to a <code>SummaryWriter</code>.
The result will be noisy summaries, because they're only computed on one batch.</p>

<p>However, I would like to compute the summaries on the entire validation dataset.
Of course, I can't pass the validation dataset as a single batch, because it would be too big.
So, I'll get summary outputs for each validation batch.</p>

<p>Is there a way to average those summaries so that it appears as if the summaries have been computed on the entire validation set?</p>
",783758.0,,,,,2019-05-14 08:52:09,How to average summaries over multiple batches?,<tensorflow>,9,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40788785
37849322,1,37870634,,2016-06-16 03:18:40,,40,20524,"<p>I am new to TensorFlow. While I am reading the existing documentation, I found the term <code>tensor</code> really confusing. Because of it, I need to clarify the following questions:</p>

<ol>
<li>What is the relationship between <code>tensor</code> and <code>Variable</code>, <code>tensor</code><br>
vs. <code>tf.constant</code>, 'tensor' vs. <code>tf.placeholder</code>?</li>
<li>Are they all types of tensors?</li>
</ol>
",2452761.0,,606664.0,,2018-05-20 09:09:11,2022-08-18 10:01:35,How to understand the term `tensor` in TensorFlow?,<python><tensorflow><machine-learning><deep-learning><tensor>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/37849322
33679382,1,33680246,,2015-11-12 19:11:52,,40,94652,"<p>Suppose we have a variable:</p>

<pre><code>x = tf.Variable(...)
</code></pre>

<p>This variable can be updated during the training process using the <code>assign()</code> method.</p>

<p><em>What is the best way to get the current value of a variable?</em></p>

<p>I know we could use this:</p>

<pre><code>session.run(x)
</code></pre>

<p>But I'm afraid this would trigger a whole chain of operations.</p>

<p>In Theano, you could just do</p>

<pre><code>y = theano.shared(...)
y_vals = y.get_value()
</code></pre>

<p>I'm looking for the equivalent thing in TensorFlow.</p>
",3731804.0,,3924118.0,,2018-07-14 18:00:27,2019-07-09 10:10:48,How do I get the current value of a Variable?,<python><tensorflow>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/33679382
55392100,1,55392567,,2019-03-28 07:20:58,,40,90094,"<p>I would like to know if anyone knows how can I install tensorflow==2.0.0-alpha0 in a conda enviroment using python 3.7. Is it possible to use python 3.7 or do I have to downgrade to 3.6. Either way what is the command I need to use because the following don't find any package</p>

<pre><code>conda install tensorflow==2.0.0-alpha0
conda install tensorflow 
conda install tensorflow=2.0.0-alpha0
</code></pre>

<p>I am using fedora 29 and conda 4.6.8
Thanks!</p>
",8493740.0,,,,,2022-04-07 14:13:10,Install Tensorflow 2.0 in conda enviroment,<python><tensorflow><conda>,7,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55392100
38543850,1,38676842,,2016-07-23 16:15:43,,40,43500,"<p>The <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#image-dashboard"" rel=""noreferrer"">Image Dashboard</a> section of the Tensorboard ReadMe says:</p>

<blockquote>
  <p>Since the image dashboard supports arbitrary pngs, you can use this to embed custom visualizations (e.g. matplotlib scatterplots) into TensorBoard.</p>
</blockquote>

<p>I see how a pyplot image could be written to file, read back in as a tensor, and then used with tf.image_summary() to write it to TensorBoard, but this statement from the readme suggests there is a more direct way. Is there? If so, is there any further documentation and/or examples of how to do this efficiently?  </p>
",5587428.0,,913098.0,,2020-12-31 12:13:31,2021-07-06 17:36:57,How to Display Custom Images in Tensorboard (e.g. Matplotlib Plots)?,<python><tensorflow><matplotlib><pytorch><tensorboard>,8,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38543850
41074688,1,41083104,,2016-12-10 10:53:04,,39,23331,"<p>How can you write a python script to read Tensorboard log files, extracting the loss and accuracy and other numerical data, without launching the GUI <code>tensorboard --logdir=...</code>?</p>
",3993741.0,,,,,2022-08-22 09:00:25,How do you read Tensorboard files programmatically?,<python><machine-learning><tensorflow><tensorboard>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41074688
42497340,1,42497456,,2017-02-27 22:58:54,,39,56608,"<p>I have a numpy array data set with shape (100,10). Each row is a one-hot encoding. I want to transfer it into a nd-array with shape (100,) such that I transferred each vector row into a integer that denote the index of the nonzero index. Is there a quick way of doing this using numpy or tensorflow?</p>
",4188354.0,,7579547.0,,2018-11-15 07:27:33,2022-06-16 01:01:19,How to convert one-hot encodings into integers?,<python><numpy><tensorflow>,8,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42497340
36990476,1,43953246,,2016-05-02 19:45:56,,39,27714,"<p>I'd like print out the learning rate for each training step of my nn.</p>

<p>I know that Adam has an adaptive learning rate, but is there a way i can see this (for visualization in tensorboard)</p>
",697065.0,,,,,2022-07-05 07:54:55,Getting the current learning rate from a tf.train.AdamOptimizer,<tensorflow>,6,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36990476
33622842,1,33623372,,2015-11-10 04:24:02,,39,49462,"

<p>I installed TensorFlow on my Ubuntu 15.10 machine as instructed for CPU only:</p>

<pre class=""lang-sh prettyprint-override""><code>$ pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
</code></pre>

<p>Then when I run the Python REPL and import tensorflow, I get:</p>

<pre class=""lang-sh prettyprint-override""><code>$ python
Python 2.7.10 (default, Oct 14 2015, 16:09:02) 
[GCC 5.2.1 20151010] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import tensorflow as tf
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/phil/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 4, in &lt;module&gt;
   from tensorflow.python import *
  File ""/home/phil/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 13, in &lt;module&gt;
    from tensorflow.core.framework.graph_pb2 import *
  File ""/home/phil/.local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in &lt;module&gt;
    from tensorflow.core.framework import attr_value_pb2 as     tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/home/phil/.local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in &lt;module&gt;
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/home/phil/.local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in &lt;module&gt;
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/home/phil/.local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in &lt;module&gt;
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto \x12\ntensorflow\""d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
</code></pre>

<p>I have the Ubuntu protobuf-compiler package installed and it's version 2.6.1-1.2</p>
",46190.0,,2464597.0,,2017-08-24 03:07:33,2018-08-29 10:03:33,Error in python after 'import tensorflow': TypeError: __init__() got an unexpected keyword argument 'syntax',<ubuntu><tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33622842
38218174,1,38226516,,2016-07-06 07:12:20,,39,41862,"<p>I want to see the variables that are saved in a TensorFlow checkpoint along with their values. How can I find the variable names that are saved in a TensorFlow checkpoint?</p>

<p>I used <code>tf.train.NewCheckpointReader</code> which is explained <a href=""https://github.com/tensorflow/tensorflow/blob/861644c0bcae5d56f7b3f439696eefa6df8580ec/tensorflow/python/training/saver_test.py#L1203"" rel=""noreferrer"">here</a>. But, it is not given in the documentation of TensorFlow. Is there any other way?</p>
",806160.0,,429972.0,,2019-03-10 21:50:30,2021-03-17 07:40:10,How do I find the variable names and values that are saved in a checkpoint?,<tensorflow>,6,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38218174
33664651,1,33664749,,2015-11-12 04:51:26,,39,109377,"<p><a href=""https://stackoverflow.com/questions/33659424/tensorflow-mnist-example-not-running"">TensorFlow MNIST example not running with fully_connected_feed.py</a></p>

<p>I checked this out and realized that <code>input_data</code> was not built-in.  So I downloaded the whole folder from <a href=""https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/mnist/input_data.py"" rel=""noreferrer"">here</a>. How can I start the tutorial:</p>

<pre><code>import input_data
mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)


---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-6-a5af65173c89&gt; in &lt;module&gt;()
----&gt; 1 import input_data
      2 mnist = tf.input_data.read_data_sets(""MNIST_data/"", one_hot=True)

ImportError: No module named input_data
</code></pre>

<p>I'm using iPython (Jupyter) so do I need to change my working directory to this folder I downloaded? or can I add this to my <code>tensorflow</code> directory? If so, where do I add the files? I installed <code>tensorflow</code> with <code>pip</code> (on my OSX) and the current location is <code>~/anaconda/lib/python2.7/site-packages/tensorflow/__init__.py</code></p>

<p>Are these files meant to be accessed directly through <code>tensorflow</code> like <code>sklearn</code> datasets? or am I just supposed to cd into the directory and work from there? The example is not clear. </p>

<p>EDIT:</p>

<p>This post is very out-dated</p>
",678572.0,,678572.0,,2020-06-01 21:21:13,2021-01-21 17:05:05,import input_data MNIST tensorflow not working,<python><import><machine-learning><tensorflow><mnist>,15,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/33664651
40511562,1,40512652,,2016-11-09 16:20:16,,39,32908,"<p>I'm new to Tensorflow
I'm running a Deep learning Assignment from Udacity on iPython notebook.
<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/5_word2vec.ipynb"">link</a></p>

<p>And it has an error.</p>

<pre><code>AttributeError                            Traceback (most recent call last)
`&lt;ipython-input-18-3446420b5935&gt;` in `&lt;module&gt;`()
  2 
  3 with tf.Session(graph=graph) as session:
----&gt; 4   tf.global_variables_initializer().run()

AttributeError: 'module' object has no attribute 'global_variables_initializer'
</code></pre>

<p>Please help! How can I fix this? Thank you.</p>
",6477475.0,,434217.0,,2016-11-10 22:21:24,2022-03-07 11:28:56,TensorFlow 'module' object has no attribute 'global_variables_initializer',<python><tensorflow><deep-learning><word2vec>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40511562
41244421,1,41245540,,2016-12-20 14:17:17,,38,56121,"<p>I'm new to machine learning and neural networks. I know how to build a nonlinear classification model, but my current problem has a continuous output. I've been searching for information on neural network regression, but all I encounter is information on <strong>linear</strong> regression - nothing about <strong>nonlinear</strong> cases. Which is odd, because why would someone use neural networks to solve a simple linear regression anyway? Isn't that like killing a fly with a nuclear bomb?</p>

<p>So my question is this: what makes a neural network nonlinear? (Hidden layers? Nonlinear activation function?) Or do I have a completely wrong understanding of the word ""linear"" - can a linear regression NN accurately model datasets that are more complex than y=aX+b? Is the word ""linear"" used just as the opposite of ""logistic""?</p>

<p>(I'm planning to use TensorFlow, but the TensorFlow Linear Model Tutorial uses a binary classification problem as an example, so that doesn't help me either.)</p>
",7321233.0,,,,,2022-05-31 02:12:45,Linear vs nonlinear neural network?,<neural-network><tensorflow>,9,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41244421
35094899,1,35095052,,2016-01-29 22:06:41,,38,10636,"<p>What is the difference between </p>

<pre><code>   tf.add(x, y)
</code></pre>

<p>and </p>

<pre><code>   x + y
</code></pre>

<p>in TensorFlow? What would be different in your computation graph when you construct your graph with <code>+</code> instead of <code>tf.add()</code>? </p>

<p>More generally, are  <code>+</code> or other operations overloaded for tensors?</p>
",5540330.0,,3574081.0,,2016-01-29 22:19:11,2018-10-24 04:31:46,TensorFlow operator overloading,<python><machine-learning><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35094899
37326002,1,37327561,,2016-05-19 14:17:19,,38,32901,"<p>I created a <em><strong>trainable</strong> variable</em> in a scope. Later, I entered the same scope, set the scope to <code>reuse_variables</code>, and used <code>get_variable</code> to retrieve the same variable. However, I cannot set the variable's trainable property to <code>False</code>. My <code>get_variable</code> line is like:</p>

<pre><code>weight_var = tf.get_variable('weights', trainable = False)
</code></pre>

<p>But the variable <code>'weights'</code> is still in the output of <code>tf.trainable_variables</code>.</p>

<p>Can I set a shared variable's <code>trainable</code> flag to <code>False</code> by using <code>get_variable</code>?</p>

<p>The reason I want to do this is that I'm trying to reuse the low-level filters pre-trained from VGG net in my model, and I want to build the graph like before, retrieve the weights variable, and assign VGG filter values to the weight variable, and then keep them fixed during the following training step. </p>
",1913898.0,,3924118.0,,2018-01-04 02:52:23,2019-05-17 20:21:56,Is it possible to make a trainable variable not trainable?,<tensorflow><pre-trained-model>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37326002
33748552,1,33770771,,2015-11-17 03:17:24,,38,21119,"<p>If you have two disjoint graphs, and want to link them, turning this:</p>

<pre><code>x = tf.placeholder('float')
y = f(x)

y = tf.placeholder('float')
z = f(y)
</code></pre>

<p>into this:</p>

<pre><code>x = tf.placeholder('float')
y = f(x)
z = g(y)
</code></pre>

<p>Is there a way to do that? It seems like it could make construction easier in some cases. </p>

<p>For example if you have a graph that has the input image as a <code>tf.placeholder</code>, and want to optimize the input image, deep-dream style, is there a way to just replace the placeholder with a <code>tf.variable</code> node? Or do you have to think of that before building the graph?</p>
",997378.0,,997378.0,,2015-11-17 13:11:03,2018-10-02 17:10:55,Tensorflow: How to replace a node in a calculation graph?,<python><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33748552
70520120,1,70563364,,2021-12-29 13:30:10,,38,46682,"<p>I was trying to train a model using tensorboard.
While executing, I got this error:</p>
<p><code>$ python train.py  Traceback (most recent call last): File &quot;train.py&quot;, line 6, in &lt;module&gt; from torch.utils.tensorboard import SummaryWriter   File &quot;C:\Users\91960\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\utils\tensorboard\__init__.py&quot;, line 4, in &lt;module&gt; LooseVersion = distutils.version.LooseVersion </code></p>
<p><code>AttributeError: module 'setuptools._distutils' has no attribute 'version'</code>.</p>
<p>I'm using python 3.8.9 64-bit &amp; tensorflow with distutils is already installed which is required by tensorboard.</p>
<p>Why is this happening ? Please help !</p>
",13896155.0,,,,,2023-05-02 17:57:27,AttributeError: module 'setuptools._distutils' has no attribute 'version',<python><tensorflow><tensorboard><distutils>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/70520120
52934795,1,52937580,,2018-10-22 17:34:42,,38,29237,"<p>I have a trained model (Faster R-CNN) which I exported using <code>export_inference_graph.py</code> to use for inference. I'm trying to understand the difference between the created <code>frozen_inference_graph.pb</code> and <code>saved_model.pb</code> and also <code>model.ckpt*</code> files. I've also seen <code>.pbtxt</code> representations.</p>

<p>I tried reading through this but couldn't really find the answers: <a href=""https://www.tensorflow.org/extend/tool_developers/"" rel=""noreferrer"">https://www.tensorflow.org/extend/tool_developers/</a></p>

<p>What do each of these files contain?
Which ones can be converted to which other ones?
What is the ideal purpose of each?</p>
",1185242.0,,,,,2020-11-07 00:38:15,What is difference frozen_inference_graph.pb and saved_model.pb?,<python><tensorflow><object-detection-api>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52934795
38542763,1,38543201,,2016-07-23 14:17:43,,38,23849,"<p>I've successfully installed tensorflow (GPU) on Linux Ubuntu 16.04 and made some small changes in order to make it work with the new Ubuntu LTS release.</p>

<p>However, I thought (who knows why) that my GPU met the minimum requirement of a compute capability greater than 3.5. That was not the case since my <a href=""http://www.geforce.com/hardware/notebook-gpus/geforce-820m"" rel=""noreferrer"">GeForce 820M</a> has just 2.1. Is there a way of making tensorflow GPU version working with my GPU?</p>

<p>I am asking this question since apparently there was no way of making tensorflow GPU version working on Ubuntu 16.04 but by searching the internet I found out that was not the case and indeed I made it almost work were it not for this unsatisfied requirement. Now I am wondering if this issue with GPU compute capability could be fixed as well.</p>
",3775577.0,,1695960.0,,2019-11-02 20:09:52,2019-11-02 20:09:52,How can I make tensorflow run on a GPU with capability 2.x?,<cuda><tensorflow><nvidia><cudnn>,3,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38542763
47465696,1,47495905,,2017-11-24 02:51:53,,38,35476,"<p>I am able to run a tensorflow container w/ access to the GPU from the command line w/ the following command</p>

<p><code>$ sudo docker run --runtime=nvidia --rm gcr.io/tensorflow/tensorflow:latest-gpu</code></p>

<p>I would like to be able to run this container from docker-compose. Is it possible to specify the <code>--runtime</code> flag from <code>docker-compose.yml</code>?</p>
",2313424.0,,,,,2018-08-28 18:04:47,How do I specify nvidia runtime from docker-compose.yml?,<docker><docker-compose><tensorflow><nvidia-docker>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47465696
49094597,1,49094955,,2018-03-04 10:54:06,,37,51819,"<p>I created a fresh virtual environment: <code>virtualenv -p python2 test_venv/</code>
And installed tensorflow: <code>pip install --upgrade --no-cache-dir tensorflow</code></p>

<p><code>import tensorflow</code> gives me <code>Illegal instruction (core dumped)</code></p>

<p>Please help me understand what's going on and how I can fix it. Thank you.</p>

<h3>CPU information:</h3>

<pre><code>-cpu
          description: CPU
          product: Intel(R) Core(TM) i3 CPU       M 330  @ 2.13GHz
          bus info: cpu@0
          version: CPU Version
          capabilities: x86-64 fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm tpr_shadow vnmi flexpriority ept vpid dtherm arat cpufreq
</code></pre>

<h3>Stacktrace obtained with gdb:</h3>

<pre><code>#0  0x00007fffe5793880 in std::pair&lt;std::__detail::_Node_iterator&lt;std::pair&lt;tensorflow::StringPiece const, std::function&lt;bool (tensorflow::Variant*)&gt; &gt;, false, true&gt;, bool&gt; std::_Hashtable&lt;tensorflow::StringPiece, std::pair&lt;tensorflow::StringPiece const, std::function&lt;bool (tensorflow::Variant*)&gt; &gt;, std::allocator&lt;std::pair&lt;tensorflow::StringPiece const, std::function&lt;bool (tensorflow::Variant*)&gt; &gt; &gt;, std::__detail::_Select1st, std::equal_to&lt;tensorflow::StringPiece&gt;, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits&lt;true, false, true&gt; &gt;::_M_emplace&lt;std::pair&lt;tensorflow::StringPiece, std::function&lt;bool (tensorflow::Variant*)&gt; &gt; &gt;(std::integral_constant&lt;bool, true&gt;, std::pair&lt;tensorflow::StringPiece, std::function&lt;bool (tensorflow::Variant*)&gt; &gt;&amp;&amp;) ()
   from /media/gerry/hdd_1/ws_hdd/test_venv/local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#1  0x00007fffe5795735 in tensorflow::UnaryVariantOpRegistry::RegisterDecodeFn(std::string const&amp;, std::function&lt;bool (tensorflow::Variant*)&gt; const&amp;) () from /media/gerry/hdd_1/ws_hdd/test_venv/local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#2  0x00007fffe5770a7c in tensorflow::variant_op_registry_fn_registration::UnaryVariantDecodeRegistration&lt;tensorflow::Tensor&gt;::UnaryVariantDecodeRegistration(std::string const&amp;) ()
   from /media/gerry/hdd_1/ws_hdd/test_venv/local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#3  0x00007fffe56ea165 in _GLOBAL__sub_I_tensor.cc ()
   from /media/gerry/hdd_1/ws_hdd/test_venv/local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#4  0x00007ffff7de76ba in call_init (l=&lt;optimized out&gt;, argc=argc@entry=2, argv=argv@entry=0x7fffffffd5c8, env=env@entry=0xa7b4d0)
    at dl-init.c:72
#5  0x00007ffff7de77cb in call_init (env=0xa7b4d0, argv=0x7fffffffd5c8, argc=2, l=&lt;optimized out&gt;) at dl-init.c:30
#6  _dl_init (main_map=main_map@entry=0xa11920, argc=2, argv=0x7fffffffd5c8, env=0xa7b4d0) at dl-init.c:120
#7  0x00007ffff7dec8e2 in dl_open_worker (a=a@entry=0x7fffffffb5c0) at dl-open.c:575
#8  0x00007ffff7de7564 in _dl_catch_error (objname=objname@entry=0x7fffffffb5b0, errstring=errstring@entry=0x7fffffffb5b8, 
    mallocedp=mallocedp@entry=0x7fffffffb5af, operate=operate@entry=0x7ffff7dec4d0 &lt;dl_open_worker&gt;, args=args@entry=0x7fffffffb5c0)
    at dl-error.c:187
#9  0x00007ffff7debda9 in _dl_open (
    file=0x7fffea7cbc34 ""/media/gerry/hdd_1/ws_hdd/test_venv/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so"", mode=-2147483646, caller_dlopen=0x51ad19 &lt;_PyImport_GetDynLoadFunc+233&gt;, nsid=-2, argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;, env=0xa7b4d0)
    at dl-open.c:660
#10 0x00007ffff75ecf09 in dlopen_doit (a=a@entry=0x7fffffffb7f0) at dlopen.c:66
#11 0x00007ffff7de7564 in _dl_catch_error (objname=0x9b1870, errstring=0x9b1878, mallocedp=0x9b1868, operate=0x7ffff75eceb0 &lt;dlopen_doit&gt;, 
    args=0x7fffffffb7f0) at dl-error.c:187
#12 0x00007ffff75ed571 in _dlerror_run (operate=operate@entry=0x7ffff75eceb0 &lt;dlopen_doit&gt;, args=args@entry=0x7fffffffb7f0) at dlerror.c:163
#13 0x00007ffff75ecfa1 in __dlopen (file=&lt;optimized out&gt;, mode=&lt;optimized out&gt;) at dlopen.c:87
#14 0x000000000051ad19 in _PyImport_GetDynLoadFunc ()
#15 0x000000000051a8e4 in _PyImport_LoadDynamicModule ()
#16 0x00000000005b7b1b in ?? ()
#17 0x00000000004bc3fa in PyEval_EvalFrameEx ()
#18 0x00000000004c136f in PyEval_EvalFrameEx ()
#19 0x00000000004b9ab6 in PyEval_EvalCodeEx ()
#20 0x00000000004b97a6 in PyEval_EvalCode ()
#21 0x00000000004b96df in PyImport_ExecCodeModuleEx ()
#22 0x00000000004b2b06 in ?? ()
#23 0x00000000004a4ae1 in ?? ()
</code></pre>
",4405942.0,,,,,2021-03-10 16:25:48,Illegal instruction (core dumped) after running import tensorflow,<python><tensorflow><pip><virtualenv>,9,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49094597
33802336,1,33816991,,2015-11-19 11:14:26,,37,23432,"

<p>I'm trying to visualize the output of a convolutional layer in tensorflow using the function <code>tf.image_summary</code>. I'm already using it successfully in other instances (e. g. visualizing the input image), but have some difficulties reshaping the output here correctly. I have the following conv layer:</p>

<pre class=""lang-py prettyprint-override""><code>img_size = 256
x_image = tf.reshape(x, [-1,img_size, img_size,1], ""sketch_image"")

W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])

h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
</code></pre>

<p>So the output of <code>h_conv1</code> would have the shape <code>[-1, img_size, img_size, 32]</code>. Just using <code>tf.image_summary(""first_conv"", tf.reshape(h_conv1, [-1, img_size, img_size, 1]))</code> Doesn't account for the 32 different kernels, so I'm basically slicing through different feature maps here.</p>

<p>How can I reshape them correctly? Or is there another helper function I could use for including this output in the summary?</p>
",867505.0,,2464597.0,,2017-08-24 15:54:47,2019-09-07 13:40:17,Visualizing output of convolutional layer in tensorflow,<tensorflow><conv-neural-network>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33802336
43134753,1,43135194,,2017-03-31 07:18:23,,37,46124,"<p>I am running TensorFlow for the first time using some example code. I got the following warnings when running my code. Does anybody know why this happened, and how to fix it?</p>
<pre><code>2017-03-31 02:12:59.346109: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
2017-03-31 02:12:59.346968: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
2017-03-31 02:12:59.346975: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow libbrary wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
2017-03-31 02:12:59.346979: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-03-31 02:12:59.346983: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-03-31 02:12:59.346987: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-03-31 02:12:59.346991: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-03-31 02:12:59.346995: W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
</code></pre>
",7777877.0,,8163071.0,,2021-06-05 05:25:23,2021-06-06 18:23:06,"TensorFlow wasn't compiled to use SSE (etc.) instructions, but these are available",<python><python-3.x><tensorflow>,3,6,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43134753
34987509,1,34988069,,2016-01-25 07:49:27,,37,70152,"<p>My question is in two connected parts:</p>

<ol>
<li><p>How do I calculate the max along a certain axis of a tensor? For example, if I have</p>

<pre><code>x = tf.constant([[1,220,55],[4,3,-1]])
</code></pre>

<p>I want something like </p>

<pre><code>x_max = tf.max(x, axis=1)
print sess.run(x_max)

output: [220,4]
</code></pre>

<p>I know there is a <code>tf.argmax</code> and a <code>tf.maximum</code>, but neither give the maximum value along an axis of a single tensor. For now I have a workaround:</p>

<pre><code>x_max = tf.slice(x, begin=[0,0], size=[-1,1])
for a in range(1,2):
    x_max = tf.maximum(x_max , tf.slice(x, begin=[0,a], size=[-1,1]))
</code></pre>

<p>But it looks less than optimal. Is there a better way to do this?</p></li>
<li><p>Given the indices of an <code>argmax</code> of a tensor, how do I index into another tensor using those indices? Using the example of <code>x</code> above, how do I do something like the following:</p>

<pre><code>ind_max = tf.argmax(x, dimension=1)    #output is [1,0]
y = tf.constant([[1,2,3], [6,5,4])
y_ = y[:, ind_max]                     #y_ should be [2,6]
</code></pre>

<p>I know slicing, like the last line, does not exist in TensorFlow yet (<a href=""https://github.com/tensorflow/tensorflow/issues/206"" rel=""noreferrer"">#206</a>). </p>

<p>My question is: <em>what is the best workaround for my specific case (maybe using other methods like gather, select, etc.)?</em></p>

<p>Additional information: I know <code>x</code> and <code>y</code> are going to be two dimensional tensors only!</p></li>
</ol>
",5813490.0,,2956066.0,,2018-10-12 18:11:31,2018-10-12 18:11:31,TensorFlow: Max of a tensor along an axis,<python><tensorflow><deep-learning><max><tensor>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34987509
42327543,1,42420014,,2017-02-19 13:05:45,,37,13501,"<p>I've been seeing a very strange behavior when training a network, where after a couple of 100k iterations (8 to 10 hours) of learning fine, everything breaks and the training loss <em>grows</em>:</p>

<p><a href=""https://i.stack.imgur.com/47T4x.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/47T4x.jpg"" alt=""Loss explodes""></a></p>

<p>The training data itself is randomized and spread across many <code>.tfrecord</code> files containing <code>1000</code> examples each, then shuffled again in the input stage and batched to <code>200</code> examples.</p>

<h3>The background</h3>

<p>I am designing a network that performs four different regression tasks at the same time, e.g. determining the likelihood of an object appearing in the image and simultanously determining its orientation. The network starts with a couple of convolutional layers, some with residual connections, and then branches into the four fully-connected segments.</p>

<p>Since the first regression results in a probability, I'm using cross entropy for the loss, whereas the others use classical L2 distance. However, due to their nature, the probability loss is around the order of <code>0..1</code>, while the orientation losses can be much larger, say <code>0..10</code>. I already normalized both input and output values and use clipping</p>

<pre><code>normalized = tf.clip_by_average_norm(inferred.sin_cos, clip_norm=2.)
</code></pre>

<p>in cases where things can get really bad.</p>

<p>I've been (successfully) using the Adam optimizer to optimize on the tensor containing all distinct losses (rather than <code>reduce_sum</code>ing them), like so:</p>

<pre><code>reg_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))
loss = tf.pack([loss_probability, sin_cos_mse, magnitude_mse, pos_mse, reg_loss])

optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,
                                   epsilon=self.params.adam_epsilon)
op_minimize = optimizer.minimize(loss, global_step=global_step)
</code></pre>

<p>In order to display the results in TensorBoard, I then actually do</p>

<pre><code>loss_sum = tf.reduce_sum(loss)
</code></pre>

<p>for a scalar summary.</p>

<p>Adam is set to learning rate <code>1e-4</code> and epsilon <code>1e-4</code> (I see the same behavior with the default value for epislon and it breaks even faster when I keep the learning rate on <code>1e-3</code>). Regularization also has no influence on this one, it does this sort-of consistently at some point.</p>

<p>I should also add that stopping the training and restarting from the last checkpoint - implying that the training input files are shuffled again as well - results in the same behavior. The training always seems to behave similarly at that point.</p>
",195651.0,,195651.0,,2017-09-18 20:18:10,2017-09-18 20:18:10,"Adam optimizer goes haywire after 200k batches, training loss grows",<tensorflow><neural-network><deep-learning><conv-neural-network>,2,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42327543
45864363,1,45868106,,2017-08-24 14:32:59,,37,46831,"<p>In tensorflow the training from the scratch produced following 6 files:</p>

<blockquote>
  <ol>
  <li>events.out.tfevents.1503494436.06L7-BRM738 </li>
  <li>model.ckpt-22480.meta </li>
  <li>checkpoint </li>
  <li>model.ckpt-22480.data-00000-of-00001 </li>
  <li>model.ckpt-22480.index </li>
  <li>graph.pbtxt</li>
  </ol>
</blockquote>

<p>I would like to convert them (or only the needed ones) into one file <strong>graph.pb</strong> to be able to transfer it to my Android application.</p>

<p>I tried the script <code>freeze_graph.py</code> but it requires as an input already the <strong>input.pb</strong> file which I do not have. (I have only these 6 files mentioned before). How to proceed to get this one <strong>freezed_graph.pb</strong> file? I saw several threads but none was working for me.</p>
",7647304.0,,7647304.0,,2017-08-24 15:11:36,2021-01-25 15:03:03,"Tensorflow: How to convert .meta, .data and .index model files into one graph.pb file",<graph><tensorflow><model><meta><checkpoint>,4,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45864363
65383338,1,68214296,,2020-12-20 18:26:16,,37,96182,"<p>I'm trying to get tensorflow working on my MacBook pro M1. However, I keep getting the following error when trying to import: <code>zsh: illegal hardware instruction  python</code></p>
<p>I have downloaded and installed tensorflow via this <a href=""https://github.com/apple/tensorflow_macos/releases/tag/v0.1alpha1"" rel=""nofollow noreferrer"">link</a>.</p>
<p>These were my installation steps:</p>
<ul>
<li>install a venv: <code>python3 -m venv venv</code>.</li>
<li>drag the <code>install_venv.sh</code> (which is located within the downloaded folder) file to the terminal, add <code>-p</code> at the end.</li>
<li>select the directory of the venv as the location where tensorflow should be installed.</li>
<li>activate the venv.</li>
<li>type &quot;python&quot;.</li>
<li>try to import tensorflow: <code>import tensorflow as tf</code>.</li>
</ul>
<p>I'm using Python 3.8.2.</p>
",14861092.0,,8293309.0,,2023-04-12 22:33:34,2023-04-12 22:33:34,"""zsh: illegal hardware instruction python"" when installing Tensorflow on macbook pro M1",<python><python-3.x><tensorflow><macos-big-sur><apple-silicon>,3,2,0.0,2021-09-05 10:25:03,,CC BY-SA 4.0,https://stackoverflow.com/q/65383338
37441140,1,37444810,,2016-05-25 15:09:35,,37,40182,"<p>This is a generic question. I found that in the tensorflow, after we build the graph, fetch data into the graph, the output from graph is a tensor. but in many cases, we need to do some computation based on this output (which is a <code>tensor</code>), which is not allowed in tensorflow. </p>

<p>for example, I'm trying to implement a RNN, which loops times based on data self property. That is, I need use a <code>tensor</code> to judge whether I should stop (I am not using dynamic_rnn since in my design, the rnn is highly customized). I find <code>tf.while_loop(cond,body.....)</code> might be a candidate for my implementation. But the official tutorial is too simple. I don't know how to add more functionalities into the 'body'. Can anyone give me few more complex example? </p>

<p>Also, in such case that if the future computation is based on the tensor output (ex: the RNN stop based on the output criterion), which is very common case. Is there an elegant way or better way instead of dynamic graph?</p>
",4524141.0,,,,,2018-12-28 13:54:14,How to use tf.while_loop() in tensorflow,<python><tensorflow>,1,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37441140
44516609,1,44521818,,2017-06-13 08:50:57,,36,43537,"<p>I used <code>saver=tf.train.Saver()</code> to save the model that I trained, and I get three kinds of files named:</p>

<ul>
<li>.ckpt.meta </li>
<li>.ckpt.index</li>
<li>.ckpt.data</li>
</ul>

<p>And a file called:</p>

<ul>
<li>checkpoint</li>
</ul>

<p>What is the connection with the <strong>.ckpt</strong> file? </p>

<p>I saw someone saved model with only .ckpt file, I don't know how to make it. 
How can I save model as a .pb file?</p>
",8047378.0,,260826.0,,2018-09-19 22:42:47,2018-09-19 22:42:47,"Tensorflow : What is the relationship between .ckpt file and .ckpt.meta and .ckpt.index , and .pb file",<python><tensorflow>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44516609
66083545,1,70992274,,2021-02-07 00:57:32,,36,60116,"<p>Using <code>tensorflow 2.4.1</code></p>
<p>When I run my program, I'm getting this error and can't use my <code>gpu</code>.</p>
<p>I'm using <code>CUDA 11.0</code>, <code>cudnn 8.0</code></p>
<pre><code>2021-02-07 03:36:18.132005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
WARNING:tensorflow:From D:/PycharmProjects/pythonProject/models/kpş,i.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
2021-02-07 03:36:19.735127: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-02-07 03:36:19.739052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-02-07 03:36:20.715634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5
coreClock: 1.56GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 119.24GiB/s
2021-02-07 03:36:20.716281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-02-07 03:36:20.723519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-02-07 03:36:20.724040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-02-07 03:36:20.729436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-02-07 03:36:20.731800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-02-07 03:36:20.741580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-02-07 03:36:20.745576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-02-07 03:36:20.746657: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2021-02-07 03:36:20.746971: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-02-07 03:36:20.836861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-07 03:36:20.837144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2021-02-07 03:36:20.837314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2021-02-07 03:36:20.837493: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
</code></pre>
",15160674.0,,1832058.0,,2021-02-07 03:08:54,2022-11-30 00:16:24,Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found,<python><tensorflow>,8,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/66083545
44167134,1,44167844,,2017-05-24 19:38:56,,36,13680,"<p>
What's the difference between <code>Tensor</code> and <code>Variable</code> in Tensorflow? I noticed in <a href=""https://stackoverflow.com/questions/38556078/in-tensorflow-what-is-the-difference-between-a-variable-and-a-tensor"">this stackoverflow answer</a>, we can use <code>Variable</code> wherever <code>Tensor</code> can be used. However, I failed to do <code>session.run()</code> on a <code>Variable</code>:</p>

<pre class=""lang-py prettyprint-override""><code>A = tf.zeros([10])   # A is a Tensor
B = tf.Variable([111, 11, 11]) # B is a Variable
sess.run(A) # OK. Will return the values in A
sess.run(B) # Error.
</code></pre>
",4434038.0,,2464597.0,,2017-10-10 15:43:30,2020-08-11 14:19:54,What's the difference between Tensor and Variable in Tensorflow,<tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44167134
33648322,1,33862534,,2015-11-11 10:09:45,,35,122528,"<p>I've got a bunch of images in a format similar to Cifar10 (binary file, <code>size = 96*96*3</code> bytes per image), one image after another (<a href=""http://cs.stanford.edu/~acoates/stl10/"" rel=""noreferrer"">STL-10 dataset</a>). The file I'm opening has 138MB.</p>

<p>I tried to read &amp; check the contents of the Tensors containing the images to be sure that the reading is done right, however I have two questions - </p>

<ol>
<li>Does the <code>FixedLengthRecordReader</code> load the whole file, however just provide inputs one at a time? Since reading the first <code>size</code> bytes should be relatively fast. However, the code takes about two minutes to run. </li>
<li>How to get the actual image contents in a displayable format, or display them internally to validate that the images are read well? I did <code>sess.run(uint8image)</code>, however the result is empty.</li>
</ol>

<p>The code is below:</p>

<pre><code>import tensorflow as tf
def read_stl10(filename_queue):
  class STL10Record(object):
    pass
  result = STL10Record()

  result.height = 96
  result.width = 96
  result.depth = 3
  image_bytes = result.height * result.width * result.depth
  record_bytes = image_bytes

  reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)
  result.key, value = reader.read(filename_queue)
  print value
  record_bytes = tf.decode_raw(value, tf.uint8)

  depth_major = tf.reshape(tf.slice(record_bytes, [0], [image_bytes]),
                       [result.depth, result.height, result.width])
  result.uint8image = tf.transpose(depth_major, [1, 2, 0])
  return result
# probably a hack since I should've provided a string tensor

filename_queue = tf.train.string_input_producer(['./data/train_X'])
image = read_stl10(filename_queue)

print image.uint8image
with tf.Session() as sess:
  result = sess.run(image.uint8image)
  print result, type(result)
</code></pre>

<p><strong>Output:</strong></p>

<pre><code>Tensor(""ReaderRead:1"", shape=TensorShape([]), dtype=string)
Tensor(""transpose:0"", shape=TensorShape([Dimension(96), Dimension(96), Dimension(3)]), dtype=uint8)
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
[empty line for last print]
Process finished with exit code 137
</code></pre>

<p>I'm running this on my CPU, if that adds anything.</p>

<p>EDIT: I found the pure TensorFlow solution thanks to Rosa. Apparently, when using the <code>string_input_producer</code>, in order to see the results, you need to initialize the queue runners. 
The only required thing to add to the code above is the second line from below:</p>

<pre><code>...
with tf.Session() as sess:
    tf.train.start_queue_runners(sess=sess)
...
</code></pre>

<p>Afterwards, the image in the <code>result</code> can be displayed with <code>matplotlib.pyplot.imshow(result)</code>. I hope this helps someone. If you have any further questions, feel free to ask me or check the link in Rosa's answer.</p>
",4952564.0,,4952564.0,,2015-11-18 16:23:18,2020-05-02 00:30:44,Tensorflow image reading & display,<python><tensorflow>,8,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33648322
39157723,1,39218426,,2016-08-26 03:07:05,,35,34250,"<p>I found that Tensorflow provides <code>scatter_update()</code> to assign values to the slice of a tensor in the 0 dimension. For example, if the tensor <code>T</code> is three dimensional, I can assign value <code>v[1, :, :]</code> to <code>T[i, :, :]</code>. </p>

<pre><code>a = tf.Variable(tf.zeros([10,36,36]))   
value = np.ones([1,36,36])   
d = tf.scatter_update(a,[0],value)

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print a.eval()
    sess.run(d)
    print a.eval()
</code></pre>

<p>But how to assign values <code>v[1,1,:]</code> to <code>T[i,j,:]</code>?  </p>

<pre><code>a = tf.Variable(tf.zeros([10,36,36]))   
value1 = np.random.randn(1,1,36)    
e = tf.scatter_update(a,[0],value1) #Error

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print a.eval()
    sess.rum(e)
    print a.eval()
</code></pre>

<p>Is there any other function that TF provide or a simple way to do this?</p>
",5522711.0,,3924118.0,,2018-07-08 13:55:14,2023-06-02 19:39:13,How to do slice assignment in Tensorflow,<python-2.7><tensorflow>,6,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/39157723
42216208,1,43531616,,2017-02-14 01:06:27,,35,9197,"<p>From <a href=""https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/saved_model/"" rel=""noreferrer"">SavedModel Docs</a>,</p>

<blockquote>
  <p>SavedModel, the universal serialization format for TensorFlow models.</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>SavedModel wraps a TensorFlow Saver. The Saver is primarily used to generate the variable checkpoints.</p>
</blockquote>

<p>From my understanding, <code>SavedModel</code> is must if someone wants use TensorFlow Serving. However, I can deploy Tensorflow Model to service server without <code>SavedModel</code>: Freeze graph and export it as <code>GraphDef</code>, and load graph into Session using <code>ReadBinaryProto</code> and <a href=""https://www.tensorflow.org/api_docs/cc/class/tensorflow/session#create"" rel=""noreferrer"">Create</a> in C++ or <a href=""https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go#Graph.Import"" rel=""noreferrer"">Import</a> in Go.</p>

<p>What is the purpose of SavedModel? Should users prefer SavedModel over Checkpoint or GraphDef to aggregate more data related to the model?</p>
",3627572.0,,3627572.0,,2017-02-14 01:12:36,2017-04-21 03:47:56,Should TensorFlow users prefer SavedModel over Checkpoint or GraphDef?,<python><c++><tensorflow>,1,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42216208
37061089,1,39355763,,2016-05-05 22:08:08,,35,97172,"<p>I installed Jupyter notebooks in Ubuntu 14.04 via Anaconda earlier, and just now I installed TensorFlow. I would like TensorFlow to work regardless of whether I am working in a notebook or simply scripting. In my attempt to achieve this, I ended up installing TensorFlow twice, once using Anaconda, and once using pip. The Anaconda install works, but I need to preface any call to python with ""source activate tensorflow"". And the pip install works nicely, if start python the standard way (in the terminal) then tensorflow loads just fine. </p>

<p>My question is: how can I also have it work in the Jupyter notebooks? </p>

<p>This leads me to a more general question: it seems that my python kernel in Jupyter/Anaconda is separate from the python kernel (or environment? not sure about the terminology here) used system wide. It would be nice if these coincided, so that if I install a new python library, it becomes accessible to all the varied ways I have of running python.</p>
",4556722.0,,364772.0,,2016-05-06 00:10:23,2023-01-11 01:51:31,Trouble with TensorFlow in Jupyter Notebook,<python><tensorflow><jupyter>,16,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37061089
35400065,1,39472895,,2016-02-15 01:10:07,,35,24353,"<p>The text data is organized as vector with 20,000 elements, like [2, 1, 0, 0, 5, ...., 0]. 
i-th element indicates the frequency of the i-th word in a text. </p>

<p>The ground truth label data is also represented as vector with 4,000 elements, like [0, 0, 1, 0, 1, ...., 0]. 
i-th element indicates whether the i-th label is a positive label for a text. 
The number of labels for a text differs depending on texts. </p>

<p>I have a code for single-label text classification. </p>

<p>How can I edit the following code for multilabel text classification?</p>

<p>Especially, I would like to know following points. </p>

<ul>
<li>How to compute accuracy using TensorFlow. </li>
<li>How to set a threshold which judges whether a label is positive or negative. For instance, if the output is [0.80, 0.43, 0.21, 0.01, 0.32] and the ground truth is [1, 1, 0, 0, 1], the labels with scores over 0.25 should be judged as positive. </li>
</ul>

<p>Thank you. </p>

<pre><code>import tensorflow as tf

# hidden Layer
class HiddenLayer(object):
    def __init__(self, input, n_in, n_out):
        self.input = input

        w_h = tf.Variable(tf.random_normal([n_in, n_out],mean = 0.0,stddev = 0.05))
        b_h = tf.Variable(tf.zeros([n_out]))

        self.w = w_h
        self.b = b_h
        self.params = [self.w, self.b]

    def output(self):
        linarg = tf.matmul(self.input, self.w) + self.b
        self.output = tf.nn.relu(linarg)

        return self.output

# output Layer
class OutputLayer(object):
    def __init__(self, input, n_in, n_out):
        self.input = input

        w_o = tf.Variable(tf.random_normal([n_in, n_out], mean = 0.0, stddev = 0.05))
        b_o = tf.Variable(tf.zeros([n_out]))

        self.w = w_o
        self.b = b_o
        self.params = [self.w, self.b]

    def output(self):
        linarg = tf.matmul(self.input, self.w) + self.b
        self.output = tf.nn.relu(linarg)

        return self.output

# model
def model():
    h_layer = HiddenLayer(input = x, n_in = 20000, n_out = 1000)
    o_layer = OutputLayer(input = h_layer.output(), n_in = 1000, n_out = 4000)

    # loss function
    out = o_layer.output()
    cross_entropy = -tf.reduce_sum(y_*tf.log(out + 1e-9), name='xentropy')    

    # regularization
    l2 = (tf.nn.l2_loss(h_layer.w) + tf.nn.l2_loss(o_layer.w))
    lambda_2 = 0.01

    # compute loss
    loss = cross_entropy + lambda_2 * l2

    # compute accuracy for single label classification task
    correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, ""float""))

    return loss, accuracy
</code></pre>
",1336058.0,,,,,2017-02-03 08:58:31,Multilabel Text Classification using TensorFlow,<python><tensorflow><text-classification><multilabel-classification>,2,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35400065
34192229,1,34192524,,2015-12-10 01:32:48,,35,47027,"<p>What would be the most efficient way to multiply (element-wise) a 2D tensor (matrix):</p>

<pre><code>x11 x12 .. x1N
...
xM1 xM2 .. xMN
</code></pre>

<p>by a vertical vector:</p>

<pre><code>w1
...
wN
</code></pre>

<p>to obtain a new matrix:</p>

<pre><code>x11*w1 x12*w2 ... x1N*wN
...
xM1*w1 xM2*w2 ... xMN*wN
</code></pre>

<p>To give some context, we have <code>M</code> data samples in a batch that can be processed in parallel, and each <code>N</code>-element sample must be multiplied by weights <code>w</code> stored in a variable to eventually pick the largest <code>Xij*wj</code> for each row <code>i</code>.</p>
",1576602.0,,2956066.0,,2018-06-19 19:04:15,2018-06-19 19:04:15,Efficient element-wise multiplication of a matrix and a vector in TensorFlow,<python><tensorflow><linear-algebra><matrix-multiplication><tensor>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34192229
43245231,1,44347843,,2017-04-06 03:36:10,,35,13992,"<p>I'm trying to understand the difference between using <code>tf.Session</code> and <code>tf.train.MonitoredTrainingSession</code>, and where I might prefer one over the other. It seems that when I use the latter, I can avoid many ""chores"" such as initializing variables, starting queue runners, or setting up file writers for summary operations. On the other hand, with a monitored training session, I cannot specify the computation graph I want to use explicitly. All of this seems rather mysterious to me. Is there some underlying philosophy behind how these classes were created that I'm not understanding?</p>
",4444582.0,,281545.0,,2017-06-04 18:44:26,2017-06-05 17:25:43,How do Monitored Training Sessions work?,<python><tensorflow>,1,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43245231
35596629,1,35596680,,2016-02-24 08:13:17,,35,67141,"<p>I tried:</p>

<pre><code>test_image = tf.convert_to_tensor(img, dtype=tf.float32)
</code></pre>

<p>Then following error appears:</p>

<pre><code>ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int64: 'Tensor(""test/ArgMax:0"", shape=TensorShape([Dimension(None)]), dtype=int64)'
</code></pre>
",5948325.0,,2725435.0,,2016-02-24 08:31:31,2020-03-31 04:25:53,How to convert tf.int64 to tf.float32?,<tensorflow><int64>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35596629
39008821,1,39009002,,2016-08-18 01:57:21,,35,35521,"<p>Tensorflow tutorials include the use of <code>tf.expand_dims</code> to add a ""batch dimension"" to a tensor. I have read the docs for this function but it still is rather mysterious to me. Does anyone know exactly under what circumstances this must be used?</p>

<p>My code is below. My intent is to calculate a loss based on the distance between the predicted and actual bins. (E.g. if <code>predictedBin = 10</code> and <code>truthBin = 7</code> then <code>binDistanceLoss = 3</code>).</p>

<pre><code>batch_size = tf.size(truthValues_placeholder)
labels = tf.expand_dims(truthValues_placeholder, 1)
predictedBin = tf.argmax(logits)
binDistanceLoss = tf.abs(tf.sub(labels, logits))
</code></pre>

<p>In this case, do I need to apply <code>tf.expand_dims</code> to <code>predictedBin</code> and <code>binDistanceLoss</code>? Thanks in advance.</p>
",3444294.0,,3444294.0,,2016-08-18 02:29:55,2017-12-15 18:07:00,Tensorflow: When use tf.expand_dims?,<tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39008821
44238154,1,44239754,,2017-05-29 08:43:37,,35,34356,"<p>These two attentions are used in <strong>seq2seq</strong> modules. The two different attentions are introduced as multiplicative and additive attentions in <a href=""https://www.tensorflow.org/versions/master/api_guides/python/contrib.seq2seq"" rel=""noreferrer"">this</a> TensorFlow documentation. What is the difference?</p>
",5915270.0,,63550.0,,2020-10-26 12:21:28,2022-04-11 08:46:58,What is the difference between Luong attention and Bahdanau attention?,<tensorflow><deep-learning><nlp><attention-model>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44238154
41482913,1,41483033,,2017-01-05 10:43:17,,35,46355,"<p>I'm using Tensorflow version 0.12.head with Python 2.7 on a linux CentOS 7 and when I run this:</p>

<pre><code>import tensorflow as tf

a = tf.constant(5, name=""input_a"")
b = tf.constant(3, name=""input_b"")
c = tf.mul(a, b, name=""mul_c"")
d = tf.add(a, b, name=""add_d"")
e = tf.add(c, d, name=""add_e"")
sess = tf.Session()
output = sess.run(e)
writer = tf.train.SummaryWriter('./my_graph', sess.graph)
</code></pre>

<p>I get this error:</p>

<pre><code>AttributeError                            Traceback (most recent call last) &lt;ipython-input-6-29c037e85eec&gt; in &lt;module&gt;()
----&gt; 1 writer = tf.train.SummaryWriter('./my_graph', sess.graph)

AttributeError: 'module' object has no attribute 'SummaryWriter'
</code></pre>

<p>I have run these two commands because there is bug <a href=""https://github.com/tensorflow/tensorflow/issues/1645"" rel=""noreferrer"">issue</a> on Github for the same problem:</p>

<pre><code>&gt;&gt;&gt; import six
&gt;&gt;&gt; print(six.__version__)
1.10.0
&gt;&gt;&gt; print(dir(six.moves.queue)) ['Empty', 'Full', 'LifoQueue', 'PriorityQueue', 'Queue', '__all__', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '_threading', '_time', 'deque', 'heapq']
&gt;&gt;&gt; print(six.moves.queue.__file__) /usr/lib64/python2.7/Queue.pyc
</code></pre>

<p>I'm new in Python and in Tensorflow. Do you know how can I fix this error?</p>

<p>I have changed <code>SummaryWriter</code> with <code>FileWriter</code>:</p>

<pre><code>writer = tf.train.FileWriter('./my_graph', sess.graph)
</code></pre>

<p>And I get the same error but with <code>FileWriter</code> function:</p>

<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-8-daa50ea2b8f9&gt; in &lt;module&gt;()
----&gt; 1 writer = tf.train.FileWriter('./my_graph', sess.graph)

AttributeError: 'module' object has no attribute 'FileWriter'
</code></pre>

<p>I have also run it in a terminal and I get the same result:</p>

<pre><code>[VansFannel@localhost ~]$ python
Python 2.7.5 (default, Nov  6 2016, 00:28:07) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import tensorflow as tf
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
&gt;&gt;&gt; a = tf.constant(5, name=""input_a"")
&gt;&gt;&gt; b = tf.constant(3, name=""input_b"")
&gt;&gt;&gt; c = tf.mul(a, b, name=""mul_c"")
&gt;&gt;&gt; d = tf.add(a, b, name=""add_d"")
&gt;&gt;&gt; e = tf.add(c, d, name=""add_e"")
&gt;&gt;&gt; sess = tf.Session()
&gt;&gt;&gt; output = sess.run(e)
&gt;&gt;&gt; writer = tf.train.FileWriter('./my_graph', sess.graph)
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
AttributeError: 'module' object has no attribute 'FileWriter'
&gt;&gt;&gt; 
</code></pre>
",68571.0,,68571.0,,2017-01-05 11:14:41,2021-01-21 14:15:29,'module' object has no attribute 'SummaryWriter',<python><python-2.7><tensorflow>,5,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41482913
35451948,1,35464950,,2016-02-17 08:57:43,,35,32862,"<p>I have an image that is 478 x 717 x 3 = 1028178 pixels, with a rank of 1. I verified it by calling tf.shape and tf.rank.</p>

<p>When I call image.set_shape([478, 717, 3]), it throws the following error.</p>

<pre><code>""Shapes %s and %s must have the same rank"" % (self, other)) 
ValueError: Shapes (?,) and (478, 717, 3) must have the same rank
</code></pre>

<p>I tested again by first casting to 1028178, but the error still exists.</p>

<pre><code>ValueError: Shapes (1028178,) and (478, 717, 3) must have the same rank
</code></pre>

<p>Well, that does make sense because one is of rank 1 and the other is of rank 3. However, why is it necessary to throw an error, as the total number of pixels still match.</p>

<p>I could of course use tf.reshape and it works, but I think that's not optimal.</p>

<p>As stated on the TensorFlow FAQ</p>

<blockquote>
  <p>What is the difference between x.set_shape() and x = tf.reshape(x)?</p>
  
  <p>The tf.Tensor.set_shape() method updates the static shape of a Tensor
  object, and it is typically used to provide additional shape
  information when this cannot be inferred directly. It does not change
  the dynamic shape of the tensor.</p>
  
  <p>The tf.reshape() operation creates a new tensor with a different dynamic shape.</p>
</blockquote>

<p>Creating a new tensor involves memory allocation and that could potentially be more costly when more training examples are involved. Is this by design, or am I  missing something here?</p>
",5703903.0,,3574081.0,,2016-10-10 16:24:38,2018-11-14 12:59:53,Clarification on tf.Tensor.set_shape(),<tensorflow>,1,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35451948
39219414,1,39223400,,2016-08-30 05:34:07,,34,37373,"<p>I want to do something like this.<br>
Let's say we have a tensor A.  </p>

<pre><code>A = [[1,0],[0,4]]
</code></pre>

<p>And I want to get nonzero values and their indices from it.  </p>

<pre><code>Nonzero values: [1,4]  
Nonzero indices: [[0,0],[1,1]]
</code></pre>

<p>There are similar operations in Numpy.<br>
<code>np.flatnonzero(A)</code> return indices that are non-zero in the flattened A.<br>
<code>x.ravel()[np.flatnonzero(x)]</code> extract elements according to non-zero indices.<br>
Here's <a href=""http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.flatnonzero.html"" rel=""noreferrer"">a link</a> for these operations.</p>

<p>How can I do somthing like above Numpy operations in Tensorflow with python?<br>
(Whether a matrix is flattened or not doesn't really matter.)</p>
",6772741.0,,,,,2022-03-27 11:00:35,"In TensorFlow, how can I get nonzero values and their indices from a tensor with python?",<python><tensorflow><indices>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39219414
33833818,1,33834561,,2015-11-20 18:41:15,,34,33176,"<p>I am looking at the TensorFlow ""<a href=""https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners#evaluating_our_model"" rel=""noreferrer"">MNIST For ML Beginners</a>"" tutorial, and I want to print out the training loss after every training step.</p>

<p>My training loop currently looks like this:</p>

<pre><code>for i in range(100):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
</code></pre>

<p>Now, <code>train_step</code> is defined as:</p>

<pre><code>train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
</code></pre>

<p>Where <code>cross_entropy</code> is the loss which I want to print out:</p>

<pre><code>cross_entropy = -tf.reduce_sum(y_ * tf.log(y))
</code></pre>

<p>One way to print this would be to explicitly compute <code>cross_entropy</code> in the training loop:</p>

<pre><code>for i in range(100):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))
    print 'loss = ' + str(cross_entropy)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
</code></pre>

<p>I now have two questions regarding this:</p>

<ol>
<li><p>Given that <code>cross_entropy</code> is already computed during <code>sess.run(train_step, ...)</code>, it seems inefficient to compute it twice, requiring twice the number of forward passes of all the training data. Is there a way to access the value of <code>cross_entropy</code> when it was computed during <code>sess.run(train_step, ...)</code>?</p></li>
<li><p>How do I even print a <code>tf.Variable</code>? Using <code>str(cross_entropy)</code> gives me an error...</p></li>
</ol>

<p>Thank you!</p>
",3320135.0,,5483914.0,,2018-04-15 01:40:02,2018-04-15 01:40:02,Printing the loss during TensorFlow training,<python><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33833818
36210887,1,36211137,,2016-03-24 22:12:23,,34,69443,"<p>I am trying to save Nueral Network weights into a file and then restoring those weights by initializing the network instead of random initialization. My code works fine with random initialization. But, when i initialize weights from file it is showing me an error <code>TypeError: Input 'b' of 'MatMul' Op has type float64 that does not match type float32 of argument 'a'.</code> I don't know how do i solve this issue.Here is my code:</p>

<p><strong>Model Initialization</strong></p>

<pre><code># Parameters
training_epochs = 5
batch_size = 64
display_step = 5
batch = tf.Variable(0, trainable=False)
regualarization =  0.008

# Network Parameters
n_hidden_1 = 300 # 1st layer num features
n_hidden_2 = 250 # 2nd layer num features

n_input = model.layer1_size # Vector input (sentence shape: 30*10)
n_classes = 12 # Sentence Category detection total classes (0-11 categories)

#History storing variables for plots
loss_history = []
train_acc_history = []
val_acc_history = []

# tf Graph input
x = tf.placeholder(""float"", [None, n_input])
y = tf.placeholder(""float"", [None, n_classes])
</code></pre>

<p><strong>Model parameters</strong></p>

<pre><code>#loading Weights
def weight_variable(fan_in, fan_out, filename):
    stddev = np.sqrt(2.0/fan_in)
    if (filename == """"):
        initial  = tf.random_normal([fan_in,fan_out], stddev=stddev)
    else:
        initial  = np.loadtxt(filename)
    print initial.shape
    return tf.Variable(initial)

#loading Biases
def bias_variable(shape, filename):
    if (filename == """"):
     initial = tf.constant(0.1, shape=shape)
    else:
     initial  = np.loadtxt(filename)  
    print initial.shape
    return tf.Variable(initial)

# Create model
def multilayer_perceptron(_X, _weights, _biases):
    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) 
    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2'])) 
    return tf.matmul(layer_2, weights['out']) + biases['out']  

# Store layers weight &amp; bias
weights = {
'h1':  w2v_utils.weight_variable(n_input, n_hidden_1,    filename=""weights_h1.txt""),
'h2':  w2v_utils.weight_variable(n_hidden_1, n_hidden_2, filename=""weights_h2.txt""),
'out': w2v_utils.weight_variable(n_hidden_2, n_classes,  filename=""weights_out.txt"") 
}

 biases = {
'b1': w2v_utils.bias_variable([n_hidden_1], filename=""biases_b1.txt""),
'b2': w2v_utils.bias_variable([n_hidden_2], filename=""biases_b2.txt""),
'out': w2v_utils.bias_variable([n_classes], filename=""biases_out.txt"")
}

# Define loss and optimizer
#learning rate
# Optimizer: set up a variable that's incremented once per batch and
# controls the learning rate decay.
learning_rate = tf.train.exponential_decay(
    0.02*0.01,           # Base learning rate. #0.002
    batch * batch_size,  # Current index into the dataset.
    X_train.shape[0],    # Decay step.
    0.96,                # Decay rate.
    staircase=True)


# Construct model
pred = tf.nn.relu(multilayer_perceptron(x, weights, biases))

#L2 regularization
l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])

#Softmax loss
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y)) 

#Total_cost
cost = cost+ (regualarization*0.5*l2_loss)

# Adam Optimizer
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost,global_step=batch)


# Add ops to save and restore all the variables.
saver = tf.train.Saver()

# Initializing the variables
init = tf.initialize_all_variables()

print ""Network Initialized!""
</code></pre>

<p><strong>ERROR DETAILS</strong>
<a href=""https://i.stack.imgur.com/2ZNj9.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/2ZNj9.png"" alt=""enter image description here""></a></p>
",2235817.0,,2235817.0,,2016-03-24 22:29:02,2022-08-23 16:23:46,How to fix MatMul Op has type float64 that does not match type float32 TypeError?,<python><machine-learning><neural-network><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36210887
46568913,1,46573114,,2017-10-04 15:40:20,,34,284516,"<p>I installed TensorFlow on my Windows Python 3.5 Anaconda environment
The validation was successful (with a warning)</p>

<pre><code>(tensorflow) C:\&gt;python
</code></pre>

<p>Python 3.5.3 |Intel Corporation| (default, Apr 27 2017, 17:03:30) [MSC v.1900 64 bit (AMD64)] on win32</p>

<p>Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Intel(R) Distribution for Python is brought to you by Intel Corporation.
Please check out: <a href=""https://software.intel.com/en-us/python-distribution"" rel=""noreferrer"">https://software.intel.com/en-us/python-distribution</a></p>

<pre><code>&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
&gt;&gt;&gt; sess = tf.Session()
</code></pre>

<p>2017-10-04 11:06:13.569696: W C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.</p>

<pre><code>&gt;&gt;&gt; print(sess.run(hello))
</code></pre>

<p>b'Hello, TensorFlow!'</p>

<p>However, when I attempt to import it into my python code</p>

<pre><code>from __future__ import print_function, division
import numpy as np
import os
import matplotlib
import tensorflow as tf
</code></pre>

<p>I get this error</p>

<blockquote>
  <p><strong>ImportError: No module named 'tensorflow'</strong></p>
</blockquote>

<p>This is the location of the tensorflow package on my C drive</p>

<pre><code>C:\Users\myname\Anaconda2\envs\tensorflow\Lib\site-packages\tensorflow
</code></pre>

<p>When I go to Anaconda Navigator, it seems I have to choose either root, Python35, or Tensorflow. It looks like the Tensorflow environment includes Python35.</p>

<p>Anaconda Navigator launcher had to be reinstalled recently, possibly due to the Tensorflow installation. Maybe if there were another way to set the environment to Tensorflow within Anaconda /Spyder IDE other than the Navigator it might help</p>

<p>Method of installing tensorflow</p>

<pre><code>conda create --name tensorflow python=3.5; 
pip install --ignore-installed --upgrade tensorflow 
</code></pre>

<p>I did try:
uninstalling and reinstalling protobuf, as suggesed by some blogs</p>

<p>I see another SO user asked <a href=""https://stackoverflow.com/questions/42619665/why-spyder-cant-import-tensorflow"">the same question</a> in March, received no reply</p>
",2363193.0,,1033581.0,,2017-10-19 02:28:13,2023-04-17 09:00:49,Tensorflow import error: No module named 'tensorflow',<python><windows><tensorflow><installation><anaconda>,16,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46568913
34079787,1,34082273,,2015-12-04 02:11:33,,34,59038,"<p>I'm playing around with tensorflow and ran into a problem with the following code:</p>

<pre><code>def _init_parameters(self, input_data, labels):

    # the input shape is (batch_size, input_size)
    input_size = tf.shape(input_data)[1]

    # labels in one-hot format have shape (batch_size, num_classes)
    num_classes = tf.shape(labels)[1]

    stddev = 1.0 / tf.cast(input_size, tf.float32)

    w_shape = tf.pack([input_size, num_classes], 'w-shape')
    normal_dist = tf.truncated_normal(w_shape, stddev=stddev, name='normaldist')
    self.w = tf.Variable(normal_dist, name='weights')
</code></pre>

<p>(I'm using <code>tf.pack</code> as suggested in <a href=""https://stackoverflow.com/questions/33711427/tensorflow-initializing-tensor-of-ones"">this question</a>, since I was getting the same error)</p>

<p>When I run it (from a larger script that invokes this one), I get this error:</p>

<pre><code>ValueError: initial_value must have a shape specified: Tensor(""normaldist:0"", shape=TensorShape([Dimension(None), Dimension(None)]), dtype=float32)
</code></pre>

<p>I tried to replicate the process in the interactive shell. Indeed, the dimensions of <code>normal_dist</code> are unspecified, although the supplied values do exist:</p>

<pre><code>In [70]: input_size.eval()
Out[70]: 4

In [71]: num_classes.eval()
Out[71]: 3

In [72]: w_shape.eval()
Out[72]: array([4, 3], dtype=int32)

In [73]: normal_dist.eval()
Out[73]: 
array([[-0.27035281, -0.223277  ,  0.14694688],
       [-0.16527176,  0.02180306,  0.00807841],
       [ 0.22624688,  0.36425814, -0.03099642],
       [ 0.25575709, -0.02765726, -0.26169327]], dtype=float32)

In [78]: normal_dist.get_shape()
Out[78]: TensorShape([Dimension(None), Dimension(None)])
</code></pre>

<p>This is weird. Tensorflow generates the vector but can't say its shape. Am I doing something wrong?</p>
",348412.0,,-1.0,,2017-05-23 12:26:09,2018-10-15 20:25:13,Tensor with unspecified dimension in tensorflow,<python><tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34079787
44912297,1,44913058,,2017-07-04 18:33:39,,34,19904,"<p>I am used to using tf.contrib.layers.fully_connected to build a fully connected layer. Recently I ran into tf.layers.dense apparently used where the first functioned could be used. Are the interchangeable, producing the same output?</p>
",7332065.0,,,,,2018-03-23 20:02:44,Are tf.layers.dense() and tf.contrib.layers.fully_connected() interchangeable?,<tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44912297
45473682,1,45474743,,2017-08-03 02:10:33,,34,12728,"<p>I am confused about the difference between <code>apply_gradients</code> and <code>minimize</code> of optimizer in tensorflow. For example,</p>

<pre class=""lang-py prettyprint-override""><code>optimizer = tf.train.AdamOptimizer(1e-3)
grads_and_vars = optimizer.compute_gradients(cnn.loss)
train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)
</code></pre>

<p>and</p>

<pre class=""lang-py prettyprint-override""><code>optimizer = tf.train.AdamOptimizer(1e-3)
train_op = optimizer.minimize(cnn.loss, global_step=global_step)
</code></pre>

<p>Are they the same indeed?</p>

<p>If I want to decay the learning rate, can I use the following codes?</p>

<pre class=""lang-py prettyprint-override""><code>global_step = tf.Variable(0, name=""global_step"", trainable=False)
starter_learning_rate = 1e-3
learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,
                                       100, FLAGS.decay_rate, staircase=True)
# Passing global_step to minimize() will increment it at each step.
learning_step = (
    optimizer = tf.train.AdamOptimizer(learning_rate)
    grads_and_vars = optimizer.compute_gradients(cnn.loss)
    train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)
)
</code></pre>

<p>Thanks for your help!</p>
",6254131.0,,5046896.0,,2019-06-24 07:16:22,2021-03-10 10:23:54,Difference between `apply_gradients` and `minimize` of optimizer in tensorflow,<tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45473682
44623184,1,46268531,,2017-06-19 05:58:24,,34,125147,"<p>Today I installed TensorFlow using:</p>
<pre><code>C:\&gt;pip3 install --upgrade tensorflow
Collecting tensorflow
  Using cached tensorflow-1.2.0-cp35-cp35m-win_amd64.whl
Requirement already up-to-date: bleach==1.5.0 in c:\python35\lib\site-packages (
from tensorflow)
Requirement already up-to-date: werkzeug&gt;=0.11.10 in c:\python35\lib\site-packag
es (from tensorflow)
Requirement already up-to-date: html5lib==0.9999999 in c:\python35\lib\site-pack
ages (from tensorflow)
Requirement already up-to-date: protobuf&gt;=3.2.0 in c:\python35\lib\site-packages
 (from tensorflow)
Requirement already up-to-date: backports.weakref==1.0rc1 in c:\python35\lib\sit
e-packages (from tensorflow)
Requirement already up-to-date: markdown==2.2.0 in c:\python35\lib\site-packages
 (from tensorflow)
Requirement already up-to-date: numpy&gt;=1.11.0 in c:\python35\lib\site-packages (
from tensorflow)
Requirement already up-to-date: six&gt;=1.10.0 in c:\python35\lib\site-packages (fr
om tensorflow)
Requirement already up-to-date: wheel&gt;=0.26 in c:\python35\lib\site-packages (fr
om tensorflow)
Requirement already up-to-date: setuptools in c:\python35\lib\site-packages (fro
m protobuf&gt;=3.2.0-&gt;tensorflow)
Installing collected packages: tensorflow
Successfully installed tensorflow-1.2.0
</code></pre>
<p>When I tried to import TensorFlow, it throws:</p>
<pre><code>C:\&gt;python
Python 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AM
D64)] on win32
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import tensorflow as tf
Traceback (most recent call last):
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_intern
al.py&quot;, line 18, in swig_import_helper
    return importlib.import_module(mname)
  File &quot;C:\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 986, in _gcd_import
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 969, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 958, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 666, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 577, in module_from_spec
  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 906, in create_module
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, l
ine 41, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_intern
al.py&quot;, line 21, in &lt;module&gt;
    _pywrap_tensorflow_internal = swig_import_helper()
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_intern
al.py&quot;, line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File &quot;C:\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;C:\Python35\lib\site-packages\tensorflow\__init__.py&quot;, line 24, in &lt;modu
le&gt;
    from tensorflow.python import *
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\__init__.py&quot;, line 49, i
n &lt;module&gt;
    from tensorflow.python import pywrap_tensorflow
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, l
ine 52, in &lt;module&gt;
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_intern
al.py&quot;, line 18, in swig_import_helper
    return importlib.import_module(mname)
  File &quot;C:\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 986, in _gcd_import
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 969, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 958, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 666, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 577, in module_from_spec
  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 906, in create_module
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, l
ine 41, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_intern
al.py&quot;, line 21, in &lt;module&gt;
    _pywrap_tensorflow_internal = swig_import_helper()
  File &quot;C:\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_intern
al.py&quot;, line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File &quot;C:\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_probl
ems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
&gt;&gt;&gt;
</code></pre>
<p>I'm using Python 3.5.2 64bit. I don't really know why the import process throws errors.</p>
",2558463.0,,1839439.0,,2022-03-19 21:21:01,2022-03-19 21:22:29,Error: Failed to load the native TensorFlow runtime,<python><python-3.x><tensorflow>,14,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44623184
44873273,1,44873274,,2017-07-02 17:10:45,,34,35711,"<p>We see this quite often in many of the TensorFlow tutorials:</p>

<pre class=""lang-py prettyprint-override""><code>sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, 
                                        log_device_placement=True))
</code></pre>

<p>What does <code>allow_soft_placement</code> and <code>log_device_placement</code> mean?</p>
",5703903.0,,3924118.0,,2018-01-09 16:29:13,2019-10-10 15:44:22,What do the options in ConfigProto like allow_soft_placement and log_device_placement mean?,<tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44873273
42590431,1,42590869,,2017-03-04 00:02:10,,34,9730,"<p>I am trying to create a simple neural net in TensorFlow. The only tricky part is I have a custom operation that I have implemented with <code>py_func</code>. When I pass the output from <code>py_func</code> to a <code>Dense</code> layer, TensorFlow complains that the rank should be known. The specific error is:</p>



<pre class=""lang-py prettyprint-override""><code>ValueError: Inputs to `Dense` should have known rank.
</code></pre>

<p>I don't know how to preserve the shape of my data when I pass it through <code>py_func</code>. My question is how do I get the correct shape? I have a simple example below to illustrate the problem.</p>

<pre class=""lang-py prettyprint-override""><code>def my_func(x):
    return np.sinh(x).astype('float32')

inp = tf.convert_to_tensor(np.arange(5))
y = tf.py_func(my_func, [inp], tf.float32, False)

with tf.Session() as sess:
    with sess.as_default():
        print(inp.shape)
        print(inp.eval())
        print(y.shape)
        print(y.eval())
</code></pre>

<p>The output from this snippet is:</p>

<pre class=""lang-py prettyprint-override""><code>(5,)
[0 1 2 3 4]
&lt;unknown&gt;
[  0.       
1.17520118   3.62686038  10.01787472  27.28991699]
</code></pre>

<p>Why is <code>y.shape</code> <code>&lt;unknown&gt;</code>? I want the shape to be <code>(5,)</code> the same as <code>inp</code>. Thanks!</p>
",744520.0,,4315914.0,,2019-06-13 16:04:11,2019-06-13 16:04:11,Output from TensorFlow `py_func` has unknown rank/shape,<tensorflow>,1,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42590431
46154189,1,46154721,,2017-09-11 11:04:11,,34,12190,"<p>When I was learning tensorflow, one basic concept of tensorflow was computational graphs, and the graphs was said to be static.
And I found in Pytorch, the graphs was said to be dynamic.
What's the difference of static Computational Graphs in tensorflow and dynamic Computational Graphs in Pytorch?</p>
",8590947.0,,,,,2017-09-11 18:15:42,What is the difference of static Computational Graphs in tensorflow and dynamic Computational Graphs in Pytorch?,<tensorflow><deep-learning><torch>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46154189
43763858,1,44008016,,2017-05-03 15:08:38,,33,14597,"<p>TensorBoard 1.1.0's images history. I would like to set the slider's position (on top of the black image with 7) more precisely, to be able to select any step. Now I can only select e.g. between steps 2050 or 2810. Is that possible? </p>

<p>Maybe a place in sources where the 10 constant is hardcoded?</p>

<ul>
<li><a href=""https://i.stack.imgur.com/NQNnt.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/NQNnt.png"" alt=""enter image description here""></a></li>
</ul>
",2494561.0,,,,,2018-10-19 07:07:52,Change images slider step in TensorBoard,<tensorflow><tensorboard>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43763858
37063952,1,37064128,,2016-05-06 03:54:53,,33,22743,"<p>I need a conditional control flow in my graph. If <code>pred</code> is <code>True</code>, the graph should call an op that updates a variable and then returns it, otherwise it returns the variable unchanged. A simplified version is:</p>

<pre class=""lang-py prettyprint-override""><code>pred = tf.constant(True)
x = tf.Variable([1])
assign_x_2 = tf.assign(x, [2])
def update_x_2():
  with tf.control_dependencies([assign_x_2]):
    return tf.identity(x)
y = tf.cond(pred, update_x_2, lambda: tf.identity(x))
with tf.Session() as session:
  session.run(tf.initialize_all_variables())
  print(y.eval())
</code></pre>

<p>However, I find that both <code>pred=True</code> and <code>pred=False</code> lead to the same result <code>y=[2]</code>, which means the assign op is also called when <code>update_x_2</code> is not selected by <code>tf.cond</code>. How to explain this? And how to solve this problem?</p>
",3632556.0,,,,,2021-08-12 14:29:25,Confused by the behavior of `tf.cond`,<tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37063952
41921746,1,42603692,,2017-01-29 14:04:55,,33,25755,"<p>I was trying to save images of different sizes into tf-records. I found that even though the images have different sizes, I can still load them with <code>FixedLenFeature</code>. </p>

<p>By checking the docs on <code>FixedLenFeature</code> and <code>VarLenFeature</code>,  I found the difference seems to be that <code>VarLenFeauture</code> returns a sparse tensor.</p>

<p>Could anyone illustrate some situations one should use <code>FixedLenFeature</code> or <code>VarLenFeature</code>?</p>
",2452761.0,,,,,2023-03-10 13:25:21,Tensorflow VarLenFeature vs FixedLenFeature,<python><tensorflow>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41921746
40951602,1,40953146,,2016-12-03 19:25:38,,33,11530,"<p>I'm looking into magenta code, and printing its tensor object. I got this result:</p>

<pre><code>Tensor(""fully_connected/BiasAdd:0"", shape=(?, 38), dtype=float32)
</code></pre>

<p>What does this question mark in shape mean?</p>
",4985978.0,,,,,2016-12-03 22:24:39,what does the question mark in tensorflow shape mean?,<tensorflow>,1,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40951602
45316569,1,45328447,,2017-07-26 02:46:31,,33,91323,"<p>I try to install TensorFlow via pip (<code>pip install tensorflow</code>) but get this error</p>

<blockquote>
  <p>could not find a version that satisfies the requirement tensorflow (from versions: )</p>
</blockquote>

<p>Is there a solution to this problem? I still wish to install it via pip</p>
",8328785.0,,6912508.0,,2018-06-22 00:50:59,2019-03-13 02:35:43,How to install Tensorflow on Python 2.7 on Windows?,<python><tensorflow><module><pip><installation>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45316569
41937915,1,41942396,,2017-01-30 14:08:10,,33,106853,"<p>I'm trying to install tensorflow r0.11. I tried</p>

<pre><code>pip install tensorflow==r0.11
pip install tensorflow&lt;0.12
</code></pre>

<p>But I get this error</p>

<pre><code>Could not find a version that satisfies the requirement tensorflow==0.11.0 (from versions: 0.12.0rc0, 0.12.0rc1, 0.12.0, 0.12.1)
No matching distribution found for tensorflow==0.11.0
</code></pre>

<p>I assume pip is no longer support depricated versions, how can I get it?</p>

<p>I also tried</p>

<pre><code>pip install git+git://github.com/tensorflow/tensorflow@r0.11

Cloning git://github.com/tensorflow/tensorflow (to r0.11) to /private/var/folders/1p/7km73m0s2cvdfb1js3ct8_mh0000gn/T/pip-JMMIRP-build
Complete output from command python setup.py egg_info:
Traceback (most recent call last):
  File ""&lt;string&gt;"", line 1, in &lt;module&gt;
IOError: [Errno 2] No such file or directory: '/private/var/folders/1p/7km73m0s2cvdfb1js3ct8_mh0000gn/T/pip-JMMIRP-build/setup.py'

----------------------------------------
Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/1p/7km73m0s2cvdfb1js3ct8_mh0000gn/T/pip-JMMIRP-build/
</code></pre>
",350080.0,,350080.0,,2017-01-30 14:16:37,2023-04-10 23:41:21,How to pip install old version of library(tensorflow)?,<python><macos><tensorflow><pip>,7,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41937915
40904979,1,40905027,,2016-12-01 07:35:52,,33,21647,"<p>Durng the test of TensorFlow r0.12(CPU) installed on Windows 10, I found that the printed string contant is always with an 'b' in the end. The print of python is normal. I cannot figure out the reason so came here for help. The code is as follows:</p>

<pre><code>&gt;&gt;&gt;import tensorflow as tf
&gt;&gt;&gt;hello = tf.constant('Hello, TensorFlow!')
&gt;&gt;&gt;sess = tf.Session()
&gt;&gt;&gt;print(sess.run(hello))
b'Hello, TensorFlow!'
</code></pre>
",6429277.0,,,,,2018-01-08 09:12:12,The print of string constant is always attached with 'b' inTensorFlow,<python><windows><tensorflow>,1,2,0.0,2016-12-01 07:37:53,,CC BY-SA 3.0,https://stackoverflow.com/q/40904979
40731433,1,40737933,,2016-11-21 23:38:20,,33,21873,"<p>I found the following method <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#extract_image_patches"" rel=""noreferrer"">tf.extract_image_patches</a> in tensorflow API, but I am not clear about its functionality. </p>

<p>Say the <code>batch_size = 1</code>, and an image is of size <code>225x225x3</code>, and we want to extract patches of size <code>32x32</code>. </p>

<p>How exactly does this function behave? Specifically, the documentation mentions the dimension of the output tensor to be <code>[batch, out_rows, out_cols, ksize_rows * ksize_cols * depth]</code> , but what <code>out_rows</code> and <code>out_cols</code> are is not mentioned.</p>

<p>Ideally, given an input image tensor of size <code>1x225x225x3</code> (where 1 is the batch size), I want to be able to get <code>Kx32x32x3</code> as output, where <code>K</code> is the total number of patches and <code>32x32x3</code> is the dimension of each patch. Is there something in tensorflow that already achieves this?</p>
",1252766.0,,3924118.0,,2017-10-22 15:29:23,2021-11-03 22:16:07,Understanding tf.extract_image_patches for extracting patches from an image,<python><neural-network><tensorflow>,3,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40731433
39734146,1,40986014,,2016-09-27 20:54:15,,32,16315,"<p>There are several classes in <code>tf.nn</code> that relate to RNNs. In the examples I find on the web, <code>tf.nn.dynamic_rnn</code> and <code>tf.nn.rnn</code> seem to be used interchangeably or at least I cannot seem to figure out why one is used in place of the other. What is the difference?</p>
",302268.0,,3924118.0,,2018-07-08 23:06:56,2018-12-28 06:57:26,What's the difference between tensorflow dynamic_rnn and rnn?,<tensorflow><recurrent-neural-network>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/39734146
40472139,1,40473750,,2016-11-07 18:33:46,,32,24020,"<p>Is it possible for obtain the total number of records from a <code>.tfrecords</code> file ? Related to this, how does one generally keep track of the number of epochs that have elapsed while training models? While it is possible for us to specify the <code>batch_size</code> and <code>num_of_epochs</code>, I am not sure if it is straightforward to obtain values such as <code>current epoch</code>, number of batches per epoch etc - just so that I could have more control of how the training is progressing. Currently, I'm just using a dirty hack to compute this as I know before hand how many records there are in my .tfrecords file and the size of my minibatches. Appreciate any help..</p>
",1050648.0,,5368083.0,,2018-04-12 08:51:20,2021-05-23 20:09:40,Obtaining total number of records from .tfrecords file in Tensorflow,<tensorflow><tfrecord>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40472139
33720645,1,33723404,,2015-11-15 14:12:06,,32,19178,"<p>As a toy example I'm trying to fit a function <code>f(x) = 1/x</code> from 100 no-noise data points. The matlab default implementation is phenomenally successful with mean square difference ~10^-10, and interpolates perfectly.</p>

<p>I implement a neural network with one hidden layer of 10 sigmoid neurons. I'm a beginner at neural networks so be on your guard against dumb code.</p>

<pre><code>import tensorflow as tf
import numpy as np

def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)

#Can't make tensorflow consume ordinary lists unless they're parsed to ndarray
def toNd(lst):
    lgt = len(lst)
    x = np.zeros((1, lgt), dtype='float32')
    for i in range(0, lgt):
        x[0,i] = lst[i]
    return x

xBasic = np.linspace(0.2, 0.8, 101)
xTrain = toNd(xBasic)
yTrain = toNd(map(lambda x: 1/x, xBasic))

x = tf.placeholder(""float"", [1,None])
hiddenDim = 10

b = bias_variable([hiddenDim,1])
W = weight_variable([hiddenDim, 1])

b2 = bias_variable([1])
W2 = weight_variable([1, hiddenDim])

hidden = tf.nn.sigmoid(tf.matmul(W, x) + b)
y = tf.matmul(W2, hidden) + b2

# Minimize the squared errors.
loss = tf.reduce_mean(tf.square(y - yTrain))
optimizer = tf.train.GradientDescentOptimizer(0.5)
train = optimizer.minimize(loss)

# For initializing the variables.
init = tf.initialize_all_variables()

# Launch the graph
sess = tf.Session()
sess.run(init)

for step in xrange(0, 4001):
    train.run({x: xTrain}, sess)
    if step % 500 == 0:
        print loss.eval({x: xTrain}, sess)
</code></pre>

<p>Mean square difference ends at ~2*10^-3, so about 7 orders of magnitude worse than matlab. Visualising with</p>

<pre><code>xTest = np.linspace(0.2, 0.8, 1001)
yTest = y.eval({x:toNd(xTest)}, sess)  
import matplotlib.pyplot as plt
plt.plot(xTest,yTest.transpose().tolist())
plt.plot(xTest,map(lambda x: 1/x, xTest))
plt.show()
</code></pre>

<p>we can see the fit is systematically imperfect:
<a href=""https://i.stack.imgur.com/Blxq9.png""><img src=""https://i.stack.imgur.com/Blxq9.png"" alt=""enter image description here""></a>
while the matlab one looks perfect to the naked eye with the differences uniformly &lt; 10^-5:
<a href=""https://i.stack.imgur.com/kC8aJ.jpg""><img src=""https://i.stack.imgur.com/kC8aJ.jpg"" alt=""enter image description here""></a>
I have tried to replicate with TensorFlow the diagram of the Matlab network:</p>

<p><a href=""https://i.stack.imgur.com/ORLXL.png""><img src=""https://i.stack.imgur.com/ORLXL.png"" alt=""enter image description here""></a></p>

<p>Incidentally, the diagram seems to imply a tanh rather than sigmoid activation function. I cannot find it anywhere in documentation to be sure. However, when I try to use a tanh neuron in TensorFlow the fitting quickly fails with <code>nan</code> for variables. I do not know why.</p>

<p>Matlab uses Levenberg–Marquardt training algorithm. Bayesian regularization is even more successful with mean squares at 10^-12 (we are probably in the area of vapours of float arithmetic).</p>

<p>Why is TensorFlow implementation so much worse, and what can I do to make it better?</p>
",1715157.0,,,,,2016-04-25 17:09:53,Why is this TensorFlow implementation vastly less successful than Matlab's NN?,<python><matlab><neural-network><tensorflow>,2,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33720645
41607155,1,41608016,,2017-01-12 07:13:06,,32,77454,"<p>I'm a newer to tensorflow, I really don't know how to solve the problem.</p>

<p>The code is like:</p>

<ol>
<li><p>Feed the train with values:</p>

<pre><code>sess.run(train_op, feed_dict={images: e, labels: l, keep_prob_fc2: 0.5})
</code></pre></li>
<li><p>Use the value in CNN:</p>

<pre><code>x = tf.placeholder(tf.float32, [None, 10 * 1024])
</code></pre></li>
</ol>

<p>Then have the error</p>

<blockquote>
<pre><code>InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float
     [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
</code></pre>
</blockquote>

<p>I print the input valuetypes using <code>print(e.dtype)</code> and the result is <code>float32</code> and <code>e.shape:(10, 32, 32, 1)</code>.</p>

<p>I really don't know why this error is happening.</p>

<hr>

<p>The code format</p>

<p>First: </p>

<pre><code> define the CNN model 
       ""image = tf.placeholder(tf.float32, [FLAGS.batch_size, 32,32,1])"" is here
</code></pre>

<p>Second:</p>

<pre><code> loss funtion and train_op is here
       ""label = tf.placeholder(tf.float32, [None, FLAGS.batch_size])"" is here
</code></pre>

<p>Third is the session:</p>

<pre><code>images, labels = getShuffleimage()#here will get shuffle data
num_examples = 0
init = tf.initialize_local_variables()

with tf.Session() as sess:
    # Start populating the filename queue.
    sess.run(init)
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord, sess=sess)

    try:
        step = 0
        while not coord.should_stop():
            start_time = time.time()
            image, label = sess.run([images, labels])#get shuffle images
            print(image.shape)
            print(image.dtype)
            sess.run(train_op, feed_dict={image: image, label: label , keep_prob_fc2: 0.5})
            duration = time.time() - start_time

    except tf.errors.OutOfRangeError:
        print('Done training after reading all data')
    finally:
        # When done, ask the threads to stop.
        coord.request_stop()

        # Wait for threads to finish.
        coord.join(threads)
        sess.close()
</code></pre>
",6430408.0,,8472976.0,,2018-05-17 15:56:05,2018-05-17 15:56:05,You must feed a value for placeholder tensor 'Placeholder' with dtype float,<python><tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41607155
42708989,1,49660916,,2017-03-10 02:15:37,,32,17017,"<p>I've been reading the tutorials on TensorFlow where they have written</p>

<pre><code>with tf.name_scope('read_inputs') as scope:
    # something
</code></pre>

<p>The example</p>

<pre><code>a = tf.constant(5)
</code></pre>

<p>and </p>

<pre><code>with tf.name_scope('s1') as scope:
    a = tf.constant(5)
</code></pre>

<p>seem to have the same effect. So, why do we use <code>name_scope</code>?</p>
",3702920.0,,3924118.0,,2019-11-01 18:58:42,2021-12-07 19:57:19,Why do we use tf.name_scope(),<tensorflow>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42708989
47091726,1,47096355,,2017-11-03 08:56:19,,32,14966,"<p>With the recent upgrade to version 1.4, Tensorflow included <code>tf.data</code> in the library core.
One ""major new feature"" described in the <a href=""https://github.com/tensorflow/tensorflow/blob/r1.4/RELEASE.md"" rel=""noreferrer"">version 1.4 release notes</a> is <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply"" rel=""noreferrer""><code>tf.data.Dataset.apply()</code></a>, which is a ""method for
applying custom transformation functions"". How is this different from the already existing <a href=""https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"" rel=""noreferrer""><code>tf.data.Dataset.map()</code></a>?</p>
",3214872.0,,3574081.0,,2017-12-20 04:29:34,2021-04-17 07:13:15,Difference between tf.data.Dataset.map() and tf.data.Dataset.apply(),<python><tensorflow><tensorflow-datasets>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47091726
44971349,1,44971517,,2017-07-07 12:56:27,,32,28312,"<p>I am fairly new to Tensorflow and ML in general, so I hereby apologize for a (likely) trivial question. </p>

<p>I use the dropout technique to improve learning rates of my network, and it seems to work just fine. Then, I would like to test the network on some data to see if it works like this:</p>

<pre><code>   def Ask(self, image):
        return self.session.run(self.model, feed_dict = {self.inputPh: image})
</code></pre>

<p>Obviously, it yields different results each time as the dropout is still in place. One solution I can think of is to create two separate models - one for a training and the other one for an actual later use of the network, however, such a solution seems impractical to me.</p>

<p>What's the common approach to solving this problem? </p>
",8256202.0,,5161074.0,,2017-07-07 12:59:03,2020-05-02 01:00:41,How to turn off dropout for testing in Tensorflow?,<python><machine-learning><tensorflow><neural-network><conv-neural-network>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44971349
49148962,1,49150433,,2018-03-07 09:58:43,,32,15141,"<p>I am using the <a href=""https://github.com/tensorflow/models/tree/master/research/object_detection"" rel=""noreferrer"">object detection api</a> in tensorflow. I noticed that practically all parameters pass through the config file. I could not find any documentation or tutorial on the options for these config files though.</p>

<p>I know that in the official git they provide a <a href=""https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs"" rel=""noreferrer"">list of config files</a> for their pretrained models which could be very helpful but it does not cover every case and of course does not provide any explanation if needed.</p>

<p>For example in <code>train_config</code> section there are some data augmentation options which are quite self explanatory but the potential existence of other options is unclear:</p>

<pre><code>  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  data_augmentation_options {
    ssd_random_crop {
    }
  }
</code></pre>

<p>Is there a source I could refer to? For example in this <a href=""https://medium.com/@WuStangDan/step-by-step-tensorflow-object-detection-api-tutorial-part-4-training-the-model-68a9e5d5a333"" rel=""noreferrer"">tutorial</a> two extra options (<code>batch_queue_capacity</code> and <code>prefetch_queue_capacity</code>) I did not know about appear. Where could I find a decent list of options I have? I know that it's model specific but some of them are universal and really helpful.</p>
",3584765.0,,,,,2019-03-06 15:53:37,Tensorflow object detection config files documentation,<tensorflow><config>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49148962
40994583,1,40995666,,2016-12-06 11:44:46,,32,37085,"<p>In the <a href=""https://www.tensorflow.org/versions/r0.10/tutorials/mnist/beginners/index.html"" rel=""noreferrer"">tensorflow MNIST tutorial</a> the <code>mnist.train.next_batch(100)</code> function comes very handy. I am now trying to implement a simple classification myself. I have my training data in a numpy array. How could I implement a similar function for my own data to give me the next batch?</p>

<pre><code>sess = tf.InteractiveSession()
tf.global_variables_initializer().run()
Xtr, Ytr = loadData()
for it in range(1000):
    batch_x = Xtr.next_batch(100)
    batch_y = Ytr.next_batch(100)
</code></pre>
",4139024.0,,,,,2019-07-22 20:25:34,how to implement tensorflow's next_batch for own data,<python><numpy><neural-network><tensorflow><classification>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40994583
38399609,1,38615584,,2016-07-15 15:14:08,,32,27860,"<p>I use a tensorflow to implement a simple multi-layer perceptron for regression. The code is modified from standard mnist classifier, that I only changed the output cost to MSE (use <code>tf.reduce_mean(tf.square(pred-y))</code>), and some input, output size settings. However, if I train the network using regression, after several epochs, the output batch are totally the same. for example:</p>

<pre><code>target: 48.129, estimated: 42.634
target: 46.590, estimated: 42.634
target: 34.209, estimated: 42.634
target: 69.677, estimated: 42.634
......
</code></pre>

<p>I have tried different batch size, different initialization, input normalization using sklearn.preprocessing.scale (my inputs range are quite different). However, none of them worked. I have also tried one of sklearn example from Tensorflow (<a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/boston.py"">Deep Neural Network Regression with Boston Data</a>). But I got another error in line 40:</p>

<p>'module' object has no attribute 'infer_real_valued_columns_from_input'</p>

<p>Anyone has clues on where the problem is? Thank you</p>

<p>My code is listed below, may be a little bit long, but very straghtforward:</p>

<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
from tensorflow.contrib import learn
import matplotlib.pyplot as plt

from sklearn.pipeline import Pipeline
from sklearn import datasets, linear_model
from sklearn import cross_validation
import numpy as np

boston = learn.datasets.load_dataset('boston')
x, y = boston.data, boston.target
X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(
x, y, test_size=0.2, random_state=42)

total_len = X_train.shape[0]

# Parameters
learning_rate = 0.001
training_epochs = 500
batch_size = 10
display_step = 1
dropout_rate = 0.9
# Network Parameters
n_hidden_1 = 32 # 1st layer number of features
n_hidden_2 = 200 # 2nd layer number of features
n_hidden_3 = 200
n_hidden_4 = 256
n_input = X_train.shape[1]
n_classes = 1

# tf Graph input
x = tf.placeholder(""float"", [None, 13])
y = tf.placeholder(""float"", [None])

# Create model
def multilayer_perceptron(x, weights, biases):
    # Hidden layer with RELU activation
    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])
    layer_1 = tf.nn.relu(layer_1)

    # Hidden layer with RELU activation
    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])
    layer_2 = tf.nn.relu(layer_2)

    # Hidden layer with RELU activation
    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])
    layer_3 = tf.nn.relu(layer_3)

    # Hidden layer with RELU activation
    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])
    layer_4 = tf.nn.relu(layer_4)

    # Output layer with linear activation
    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']
    return out_layer

# Store layers weight &amp; bias
weights = {
    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], 0, 0.1)),
    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], 0, 0.1)),
    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3], 0, 0.1)),
    'h4': tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4], 0, 0.1)),
    'out': tf.Variable(tf.random_normal([n_hidden_4, n_classes], 0, 0.1))
}
biases = {
    'b1': tf.Variable(tf.random_normal([n_hidden_1], 0, 0.1)),
    'b2': tf.Variable(tf.random_normal([n_hidden_2], 0, 0.1)),
    'b3': tf.Variable(tf.random_normal([n_hidden_3], 0, 0.1)),
    'b4': tf.Variable(tf.random_normal([n_hidden_4], 0, 0.1)),
    'out': tf.Variable(tf.random_normal([n_classes], 0, 0.1))
}

# Construct model
pred = multilayer_perceptron(x, weights, biases)

# Define loss and optimizer
cost = tf.reduce_mean(tf.square(pred-y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

# Launch the graph
with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())

    # Training cycle
    for epoch in range(training_epochs):
        avg_cost = 0.
        total_batch = int(total_len/batch_size)
        # Loop over all batches
        for i in range(total_batch-1):
            batch_x = X_train[i*batch_size:(i+1)*batch_size]
            batch_y = Y_train[i*batch_size:(i+1)*batch_size]
            # Run optimization op (backprop) and cost op (to get loss value)
            _, c, p = sess.run([optimizer, cost, pred], feed_dict={x: batch_x,
                                                          y: batch_y})
            # Compute average loss
            avg_cost += c / total_batch

        # sample prediction
        label_value = batch_y
        estimate = p
        err = label_value-estimate
        print (""num batch:"", total_batch)

        # Display logs per epoch step
        if epoch % display_step == 0:
            print (""Epoch:"", '%04d' % (epoch+1), ""cost="", \
                ""{:.9f}"".format(avg_cost))
            print (""[*]----------------------------"")
            for i in xrange(3):
                print (""label value:"", label_value[i], \
                    ""estimated value:"", estimate[i])
            print (""[*]============================"")

    print (""Optimization Finished!"")

    # Test model
    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
    # Calculate accuracy
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
    print (""Accuracy:"", accuracy.eval({x: X_test, y: Y_test}))
</code></pre>
",6233298.0,,6233298.0,,2016-07-15 21:49:33,2018-01-06 02:39:11,tensorflow deep neural network for regression always predict same results in one batch,<python><neural-network><regression><tensorflow>,2,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38399609
41813665,1,41929380,,2017-01-23 18:58:11,,32,33906,"<p>I am following <a href=""https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb"" rel=""noreferrer"">this</a> tutorial for learning TensorFlow Slim but upon running the following code for Inception:</p>

<pre><code>import numpy as np
import os
import tensorflow as tf
import urllib2

from datasets import imagenet
from nets import inception
from preprocessing import inception_preprocessing

slim = tf.contrib.slim

batch_size = 3
image_size = inception.inception_v1.default_image_size
checkpoints_dir = '/tmp/checkpoints/'
with tf.Graph().as_default():
    url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'
    image_string = urllib2.urlopen(url).read()
    image = tf.image.decode_jpeg(image_string, channels=3)
    processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)
    processed_images  = tf.expand_dims(processed_image, 0)

    # Create the model, use the default arg scope to configure the batch norm parameters.
    with slim.arg_scope(inception.inception_v1_arg_scope()):
        logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False)
    probabilities = tf.nn.softmax(logits)

    init_fn = slim.assign_from_checkpoint_fn(
        os.path.join(checkpoints_dir, 'inception_v1.ckpt'),
        slim.get_model_variables('InceptionV1'))

    with tf.Session() as sess:
        init_fn(sess)
        np_image, probabilities = sess.run([image, probabilities])
        probabilities = probabilities[0, 0:]
        sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]

    plt.figure()
    plt.imshow(np_image.astype(np.uint8))
    plt.axis('off')
    plt.show()

    names = imagenet.create_readable_names_for_imagenet_labels()
    for i in range(5):
        index = sorted_inds[i]
        print('Probability %0.2f%% =&gt; [%s]' % (probabilities[index], names[index]))
</code></pre>

<p>I seem to be getting this set of errors:</p>

<pre><code>Traceback (most recent call last):
  File ""DA_test_pred.py"", line 24, in &lt;module&gt;
    logits, _ = inception.inception_v1(processed_images, num_classes=1001, is_training=False)
  File ""/home/deepankar1994/Desktop/MTP/TensorFlowEx/TFSlim/models/slim/nets/inception_v1.py"", line 290, in inception_v1
    net, end_points = inception_v1_base(inputs, scope=scope)
  File ""/home/deepankar1994/Desktop/MTP/TensorFlowEx/TFSlim/models/slim/nets/inception_v1.py"", line 96, in inception_v1_base
    net = tf.concat(3, [branch_0, branch_1, branch_2, branch_3])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 1053, in concat
    dtype=dtypes.int32).get_shape(
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 651, in convert_to_tensor
    as_ref=False)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 716, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py"", line 367, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py"", line 302, in _AssertCompatible
    (dtype.name, repr(mismatch), type(mismatch).__name__))
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.
</code></pre>

<p>This is strange because all of this code is from their official guide. I am new to TF and any help would be appreciated.</p>
",4482655.0,,,,,2020-08-14 15:56:28,"Tensorflow Slim: TypeError: Expected int32, got list containing Tensors of type '_Message' instead",<python><machine-learning><tensorflow><computer-vision><deep-learning>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41813665
67120450,1,70700690,,2021-04-16 06:55:22,,32,89836,"<p>I was working on a sign language detection project on jupyter notebook. While running the code for live detection I encountered an error as shown below:</p>
<blockquote>
<p>OpenCV(4.5.1) C:\Users\appveyor\AppData\Local\Temp\1\pip-req-build-1drr4hl0\opencv\modules\highgui\src\window.cpp:651: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'</p>
</blockquote>
<p>The code that caused this error is:</p>
<pre class=""lang-py prettyprint-override""><code>while True: 
    ret, frame = cap.read()
    image_np = np.array(frame)
    
    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)
    detections = detect_fn(input_tensor)
    
    num_detections = int(detections.pop('num_detections'))
    detections = {key: value[0, :num_detections].numpy()
                  for key, value in detections.items()}
    detections['num_detections'] = num_detections

    # detection_classes should be ints.
    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

    label_id_offset = 1
    image_np_with_detections = image_np.copy()

    viz_utils.visualize_boxes_and_labels_on_image_array(
                image_np_with_detections,
                detections['detection_boxes'],
                detections['detection_classes']+label_id_offset,
                detections['detection_scores'],
                category_index,
                use_normalized_coordinates=True,
                max_boxes_to_draw=5,
                min_score_thresh=.5,
                agnostic_mode=False)

    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))
    
    if cv2.waitKey(1) &amp; 0xFF == ord('q'):
        cap.release()
        break
</code></pre>
<p>NB: I installed OpenCV using using pip install.</p>
",15657332.0,,10669875.0,,2022-06-12 05:48:56,2023-04-07 13:54:48,"error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support",<python><tensorflow><opencv><machine-learning><computer-vision>,13,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/67120450
37921781,1,37922210,,2016-06-20 11:48:45,,32,37590,"<p>The documentation is not quite clear about this. I suppose the gradients one can obtain by <code>opt.compute_gradients(E, [v])</code> contain the <code>∂E/∂x = g(x)</code> for each element <code>x</code> of the tensor that <code>v</code> stores. Does <code>opt.apply_gradients(grads_and_vars)</code> essentially execute <code>x ← -η·g(x)</code>, where <code>η</code> is the learning rate? That would imply that if I want to add a positive additive change <code>p</code> to the variable, I would need to need to change <code>g(x) ← g(x) - (1/η)p</code>, e.g. like this:</p>

<pre class=""lang-py prettyprint-override""><code>opt = tf.train.GradientDescentOptimizer(learning_rate=l)
grads_and_vars = opt.compute_gradients(loss, var_list)

for l, gv in enumerate(grads_and_vars):
    grads_and_vars[l] = (gv[0] - (1/l) * p, gv[1])

train_op = opt.apply_gradients(grads_and_vars)
</code></pre>

<p>Is there a better way to do this?</p>
",852592.0,,,,,2019-09-26 22:32:21,What does opt.apply_gradients() do in TensorFlow?,<tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37921781
34204551,1,34205394,,2015-12-10 14:35:06,,31,13729,"<p>Is there any way to run Tensorflow unit tests manually? I want to perform sanity checks while modifying TF source code.</p>

<p>I see there are many _test.py files with classes that perform many test operations and I can't figure out how to run them. There should be an easy way?</p>
",1067998.0,,7458927.0,,2019-03-11 18:02:57,2019-03-12 23:21:42,Run Tensorflow unit tests,<unit-testing><tensorflow><testing><bazel>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34204551
50764572,1,51987281,,2018-06-08 16:08:34,,31,32320,"<p>I have generated a .tflite model based on a trained model, I would like to test that the tfilte model gives the same results as the original model.</p>

<p>Giving both the same test data and obtaining the same result.</p>
",9899807.0,,606314.0,,2018-06-08 20:13:44,2020-06-12 22:22:13,How can I test a .tflite model to prove that it behaves as the original model using the same Test Data?,<python><tensorflow><tensorflow-lite>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50764572
42355122,1,42358524,,2017-02-20 22:10:33,,31,35159,"<p>Is there a way to extract scalar summaries to CSV (preferably from within tensorboard) from tfevents files?</p>

<h2>Example code</h2>

<p>The following code generates tfevent files in a <code>summary_dir</code> within the same directory. Suppose you let it run and you find something interesting. You want to get the raw data for further investigation. How would you do that?</p>

<pre class=""lang-python prettyprint-override""><code>#!/usr/bin/env python
""""""A very simple MNIST classifier.""""""
import argparse
import sys

from tensorflow.examples.tutorials.mnist import input_data

import tensorflow as tf
ce_with_logits = tf.nn.softmax_cross_entropy_with_logits

FLAGS = None


def inference(x):
    """"""
    Build the inference graph.

    Parameters
    ----------
    x : placeholder

    Returns
    -------
    Output tensor with the computed logits.
    """"""
    W = tf.Variable(tf.zeros([784, 10]))
    b = tf.Variable(tf.zeros([10]))
    y = tf.matmul(x, W) + b
    return y


def loss(logits, labels):
    """"""
    Calculate the loss from the logits and the labels.

    Parameters
    ----------
    logits : Logits tensor, float - [batch_size, NUM_CLASSES].
    labels : Labels tensor, int32 - [batch_size]
    """"""
    cross_entropy = tf.reduce_mean(ce_with_logits(labels=labels,
                                                  logits=logits))
    return cross_entropy


def training(loss, learning_rate=0.5):
    """"""
    Set up the training Ops.

    Parameters
    ----------
    loss : Loss tensor, from loss().
    learning_rate : The learning rate to use for gradient descent.

    Returns
    -------
    train_op: The Op for training.
    """"""
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    train_step = optimizer.minimize(loss)
    return train_step


def main(_):
    # Import data
    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)

    # Create the model
    x = tf.placeholder(tf.float32, [None, 784])
    y = inference(x)

    # Define loss and optimizer
    y_ = tf.placeholder(tf.float32, [None, 10])
    loss_ = loss(logits=y, labels=y_)
    train_step = training(loss_)

    # Test trained model
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    with tf.name_scope('accuracy'):
        tf.summary.scalar('accuracy', accuracy)
    merged = tf.summary.merge_all()

    sess = tf.InteractiveSession()
    train_writer = tf.summary.FileWriter('summary_dir/train', sess.graph)
    test_writer = tf.summary.FileWriter('summary_dir/test', sess.graph)
    tf.global_variables_initializer().run()

    for train_step_i in range(100000):
        if train_step_i % 100 == 0:
            summary, acc = sess.run([merged, accuracy],
                                    feed_dict={x: mnist.test.images,
                                               y_: mnist.test.labels})
            test_writer.add_summary(summary, train_step_i)
            summary, acc = sess.run([merged, accuracy],
                                    feed_dict={x: mnist.train.images,
                                               y_: mnist.train.labels})
            train_writer.add_summary(summary, train_step_i)
        batch_xs, batch_ys = mnist.train.next_batch(100)
        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

    print(sess.run(accuracy, feed_dict={x: mnist.test.images,
                                        y_: mnist.test.labels}))

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir',
                        type=str,
                        default='/tmp/tensorflow/mnist/input_data',
                        help='Directory for storing input data')
    FLAGS, unparsed = parser.parse_known_args()
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
</code></pre>
",562769.0,,3941813.0,,2017-02-25 05:11:03,2021-10-07 13:30:55,Can I export a tensorflow summary to CSV?,<csv><tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42355122
40785224,1,40785890,,2016-11-24 11:26:48,,31,51207,"<p>I am trying to build a neural network model with one hidden layer (1024 nodes). The hidden layer is nothing but a relu unit. I am also processing the input data in batches of 128. </p>

<p>The inputs are images of size 28 * 28. In the following code I get the error in line</p>

<pre><code>_, c = sess.run([optimizer, loss], feed_dict={x: batch_x, y: batch_y})
Error: TypeError: Cannot interpret feed_dict key as Tensor: Tensor Tensor(""Placeholder_64:0"", shape=(128, 784), dtype=float32) is not an element of this graph.
</code></pre>

<p>Here is the code I have written</p>

<pre class=""lang-py prettyprint-override""><code>#Initialize

batch_size = 128

layer1_input = 28 * 28
hidden_layer1 = 1024
num_labels = 10
num_steps = 3001

#Create neural network model
def create_model(inp, w, b):
    layer1 = tf.add(tf.matmul(inp, w['w1']), b['b1'])
    layer1 = tf.nn.relu(layer1)
    layer2 = tf.matmul(layer1, w['w2']) + b['b2']
    return layer2

#Initialize variables
x = tf.placeholder(tf.float32, shape=(batch_size, layer1_input))
y = tf.placeholder(tf.float32, shape=(batch_size, num_labels))

w = {
'w1': tf.Variable(tf.random_normal([layer1_input, hidden_layer1])),
'w2': tf.Variable(tf.random_normal([hidden_layer1, num_labels]))
}
b = {
'b1': tf.Variable(tf.zeros([hidden_layer1])),
'b2': tf.Variable(tf.zeros([num_labels]))
}

init = tf.initialize_all_variables()
train_prediction = tf.nn.softmax(model)

tf_valid_dataset = tf.constant(valid_dataset)
tf_test_dataset = tf.constant(test_dataset)

model = create_model(x, w, b)

loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model, y))    
optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

#Process
with tf.Session(graph=graph1) as sess:
    tf.initialize_all_variables().run()
    total_batch = int(train_dataset.shape[0] / batch_size)

    for epoch in range(num_steps):    
        loss = 0
        for i in range(total_batch):
            batch_x, batch_y = train_dataset[epoch * batch_size:(epoch+1) * batch_size, :], train_labels[epoch * batch_size:(epoch+1) * batch_size,:]

            _, c = sess.run([optimizer, loss], feed_dict={x: batch_x, y: batch_y})
            loss = loss + c
        loss = loss / total_batch
        if epoch % 500 == 0:
            print (""Epoch :"", epoch, "". cost = {:.9f}"".format(avg_cost))
            print(""Minibatch accuracy: %.1f%%"" % accuracy(predictions, batch_labels))
            valid_prediction = tf.run(tf_valid_dataset, {x: tf_valid_dataset})
            print(""Validation accuracy: %.1f%%"" % accuracy(valid_prediction.eval(), valid_labels))
    test_prediction = tf.run(tf_test_dataset,  {x: tf_test_dataset})
    print(""TEST accuracy: %.1f%%"" % accuracy(test_prediction.eval(), test_labels))
</code></pre>
",762819.0,,155137.0,,2018-04-07 17:08:28,2021-05-19 18:28:04,Tensorflow: Cannot interpret feed_dict key as Tensor,<neural-network><tensorflow><deep-learning>,8,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40785224
42616625,1,42616834,,2017-03-06 02:32:32,,31,50213,"<p>I'm doing text tagger using Bidirectional dynamic RNN in tensorflow.
After maching input's dimension, I tried to run a Session. 
this is blstm setting parts:</p>

<pre><code>fw_lstm_cell = BasicLSTMCell(LSTM_DIMS)
bw_lstm_cell = BasicLSTMCell(LSTM_DIMS)

(fw_outputs, bw_outputs), _ = bidirectional_dynamic_rnn(fw_lstm_cell,
                                                        bw_lstm_cell,
                                                        x_place,
                                                        sequence_length=SEQLEN,
                                                        dtype='float32')
</code></pre>

<p>and this is runing part:</p>

<pre><code>  with tf.Graph().as_default():
    # Placehoder Settings
    x_place, y_place = set_placeholder(BATCH_SIZE, EM_DIMS, MAXLEN)

    # BLSTM Model Building
    hlogits = tf_kcpt.build_blstm(x_place)

    # Compute loss
    loss = tf_kcpt.get_loss(log_likelihood)

    # Training
    train_op = tf_kcpt.training(loss)

    # load Eval method
    eval_correct = tf_kcpt.evaluation(logits, y_place)

    # Session Setting &amp; Init
    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init)

    # tensor summary setting
    summary = tf.summary.merge_all()
    summary_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)

    # Save
    saver = tf.train.Saver()

    # Run epoch
    for step in range(EPOCH):
        start_time = time.time()

        feed_dict = fill_feed_dict(KCPT_SET['train'], x_place, y_place)
        _, loss_value = sess.run([train_op, loss], feed_dict=feed_dict)
</code></pre>

<p>But, it give me the error:</p>

<blockquote>
  <p>ValueError: Tensor(""Shape:0"", shape=(1,), dtype=int32) must be from the same graph as Tensor(""bidirectional_rnn/fw/fw/stack_2:0"", shape=(1,), dtype=int32).</p>
</blockquote>

<p>Help me, please</p>
",7663887.0,,6583140.0,,2018-04-02 14:43:39,2020-08-12 01:48:34,ValueError: Tensor must be from the same graph as Tensor with Bidirectinal RNN in Tensorflow,<python><tensorflow><deep-learning><recurrent-neural-network><bidirectional>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42616625
36123740,1,37931964,,2016-03-21 05:27:50,,30,33433,"<p>Tensorflow tends to preallocate the entire available memory on it's GPUs. For debugging, is there a way of telling how much of that memory is actually in use?</p>
",349760.0,,,,,2022-11-25 09:40:35,Is there a way of determining how much GPU memory is in use by TensorFlow?,<gpu><tensorflow>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36123740
35289773,1,35289851,,2016-02-09 10:35:55,,30,26779,"<p>There are many methods in TensorFlow that requires specifying a shape, for example truncated_normal:</p>

<pre><code>tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)
</code></pre>

<p>I have a placeholder for the input of shape [None, 784], where the first dimension is None because the batch size can vary. I could use a fixed batch size but it still would be different from the test/validation set size.</p>

<p>I cannot feed this placeholder to tf.truncated_normal because it requires a fully specified tensor shape. What is a simple way to having tf.truncated_normal accept different tensor shapes?</p>
",1851402.0,,,,,2016-04-29 10:31:45,Cannot convert a partially converted tensor in TensorFlow,<python><tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35289773
36610290,1,54562773,,2016-04-13 21:54:48,,30,32590,"<p>I have recently been working on a project that uses a neural network for virtual robot control. I used tensorflow to code it up and it runs smoothly. So far, I used sequential simulations to evaluate how good the neural network is, however, I want to run several simulations <strong>in parallel</strong> to reduce the amount of time it takes to get data.</p>

<p>To do this I am importing python's <code>multiprocessing</code> package. Initially I was passing the sess variable (<code>sess=tf.Session()</code>) to a function that would run the simulation. However, once I get to any statement that uses this <code>sess</code> variable, the process quits without a warning. After searching around for a bit I found these two posts:
<a href=""https://stackoverflow.com/questions/34900246/tensorflow-passing-a-session-to-a-python-multiprocess"">Tensorflow: Passing a session to a python multiprocess</a>
and <a href=""https://stackoverflow.com/questions/33758669/running-multiple-tensorflow-sessions-concurrently"">Running multiple tensorflow sessions concurrently</a></p>

<p>While they are highly related I haven't been able to figure out how to make it work. I tried creating a session for each individual process and assigning the weights of the neural net to its trainable parameters without success. I've also tried saving the session into a file and then loading it within a process, but no luck there either.</p>

<p>Has someone been able to pass a session (or clones of sessions) to several processes?</p>

<p>Thanks.</p>
",3691859.0,,-1.0,,2017-05-23 10:29:30,2022-05-03 12:22:14,Tensorflow and Multiprocessing: Passing Sessions,<python><parallel-processing><multiprocessing><tensorflow><reinforcement-learning>,2,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36610290
65273118,1,65319255,,2020-12-13 06:54:08,,30,60753,"<p>I am new to deep learning and I have been trying to install tensorflow-gpu version in my pc in vain for the last 2 days. I avoided installing CUDA and cuDNN drivers since several forums online don't recommend it due to numerous compatibility issues. Since I was already using the conda distribution of python before, I went for the <code>conda install -c anaconda tensorflow-gpu</code> as written in their official website here: <a href=""https://anaconda.org/anaconda/tensorflow-gpu"" rel=""noreferrer"">https://anaconda.org/anaconda/tensorflow-gpu</a> .</p>
<p>However even after installing the gpu version in a fresh virtual environment (to avoid potential conflicts with pip installed libraries in the base env), tensorflow doesn't seem to even recognize my GPU for some mysterious reason.</p>
<p>Some of the code snippets I ran(in anaconda prompt) to understand that it wasn't recognizing my GPU:-</p>
<p>1.</p>
<pre><code>&gt;&gt;&gt;from tensorflow.python.client import device_lib
        &gt;&gt;&gt;print(device_lib.list_local_devices())
                    [name: &quot;/device:CPU:0&quot;
                device_type: &quot;CPU&quot;
                memory_limit: 268435456
                locality {
                }
                incarnation: 7692219132769779763
                ]
</code></pre>
<p>As you can see it completely ignores the GPU.</p>
<p>2.</p>
<pre><code>&gt;&gt;&gt;tf.debugging.set_log_device_placement(True)
    &gt;&gt;&gt;a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
2020-12-13 10:11:30.902956: I tensorflow/core/platform/cpu_feature_guard.cc:142] This 
TensorFlow 
binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU 
instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
&gt;&gt;&gt;b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
&gt;&gt;&gt;c = tf.matmul(a, b)
&gt;&gt;&gt;print(c)
tf.Tensor(
[[22. 28.]
[49. 64.]], shape=(2, 2), dtype=float32)
</code></pre>
<p>Here, it was supposed to indicate that it ran with a GPU by showing <code>Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0</code> (as written here: <a href=""https://www.tensorflow.org/guide/gpu"" rel=""noreferrer"">https://www.tensorflow.org/guide/gpu</a>) but nothing like that is present. Also I am not sure what the message after the 2nd line means.</p>
<p>I have also searched for several solutions online including here but almost all of the issues are related to the first manual installation method which I haven't tried yet since everyone recommended this approach.</p>
<p>I don't use cmd anymore since the environment variables somehow got messed up after uninstalling tensorflow-cpu from the base env and on re-installing, it worked perfectly with anaconda prompt but not cmd. This is a separate issue (and widespread also) but I mentioned it in case that has a role to play here. I installed the gpu version in a fresh virtual environment to ensure a clean installation and as far as I understand path variables need to be set up only for manual installation of CUDA and cuDNN libraries.</p>
<p>The card which I use:-(which is CUDA enabled)</p>
<pre><code>C:\WINDOWS\system32&gt;wmic path win32_VideoController get name
Name
NVIDIA GeForce 940MX
Intel(R) HD Graphics 620
</code></pre>
<p>Tensorflow and python version I am using currently:-</p>
<pre><code>&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; tf.__version__
'2.3.0'

Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
</code></pre>
<p>System information: Windows 10 Home, 64-bit operating system, x64-based processor.</p>
<p>Any help would be really appreciated. Thanks in advance.</p>
",14372142.0,,,,,2022-04-27 14:53:21,Why is Tensorflow not recognizing my GPU after conda install?,<python><tensorflow><anaconda><gpu><path-variables>,11,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/65273118
46409626,1,46414395,,2017-09-25 16:08:40,,30,54994,"<p>I have some trouble using the <code>accuracy</code> function from <code>tf.metrics</code> for a multiple classification problem with logits as input.</p>

<p>My model output looks like:</p>

<pre><code>logits = [[0.1, 0.5, 0.4],
          [0.8, 0.1, 0.1],
          [0.6, 0.3, 0.2]]
</code></pre>

<p>And my labels are one hot encoded vectors:</p>

<pre><code>labels = [[0, 1, 0],
          [1, 0, 0],
          [0, 0, 1]]
</code></pre>

<p>When I try to do something like <code>tf.metrics.accuracy(labels, logits)</code> it never gives the correct result. I am obviously doing something wrong but I can't figure what it is.</p>
",5236675.0,,5236675.0,,2017-09-26 09:03:10,2022-03-28 11:44:22,How to properly use tf.metrics.accuracy?,<tensorflow>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46409626
37049411,1,37050111,,2016-05-05 11:27:18,,30,81246,"<p>In Tensorflow, I'd like to convert a scalar tensor to an integer. Is it possible to do? </p>

<p>I need to create a loop and the index of the loop is a scalar tensor, and inside the loop body, I want to use the index to access an entry in a tensor array. </p>

<p>For example:</p>

<pre><code>idx = tf.constant(0)
c = lambda i : tf.less(i, 10)
def body(idx) :
  i = # convert idx to int 
  b = weights[i]  # access an entry in a tensor array, tensor cannot be used directly
  ....
  return idx+1
tf.while_loop(c, body, [idx])
</code></pre>
",1744537.0,,,,,2021-03-07 12:08:01,Tensorflow: How to convert scalar tensor to scalar variable in python?,<tensorflow>,7,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37049411
39354566,1,39354802,,2016-09-06 17:19:49,,30,22477,"<p>Just looking for the equivalent of np.std() in TensorFlow to calculate the standard deviation of a tensor.</p>
",4962207.0,,,,,2023-01-30 05:36:48,What is the equivalent of np.std() in TensorFlow?,<python><tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39354566
47059848,1,48318045,,2017-11-01 16:53:14,,30,24717,"<p>I'm quite new to the tensorflow. I would like to understand to conceptual difference between Graph and GraphDef. </p>

<p>furthermore, which one should I have to run a graph loaded from protobuf file (.pb)?</p>

<p>Thanks!</p>
",5145700.0,,,,,2019-07-10 06:55:33,difference between Tensorflow's Graph and GraphDef,<tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47059848
41338509,1,41363704,,2016-12-27 03:04:36,,30,59034,"<p>I have seen a few different mean squared error loss functions in various posts for regression models in Tensorflow:</p>

<pre><code>loss = tf.reduce_sum(tf.pow(prediction - Y,2))/(n_instances)
loss = tf.reduce_mean(tf.squared_difference(prediction, Y))
loss = tf.nn.l2_loss(prediction - Y)
</code></pre>

<p>What are the differences between these?</p>
",2059708.0,,2059708.0,,2016-12-27 03:11:19,2017-05-07 09:45:38,Tensorflow mean squared error loss function,<python><machine-learning><tensorflow>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41338509
58688481,1,58688482,,2019-11-04 06:52:44,,30,63294,"<p>Now, the official TensorFlow on Anaconda is 2.0. My question is how to force Anaconda to install an earlier version of TensorFlow instead. So, for example, I would like Anaconda to install TensorFlow 1.14 as plenty of my projects are depending on this version.</p>
",5612363.0,,,,,2021-11-14 07:10:57,Force Anaconda to install tensorflow 1.14,<python><python-3.x><tensorflow><anaconda><version>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58688481
40146428,1,40148954,,2016-10-20 05:50:58,,30,42089,"<p>I have a TensorFlow model, and one part of this model evaluates the accuracy. The <code>accuracy</code> is just another node in the tensorflow graph, that takes in <code>logits</code> and <code>labels</code>.</p>

<p>When I want to plot the training accuracy, this is simple: I have something like:</p>

<pre><code>tf.scalar_summary(""Training Accuracy"", accuracy)
tf.scalar_summary(""SomethingElse"", foo)
summary_op = tf.merge_all_summaries()
writer = tf.train.SummaryWriter('/me/mydir/', graph=sess.graph)
</code></pre>

<p>Then, during my training loop, I have something like:</p>

<pre><code>for n in xrange(1000):
  ...
  summary, ..., ... = sess.run([summary_op, ..., ...], feed_dict)
  writer.add_summary(summary, n)
  ...
</code></pre>

<p>Also inside that for loop, every say, 100 iterations, I want to evaluate the <strong>validation</strong> accuracy. I have a separate feed_dict for this, and I am able to evaluate the validation accuracy very nicely in python. </p>

<p>However, here is my problem: I want to make another <em>summary for the validation accuracy</em>, by using the <code>accuracy</code> node. I am not clear on how to do this though. Since I have the <code>accuracy</code> node it makes sense that I should be able to re-use it, but I am unsure how to do this exactly, such that I can also get the validation accuracy written out as a separate scalar_summary... </p>

<p>How might this be possible?</p>
",1195250.0,,1195250.0,,2016-10-20 17:08:36,2017-06-12 07:14:11,Show training and validation accuracy in TensorFlow using same graph,<python><machine-learning><tensorflow><tensorboard>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40146428
56122670,1,56122892,,2019-05-14 03:37:35,,30,37036,"<p>I want to use tf.data.Dataset.list_files function to feed my datasets.<br>
But because the file is not image, I need to load it manually.<br>
The problem is tf.data.Dataset.list_files pass variable as tf.tensor and my python code can not handle tensor. </p>

<p>How can I get string value from tf.tensor.
The dtype is string.</p>

<pre><code>train_dataset = tf.data.Dataset.list_files(PATH+'clean_4s_val/*.wav')
train_dataset = train_dataset.map(lambda x: load_audio_file(x))

def load_audio_file(file_path):
  print(""file_path: "", file_path)
  # i want do something like string_path = convert_tensor_to_string(file_path)
</code></pre>

<p>file_path is <code>Tensor(""arg0:0"", shape=(), dtype=string)</code></p>

<p>I use tensorflow 1.13.1 and eager mode.</p>

<p>thanks in advance</p>
",1202679.0,,4685471.0,,2020-04-10 15:38:30,2023-05-25 19:04:37,how to get string value out of tf.tensor which dtype is string,<python><tensorflow><tensorflow-datasets>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/56122670
45095820,1,47715665,,2017-07-14 06:09:02,,30,77057,"<p>I installed TensorFlow on my MacBook Pro 10.12.5 from source code by steps described here.
<a href=""https://www.tensorflow.org/install/install_sources"" rel=""noreferrer"">https://www.tensorflow.org/install/install_sources</a></p>

<p>TensorFlow itself works well but I cannot run TensorBoard.
It seems tensorboard is not installed properly.</p>

<p>When I try running <code>tensorboard --logdir=...</code> it says <code>-bash: tensorboard: command not found</code>. And <code>locate tensorboard</code>  returns empty.</p>

<p>Do I need any additional step to install tensorboard?</p>
",3864315.0,,,,,2022-04-24 02:55:33,tensorboard: command not found,<tensorflow><tensorboard>,7,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45095820
47115946,1,47162390,,2017-11-04 21:47:12,,30,55538,"<p>I'm getting this error</p>

<blockquote>
  <p>'ValueError: Tensor Tensor(""Placeholder:0"", shape=(1, 1), dtype=int32)
  is not an element of this graph.'</p>
</blockquote>

<p>The code is running perfectly fine without <code>with tf.Graph(). as_default():</code>. However I need to call <code>M.sample(...)</code> multiple times and each time the memory won't be free after <code>session.close()</code>. Probably there is a memory leak but not sure where is it.</p>

<p>I want to restore a pre-trained neural network, set it as default graph, and testing it multiple times (like 10000) over the default graph without making it larger each time.</p>

<p>The code is:</p>



<pre><code>def SessionOpener(save):
    grph = tf.get_default_graph()
    sess = tf.Session(graph=grph)
    ckpt = tf.train.get_checkpoint_state(save)
    saver = tf.train.import_meta_graph('./predictor/save/model.ckpt.meta')
    if ckpt and ckpt.model_checkpoint_path:
        saver.restore(sess, ckpt.model_checkpoint_path)
        tf.global_variables_initializer().run(session=sess)
    return sess

def LoadPredictor(save):
    with open(os.path.join(save, 'config.pkl'), 'rb') as f:
        saved_args = cPickle.load(f)
    with open(os.path.join(save, 'words_vocab.pkl'), 'rb') as f:
        words, vocab = cPickle.load(f)
    model = Model(saved_args, True)
    return model, words, vocab

if __name__ == '__main__':
    Save = './save'
    M, W, V = LoadPredictor(Save)
    Sess = SessionOpener(Save)
    word = M.sample(Sess, W, V, 1, str(123), 2, 1, 4)
    Sess.close()
</code></pre>

<p>And the model is:</p>

<pre><code>class Model():
    def __init__(self, args, infer=False):
        with tf.Graph().as_default():
            self.args = args
            if infer:
                args.batch_size = 1
                args.seq_length = 1

            if args.model == 'rnn':
                cell_fn = rnn.BasicRNNCell
            elif args.model == 'gru':
                cell_fn = rnn.GRUCell
            elif args.model == 'lstm':
                cell_fn = rnn.BasicLSTMCell
            else:
                raise Exception(""model type not supported: {}"".format(args.model))

            cells = []
            for _ in range(args.num_layers):
                cell = cell_fn(args.rnn_size)
                cells.append(cell)

            self.cell = cell = rnn.MultiRNNCell(cells)

            self.input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])
            self.targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])
            self.initial_state = cell.zero_state(args.batch_size, tf.float32)
            self.batch_pointer = tf.Variable(0, name=""batch_pointer"", trainable=False, dtype=tf.int32)
            self.inc_batch_pointer_op = tf.assign(self.batch_pointer, self.batch_pointer + 1)
            self.epoch_pointer = tf.Variable(0, name=""epoch_pointer"", trainable=False)
            self.batch_time = tf.Variable(0.0, name=""batch_time"", trainable=False)
            tf.summary.scalar(""time_batch"", self.batch_time)

            def variable_summaries(var):
            """"""Attach a lot of summaries to a Tensor (for TensorBoard visualization).""""""
                with tf.name_scope('summaries'):
                    mean = tf.reduce_mean(var)
                    tf.summary.scalar('mean', mean)
                    tf.summary.scalar('max', tf.reduce_max(var))
                    tf.summary.scalar('min', tf.reduce_min(var))


            with tf.variable_scope('rnnlm'):
                softmax_w = tf.get_variable(""softmax_w"", [args.rnn_size, args.vocab_size])
                variable_summaries(softmax_w)
                softmax_b = tf.get_variable(""softmax_b"", [args.vocab_size])
                variable_summaries(softmax_b)
                with tf.device(""/cpu:0""):
                    embedding = tf.get_variable(""embedding"", [args.vocab_size, args.rnn_size])
                    inputs = tf.split(tf.nn.embedding_lookup(embedding, self.input_data), args.seq_length, 1)
                    inputs = [tf.squeeze(input_, [1]) for input_ in inputs]

            def loop(prev, _):
                prev = tf.matmul(prev, softmax_w) + softmax_b
                prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))
                return tf.nn.embedding_lookup(embedding, prev_symbol)

            outputs, last_state = legacy_seq2seq.rnn_decoder(inputs, self.initial_state, cell, loop_function=loop if infer else None, scope='rnnlm')
            output = tf.reshape(tf.concat(outputs, 1), [-1, args.rnn_size])
            self.logits = tf.matmul(output, softmax_w) + softmax_b
            self.probs = tf.nn.softmax(self.logits)
            loss = legacy_seq2seq.sequence_loss_by_example([self.logits],
                    [tf.reshape(self.targets, [-1])],
                    [tf.ones([args.batch_size * args.seq_length])],
                    args.vocab_size)
            self.cost = tf.reduce_sum(loss) / args.batch_size / args.seq_length
            tf.summary.scalar(""cost"", self.cost)
            self.final_state = last_state
            self.lr = tf.Variable(0.0, trainable=False)
            tvars = tf.trainable_variables()
            grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),
                args.grad_clip)
            optimizer = tf.train.AdamOptimizer(self.lr)
            self.train_op = optimizer.apply_gradients(zip(grads, tvars))

    def sample(self, sess, words, vocab, num=200, prime='first all', sampling_type=1, pick=0, width=4):
        def weighted_pick(weights):
            t = np.cumsum(weights)
            s = np.sum(weights)
            return(int(np.searchsorted(t, np.random.rand(1)*s)))

        ret = ''
        if pick == 1:
            state = sess.run(self.cell.zero_state(1, tf.float32))

            if not len(prime) or prime == ' ':
                prime  = random.choice(list(vocab.keys()))
            for word in prime.split()[:-1]:
                x = np.zeros((1, 1))
                x[0, 0] = vocab.get(word,0)
                feed = {self.input_data: x, self.initial_state:state}
                [state] = sess.run([self.final_state], feed)

            ret = prime
            word = prime.split()[-1]
            for n in range(num):
                x = np.zeros((1, 1))
                x[0, 0] = vocab.get(word, 0)
                feed = {self.input_data: x, self.initial_state:state}
                [probs, state] = sess.run([self.probs, self.final_state], feed)
                p = probs[0]

                if sampling_type == 0:
                    sample = np.argmax(p)
                elif sampling_type == 2:
                    if word == '\n':
                        sample = weighted_pick(p)
                    else:
                        sample = np.argmax(p)
                else: # sampling_type == 1 default:
                    sample = weighted_pick(p)

                ret = words[sample]
        return ret
</code></pre>

<p>and the output is:</p>

<pre><code>Traceback (most recent call last):
  File ""/rcg/software/Linux/Ubuntu/16.04/amd64/TOOLS/TENSORFLOW/1.2.1-GPU-PY352/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 942, in _run
    allow_operation=False)
  File ""/rcg/software/Linux/Ubuntu/16.04/amd64/TOOLS/TENSORFLOW/1.2.1-GPU-PY352/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2584, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/rcg/software/Linux/Ubuntu/16.04/amd64/TOOLS/TENSORFLOW/1.2.1-GPU-PY352/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2663, in _as_graph_element_locked
    raise ValueError(""Tensor %s is not an element of this graph."" % obj)
ValueError: Tensor Tensor(""Placeholder:0"", shape=(1, 1), dtype=int32) is not an element of this graph.
</code></pre>
",5368870.0,,712995.0,,2017-11-07 16:07:03,2020-08-22 06:00:37,Tensor is not an element of this graph,<python><machine-learning><tensorflow><memory-leaks><neural-network>,7,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47115946
45074049,1,45074843,,2017-07-13 07:25:59,,29,29167,"<p>I have read about <code>tf.get_variable</code> from this <a href=""https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow"">question</a> and also a bit from the documentation available at the tensorflow website. However, I am still not clear and was unable to find an answer online.</p>
<p>How does <code>tf.get_variable</code> work? For example:</p>
<pre><code>var1 = tf.Variable(3.,dtype=float64)
var2 = tf.get_variable(&quot;var1&quot;,[],dtype=tf.float64)
</code></pre>
<p>Does it mean that <strong>var2</strong> is <strong>another</strong> variable with initialization similar to <strong>var1</strong>? Or is <strong>var2</strong> an alias for <strong>var1</strong> (I tried and it doesn't seem to)?</p>
<p>How are <strong>var1</strong> and <strong>var2</strong> related?</p>
<p>How is a variable constructed when the variable we are <em>getting</em> doesn't really exist?</p>
",6687875.0,,9215780.0,,2021-05-25 17:25:22,2021-05-25 17:26:05,Tensorflow: How does tf.get_variable work?,<tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45074049
48915003,1,48915493,,2018-02-21 20:36:23,,29,51801,"<p>I am new to both Python and Tensorflow. I am trying to run the object detection tutorial file from the <a href=""https://github.com/tensorflow/models/tree/master/research/object_detection"" rel=""nofollow noreferrer"">Tensorflow Object Detection API</a>,
but I cannot find where I can get the coordinates of the bounding boxes when objects are detected.</p>
<p>Relevant code:</p>
<pre><code> # The following processing is only for single image
 detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])
 detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])
</code></pre>
<p>The place where I assume bounding boxes are drawn is like this:</p>
<pre><code> # Visualization of the results of detection.
 vis_util.visualize_boxes_and_labels_on_image_array(
      image_np,
      output_dict['detection_boxes'],
      output_dict['detection_classes'],
      output_dict['detection_scores'],
      category_index,
      instance_masks=output_dict.get('detection_masks'),
      use_normalized_coordinates=True,
      line_thickness=8)
 plt.figure(figsize=IMAGE_SIZE)
 plt.imshow(image_np)
</code></pre>
<p>I tried printing <code>output_dict['detection_boxes']</code> but I am not sure what the numbers mean. There are a lot.</p>
<pre><code>array([[ 0.56213236,  0.2780568 ,  0.91445708,  0.69120586],
       [ 0.56261235,  0.86368728,  0.59286624,  0.8893863 ],
       [ 0.57073039,  0.87096912,  0.61292225,  0.90354401],
       [ 0.51422435,  0.78449738,  0.53994244,  0.79437423],
......

       [ 0.32784131,  0.5461576 ,  0.36972913,  0.56903434],
       [ 0.03005961,  0.02714229,  0.47211722,  0.44683522],
       [ 0.43143299, 0.09211366,  0.58121657,  0.3509962 ]], dtype=float32)
</code></pre>
<p>I found answers for similar questions, but I don't have a variable called boxes as they do. How can I get the coordinates?</p>
",9393009.0,,2423278.0,,2021-11-30 09:12:25,2021-11-30 09:12:25,Get the bounding box coordinates in the TensorFlow object detection API tutorial,<python><tensorflow><bounding-box><object-detection-api>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48915003
42426960,1,42647980,,2017-02-23 21:57:13,,29,24599,"<p>Say I have access to a number of GPUs in a single machine (for the sake of argument assume 8GPUs each with max memory of 8GB each in one single machine with some amount of RAM and disk). I wanted to run in <strong>one single script</strong> and in one single machine a program that evaluates multiple models (say 50 or 200) in TensorFlow, each with a different hyper parameter setting (say, step-size, decay rate, batch size, epochs/iterations, etc). At the end of training assume we just record its accuracy and get rid of the model (if you want assume the model is being check pointed every so often, so its fine to just throw away the model and start training from scratch. You may also assume some other data may be recorded like the specific hyper params, train, validation, train errors are recorded as we train etc).</p>

<p>Currently I have a (pseudo-)script that looks as follow:</p>

<pre><code>def train_multiple_modles_in_one_script_with_gpu(arg):
    '''
    trains multiple NN models in one session using GPUs correctly.

    arg = some obj/struct with the params for trianing each of the models.
    '''
    #### try mutliple models
    for mdl_id in range(100):
        #### define/create graph
        graph = tf.Graph()
        with graph.as_default():
            ### get mdl
            x = tf.placeholder(float_type, get_x_shape(arg), name='x-input')
            y_ = tf.placeholder(float_type, get_y_shape(arg))
            y = get_mdl(arg,x)
            ### get loss and accuracy
            loss, accuracy = get_accuracy_loss(arg,x,y,y_)
            ### get optimizer variables
            opt = get_optimizer(arg)
            train_step = opt.minimize(loss, global_step=global_step)
        #### run session
        with tf.Session(graph=graph) as sess:
            # train
            for i in range(nb_iterations):
                batch_xs, batch_ys = get_batch_feed(X_train, Y_train, batch_size)
                sess.run(fetches=train_step, feed_dict={x: batch_xs, y_: batch_ys})
                # check_point mdl
                if i % report_error_freq == 0:
                    sess.run(step.assign(i))
                    #
                    train_error = sess.run(fetches=loss, feed_dict={x: X_train, y_: Y_train})
                    test_error = sess.run(fetches=loss, feed_dict={x: X_test, y_: Y_test})
                    print( 'step %d, train error: %s test_error %s'%(i,train_error,test_error) )
</code></pre>

<p>essentially it tries lots of models in one single run but it builds each model in a separate graph and runs each one in a separate session.</p>

<p>I guess my main worry is that its unclear to me how tensorflow under the hood allocates resources for the GPUs to be used. For example, does it load the (part of the) data set only when a session is ran? When I create a graph and a model, is it brought in the GPU immediately or when is it inserted in the GPU? Do I need to clear/free the GPU each time it tries a new model? I don't actually care too much if the models are ran in parallel in multiple GPU (which can be a nice addition), but I want it to first run everything serially without crashing. Is there anything special I need to do for this to work?</p>

<hr>

<p>Currently I am getting an error that starts as follow:</p>

<pre><code>I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:
Limit:                   340000768
InUse:                   336114944
MaxInUse:                339954944
NumAllocs:                      78
MaxAllocSize:            335665152

W tensorflow/core/common_runtime/bfc_allocator.cc:274] ***************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
W tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 160.22MiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[60000,700]
</code></pre>

<p>and further down the line it says:</p>

<pre><code>ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[60000,700]
         [[Node: standardNN/NNLayer1/Z1/add = Add[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](standardNN/NNLayer1/Z1/MatMul, b1/read)]]

I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
</code></pre>

<p>however further down the output file (where it prints) it seems to print fine the errors/messages that should show as training proceeds. Does this mean that it didn't run out of resources? Or was it actually able to use the GPU? If it was able to use the CPU instead of the CPU, when why is this an error only happening when GPU are about to be used?</p>

<p>The weird thing is that the data set is really not that big (all 60K points are 24.5M) and when I run a single model locally in my own computer it seems that the process uses less than 5GB. The GPUs have at least 8GB and the computer with them has plenty of RAM and disk (at least 16GB). Thus, the errors that tensorflow is throwing at me are quite puzzling. What is it trying to do and why are they occurring? Any ideas?</p>

<hr>

<p>After reading the answer that suggests to use the multiprocessing library I came up with the following script:</p>

<pre><code>def train_mdl(args):
    train(mdl,args)

if __name__ == '__main__':
    for mdl_id in range(100):
        # train one model with some specific hyperparms (assume they are chosen randomly inside the funciton bellow or read from a config file or they could just be passed or something)
        p = Process(target=train_mdl, args=(args,))
        p.start()
        p.join()
    print('Done training all models!')
</code></pre>

<p>honestly I am not sure why his answer suggests to use pool, or why there are weird tuple brackets but this is what would make sense for me. Would the resources for tensorflow be re-allocated every time a new process is created in the above loop?</p>
",1601580.0,,1601580.0,,2017-03-09 23:17:25,2023-01-31 16:07:56,How does one train multiple models in a single script in TensorFlow when there are GPUs present?,<python><machine-learning><tensorflow><neural-network>,5,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42426960
47113472,1,47859280,,2017-11-04 17:27:10,,29,59062,"<p>I am trying to use Tensorboard but every time I run any program with Tensorflow, I get an error when I go to localhost:6006 to view the Visualization</p>

<p>Here is my code</p>

<pre><code>a = tf.add(1, 2,)
b = tf.multiply(a, 3)

with tf.Session() as sess:
    writer = tf.summary.FileWriter(""output"", sess.graph)
    print(sess.run(b))
    writer.close()
</code></pre>

<p>When I go to the command prompt and enter</p>

<pre><code>tensorboard --logdir=C:\path\to\output\folder
</code></pre>

<p>It returns with </p>

<pre><code>TensorBoard 0.1.8 at http://MYCOMP:6006 (Press CTRL+C to quit)
</code></pre>

<p>When I go to localhost:6006 it states</p>

<blockquote>
  <p>No dashboards are active for the current data set.
  Probable causes:
  - You haven’t written any data to your event files.
  - TensorBoard can’t find your event files.</p>
</blockquote>

<p>I have looked at this link (<a href=""https://stackoverflow.com/questions/46108507/tensorboard-no-dashboards-are-active-for-the-current-data-set"">Tensorboard: No dashboards are active for the current data set</a>) but it doesn't seem to fix this issue</p>

<p>And I am running this on Windows 10</p>

<p>What do I do to fix this issue? Am I giving the right path for Tensorboard in the command prompt? </p>

<p>Thank you in advance</p>
",7359915.0,,7359915.0,,2017-11-05 00:31:23,2022-05-03 19:10:31,Tensorboard Error: No dashboards are active for current data set,<python-3.x><tensorflow><tensorboard>,13,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47113472
46940857,1,46941087,,2017-10-25 19:43:09,,29,8154,"<p>I have seen pieces of code using either <code>[]</code>, <code>[None]</code>, <code>None</code> or <code>()</code> as the shape for a <code>placeholder</code>, that is</p>

<pre><code>x = tf.placeholder(..., shape=[], ...)
y = tf.placeholder(..., shape=[None], ...)
z = tf.placeholder(..., shape=None, ...) 
w = tf.placeholder(..., shape=(), ...)
</code></pre>

<p>What's the difference between these?</p>
",722271.0,,3924118.0,,2018-01-09 23:18:17,2022-08-24 05:20:01,"What is the difference between [], [None], None and () for the shape of a placeholder?",<tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46940857
45482813,1,45543949,,2017-08-03 11:24:55,,29,5426,"<p>I am using Tensorflow's <code>tf.nn.ctc_beam_search_decoder()</code> to decode the output of a RNN doing some many-to-many mapping (i.e., multiple softmax outputs for each network cell).</p>

<p>A simplified version of the network's output and the Beam search decoder is:</p>

<pre><code>import numpy as np
import tensorflow as tf

batch_size = 4
sequence_max_len = 5
num_classes = 3

y_pred = tf.placeholder(tf.float32, shape=(batch_size, sequence_max_len, num_classes))
y_pred_transposed = tf.transpose(y_pred,
                                 perm=[1, 0, 2])  # TF expects dimensions [max_time, batch_size, num_classes]
logits = tf.log(y_pred_transposed)
sequence_lengths = tf.to_int32(tf.fill([batch_size], sequence_max_len))
decoded, log_probabilities = tf.nn.ctc_beam_search_decoder(logits,
                                                           sequence_length=sequence_lengths,
                                                           beam_width=3,
                                                           merge_repeated=False, top_paths=1)

decoded = decoded[0]
decoded_paths = tf.sparse_tensor_to_dense(decoded)  # Shape: [batch_size, max_sequence_len]

with tf.Session() as session:
    tf.global_variables_initializer().run()

    softmax_outputs = np.array([[[0.1, 0.1, 0.8], [0.8, 0.1, 0.1], [0.8, 0.1, 0.1], [0.8, 0.1, 0.1], [0.8, 0.1, 0.1]],
                                [[0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7]],
                                [[0.1, 0.7, 0.2], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7]],
                                [[0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7], [0.1, 0.2, 0.7]]])

    decoded_paths = session.run(decoded_paths, feed_dict = {y_pred: softmax_outputs})
    print(decoded_paths)
</code></pre>

<p>The output in this case is:</p>

<pre><code>[[0]
 [1]
 [1]
 [1]]
</code></pre>

<p>My understanding is that the output tensor should be of dimensions <code>[batch_size, max_sequence_len]</code>, with each row containing the indices of the relevant classes in the found path.</p>

<p>In this case I would expect the output to be similar to:</p>

<pre><code>[[2, 0, 0, 0, 0],
 [2, 2, 2, 2, 2],
 [1, 2, 2, 2, 2],
 [2, 2, 2, 2, 2]]
</code></pre>

<p>What am I not understanding about how <code>ctc_beam_search_decoder</code> works?</p>
",1147323.0,,,,,2017-08-07 13:36:47,Tensorflow: Can't understand ctc_beam_search_decoder() output sequence,<python><tensorflow><beam-search>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45482813
65608713,1,65608751,,2021-01-07 08:10:51,,29,38598,"<p>When i run</p>
<pre><code>import tensorflow as tf 
tf.test.is_gpu_available(
    cuda_only=False, min_cuda_compute_capability=None
)
</code></pre>
<p>I get the following error</p>
<p><a href=""https://i.stack.imgur.com/Mv2p5.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Mv2p5.jpg"" alt=""enter image description here"" /></a></p>
",10900548.0,,,,,2021-05-31 16:23:57,Tensorflow GPU Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found,<python><tensorflow><gpu>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/65608713
41860817,1,46318446,,2017-01-25 20:13:07,,29,4186,"<p>I have constructed a CLDNN (Convolutional, LSTM, Deep Neural Network) structure for raw signal classification task.</p>

<p>Each training epoch runs for about 90 seconds and the hyperparameters seems to be very difficult to optimize.</p>

<p>I have been research various ways to optimize the hyperparameters (e.g. random or grid search) and found out about Bayesian Optimization.</p>

<p>Although I am still not fully understanding the optimization algorithm, I feed like it will help me greatly.</p>

<p>I would like to ask few questions regarding the optimization task.</p>

<ol>
<li>How do I set up the Bayesian Optimization with regards to a deep network?(What is the cost function we are trying to optimize?)</li>
<li>What is the function I am trying to optimize? Is it the cost of the validation set after N epochs?</li>
<li>Is spearmint a good starting point for this task? Any other suggestions for this task?</li>
</ol>

<p>I would greatly appreciate any insights into this problem.</p>
",7415539.0,,712995.0,,2017-10-17 09:22:52,2018-01-13 16:17:51,Hyperparameter optimization for Deep Learning Structures using Bayesian Optimization,<optimization><machine-learning><tensorflow><deep-learning><bayesian>,1,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41860817
63199164,1,63203772,,2020-07-31 21:14:41,,29,28213,"<p>I am trying to install Tensorflow but it is asking for libcusolver.so.11 and I only have libcusolver.so.10. Can someone tell me what I am doing wrong</p>
<p>Here are my Ubuntu, nvidia and CUDA versions</p>
<pre><code>$ uname -a
$ Linux *****-dev-01 5.4.0-42-generic #46-Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux

$nvidia-smi --query-gpu=gpu_name --format=csv|tail -n 1
GeForce GTX 1650

$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Thu_Jun_11_22:26:38_PDT_2020
Cuda compilation tools, release 11.0, V11.0.194
Build cuda_11.0_bu.TC445_37.28540450_0
</code></pre>
<p>Here is how I am building tensorflow</p>
<pre><code>$git clone https://github.com/tensorflow/tensorflow.git
$cd ./tensorflow
$git checkout tags/v2.2.0
$./configure
$bazel build --config=v2 --config=cuda --config=monolithic --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.1 --copt=-msse4.2 --copt=-Wno-sign-compare //        tensorflow:libtensorflow_cc.so
</code></pre>
<p>Here is the error I am receiving</p>
<pre><code>ERROR: An error occurred during the fetch of repository 'local_config_cuda':
    Traceback (most recent call last):
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 1210
         _create_local_cuda_repository(&lt;1 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 934, in _create_local_cuda_repository
         _find_libs(repository_ctx, &lt;2 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 577, in _find_libs
         _check_cuda_libs(repository_ctx, &lt;2 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 479, in _check_cuda_libs
         execute(repository_ctx, &lt;1 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/remote_config/common.bzl&quot;, line 208, in execute
         fail(&lt;1 more arguments&gt;)
 Repository command failed
 No library found under: /usr/local/cuda/lib64/libcusolver.so.11
 ERROR: Skipping '//tensorflow:libtensorflow_cc.so': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 1210
         _create_local_cuda_repository(&lt;1 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 934, in _create_local_cuda_repository
         _find_libs(repository_ctx, &lt;2 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 577, in _find_libs
         _check_cuda_libs(repository_ctx, &lt;2 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 479, in _check_cuda_libs
         execute(repository_ctx, &lt;1 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/remote_config/common.bzl&quot;, line 208, in execute
         fail(&lt;1 more arguments&gt;)
 Repository command failed
 No library found under: /usr/local/cuda/lib64/libcusolver.so.11
 WARNING: Target pattern parsing failed.
 ERROR: no such package '@local_config_cuda//cuda': Traceback (most recent call last):
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 1210
         _create_local_cuda_repository(&lt;1 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 934, in _create_local_cuda_repository
         _find_libs(repository_ctx, &lt;2 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 577, in _find_libs
         _check_cuda_libs(repository_ctx, &lt;2 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl&quot;, line 479, in _check_cuda_libs
         execute(repository_ctx, &lt;1 more arguments&gt;)
     File &quot;/home/********/Documents/foo/.temp_install_dir/tensorflow/tensorflow/third_party/remote_config/common.bzl&quot;, line 208, in execute
         fail(&lt;1 more arguments&gt;)
 Repository command failed
 No library found under: /usr/local/cuda/lib64/libcusolver.so.11
 INFO: Elapsed time: 1.998s
 INFO: 0 processes.
 FAILED: Build did NOT complete successfully (0 packages loaded)
     currently loading: tensorflow
 NORMAL   test.log
</code></pre>
",654789.0,,654789.0,,2020-07-31 21:23:00,2022-08-24 20:39:30,How to install libcusolver.so.11,<tensorflow><cuda>,3,6,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/63199164
35049379,1,38742267,,2016-01-27 22:30:20,,29,18702,"<p><strong>The Situation:</strong></p>

<p>I am wondering how to use TensorFlow optimally when my training data is imbalanced in label distribution between 2 labels. For instance, suppose the <a href=""https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html"" rel=""noreferrer"">MNIST tutorial</a> is simplified to only distinguish between 1's and 0's, where all images available to us are either 1's or 0's. This is straightforward to train using the provided TensorFlow tutorials when we have roughly 50% of each type of image to train and test on. But what about the case where 90% of the images available in our data are 0's and only 10% are 1's? I observe that in this case, TensorFlow routinely predicts my entire test set to be 0's, achieving an accuracy of a meaningless 90%.</p>

<p>One strategy I have used to some success is to pick random batches for training that do have an even distribution of 0's and 1's. This approach ensures that I can still use all of my training data and produced decent results, with less than 90% accuracy, but a much more useful classifier. Since accuracy is somewhat useless to me in this case, my metric of choice is typically area under the ROC curve (AUROC), and this produces a result respectably higher than .50.</p>

<p><strong>Questions:</strong></p>

<p>(1) Is the strategy I have described an accepted or optimal way of training on imbalanced data, or is there one that might work better?</p>

<p>(2) Since the accuracy metric is not as useful in the case of imbalanced data, is there another metric that can be maximized by altering the cost function? I can certainly calculate AUROC post-training, but can I train in such a way as to maximize AUROC?</p>

<p>(3) Is there some other alteration I can make to my cost function to improve my results for imbalanced data? Currently, I am using a default suggestion given in TensorFlow tutorials:</p>

<pre><code>cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
</code></pre>

<p>I have heard this may be possible by up-weighting the cost of miscategorizing the smaller label class, but I am unsure of how to do this.</p>
",5849136.0,,,,,2020-05-04 07:46:28,Training on imbalanced data using TensorFlow,<machine-learning><neural-network><deep-learning><tensorflow><perceptron>,4,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35049379
48796169,1,48798075,,2018-02-14 21:03:46,,29,94339,"<p>I am following this tensorflow <a href=""https://www.tensorflow.org/get_started/get_started_for_beginners"" rel=""noreferrer"">tutorial</a> after two days setting up the environment I finally could run <code>premade_estimator.py</code> using cmd</p>

<p><a href=""https://i.stack.imgur.com/DmlmX.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DmlmX.png"" alt=""""></a></p>

<p>but when I try to run the same code in a jupyter notebook I am getting this error:</p>

<blockquote>
<pre><code>usage: ipykernel_launcher.py [-h] [--batch_size BATCH_SIZE]
                             [--train_steps TRAIN_STEPS]

ipykernel_launcher.py: error: unrecognized arguments: -f C:\Users\david\AppData\Roaming\jupyter\runtime\kernel-4faecb24-6e87-40b4-bf15-5d24520d7130.json
</code></pre>
  
  <p>An exception has occurred, use %tb to see the full traceback.</p>

<pre><code>SystemExit: 2

C:\Anaconda3\envs\python3x\lib\site-packages\IPython\core\interactiveshell.py:2918: 
UserWarning: To exit: use 'exit', 'quit', or Ctrl-D. warn(""To exit: use 'exit', 'quit', or Ctrl-D."", stacklevel=1)
</code></pre>
</blockquote>

<p>I have tried to fix it without success using:</p>

<pre><code>pip install --ignore-installed --upgrade jupyter

pip install ipykernel
python -m ipykernel install

conda install notebook ipykernel
ipython kernelspec install-self
</code></pre>

<p>Any idea will be appreciate! Thanks!</p>
",8828524.0,,8828524.0,,2018-02-14 23:49:50,2022-12-27 11:11:19,How to fix ipykernel_launcher.py: error: unrecognized arguments in jupyter?,<python><python-3.x><tensorflow><jupyter-notebook><jupyter>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48796169
47296969,1,47297097,,2017-11-14 23:26:26,,29,32632,"<p>Any ideas how can I solve problem shown below? With the information that I found on the web it is associated with problem of reusing tensorflow scope however nothing works. </p>



<pre class=""lang-python prettyprint-override""><code>ValueError: Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:

  File ""/code/backend/management/commands/RNN.py"", line 370, in predict
    states_series, current_state = tf.nn.dynamic_rnn(cell=cell, inputs=batchX_placeholder, dtype=tf.float32)
  File ""/code/backend/management/commands/RNN.py"", line 499, in Command
    predict(""string"")
  File ""/code/backend/management/commands/RNN.py"", line 12, in &lt;module&gt;
    class Command(BaseCommand):
</code></pre>

<p>I tried for instance something like this</p>

<pre class=""lang-python prettyprint-override""><code>with tf.variable_scope('scope'):
 states_series, current_state = tf.nn.dynamic_rnn(cell=cell, inputs=batchX_placeholder, dtype=tf.float32)
</code></pre>

<p>and this</p>

<pre class=""lang-python prettyprint-override""><code>with tf.variable_scope('scope', reuse = True ):
 states_series, current_state = tf.nn.dynamic_rnn(cell=cell, inputs=batchX_placeholder, dtype=tf.float32)
</code></pre>

<p>and this</p>

<pre class=""lang-python prettyprint-override""><code>with tf.variable_scope('scope', reuse = tf.AUTO_REUSE ):
 states_series, current_state = tf.nn.dynamic_rnn(cell=cell, inputs=batchX_placeholder, dtype=tf.float32)
</code></pre>

<p>Any ideas?</p>
",,user7304253,,,,2017-11-14 23:38:44,"ValueError: Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?",<python><python-3.x><machine-learning><tensorflow><neural-network>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47296969
43408463,1,43434568,,2017-04-14 09:03:34,,29,16101,"<p>Could someone help to explain the inner mechanism of TensorFlow's <code>tf.contrib.rnn.MultiRnnCell</code>? </p>

<p>For example, if I wanted to stack up two basic RNN cells into a <code>MultiRnnCell</code>, what would be the input and output of each basic RNN cell? </p>

<p>I would like to know the details of how it works.</p>
",7795558.0,,3924118.0,,2017-11-10 18:55:31,2017-11-10 18:55:31,How does TensorFlow's MultiRnnCell work?,<tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43408463
38241410,1,39954167,,2016-07-07 09:02:40,,29,16665,"<p>Given a trained LSTM model I want to perform inference for single timesteps, i.e. <code>seq_length = 1</code> in the example below. After each timestep the internal LSTM (memory and hidden) states need to be remembered for the next 'batch'. For the very beginning of the inference the internal LSTM states <code>init_c, init_h</code> are computed given the input. These are then stored in a <code>LSTMStateTuple</code> object which is passed to the LSTM. During training this state is updated every timestep. However for inference I want the <code>state</code> to be saved in between batches, i.e. the initial states only need to be computed at the very beginning and after that the LSTM states should be saved after each 'batch' (n=1). </p>

<p>I found this related StackOverflow question: <a href=""https://stackoverflow.com/questions/37969065/tensorflow-best-way-to-save-state-in-rnns"">Tensorflow, best way to save state in RNNs?</a>. However this only works if <code>state_is_tuple=False</code>, but this behavior is soon to be deprecated by TensorFlow (see <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L265"" rel=""noreferrer"">rnn_cell.py</a>). Keras seems to have a nice wrapper to make <strong>stateful</strong> LSTMs possible but I don't know the best way to achieve this in TensorFlow. This issue on the TensorFlow GitHub is also related to my question: <a href=""https://github.com/tensorflow/tensorflow/issues/2838"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/issues/2838</a></p>

<p>Anyone good suggestions for building a stateful LSTM model? </p>

<pre><code>inputs  = tf.placeholder(tf.float32, shape=[None, seq_length, 84, 84], name=""inputs"")
targets = tf.placeholder(tf.float32, shape=[None, seq_length], name=""targets"")

num_lstm_layers = 2

with tf.variable_scope(""LSTM"") as scope:

    lstm_cell  = tf.nn.rnn_cell.LSTMCell(512, initializer=initializer, state_is_tuple=True)
    self.lstm  = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_lstm_layers, state_is_tuple=True)

    init_c = # compute initial LSTM memory state using contents in placeholder 'inputs'
    init_h = # compute initial LSTM hidden state using contents in placeholder 'inputs'
    self.state = [tf.nn.rnn_cell.LSTMStateTuple(init_c, init_h)] * num_lstm_layers

    outputs = []

    for step in range(seq_length):

        if step != 0:
            scope.reuse_variables()

        # CNN features, as input for LSTM
        x_t = # ... 

        # LSTM step through time
        output, self.state = self.lstm(x_t, self.state)
        outputs.append(output)
</code></pre>
",3419427.0,,-1.0,,2017-05-23 12:10:30,2016-12-22 18:42:43,TensorFlow: Remember LSTM state for next batch (stateful LSTM),<python><tensorflow><lstm><recurrent-neural-network><stateful>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38241410
40884668,1,40891721,,2016-11-30 09:32:08,,29,126537,"<p>I'm trying to install <a href=""https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#pip-installation-on-windows"" rel=""noreferrer"">TensorFlow on Windows</a>.</p>

<p>I tried to install it with <code>pip</code>, but I always get the same error message:</p>

<pre><code>... is not a supported wheel on this platform.
</code></pre>

<p>I first tried it with Python 3.5.1, now I upgraded to <strong>3.6.0b4</strong>, but it makes no difference.</p>

<hr />

<p>Python:</p>

<pre><code>Python 3.6.0b4 (default, Nov 22 2016, 05:30:12) [MSC v.1900 64 bit (AMD64)] on win32
</code></pre>

<p>pip:</p>

<pre><code>pip 9.0.1 from ...\python\lib\site-packages (python 3.6)
</code></pre>

<hr />

<p>To be exact, I tried the following two commands:</p>

<pre><code>pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl
pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl
</code></pre>

<p>they output the following:</p>

<pre><code>&gt; tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.
&gt; tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.
</code></pre>

<p>Does anyone know how to solve this problem? I'm not sure where I'm making a mistake.</p>

<p>Thanks!</p>

<p><hr />
<strong>Edit 1</strong></p>

<p>Btw, I also tried <code>pip install tensorflow</code> and <code>pip install tensorflow-gpu</code> like suggested <a href=""https://stackoverflow.com/a/38900276/6459948"">here</a>. I got the following output:</p>

<pre><code>&gt; Could not find a version that satisfies the requirement tensorflow (from versions: ) No matching distribution found for tensorflow
&gt; Could not find a version that satisfies the requirement tensorflow-gpu (from versions: ) No matching distribution found for tensorflow-gpu
</code></pre>
",6459948.0,,-1.0,,2017-05-23 11:47:31,2019-07-31 00:34:15,Installing TensorFlow on Windows (Python 3.6.x),<python><python-3.x><installation><tensorflow>,22,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40884668
47580716,1,47721194,,2017-11-30 18:55:38,,28,18616,"<p>I have a long list of lists of integers (representing sentences, each one of different sizes) that I want to feed using the tf.data library. Each list (of the lists of list) has different length, and I get an error, which I can reproduce here:</p>

<pre><code>t = [[4,2], [3,4,5]]
dataset = tf.data.Dataset.from_tensor_slices(t)
</code></pre>

<p>The error I get is:</p>

<pre><code>ValueError: Argument must be a dense tensor: [[4, 2], [3, 4, 5]] - got shape [2], but wanted [2, 2].
</code></pre>

<p>Is there a way to do this?</p>

<p>EDIT 1: Just to be clear, I don't want to pad the input list of lists (it's a list of sentences containing over a million elements, with varying lengths) I want to use the tf.data library to feed, in a proper way, a list of lists with varying length.</p>
",4002012.0,,3574081.0,,2017-12-08 19:46:13,2019-11-15 02:55:21,How to input a list of lists with different sizes in tf.data.Dataset,<python><tensorflow><tensorflow-datasets>,4,10,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47580716
58986126,1,59158900,,2019-11-22 01:22:28,,28,48299,"<p>For my project, I need to convert a directed graph into a tensorflow implementation of the graph as if it was a neural network. In tensorflow version 1, I could just define all of my inputs as placeholders and then just generate the dataflow graph for the outputs using a breadthfirst search of the graph. Then I would just feed in my inputs using a feed_dict. However, in TensorFlow v2.0 they have decided to do away with placeholders entirely.</p>

<p>How would I make a tf.function for each graph that takes in a variable amount of inputs and returns a variable amount of outputs without using a placeholder?</p>

<p>I want to generate a tf.function like this that works for an arbitrary acyclic directed graph so that I can take advantage of tensorflow GPU support to run the graph feed forward a few thousand times in a row after I have generated it.</p>

<hr>

<p>Edit for code example:</p>

<p>My graph is defined as a dictionary. Each key represents a node and has a corresponding value of another dictionary specifying incoming and outgoing links with weights.</p>

<pre class=""lang-py prettyprint-override""><code>{
    ""A"": {
        ""incoming"": [(""B"", 2), (""C"", -1)],
        ""outgoing"": [(""D"", 3)]
    }
}
</code></pre>

<p>I have omitted the entries for B,C, and D for brevity.
Here is how I would construct the code I want in tensorflow v1.0 where inputs is just a list of key values that are strictly inputs to the graph</p>

<pre class=""lang-py prettyprint-override""><code>def construct_graph(graph_dict, inputs, outputs):
    queue = inputs[:]
    make_dict = {}
    for key, val in graph_dict.items():
        if key in inputs:
            make_dict[key] = tf.placeholder(tf.float32, name=key)
        else:
            make_dict[key] = None
    # Breadth-First search of graph starting from inputs
    while len(queue) != 0:
        cur = graph_dict[queue[0]]
        for outg in cur[""outgoing""]:
            if make_dict[outg[0]]: # If discovered node, do add/multiply operation
                make_dict[outg[0]] = tf.add(make_dict[outg[0]], tf.multiply(outg[1], make_dict[queue[0]]))
            else: # If undiscovered node, input is just coming in multiplied and add outgoing to queue
                make_dict[outg[0]] = tf.multiply(make_dict[queue[0]], outg[1])
                for outgo in graph_dict[outg[0]][""outgoing""]:
                    queue.append(outgo[0])
        queue.pop(0)
    # Returns one data graph for each output
    return [make_dict[x] for x in outputs]
</code></pre>

<p>I would then be able to run the outputs many times as they are simply graphs with placeholders that I would provide a feed_dict for.</p>

<p>Obviously, this is not the intended way in TensorFlow v2.0 as they seem to strongly discourage the use of placeholders in this new version.</p>

<p>The point is that I only have to do this preprocessing for a graph once, as it returns a datagraph which is independent of the graph_dict definition.</p>
",2372101.0,,2372101.0,,2019-11-29 23:24:03,2020-03-26 20:06:38,Replacing placeholder for tensorflow v2,<python><python-3.x><tensorflow><tensorflow2.0>,1,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58986126
64193633,1,64193672,,2020-10-04 10:43:16,,28,78407,"<p>When I try to run a python script , which uses tensorflow, it shows following error ...</p>
<pre><code>2020-10-04 16:01:44.994797: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-04 16:01:46.780656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-04 16:01:46.795642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: TITAN X (Pascal) computeCapability: 6.1
coreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s
2020-10-04 16:01:46.795699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-04 16:01:46.795808: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda-10.0/lib64
2020-10-04 16:01:46.797391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-04 16:01:46.797707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-04 16:01:46.799529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-04 16:01:46.800524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-04 16:01:46.804150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-04 16:01:46.804169: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
</code></pre>
<p>Output of nvidia-smi</p>
<pre><code>+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    On   | 00000000:03:00.0 Off |                  N/A |
| 23%   28C    P8     9W / 250W |     18MiB / 12194MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1825      G   /usr/lib/xorg/Xorg                  9MiB |
|    0   N/A  N/A      1957      G   /usr/bin/gnome-shell                6MiB |
+-----------------------------------------------------------------------------+
</code></pre>
<p>Tensorflow version 2.3.1,
Ubuntu - 18.04</p>
<p>I tried to completely remove cuda toolkit and install from scratch but the error remains.
Anybody could help me to identify the source of problem??</p>
",14191514.0,,681865.0,,2020-10-04 10:58:46,2023-03-07 17:53:01,Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory;,<tensorflow><gpu><ubuntu-18.04><nvidia>,7,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/64193633
49450829,1,49985458,,2018-03-23 13:31:54,,28,60441,"<p>I am trying to train custom object classifier in Darknet YOLO v2
<a href=""https://pjreddie.com/darknet/yolo/"" rel=""noreferrer"">https://pjreddie.com/darknet/yolo/</a></p>

<p>I gathered a dataset for images most of them are 6000 x 4000 px and some lower resolutions as well.</p>

<p>Do I need to resize the images before training to be squared ?</p>

<p>I found that the config uses:</p>

<pre><code>[net]
batch=64
subdivisions=8
height=416
width=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1
</code></pre>

<p>thats why I was wondering how to use it for different sizes of data sets.</p>
",2661973.0,,,,,2021-01-17 13:32:53,Darknet YOLO image size,<tensorflow><machine-learning><image-recognition><darknet><yolo>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49450829
44745855,1,44746203,,2017-06-25 11:22:48,,28,24439,"<p>I am new to tensorflow , I am not able to understand the difference of variable and constant, I get the idea that we use variables for equations and constants for direct values , but why code #1 works only and why not code#2 and #3, and please explain in which cases we have to run our graph first(a) and then our variable(b) i.e </p>

<pre><code> (a) session.run(model)
 (b) print(session.run(y))
</code></pre>

<p>and in which case I can directly execute this command
i.e </p>

<pre><code>print(session.run(y))
</code></pre>

<p>Code #1 :</p>

<pre><code>x = tf.constant(35, name='x')
y = tf.Variable(x + 5, name='y')

model = tf.global_variables_initializer() 

with tf.Session() as session:
    session.run(model)
    print(session.run(y))
</code></pre>

<p>Code #2 :</p>

<pre><code>x = tf.Variable(35, name='x')
y = tf.Variable(x + 5, name='y')

model = tf.global_variables_initializer() 

with tf.Session() as session:
    session.run(model)
    print(session.run(y))
</code></pre>

<p>Code #3 :</p>

<pre><code>x = tf.constant(35, name='x')
y = tf.constant(x + 5, name='y')

model = tf.global_variables_initializer() 

with tf.Session() as session:
    session.run(model)
    print(session.run(y))
</code></pre>
",7500631.0,,3921457.0,,2017-06-26 05:26:33,2021-06-13 11:28:45,TensorFlow Variables and Constants,<python><tensorflow>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44745855
37374454,1,37378755,,2016-05-22 12:36:22,,28,24531,"<p>I have a django form, which is collecting user response. I also have a tensorflow sentences classification model. What is the best/standard way to  put these two together.
Details: </p>

<ol>
<li>tensorflow model was trained on the Movie Review data from Rotten Tomatoes.</li>
<li>Everytime a new row is made in my response model , i want the tensorflow code to classify it( + or - ).</li>
<li>Basically I have a django project directory and two .py files for classification. Before going ahead myself , i wanted to know what is the standard way to implement machine learning algorithms to a web app.</li>
</ol>

<p>It'd be awesome if you could suggest a tutorial or a repo.
Thank you !</p>
",6253584.0,,238639.0,,2016-05-23 09:52:25,2019-05-09 20:22:04,Machine Learning (tensorflow / sklearn) in Django?,<django><machine-learning><scikit-learn><tensorflow><sentiment-analysis>,3,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37374454
50313441,1,50336645,,2018-05-13 06:40:45,,28,77209,"<p>When I import tensorflow</p>

<pre><code>import tensorflow as tf
</code></pre>

<p>I don't get an error. However, I do get the error below. I'm using spyder if that helps.</p>

<p>As per other questions, I ensured up to date (v1.8) tensorflow using both conda and then pip installs. This didn't resolve the issue. Please assist.</p>

<pre><code>import tensorflow.examples.tutorials.mnist.input_data as input_data

ModuleNotFoundError: No module named 'tensorflow.examples'
</code></pre>
",8297514.0,,,,,2023-05-23 01:58:21,ModuleNotFoundError: No module named 'tensorflow.examples',<python><tensorflow><mnist>,12,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50313441
43010339,1,43012341,,2017-03-24 22:45:09,,28,80246,"<p>I have the following code portion for a convolutional neural network:</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import cifar_tools
import tensorflow as tf

data, labels = cifar_tools.read_data('C:\\Users\\abc\\Desktop\\temp')

x = tf.placeholder(tf.float32, [None, 150 * 150])
y = tf.placeholder(tf.float32, [None, 2])

w1 = tf.Variable(tf.random_normal([5, 5, 1, 64]))
b1 = tf.Variable(tf.random_normal([64]))

w2 = tf.Variable(tf.random_normal([5, 5, 64, 64]))
b2 = tf.Variable(tf.random_normal([64]))

w3 = tf.Variable(tf.random_normal([6*6*64, 1024]))
b3 = tf.Variable(tf.random_normal([1024]))

w_out = tf.Variable(tf.random_normal([1024, 2]))
b_out = tf.Variable(tf.random_normal([2]))

def conv_layer(x,w,b):
    conv = tf.nn.conv2d(x,w,strides=[1,1,1,1], padding = 'SAME')
    conv_with_b = tf.nn.bias_add(conv,b)
    conv_out = tf.nn.relu(conv_with_b)
    return conv_out

def maxpool_layer(conv,k=2):
    return tf.nn.max_pool(conv, ksize=[1,k,k,1], strides=[1,k,k,1], padding='SAME')

def model():
    x_reshaped = tf.reshape(x, shape=[-1,150,150,1])

    conv_out1 = conv_layer(x_reshaped, w1, b1)
    maxpool_out1 = maxpool_layer(conv_out1)
    norm1 = tf.nn.lrn(maxpool_out1, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)

    conv_out2 = conv_layer(norm1, w2, b2)
    maxpool_out2 = maxpool_layer(conv_out2)
    norm2 = tf.nn.lrn(maxpool_out2, 4, bias=1.0, alpha=0.001/9.0, beta=0.75)

    maxpool_reshaped = tf.reshape(maxpool_out2, [-1,w3.get_shape().as_list()[0]])
    local = tf.add(tf.matmul(maxpool_reshaped, w3), b3)
    local_out = tf.nn.relu(local)

    out = tf.add(tf.matmul(local_out, w_out), b_out)
    return out

model_op = model()

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model_op, y))
train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)

correct_pred = tf.equal(tf.argmax(model_op, 1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))
</code></pre>

<p>I'm reading <code>150x150</code> grayscale images, but couldn't understand the following error I'm having:</p>

<pre><code>EPOCH 0
Traceback (most recent call last):
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1021, in _do_call
    return fn(*args)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1003, in _run_fn
    status, run_metadata)
  File ""C:\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304
         [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](MaxPool_1, Reshape_1/shape)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""cnn.py"", line 70, in &lt;module&gt;
    _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 766, in run
    run_metadata_ptr)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304
         [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](MaxPool_1, Reshape_1/shape)]]

Caused by op 'Reshape_1', defined at:
  File ""cnn.py"", line 50, in &lt;module&gt;
    model_op = model()
  File ""cnn.py"", line 43, in model
    maxpool_reshaped = tf.reshape(maxpool_out2, [-1,w3.get_shape().as_list()[0]])
  File ""C:\Python35\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 2448, in reshape
    name=name)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304
         [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](MaxPool_1, Reshape_1/shape)]]
</code></pre>

<p><strong>EDIT-1</strong></p>

<p>Got this new error after modifying based on those edits:</p>

<pre><code>x_reshaped = tf.reshape(x, shape=[-1,150,150,1])
batch_size = x_reshaped.get_shape().as_list()[0]

... Same code as above ...

maxpool_reshaped = tf.reshape(maxpool_out2, [batch_size, -1])
</code></pre>

<p>Error:</p>

<pre><code>Traceback (most recent call last):
  File ""cnn.py"", line 52, in &lt;module&gt;
    model_op = model()
  File ""cnn.py"", line 45, in model
    maxpool_reshaped = tf.reshape(maxpool_out2, [batch_size, -1])
  File ""C:\Python35\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 2448, in reshape
    name=name)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 493, in apply_op
    raise err
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 490, in apply_op
    preferred_dtype=default_dtype)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 441, in make_tensor_proto
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 441, in &lt;listcomp&gt;
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""C:\Python35\lib\site-packages\tensorflow\python\util\compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got None
</code></pre>

<p><strong>EDIT-2</strong></p>

<p>After doing the following edits (in addtion to removing <code>batch_size</code>:</p>

<pre><code>w3 = tf.Variable(tf.random_normal([361, 256])) 
...
...
w_out = tf.Variable(tf.random_normal([256, 2])) 
</code></pre>

<p>I'm having the following error:</p>

<pre><code>EPOCH 0
W c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:975] Invalid argument: logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]
         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Reshape_2, Reshape_3)]]
Traceback (most recent call last):
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1021, in _do_call
    return fn(*args)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1003, in _run_fn
    status, run_metadata)
  File ""C:\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]
         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Reshape_2, Reshape_3)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""cnn.py"", line 73, in &lt;module&gt;
    _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: batch_data, y: batch_onehot_vals})
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 766, in run
    run_metadata_ptr)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""C:\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]
         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Reshape_2, Reshape_3)]]

Caused by op 'SoftmaxCrossEntropyWithLogits', defined at:
  File ""cnn.py"", line 55, in &lt;module&gt;
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(model_op, y))
  File ""C:\Python35\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 1449, in softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""C:\Python35\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 2265, in _softmax_cross_entropy_with_logits
    features=features, labels=labels, name=name)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[256,2] labels_size=[1,2]
         [[Node: SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Reshape_2, Reshape_3)]]
</code></pre>

<p><strong>EDIT-3</strong></p>

<p>This is how the binary (pickled) file looks like [label, filename, data]:</p>

<pre><code>[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array(['1.jpg', '10.jpg', '2.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg',
       '7.jpg', '8.jpg', '9.jpg'], 
      dtype='&lt;U6'), array([[142, 138, 134, ..., 128, 125, 122],
       [151, 151, 149, ..., 162, 159, 157],
       [120, 121, 122, ..., 132, 128, 122],
       ..., 
       [179, 175, 177, ..., 207, 205, 203],
       [126, 129, 130, ..., 134, 130, 134],
       [165, 170, 175, ..., 193, 193, 187]])]
</code></pre>

<p>How can I solve this issue?</p>
",588855.0,,6296561.0,,2019-06-03 16:35:30,2019-06-03 16:35:30,"Python / Tensorflow - Input to reshape is a tensor with 92416 values, but the requested shape requires a multiple of 2304",<python><tensorflow>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43010339
34229140,1,34248291,,2015-12-11 17:26:10,,28,16495,"<p>Recently I started toying with neural networks. I was trying to implement an <code>AND</code> gate with Tensorflow. I am having trouble understanding when to use different cost and activation functions. This is a basic neural network with only input and output layers, no hidden layers.</p>

<p>First I tried to implement it in this way. As you can see this is a poor implementation, but I think it gets the job done, at least in some way. So, I tried only the real outputs, no one hot true outputs. For activation functions, I used a sigmoid function and for cost function I used squared error cost function (I think its called that, correct me if I'm wrong). </p>

<p>I've tried using ReLU and Softmax as activation functions (with the same cost function) and it doesn't work. I figured out why they don't work. I also tried the sigmoid function with Cross Entropy cost function, it also doesn't work.</p>

<pre><code>import tensorflow as tf
import numpy

train_X = numpy.asarray([[0,0],[0,1],[1,0],[1,1]])
train_Y = numpy.asarray([[0],[0],[0],[1]])

x = tf.placeholder(""float"",[None, 2])
y = tf.placeholder(""float"",[None, 1])

W = tf.Variable(tf.zeros([2, 1]))
b = tf.Variable(tf.zeros([1, 1]))

activation = tf.nn.sigmoid(tf.matmul(x, W)+b)
cost = tf.reduce_sum(tf.square(activation - y))/4
optimizer = tf.train.GradientDescentOptimizer(.1).minimize(cost)

init = tf.initialize_all_variables()

with tf.Session() as sess:
    sess.run(init)
    for i in range(5000):
        train_data = sess.run(optimizer, feed_dict={x: train_X, y: train_Y})

    result = sess.run(activation, feed_dict={x:train_X})
    print(result)
</code></pre>

<p>after 5000 iterations:</p>

<pre><code>[[ 0.0031316 ]
[ 0.12012422]
[ 0.12012422]
[ 0.85576665]]
</code></pre>

<p><strong>Question 1</strong> - Is there any other activation function and cost function, that can work(learn) for the above network, without changing the parameters(meaning without changing W, x, b). </p>

<p><strong>Question 2</strong> - I read from a StackOverflow post <a href=""https://stackoverflow.com/questions/20850895/neural-networks-activation-function"">here</a>:</p>

<blockquote>
  <p>[Activation Function] selection depends on the problem.</p>
</blockquote>

<p>So there are no cost functions that can be used anywhere? I mean there is no <em>standard</em> cost function that can be used on any neural network. Right? Please correct me on this.</p>

<p><br/></p>

<p>I also implemented the <code>AND</code> gate with a different approach, with the output as one-hot true. As you can see the <code>train_Y</code> <code>[1,0]</code> means that the 0th index is 1, so the answer is 0. I hope you get it. </p>

<p>Here I have used a softmax activation function, with cross entropy as cost function. Sigmoid function as activation function fails miserably. </p>

<pre><code>import tensorflow as tf
import numpy

train_X = numpy.asarray([[0,0],[0,1],[1,0],[1,1]])
train_Y = numpy.asarray([[1,0],[1,0],[1,0],[0,1]])

x = tf.placeholder(""float"",[None, 2])
y = tf.placeholder(""float"",[None, 2])

W = tf.Variable(tf.zeros([2, 2]))
b = tf.Variable(tf.zeros([2]))

activation = tf.nn.softmax(tf.matmul(x, W)+b)

cost = -tf.reduce_sum(y*tf.log(activation))

optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(cost)

init = tf.initialize_all_variables()

with tf.Session() as sess:
    sess.run(init)
    for i in range(5000):
        train_data = sess.run(optimizer, feed_dict={x: train_X, y: train_Y})

    result = sess.run(activation, feed_dict={x:train_X})
    print(result)
</code></pre>

<p>after 5000 iteration</p>

<pre><code>[[  1.00000000e+00   1.41971401e-09]
 [  9.98996437e-01   1.00352429e-03]
 [  9.98996437e-01   1.00352429e-03]
 [  1.40495342e-03   9.98595059e-01]]
</code></pre>

<p><strong>Question 3</strong> So in this case what cost function and activation function can I use? How do I understand what type of cost and activation functions I should use? Is there a standard way or rule, or just experience only? Should I have to try every cost and activation function in a brute force manner? I found an answer <a href=""https://stackoverflow.com/questions/20368015/activation-function-choice-for-neural-network"">here</a>. But I am hoping for a more elaborate explanation. </p>

<p><strong>Question 4</strong> I have noticed that it takes many iterations to converge to a near accurate prediction. I think the convergance rate depends on the learning rate (using too large of will miss the solution) and the cost function (correct me if I'm wrong). So, is there any optimal way (meaning the fastest) or cost function for converging to a correct solution?</p>
",4341948.0,,-1.0,,2017-05-23 11:54:56,2020-09-04 10:24:31,Choosing from different cost function and activation function of a neural network,<python><machine-learning><neural-network><svm><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34229140
39024493,1,39024533,,2016-08-18 17:45:47,,28,103351,"<p>What's the command to find out the version of TensorFlow on my computer? I installed TensorFlow on my computer some time ago and want to make sure that I have the latest version.</p>
",6227592.0,,,,,2020-03-08 05:02:57,How do I find out the version of TensorFlow on my computer?,<tensorflow>,7,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39024493
39325275,1,39331675,,2016-09-05 06:57:38,,28,22111,"<p>The TensorFlow <a href=""https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/index.html"" rel=""noreferrer"">docs</a> describe a bunch of ways to read data using TFRecordReader, TextLineReader, QueueRunner etc and queues.</p>

<p>What I would like to do is much, much simpler:  I have a python generator function that produces an infinite sequence of training data as (X, y) tuples (both are numpy arrays, and the first dimension is the batch size).  I just want to train a network using that data as inputs.  </p>

<p>Is there a simple self-contained example of training a TensorFlow network using a generator which produces the data?  (along the lines of the MNIST or CIFAR examples)</p>
",1828289.0,,,,,2018-01-26 11:27:00,How to train TensorFlow network using a generator to produce inputs?,<python><tensorflow>,1,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39325275
41123879,1,41124526,,2016-12-13 14:45:13,,28,28860,"<p>Is there an equivalent function to numpy random choice in Tensorflow. 
In numpy we can get an item randomly from the given list with its weights. </p>

<pre><code> np.random.choice([1,2,3,5], 1, p=[0.1, 0, 0.3, 0.6, 0])
</code></pre>

<p>This code will select an item from the given list with p weights. </p>
",797880.0,,,,,2022-12-22 17:16:31,numpy random choice in Tensorflow,<python><numpy><tensorflow><deep-learning>,10,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41123879
48889482,1,48889586,,2018-02-20 16:08:43,,28,27505,"<p>Tensorflow seems to lack a reader for "".npy"" files.
How can I read my data files into the new tensorflow.data.Dataset pipline?
My data doesn't fit in memory.</p>

<p>Each object is saved in a separate "".npy"" file. each file contains 2 different ndarrays as features and a scalar as their label.</p>
",7758192.0,,7758192.0,,2018-02-20 16:56:46,2021-08-26 09:14:11,Feeding .npy (numpy files) into tensorflow data pipeline,<numpy><tensorflow><dataset><data-pipeline>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48889482
33634525,1,33635450,,2015-11-10 16:14:05,,27,30590,"<p>Is there a version of TensorFlow for 32-bit Linux?  I only see the 64-bit wheel available, and didn't find anything about it on the site.</p>
",5547331.0,,,,,2020-01-14 01:57:49,TensorFlow on 32-bit Linux?,<tensorflow>,4,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33634525
44973184,1,44973203,,2017-07-07 14:22:50,,27,21540,"<p>After spending a couple days trying to achieve this task, I would like to share my experience of how I went about answering the question:</p>

<p><em>How do I use <a href=""https://github.com/tensorflow/models/tree/master/research/object_detection"" rel=""noreferrer"">TS Object Detection</a> to train using my own dataset?</em></p>
",4962554.0,,5330223.0,,2017-10-26 06:06:29,2018-07-26 10:43:14,Train Tensorflow Object Detection on own dataset,<machine-learning><tensorflow><object-detection>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44973184
36195454,1,36203288,,2016-03-24 07:56:00,,27,19563,"<p>When saving a checkpoint, TensorFlow often saves a meta file: <code>my_model.ckpt.meta</code>. What is in that file, can we still restore a model even if we delete it and what kind of info did we lose if we restore a model without the meta file?</p>
",234167.0,,,,,2018-12-04 11:50:14,What is the TensorFlow checkpoint meta file?,<tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36195454
44395547,1,44404530,,2017-06-06 16:44:30,,27,14444,"<p>I'm quite confused about whether to use tf.nn.dropout or tf.layers.dropout.</p>

<p>many MNIST CNN examples seems to use tf.nn.droput, with keep_prop as one of params. </p>

<p>but how is it different with tf.layers.dropout? is the ""rate"" params in tf.layers.dropout similar to tf.nn.dropout?</p>

<p>Or generally speaking, is the difference between tf.nn.dropout and tf.layers.dropout applies to all other similar situations, like similar functions in tf.nn and tf.layers. </p>
",8102163.0,,1090562.0,,2017-06-06 22:09:49,2018-02-01 14:07:57,tensorflow: what's the difference between tf.nn.dropout and tf.layers.dropout,<tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44395547
43147435,1,43334912,,2017-03-31 18:32:25,,27,8222,"<p>I've read <a href=""https://www.tensorflow.org/deploy/distributed"" rel=""noreferrer"">Distributed Tensorflow Doc</a>, and it mentions that in asynchronous training, </p>

<blockquote>
  <p>each replica of the graph has an independent training loop that executes without coordination.</p>
</blockquote>

<p>From what I understand, if we use parameter-server with data parallelism architecture, it means each worker computes gradients and updates its own weights without caring about other workers updates for distributed training Neural Network. As all weights are shared on parameter server (ps), I think ps still has to coordinate (or aggregate) weight updates from all workers in some way. I wonder how does the aggregation work in asynchronous training. Or in more general words, how does asynchronous training work in distributed Tensorflow?</p>
",4480756.0,,3990607.0,,2017-04-06 17:47:21,2017-12-21 01:56:12,How does asynchronous training work in distributed Tensorflow?,<python><asynchronous><tensorflow><neural-network><distributed>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43147435
42095625,1,42095969,,2017-02-07 16:56:35,,27,18397,"<p>I would like to have an example illustrating the use of the function <a href=""https://www.tensorflow.org/api_docs/python/tf/control_dependencies"" rel=""noreferrer""><code>tf.control_dependencies</code></a>. For example, I want to create two tensors <code>X</code> and <code>Y</code> and if they are equal do or print something. </p>

<pre><code>import tensorflow as tf

session = tf.Session()

X = tf.constant(5)
Y = tf.constant(50)

with tf.control_dependencies([tf.assert_equal(X, Y)]):
    print('X and Y are equal!')
</code></pre>

<p>In the code above, <code>X</code> is clearly not equal to <code>Y</code>. What is <code>tf.control_dependencies</code> doing in this case?</p>
",5540159.0,,3924118.0,,2018-07-08 14:15:52,2018-07-08 14:15:52,What does the function control_dependencies do?,<python><tensorflow>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42095625
41534593,1,41534724,,2017-01-08 15:55:47,,27,18507,"<p>Is there a good reason to use <code>tf.concat</code> instead of <code>tf.stack</code>? They seem very similar. Is it just to guarantee that the resulting tensor will have the same number of dimensions as the input list of tensors?</p>
",7287271.0,,,,,2018-02-21 14:53:56,Why would I ever use tf.concat instead of tf.stack?,<python><tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41534593
48082900,1,48083266,,2018-01-03 18:11:49,,27,27194,"<p>Could anyone help with an an explanation of what <code>axis</code> is in <code>TensorFlow</code>'s <code>one_hot</code> function?</p>

<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/one_hot"" rel=""noreferrer"">documentation</a>:</p>

<blockquote>
  <p>axis: The axis to fill (default: -1, a new inner-most axis)</p>
</blockquote>

<p>Closest I came to an answer on <a href=""https://stackoverflow.com/questions/22149584/what-does-axis-in-pandas-mean"">SO was an explanation</a> relevant to <a href=""https://pandas.pydata.org/"" rel=""noreferrer"">Pandas</a>:</p>

<p>Not sure if the context is just as applicable.</p>
",919426.0,,712995.0,,2018-08-01 12:16:13,2021-01-11 14:35:57,"In TensorFlow, what is the argument 'axis' in the function 'tf.one_hot'",<python-3.x><tensorflow><machine-learning><multidimensional-array><one-hot-encoding>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48082900
44232566,1,44238354,,2017-05-28 22:21:57,,27,29033,"<p>Is it possible to add an L2 regularization when using the layers defined in tf.layers? </p>

<p>It seems to me that since tf.layers is an high level wrapper, there is no easy way to get access to the filter weights.</p>

<p><strong>With tf.nn.conv2d</strong></p>

<pre><code>regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)

weights = tf.get_variable(
    name=""weights"",
    regularizer=regularizer
)

#Previous layers

...

#Second layer 
layer 2 = tf.nn.conv2d(
input,
weights,
[1,1,1,1],
[1,1,1,1])

#More layers
...

#Loss
loss = #some loss

reg_variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
reg_term = tf.contrib.layers.apply_regularization(regularizer, reg_variables)
loss += reg_term
</code></pre>

<p><strong>Now what would that look like with tf.layers.conv2d?</strong></p>

<p>Thanks!</p>
",6255101.0,,1937197.0,,2017-05-29 05:01:52,2018-10-20 13:36:31,Add L2 regularization when using high level tf.layers,<tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44232566
34097457,1,34097753,,2015-12-04 21:07:24,,27,4989,"

<p>Assuming I have a very simple neural network, like multilayer perceptron. For each layer the activation function is sigmoid and the network are fully connected.</p>

<p>In TensorFlow this might be defined like this:</p>

<pre class=""lang-py prettyprint-override""><code>    sess = tf.InteractiveSession()

    # Training Tensor
    x = tf.placeholder(tf.float32, shape = [None, n_fft])
    # Label Tensor
    y_ = tf.placeholder(tf.float32, shape = [None, n_fft])

    # Declaring variable buffer for weights W and bias b
    # Layer structure [n_fft, n_fft, n_fft, n_fft]
    # Input -&gt; Layer 1
    struct_w = [n_fft, n_fft]
    struct_b = [n_fft]
    W1 = weight_variable(struct_w, 'W1')
    b1 = bias_variable(struct_b, 'b1')
    h1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)

    # Layer1 -&gt; Layer 2
    W2 = weight_variable(struct_w, 'W2')
    b2 = bias_variable(struct_b, 'b2')
    h2 = tf.nn.sigmoid(tf.matmul(h1, W2) + b2)

    # Layer2 -&gt; output
    W3 = weight_variable(struct_w, 'W3')
    b3 = bias_variable(struct_b, 'b3')
    y = tf.nn.sigmoid(tf.matmul(h2, W3) + b3)

    # Calculating difference between label and output using mean square error
    mse = tf.reduce_mean(tf.square(y - y_))

    # Train the Model
    # Gradient Descent
    train_step = tf.train.GradientDescentOptimizer(0.3).minimize(mse)
</code></pre>

<p>The design target for this model is to map a <code>n_fft</code> points fft spectrogram to another <code>n_fft</code> target spectrogram. Let's assume both the training data and target data are of size <code>[3000, n_fft]</code>. They are stored in variables <code>spec_train</code> and <code>spec_target</code>.</p>

<p>Now here comes the question. For TensorFlow is there any difference between these two trainings?</p>

<p>Training 1:</p>

<pre class=""lang-py prettyprint-override""><code>for i in xrange(200):
        train_step.run(feed_dict = {x: spec_train, y_: spec_target})
</code></pre>

<p>Training 2:</p>

<pre class=""lang-py prettyprint-override""><code>for i in xrange(200):
        for j in xrange(3000):
            train = spec_train[j, :].reshape(1, n_fft)
            label = spec_target[j, :].reshape(1, n_fft)
            train_step.run(feed_dict = {x: train, y_: label})
</code></pre>

<p>Thank you very much!</p>
",5231637.0,,2464597.0,,2017-08-25 20:07:17,2017-08-25 20:07:17,TensorFlow Training,<neural-network><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34097457
34030140,1,34032563,,2015-12-01 21:06:57,,27,16445,"

<p>Multiplication of sparse tensors with themselves or with dense tensors does not seem to work in TensorFlow.  The following example</p>

<pre class=""lang-py prettyprint-override""><code>from __future__ import print_function
import tensorflow as tf

x = tf.constant([[1.0,2.0],
                 [3.0,4.0]])
y = tf.SparseTensor(indices=[[0,0],[1,1]], values=[1.0,1.0], shape=[2,2])
z = tf.matmul(x,y)

sess = tf.Session()
sess.run(tf.initialize_all_variables())
print(sess.run([x, y, z]))
</code></pre>

<p>fails with the error message</p>

<pre class=""lang-py prettyprint-override""><code>TypeError: Input 'b' of 'MatMul' Op has type string that does not match type 
float32 of argument 'a'
</code></pre>

<p>Both tensors have values of type float32 as seen by evaluating them  without the multiplication op.  Multiplication of y with itself returns a similar error message.  Multipication of x with itself works fine.</p>
",411038.0,,2464597.0,,2017-08-25 23:02:21,2021-09-17 14:06:53,Is sparse tensor multiplication implemented in TensorFlow?,<sparse-matrix><tensorflow>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34030140
36838770,1,36850019,,2016-04-25 11:04:17,,27,14912,"<p>How do I interpret the TensorFlow output for building and executing computational graphs on GPGPUs?</p>

<p>Given the following command that executes an arbitrary tensorflow script using the python API.</p>

<blockquote>
  <blockquote>
    <p>python3 tensorflow_test.py > out</p>
  </blockquote>
</blockquote>

<p>The first part <code>stream_executor</code> seems like its loading dependencies.</p>

<pre><code>I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
</code></pre>

<p>What is a <code>NUMA</code> node?</p>

<pre><code>I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
</code></pre>

<p>I assume this is when it finds the available GPU</p>

<pre><code>I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:01:00.0
Total memory: 11.25GiB
Free memory: 11.15GiB
</code></pre>

<p>Some gpu initialization? what is DMA?</p>

<pre><code>I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0)
</code></pre>

<p>Why does it throw an error <code>E</code>?</p>

<pre><code>E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 11.15G (11976531968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
</code></pre>

<p>Great answer to what the <code>pool_allocator</code> does: <a href=""https://stackoverflow.com/a/35166985/4233809"">https://stackoverflow.com/a/35166985/4233809</a></p>

<pre><code>I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 3160 get requests, put_count=2958 evicted_count=1000 eviction_rate=0.338066 and unsatisfied allocation rate=0.412025
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 1743 get requests, put_count=1970 evicted_count=1000 eviction_rate=0.507614 and unsatisfied allocation rate=0.456684
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 256 to 281
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 1986 get requests, put_count=2519 evicted_count=1000 eviction_rate=0.396983 and unsatisfied allocation rate=0.264854
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 655 to 720
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 28728 get requests, put_count=28680 evicted_count=1000 eviction_rate=0.0348675 and unsatisfied allocation rate=0.0418407
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1694 to 1863
</code></pre>
",4233809.0,,-1.0,,2017-05-23 12:34:21,2017-05-02 06:58:47,How to interpret TensorFlow output?,<python><gpu><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36838770
46146757,1,46146814,,2017-09-11 00:25:59,,27,36957,"<p>I am trying to train a simple multi-layer perceptron for a 10-class image classification task, which is a part of the assignment for the Udacity Deep-Learning course. To be more precise, the task is to classify letters rendered from various fonts (the dataset is called notMNIST).</p>

<p>The code I ended up with looks fairly simple, but no matter what I always get very low GPU usage during training. I measure load with GPU-Z and it shows just 25-30%.</p>

<p>Here is my current code:</p>

<pre><code>graph = tf.Graph()
with graph.as_default():
    tf.set_random_seed(52)

    # dataset definition
    dataset = Dataset.from_tensor_slices({'x': train_data, 'y': train_labels})
    dataset = dataset.shuffle(buffer_size=20000)
    dataset = dataset.batch(128)
    iterator = dataset.make_initializable_iterator()
    sample = iterator.get_next()
    x = sample['x']
    y = sample['y']

    # actual computation graph
    keep_prob = tf.placeholder(tf.float32)
    is_training = tf.placeholder(tf.bool, name='is_training')

    fc1 = dense_batch_relu_dropout(x, 1024, is_training, keep_prob, 'fc1')
    fc2 = dense_batch_relu_dropout(fc1, 300, is_training, keep_prob, 'fc2')
    fc3 = dense_batch_relu_dropout(fc2, 50, is_training, keep_prob, 'fc3')
    logits = dense(fc3, NUM_CLASSES, 'logits')

    with tf.name_scope('accuracy'):
        accuracy = tf.reduce_mean(
            tf.cast(tf.equal(tf.argmax(y, 1), tf.argmax(logits, 1)), tf.float32),
        )
        accuracy_percent = 100 * accuracy

    with tf.name_scope('loss'):
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))

    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
        # ensures that we execute the update_ops before performing the train_op
        # needed for batch normalization (apparently)
        train_op = tf.train.AdamOptimizer(learning_rate=1e-3, epsilon=1e-3).minimize(loss)

with tf.Session(graph=graph) as sess:
    tf.global_variables_initializer().run()
    step = 0
    epoch = 0
    while True:
        sess.run(iterator.initializer, feed_dict={})
        while True:
            step += 1
            try:
                sess.run(train_op, feed_dict={keep_prob: 0.5, is_training: True})
            except tf.errors.OutOfRangeError:
                logger.info('End of epoch #%d', epoch)
                break

        # end of epoch
        train_l, train_ac = sess.run(
            [loss, accuracy_percent],
            feed_dict={x: train_data, y: train_labels, keep_prob: 1, is_training: False},
        )
        test_l, test_ac = sess.run(
            [loss, accuracy_percent],
            feed_dict={x: test_data, y: test_labels, keep_prob: 1, is_training: False},
        )
        logger.info('Train loss: %f, train accuracy: %.2f%%', train_l, train_ac)
        logger.info('Test loss: %f, test accuracy: %.2f%%', test_l, test_ac)

        epoch += 1
</code></pre>

<p>Here's what I tried so far:</p>

<ol>
<li><p>I changed the input pipeline from simple <code>feed_dict</code> to <code>tensorflow.contrib.data.Dataset</code>. As far as I understood, it is supposed to take care of the efficiency of the input, e.g. load data in a separate thread. So there should not be any bottleneck associated with the input.</p></li>
<li><p>I collected traces as suggested here: <a href=""https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659</a>
However, these traces didn't really show anything interesting. >90% of the train step is matmul operations.</p></li>
<li><p>Changed batch size. When I change it from 128 to 512 the load increases from ~30% to ~38%, when I increase it further to 2048, the load goes to ~45%. I have 6Gb GPU memory and dataset is single channel 28x28 images. Am I really supposed to use such a big batch size? Should I increase it further?</p></li>
</ol>

<p>Generally, should I worry about the low load, is it really a sign that I am training inefficiently?</p>

<p>Here's the GPU-Z screenshots with 128 images in the batch. You can see low load with occasional spikes to 100% when I measure accuracy on the entire dataset after each epoch.</p>

<p><a href=""https://i.stack.imgur.com/0x0MS.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/0x0MS.png"" alt=""GPU load""></a> </p>
",1645784.0,,,,,2023-01-31 19:36:22,Very low GPU usage during training in Tensorflow,<python><deep-learning><gpu><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46146757
34235225,1,34235413,,2015-12-12 01:38:15,,26,13724,"<p>TensorFlow graph is usually built gradually from inputs to outputs, and then executed. Looking at the Python code, the inputs lists of operations are immutable which suggests that the inputs should not be modified. Does that mean that there is no way to update/modify an existing graph?</p>
",1576602.0,,,,,2021-09-12 20:18:38,Is it possible to modify an existing TensorFlow computation graph?,<python><tensorflow>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34235225
41533489,1,50434439,,2017-01-08 13:59:36,,26,11630,"<p>I want to use <code>MomentumOptimizer</code> in Tensorflow. However, since this optimizer uses some internal variable, attempting to use it without initializing this variable yields an error: </p>

<blockquote>
  <p><code>FailedPreconditionError</code> (see above for traceback): Attempting to use
   uninitialized value <code>Variable_2/Momentum</code></p>
</blockquote>

<p>This can be easily solved by initializing all variables, using for example</p>

<pre><code>tf.global_variables_initializer().run()
</code></pre>

<p>However, I do not want to initialize <strong>all</strong> the variables - only those of optimizer. Is there any way to do this?</p>
",3401555.0,,3924118.0,,2018-07-07 17:59:02,2018-07-07 17:59:02,How to initialise only optimizer variables in Tensorflow?,<python><tensorflow>,6,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41533489
33684657,1,33685256,,2015-11-13 01:47:05,,26,46090,"<p>I'm trying to pass a list into <code>feed_dict</code>, however I'm having trouble doing so. Say I have:</p>

<pre><code>inputs = 10 * [tf.placeholder(tf.float32, shape=(batch_size, input_size))]
</code></pre>

<p>where inputs is fed into some function <code>outputs</code> that I want to compute. So to run this in tensorflow, I created a session and ran the following:</p>

<pre><code>sess.run(outputs, feed_dict = {inputs: data}) 
#data is my list of inputs, which is also of length 10
</code></pre>

<p>but I get an error, <code>TypeError: unhashable type: 'list'.</code>
However, I'm able to pass the data element-wise like so:</p>

<pre><code>sess.run(outputs, feed_dict = {inputs[0]: data[0], ..., inputs[9]: data[9]}) 
</code></pre>

<p>So I'm wondering if there's a way I can solve this issue. I've also tried to construct a dictionary(using a <code>for</code> loop), however this results in a dictionary with a single element, where they key is: 
<code>tensorflow.python.framework.ops.Tensor at 0x107594a10</code></p>
",5557105.0,,5345646.0,,2018-01-05 11:54:31,2019-01-09 06:42:14,Issue feeding a list into feed_dict in TensorFlow,<python><tensorflow>,3,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33684657
38060825,1,38062223,,2016-06-27 18:30:12,,26,21287,"<p>I'm curious about what <code>tf.contrib</code> is, and why the code would be included in TensorFlow, but not in the main repository.</p>

<p>Furthermore, looking at the example <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py"" rel=""noreferrer"">here</a> (from the tensorflow master branch), and I want to find the source for <code>tf.contrib.layers.sparse_column_with_hash_bucket</code>. </p>

<p>It seems like some cool routines, but I wanted to make sure they were properly using queues, etc, for pre-fetching/pre-processing examples to actually use them in a production setting. </p>

<p>It appears to be documented <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.learn.html#TensorFlowClassifier"" rel=""noreferrer"">here</a>, but it is from the <a href=""https://github.com/tflearn"" rel=""noreferrer"">tflearn</a> project, but <code>tf.contrib.layers.sparse_column_with_hash_bucket</code> doesn't seem to be in that repository either.</p>
",712997.0,,3924118.0,,2018-07-08 22:55:30,2018-07-08 22:55:30,What is the purpose of the tf.contrib module in Tensorflow?,<python><tensorflow>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38060825
41957574,1,42079546,,2017-01-31 12:26:24,,26,15035,"<p>Can someone help me rewrite this one function <em>(the <code>doTheMath</code> function)</em> to do the calculations on the GPU? I used a few good days now trying to get my head around it but to no result. I wonder maybe somebody can help me rewrite this function in whatever way you may seem fit as log as I gives the same result at the end. I tried to use <code>@jit</code> from <code>numba</code> but for some reason it is actually much slower than running the code as usual. With a huge sample size, the goal is to decrease the execution time considerably so naturally I believe the GPU is the fastest way to do it. </p>

<p>I'll explain a little what is actually happening. The real data, which looks almost identical as the sample data created in the code below is divided into sample sizes of approx 5.000.000 rows each sample or around 150MB per file. In total there are around 600.000.000 rows or 20GB of data. I must loop through this data, sample by sample and then row by row in each sample, take the last 2000 (or another) rows as of each line and run the <code>doTheMath</code> function which returns a result. That result is then saved back to the hardrive where I can do some other things with it with another program. As you can see below, I do not need all of the results of all the rows, only those bigger than a specific amount. If I run my function as it is right now in python I get about 62seconds per 1.000.000 rows. This is a very long time considering all the data and how fast it should be done with.</p>

<p>I must mention that I upload the real data file by file to the RAM with the help of <code>data = joblib.load(file)</code> so uploading the data is not the problem as it takes only about 0.29 seconds per file. Once uploaded I run the entire code below. What takes the longest time is the <code>doTheMath</code> function. I am willing to give all of my 500 reputation points I have on stackoverflow as a reward for somebody willing to help me rewrite this simple code to run on the GPU. My interest is specifically in the GPU, I really want to see how it is done on this problem at hand.</p>

<p><strong>EDIT/UPDATE 1:</strong>
Here is a link to a small sample of the real data: <a href=""https://mab.to/Nx8GvwTjQ"" rel=""noreferrer"">data_csv.zip</a> About 102000 rows of real data1 and 2000 rows for real data2a and data2b. Use <code>minimumLimit = 400</code> on the real sample data </p>

<p><strong>EDIT/UPDATE 2:</strong>
For those following this post here is a short summary of the answers below. Up until now we have 4 answers to the original solution. The one offered by @Divakar are just tweaks to the original code. Of the two tweaks only the first one is actually applicable to this problem, the second one is a good tweak but does not apply here. Out of the other three answers, two of them are CPU based solutions and one tensorflow-GPU try. The Tensorflow-GPU by Paul Panzer seems to be promising but when i actually run it on the GPU it is slower than the original, so the code still needs improvement.</p>

<p>The other two CPU based solutions are submitted by @PaulPanzer (a pure numpy solution) and @MSeifert (a numba solution). Both solutions give very good results and both process data extremely fast compared to the original code. Of the two the one submitted by Paul Panzer is faster. It processes about 1.000.000 rows in about 3 seconds. The only problem is with smaller batchSizes, this can be overcome by either switching to the numba solution offered by MSeifert, or even the original code after all the tweaks that have been discussed below.</p>

<p>I am very happy and thankful to @PaulPanzer and @MSeifert for the work they did on their answers. Still, since this is a question about a GPU based solution, i am waiting to see if anybody is willing to give it a try on a GPU version and see how much faster the data can be processed on the GPU when compared to the current CPU solutions. If there will be no other answers outperforming @PaulPanzer's pure numpy solution then i'll accept his answer as the right one and gets the bounty :) </p>

<p><strong>EDIT/UPDATE 3:</strong>
@Divakar has posted a new answer with a solution for the GPU. After my testings on real data, the speed is not even comparable to the CPU counterpart solutions. The GPU processes about 5.000.000 in about 1,5 seconds. This is incredible :) I am very excited about the GPU solution and i thank @Divakar for posting it. As well as i thank @PaulPanzer and @MSeifert for their CPU solutions :) Now my research continues with an incredible speed due to the GPU :) </p>

<pre><code>import pandas as pd
import numpy as np
import time

def doTheMath(tmpData1, data2a, data2b):
    A = tmpData1[:, 0]
    B = tmpData1[:,1]
    C = tmpData1[:,2]
    D = tmpData1[:,3]
    Bmax = B.max()
    Cmin  = C.min()
    dif = (Bmax - Cmin)
    abcd = ((((A - Cmin) / dif) + ((B - Cmin) / dif) + ((C - Cmin) / dif) + ((D - Cmin) / dif)) / 4)
    return np.where(((abcd &lt;= data2a) &amp; (abcd &gt;= data2b)), 1, 0).sum()

#Declare variables
batchSize = 2000
sampleSize = 5000000
resultArray = []
minimumLimit = 490 #use 400 on the real sample data 

#Create Random Sample Data
data1 = np.matrix(np.random.uniform(1, 100, (sampleSize + batchSize, 4)))
data2a = np.matrix(np.random.uniform(0, 1, (batchSize, 1))) #upper limit
data2b = np.matrix(np.random.uniform(0, 1, (batchSize, 1))) #lower limit
#approx. half of data2a will be smaller than data2b, but that is only in the sample data because it is randomly generated, NOT the real data. The real data2a is always higher than data2b.


#Loop through the data
t0 = time.time()
for rowNr in  range(data1.shape[0]):
    tmp_df = data1[rowNr:rowNr + batchSize] #rolling window
    if(tmp_df.shape[0] == batchSize):
        result = doTheMath(tmp_df, data2a, data2b)
        if (result &gt;= minimumLimit):
            resultArray.append([rowNr , result])
print('Runtime:', time.time() - t0)

#Save data results
resultArray = np.array(resultArray)
print(resultArray[:,1].sum())
resultArray = pd.DataFrame({'index':resultArray[:,0], 'result':resultArray[:,1]})
resultArray.to_csv(""Result Array.csv"", sep=';')
</code></pre>

<p>The PC specs I am working on:</p>

<pre><code>GTX970(4gb) video card; 
i7-4790K CPU 4.00Ghz; 
16GB RAM;
a SSD drive 
running Windows 7; 
</code></pre>

<p>As a side question, would a second video card in SLI help on this problem?</p>
",2480410.0,,2480410.0,,2017-02-08 10:01:57,2017-02-08 10:01:57,Python: rewrite a looping numpy math function to run on GPU,<python><numpy><tensorflow><theano><numba>,5,8,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41957574
45085938,1,47561171,,2017-07-13 16:05:46,,26,28274,"<p>The closest example I can get is found in this issue: <a href=""https://github.com/tensorflow/tensorflow/issues/899"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/issues/899</a></p>

<p>With this minimum reproducible code:</p>

<pre><code>import tensorflow as tf
import tensorflow.python.framework.ops as ops 
g = tf.Graph()
with g.as_default():
  A = tf.Variable(tf.random_normal( [25,16] ))
  B = tf.Variable(tf.random_normal( [16,9] ))
  C = tf.matmul(A,B) # shape=[25,9]
for op in g.get_operations():
  flops = ops.get_stats_for_node_def(g, op.node_def, 'flops').value
  if flops is not None:
    print 'Flops should be ~',2*25*16*9
    print '25 x 25 x 9 would be',2*25*25*9 # ignores internal dim, repeats first
    print 'TF stats gives',flops
</code></pre>

<p>However, the FLOPS returned is always None. Is there a way to concretely measure FLOPS, especially with a PB file?</p>
",5107084.0,,7443104.0,,2018-05-11 14:10:57,2021-06-22 07:50:49,TensorFlow: Is there a way to measure FLOPS for a model?,<python><tensorflow>,4,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45085938
59953127,1,59953293,,2020-01-28 16:29:40,,26,29447,"<p>I'm trying to get <a href=""https://en.wikipedia.org/wiki/Uber"" rel=""nofollow noreferrer"">Uber</a>'s Ludwig to run. I get an error about there being no attribute 'random_normal'. I can reproduce the error in Python with these commands.</p>
<pre><code>&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; tf.reduce_sum(tf.random_normal([1000,1000]))
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
AttributeError: module 'tensorflow' has no attribute 'random_normal'
&gt;&gt;&gt; print(tf.__version__)
2.1.0
&gt;&gt;&gt; print(sys.version)
3.7.5 (defaut, Oct 25 2019, 15:51:11)
[GCC 7.3.0]
</code></pre>
<p>How can I get past this error?</p>
",667570.0,,63550.0,,2023-05-24 15:26:18,2023-05-24 15:30:24,TensorFlow 2.1.0: has no attribute 'random_normal',<python><tensorflow><ludwig>,3,5,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59953127
44299666,1,44300704,,2017-06-01 06:06:15,,26,25983,"<pre><code>import tensorflow as tf
x = tf.constant(35, name='x')
y = tf.Variable(x + 5, name='y')
# model = tf.global_variables_initializer()
with tf.Session() as session:
        print(""x = "", session.run(x)) 
        # session.run(model)
        print(""y = "", session.run(y))
</code></pre>

<p>I was not able to understand when <code>global_variables_initializer()</code> is actually required. In the above code, if we uncomment lines 4 &amp; 7, I can execute the code and see the values. If I run as-is, I see a crash.</p>

<p>My question is which variables it is initializing. <code>x</code> is a constant which does not need initialization and <code>y</code> is variable which is not being initialized but is used as an arithmetic operation.</p>
",3890359.0,,5657159.0,,2018-05-15 12:38:25,2018-05-15 12:38:25,When global_variables_initializer() is actually required,<python><python-3.x><tensorflow><initializer>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44299666
35842598,1,35847836,,2016-03-07 11:31:52,,26,30526,"<p>I have a basic question about how to do indexing in TensorFlow.</p>

<p>In numpy:</p>

<pre><code>x = np.asarray([1,2,3,3,2,5,6,7,1,3])
e = np.asarray([0,1,0,1,1,1,0,1])
#numpy 
print x * e[x]
</code></pre>

<p>I can get</p>

<pre><code>[1 0 3 3 0 5 0 7 1 3]
</code></pre>

<p>How can I do this in TensorFlow?</p>

<pre><code>x = np.asarray([1,2,3,3,2,5,6,7,1,3])
e = np.asarray([0,1,0,1,1,1,0,1])
x_t = tf.constant(x)
e_t = tf.constant(e)
with tf.Session():
    ????
</code></pre>

<p>Thanks!</p>
",200340.0,,3574081.0,,2016-03-07 16:42:40,2018-10-15 17:59:49,TensorFlow: using a tensor to index another tensor,<python><numpy><tensorflow>,1,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35842598
42134360,1,42135964,,2017-02-09 10:36:21,,26,27128,"<p>I want to save my tensorflow session <code>sess</code> but i have the following error</p>

<p><code>ValueError: Parent directory of trained_variables.ckpt doesn't exist, can't save.</code></p>

<p>This is my line of code :</p>

<p><code>saver.save(sess, ""trained_variables.ckpt"")</code></p>

<p>I've also tried to change the file name and put <code>model</code> instead of <code>trained_variables.ckpt</code> but i get the same problem.</p>

<p>Following this tutorial <a href=""http://jrmeyer.github.io/tutorial/2016/02/01/TensorFlow-Tutorial.html"" rel=""noreferrer"">A TensorFlow Tutorial: Email Classification</a></p>
",7539585.0,,7539585.0,,2017-02-09 11:09:16,2019-10-28 13:59:41,"Tensorflow - ValueError: Parent directory of trained_variables.ckpt doesn't exist, can't save",<tensorflow>,8,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42134360
66207609,1,66207610,,2021-02-15 11:55:42,,26,55984,"<p>tensorflow version 2.3.1
numpy version 1.20</p>
<p>below the code</p>
<pre><code># define model
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
</code></pre>
<p>we got</p>
<blockquote>
<p>NotImplementedError: Cannot convert a symbolic Tensor
(lstm_2/strided_slice:0) to a numpy array. This error may indicate
that you're trying to pass a Tensor to a NumPy call, which is not
supported</p>
</blockquote>
<p>it seems to me a crazy error!</p>
",1645339.0,,,,,2022-03-13 02:12:52,NotImplementedError: Cannot convert a symbolic Tensor (lstm_2/strided_slice:0) to a numpy array. T,<python><numpy><tensorflow>,8,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/66207609
41859605,1,41862548,,2017-01-25 19:05:06,,26,49241,"<p>Let's say I've read in a textfile using a <code>TextLineReader</code>. Is there some way to split this into train and test sets in <code>Tensorflow</code>? Something like:</p>

<pre><code>def read_my_file_format(filename_queue):
  reader = tf.TextLineReader()
  key, record_string = reader.read(filename_queue)
  raw_features, label = tf.decode_csv(record_string)
  features = some_processing(raw_features)
  features_train, labels_train, features_test, labels_test = tf.train_split(features,
                                                                            labels,
                                                                            frac=.1)
  return features_train, labels_train, features_test, labels_test
</code></pre>
",2985049.0,,2985049.0,,2018-07-02 17:00:33,2022-09-14 08:13:26,Split tensor into training and test sets,<tensorflow><cross-validation><training-data>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41859605
33879281,1,37682834,,2015-11-23 19:41:37,,26,3860,"<p>I am trying to define my own RNNCell (Echo State Network) in Tensorflow, according to below definition.</p>

<p>x(t + 1) = tanh(Win*u(t) + W*x(t) + Wfb*y(t))</p>

<p>y(t) = Wout*z(t)</p>

<p>z(t) = [x(t), u(t)]</p>

<p>x is state, u is input, y is output. Win, W, and Wfb are not trainable. All weights are randomly initialized, but W is modified like this: ""Set a certain percentage of elements of W to 0, scale W to keep its spectral radius below 1.0</p>

<p>I have this code to generate the equation.</p>

<pre><code>x = tf.Variable(tf.reshape(tf.zeros([N]), [-1, N]), trainable=False, name=""state_vector"")
W = tf.Variable(tf.random_normal([N, N], 0.0, 0.05), trainable=False)
# TODO: setup W according to the ESN paper
W_x = tf.matmul(x, W)

u = tf.placeholder(""float"", [None, K], name=""input_vector"")
W_in = tf.Variable(tf.random_normal([K, N], 0.0, 0.05), trainable=False)
W_in_u = tf.matmul(u, W_in)

z = tf.concat(1, [x, u])
W_out = tf.Variable(tf.random_normal([K + N, L], 0.0, 0.05))
y = tf.matmul(z, W_out)
W_fb = tf.Variable(tf.random_normal([L, N], 0.0, 0.05), trainable=False)
W_fb_y = tf.matmul(y, W_fb)

x_next = tf.tanh(W_in_u + W_x + W_fb_y)

y_ = tf.placeholder(""float"", [None, L], name=""train_output"")
</code></pre>

<p>My problem is two-fold. First I don't know how to implement this as a superclass of RNNCell. Second I don't know how to generate a W tensor according to above specification.</p>

<p>Any help about any of these question is greatly appreciated. Maybe I can figure out a way to prepare W, but I sure as hell don't understand how to implement my own RNN as a superclass of RNNCell.</p>
",310378.0,,,,,2020-07-06 22:00:30,How can I implement a custom RNN (specifically an ESN) in Tensorflow?,<python><machine-learning><neural-network><tensorflow>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33879281
59567226,1,59571639,,2020-01-02 17:04:46,,26,28729,"<p>For a vector quantization (k-means) program I like to know the amount of available memory on the present GPU (if there is one). This is needed to choose an optimal batch size in order to have as few batches as possible to run over the complete data set.</p>

<p>I have written the following test program:</p>

<pre><code>import tensorflow as tf
import numpy as np
from kmeanstf import KMeansTF
print(""GPU Available: "", tf.test.is_gpu_available())

nn=1000
dd=250000
print(""{:,d} bytes"".format(nn*dd*4))
dic = {}
for x in ""ABCD"":
    dic[x]=tf.random.normal((nn,dd))
    print(x,dic[x][:1,:2])

print(""done..."")
</code></pre>

<p>This is a typical output on my system with (ubuntu 18.04 LTS, GTX-1060 6GB). Please note the core dump.</p>

<pre><code>python misc/maxmem.py 
GPU Available:  True
1,000,000,000 bytes
A tf.Tensor([[-0.23787294 -2.0841186 ]], shape=(1, 2), dtype=float32)
B tf.Tensor([[ 0.23762687 -1.1229591 ]], shape=(1, 2), dtype=float32)
C tf.Tensor([[-1.2672468   0.92139906]], shape=(1, 2), dtype=float32)
2020-01-02 17:35:05.988473: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 953.67MiB (rounded to 1000000000).  Current allocation summary follows.
2020-01-02 17:35:05.988752: W tensorflow/core/common_runtime/bfc_allocator.cc:424] **************************************************************************************************xx
2020-01-02 17:35:05.988835: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cwise_ops_common.cc:82 : Resource exhausted: OOM when allocating tensor with shape[1000,250000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Segmentation fault (core dumped)
</code></pre>

<p>Occasionally I do get an error from python instead of a core dump (see below). This would actually be better since I could catch it and thus determine by trial and error the maximum available memory. But it alternates with core dumps:</p>

<pre><code>python misc/maxmem.py 
GPU Available:  True
1,000,000,000 bytes
A tf.Tensor([[-0.73510283 -0.94611156]], shape=(1, 2), dtype=float32)
B tf.Tensor([[-0.8458411  0.552555 ]], shape=(1, 2), dtype=float32)
C tf.Tensor([[0.30532074 0.266423  ]], shape=(1, 2), dtype=float32)
2020-01-02 17:35:26.401156: W tensorflow/core/common_runtime/bfc_allocator.cc:419] Allocator (GPU_0_bfc) ran out of memory trying to allocate 953.67MiB (rounded to 1000000000).  Current allocation summary follows.
2020-01-02 17:35:26.401486: W tensorflow/core/common_runtime/bfc_allocator.cc:424] **************************************************************************************************xx
2020-01-02 17:35:26.401571: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at cwise_ops_common.cc:82 : Resource exhausted: OOM when allocating tensor with shape[1000,250000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File ""misc/maxmem.py"", line 11, in &lt;module&gt;
    dic[x]=tf.random.normal((nn,dd))
  File ""/home/fritzke/miniconda2/envs/tf20b/lib/python3.7/site-packages/tensorflow_core/python/ops/random_ops.py"", line 76, in random_normal
    value = math_ops.add(mul, mean_tensor, name=name)
  File ""/home/fritzke/miniconda2/envs/tf20b/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py"", line 391, in add
    _six.raise_from(_core._status_to_exception(e.code, message), None)
  File ""&lt;string&gt;"", line 3, in raise_from
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1000,250000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: random_normal/
</code></pre>

<p>How could I reliably get this information for whatever system the software is running on?</p>
",5052872.0,,,,,2023-03-15 15:19:31,how to programmatically determine available GPU memory with tensorflow?,<python><tensorflow><gpu>,5,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59567226
44664285,1,44664366,,2017-06-20 22:58:41,,26,18291,"<p>I'm running a tensorflow model and getting the following error:</p>
<pre class=""lang-none prettyprint-override""><code>ValueError: 'Cement (component 1)(kg in a m^3 mixture)' is not a valid scope name.
</code></pre>
<p>I get that tensorflow probably doesn't like special chars and spaces in its scope names, but I'm trying to find an actual doc on what chars are allowed. Does anyone know where I could find this?</p>
",5540936.0,,19123103.0,,2022-12-27 03:38:13,2022-12-27 03:38:13,What are the constraints for tensorflow scope names?,<python><tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44664285
34775522,1,34776814,,2016-01-13 19:36:19,,26,24851,"<p>I have a workstation with 2 GPUs and I am trying to run multiple tensorflow jobs at the same time, so I can train more than one model at once, etc.</p>

<p>For example, I've tried to separate the sessions into different resources via the python API using in script1.py:</p>

<pre><code>with tf.device(""/gpu:0""):
    # do stuff
</code></pre>

<p>in script2.py:</p>

<pre><code>with tf.device(""/gpu:1""):
    # do stuff
</code></pre>

<p>in script3.py</p>

<pre><code>with tf.device(""/cpu:0""):
    # do stuff
</code></pre>

<p>If I run each script by itself I can see that it is using the specified device. (Also the models fit very well into a single GPU and doesn't use another one even if both are available.)</p>

<p>However, if one script is running and I try to run another, I always get this error:</p>

<pre><code>I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 8
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: 
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.2155
pciBusID 0000:01:00.0
Total memory: 4.00GiB
Free memory: 187.65MiB
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 1 with properties: 
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.2155
pciBusID 0000:04:00.0
Total memory: 4.00GiB
Free memory: 221.64MiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 1:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating    TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 980, pci bus id: 0000:04:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 187.40MiB bytes.
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 187.40M (196505600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
F tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Check failed: gpu_mem != nullptr  Could not allocate GPU device memory for device 0. Tried to allocate 187.40MiB
Aborted (core dumped)
</code></pre>

<p>It seems each tensorflow process is trying to grab all of the GPUs on the machine when it loads even if not all devices are going to be used to run the model.</p>

<p>I see there is an option to limit the amount of GPU each process uses</p>

<pre><code>tf.GPUOptions(per_process_gpu_memory_fraction=0.5)
</code></pre>

<p>...I haven't tried it, but this seems like it would make two processes try to share 50% of each GPU instead of running each process on a separate GPU...</p>

<p>Does anyone know how to configure tensorflow to use only one GPU and leave the other available for another tensorflow process?</p>
",5765409.0,,1033581.0,,2017-07-12 15:43:44,2017-07-12 15:43:44,Tensorflow multiple sessions with multiple GPUs,<gpu><tensorflow>,1,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34775522
46256747,1,46256860,,2017-09-16 17:43:42,,26,18130,"<p>I use slim framework for tensorflow, because of its simplicity. 
But I want to have convolutional layer with both biases and batch normalization. 
In vanilla tensorflow, I have:</p>

<pre><code>def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, name=""conv2d""):
    with tf.variable_scope(name):
        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],

    initializer=tf.contrib.layers.xavier_initializer(uniform=False))
    conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')

    biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))
    conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())

    tf.summary.histogram(""weights"", w)
    tf.summary.histogram(""biases"", biases)

    return conv

d_bn1 = BatchNorm(name='d_bn1')
h1 = lrelu(d_bn1(conv2d(h0, df_dim + y_dim, name='d_h1_conv')))
</code></pre>

<p>and I rewrote it to slim by this:</p>

<pre><code>h1 = slim.conv2d(h0,
                 num_outputs=self.df_dim + self.y_dim,
                 scope='d_h1_conv',
                 kernel_size=[5, 5],
                 stride=[2, 2],
                 activation_fn=lrelu,
                 normalizer_fn=layers.batch_norm,
                 normalizer_params=batch_norm_params,                           
                 weights_initializer=layers.xavier_initializer(uniform=False),
                 biases_initializer=tf.constant_initializer(0.0)
                 )
</code></pre>

<p>But this code does not add bias to conv layer. 
That is because of <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L1025"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L1025</a> where is </p>

<pre><code>    layer = layer_class(filters=num_outputs,
                    kernel_size=kernel_size,
                    strides=stride,
                    padding=padding,
                    data_format=df,
                    dilation_rate=rate,
                    activation=None,
                    use_bias=not normalizer_fn and biases_initializer,
                    kernel_initializer=weights_initializer,
                    bias_initializer=biases_initializer,
                    kernel_regularizer=weights_regularizer,
                    bias_regularizer=biases_regularizer,
                    activity_regularizer=None,
                    trainable=trainable,
                    name=sc.name,
                    dtype=inputs.dtype.base_dtype,
                    _scope=sc,
                    _reuse=reuse)
    outputs = layer.apply(inputs)
</code></pre>

<p>in the construction of layer, which results in not having bias when using batch normalization.
Does that mean that I can not have both biases and batch normalization using slim and layers library? Or is there another way to achieve having both bias and batch normalization in layer when using slim?</p>
",5224881.0,,,,,2023-05-06 23:07:51,Can not use both bias and batch normalization in convolution layers,<python><tensorflow>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46256747
40925652,1,40936352,,2016-12-02 05:51:11,,26,7722,"<pre><code>import tensorflow as tf
with tf.device('/gpu:0'):
    foo = tf.Variable(1, name='foo')
    assert foo.name == ""foo:0""
with tf.device('/gpu:1'):
    bar = tf.Variable(1, name='bar')
    assert bar.name == ""bar:0""
</code></pre>

<p>The above code returns true.I use <code>with tf.device</code> here to illustrate that the "":0"" doesn't mean the variable lie on the specific device.So what's the meaning of the "":0"" in the variable's name(foo and bar in this example)?</p>
",7239654.0,,7239654.0,,2016-12-02 06:40:18,2016-12-02 19:51:59,"In TensorFlow,what's the meaning of "":0"" in a Variable's name?",<python><tensorflow>,1,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40925652
39379792,1,39379952,,2016-09-07 22:13:17,,26,36028,"<p>I know that I can install Cuda with the following:</p>

<pre>
wget http://developer.download.nvidia.com/compute/cuda/7_0/Prod/local_installers/cuda_7.0.28_linux.run
chmod +x cuda_7.0.28_linux.run
./cuda_7.0.28_linux.run -extract=`pwd`/nvidia_installers
cd nvidia_installers
sudo ./NVIDIA-Linux-x86_64-346.46.run 
sudo modprobe nvidia
sudo ./cuda-linux64-rel-7.0.28-19326674.run 
</pre>

<p>Just wondering if I can install Cuda without root?</p>

<p>Thanks,</p>
",200340.0,,,,,2019-10-22 12:56:10,Install Cuda without root,<cuda><tensorflow><gpu><theano>,3,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39379792
36548736,1,36557995,,2016-04-11 12:29:21,,26,15527,"<p>Is there TensorFlow native function that does unpooling for Deconvolutional Networks ? </p>

<p>I have written this in normal python, but it is getting complicated when want to translate it to TensorFlow as it's objects does not even support item assignment at the moment, and I think this is a great inconvenience with TF.</p>
",5724595.0,,,,,2022-02-17 19:31:46,TensorFlow: Unpooling,<tensorflow><conv-neural-network><deconvolution>,6,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36548736
58014123,1,59063925,,2019-09-19 15:11:58,,26,5284,"<p>I try to optimize my data input pipeline.
The dataset is a set of 450 TFRecord files of size ~70MB each, hosted on GCS.
The job is executed with GCP ML Engine. There is no GPU.</p>

<p>Here is the pipeline:</p>

<pre class=""lang-py prettyprint-override""><code>def build_dataset(file_pattern):
    return tf.data.Dataset.list_files(
        file_pattern
    ).interleave(
        tf.data.TFRecordDataset,
        num_parallel_calls=tf.data.experimental.AUTOTUNE
    ).shuffle(
        buffer_size=2048
    ).batch(
        batch_size=2048,
        drop_remainder=True,
    ).cache(
    ).repeat(
    ).map(
        map_func=_parse_example_batch,
        num_parallel_calls=tf.data.experimental.AUTOTUNE
    ).prefetch(
        buffer_size=1
    )
</code></pre>

<p>With the mapped function:</p>

<pre class=""lang-py prettyprint-override""><code>def _bit_to_float(string_batch: tf.Tensor):
    return tf.reshape(tf.math.floormod(tf.dtypes.cast(tf.bitwise.right_shift(
        tf.expand_dims(tf.io.decode_raw(string_batch, tf.uint8), 2),
        tf.reshape(tf.dtypes.cast(tf.range(7, -1, -1), tf.uint8), (1, 1, 8))
    ), tf.float32), 2), (tf.shape(string_batch)[0], -1))


def _parse_example_batch(example_batch):
    preprocessed_sample_columns = {
        ""features"": tf.io.VarLenFeature(tf.float32),
        ""booleanFeatures"": tf.io.FixedLenFeature((), tf.string, """"),
        ""label"": tf.io.FixedLenFeature((), tf.float32, -1)
    }
    samples = tf.io.parse_example(example_batch, preprocessed_sample_columns)
    dense_float = tf.sparse.to_dense(samples[""features""])
    bits_to_float = _bit_to_float(samples[""booleanFeatures""])
    return (
        tf.concat([dense_float, bits_to_float], 1),
        tf.reshape(samples[""label""], (-1, 1))
    )
</code></pre>

<p>I tried to follow the best practices of the <a href=""https://www.tensorflow.org/guide/performance/datasets"" rel=""noreferrer"">data pipeline tutorial</a>, and vectorize my mapped function (as advised by <a href=""https://stackoverflow.com/a/53585477/11543584"">mrry</a>).</p>

<p>With this settings, while data are downloaded at high-speed (bandwidth is around 200MB/s) the CPU is under-used (14%) and the training is very slow (more than 1hour for a epoch).</p>

<p>I tried some parameters configuration, changing the <code>interleave()</code> arguments like <code>num_parallel_calls</code> or <code>cycle_length</code> or the <code>TFRecordDataset</code> arguments like <code>num_parallel_calls</code>.</p>

<p>The fastest configuration uses this set of parameters:</p>

<ul>
<li><code>interleave.num_parallel_calls</code>: 1</li>
<li><code>interleave.cycle_length</code>: 8</li>
<li><code>TFRecordDataset.num_parallel_calls</code>: 8</li>
</ul>

<p>With this one, one epoch only take ~20 minutes to run. <strong>However, CPU usage is only at 50% while bandwidth consumption is around 55MB/s</strong></p>

<h2>Questions:</h2>

<ol>
<li>How to optimize the pipeline to reach 100% CPU usage (and something like 100MB/s of bandwidth consumption)?</li>
<li>Why does <code>tf.data.experimental.AUTOTUNE</code> not find best value to speed up the training?</li>
</ol>

<p>Kind,
Alexis.</p>

<hr>

<h2>Edit</h2>

<p>After some more experimentations, I came to the following solution.</p>

<ol>
<li>Remove the <code>interleave</code> step which is already handled by <code>TFRecordDataset</code> if <code>num_parallel_calls</code> is greater than 0.</li>
<li>Update the mapped function to only do <code>parse_example</code> and <code>decode_raw</code>, returning a tuple `((, ), ())</li>
<li><code>cache</code> after the <code>map</code></li>
<li>Move the <code>_bit_to_float</code> function as a component of the model</li>
</ol>

<p>Finally, here is the data pipeline code:</p>

<pre class=""lang-py prettyprint-override""><code>def build_dataset(file_pattern):
    return tf.data.TFRecordDataset(
        tf.data.Dataset.list_files(file_pattern),
        num_parallel_reads=multiprocessing.cpu_count(),
        buffer_size=70*1000*1000
    ).shuffle(
        buffer_size=2048
    ).map(
        map_func=split,
        num_parallel_calls=tf.data.experimental.AUTOTUNE
    ).batch(
        batch_size=2048,
        drop_remainder=True,
    ).cache(
    ).repeat(
    ).prefetch(
        buffer_size=32
    )


def split(example):
    preprocessed_sample_columns = {
        ""features"": tf.io.VarLenFeature(tf.float32),
        ""booleanFeatures"": tf.io.FixedLenFeature((), tf.string, """"),
        ""label"": tf.io.FixedLenFeature((), tf.float32, -1)
    }
    samples = tf.io.parse_single_example(example, preprocessed_sample_columns)
    dense_float = tf.sparse.to_dense(samples[""features""])
    bits_to_float = tf.io.decode_raw(samples[""booleanFeatures""], tf.uint8)
    return (
        (dense_float, bits_to_float),
        tf.reshape(samples[""label""], (1,))
    )


def build_model(input_shape):
    feature = keras.Input(shape=(N,))
    bool_feature = keras.Input(shape=(M,), dtype=""uint8"")
    one_hot = dataset._bit_to_float(bool_feature)
    dense_input = tf.reshape(
        keras.backend.concatenate([feature, one_hot], 1),
        input_shape)
    output = actual_model(dense_input)

    model = keras.Model([feature, bool_feature], output)
    return model

def _bit_to_float(string_batch: tf.Tensor):
    return tf.dtypes.cast(tf.reshape(
        tf.bitwise.bitwise_and(
            tf.bitwise.right_shift(
                tf.expand_dims(string_batch, 2),
                tf.reshape(
                    tf.dtypes.cast(tf.range(7, -1, -1), tf.uint8),
                    (1, 1, 8)
                ),
            ),
            tf.constant(0x01, dtype=tf.uint8)
        ),
        (tf.shape(string_batch)[0], -1)
    ), tf.float32)
</code></pre>

<p>Thanks to all these optimizations:</p>

<ul>
<li>Bandwidth consumption is around 90MB/s</li>
<li>CPU usage is around 20%</li>
<li>First epoch spends 20 minutes</li>
<li>Successives epochs spend 5 minutes each</li>
</ul>

<p>So this seems to be a good first setup. But CPU and BW are still not overused, so any advice is still welcomed!</p>

<hr>

<h2>Edit Bis</h2>

<p>So, after some benchmarking I came accross what I think is our best input pipeline:</p>

<pre><code>def build_dataset(file_pattern):
    tf.data.Dataset.list_files(
        file_pattern
    ).interleave(
        TFRecordDataset,
        cycle_length=tf.data.experimental.AUTOTUNE,
        num_parallel_calls=tf.data.experimental.AUTOTUNE
    ).shuffle(
        2048
    ).batch(
        batch_size=64,
        drop_remainder=True,
    ).map(
        map_func=parse_examples_batch,
        num_parallel_calls=tf.data.experimental.AUTOTUNE
    ).cache(
    ).prefetch(
        tf.data.experimental.AUTOTUNE
    )

def parse_examples_batch(examples):
    preprocessed_sample_columns = {
        ""features"": tf.io.FixedLenSequenceFeature((), tf.float32, allow_missing=True),
        ""booleanFeatures"": tf.io.FixedLenFeature((), tf.string, """"),
        ""label"": tf.io.FixedLenFeature((), tf.float32, -1)
    }
    samples = tf.io.parse_example(examples, preprocessed_sample_columns)
    bits_to_float = tf.io.decode_raw(samples[""booleanFeatures""], tf.uint8)
    return (
        (samples['features'], bits_to_float),
        tf.expand_dims(samples[""label""], 1)
    )
</code></pre>

<p>So, what's new:</p>

<ul>
<li>According to this <a href=""https://github.com/tensorflow/tensorflow/issues/31019#issuecomment-517044334"" rel=""noreferrer"">GitHub issue</a>, the <code>TFRecordDataset</code> interleaving is a legacy one, so <code>interleave</code> function is better.</li>
<li><code>batch</code> before <code>map</code> is a good habit (<a href=""https://www.tensorflow.org/guide/function#batching"" rel=""noreferrer"">vectorizing your function</a>) and reduce the number of times the mapped function is called.</li>
<li>No need of <code>repeat</code> anymore. Since TF2.0, the Keras model API supports the dataset API and can use cache (see the <a href=""https://stackoverflow.com/a/58220646/11543584"">SO post</a>)</li>
<li>Switch from a <code>VarLenFeature</code> to a <code>FixedLenSequenceFeature</code>, removing a useless call to <code>tf.sparse.to_dense</code>.</li>
</ul>

<p>Hope this can help. Advices are still welcomed.</p>
",4373898.0,,4373898.0,,2019-10-07 13:54:38,2020-11-03 07:23:27,How to improve data input pipeline performance?,<python><python-3.x><tensorflow><tensorflow-datasets><tensorflow2.0>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58014123
48443886,1,48444172,,2018-01-25 13:22:22,,25,17094,"<p>When training an Object Detection DNN with Tensorflows Object Detection API it's Visualization Plattform Tensorboard plots a scalar named <code>regularization_loss_1</code></p>

<p>What is this? I know what regularization is (to make the Network good at generalizing through various methods like dropout) But it is not clear to me what this displayed loss could be.</p>

<p>Thanks!</p>
",9167762.0,,,,,2018-01-25 13:35:50,What is regularization loss in tensorflow?,<tensorflow><tensorboard><regularized>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48443886
47662143,1,47662958,,2017-12-05 20:29:47,,25,15514,"<p>I am having troubles understanding the meaning and usages for Tensorflow <em>Tensors</em> and <em>Sparse Tensors</em>. </p>

<p>According to the documentation</p>

<p>Tensor</p>

<blockquote>
  <p>Tensor is a typed multi-dimensional array. For example, you can represent a mini-batch of images as a 4-D array of floating point numbers with dimensions [batch, height, width, channels].</p>
</blockquote>

<p>Sparse Tensor</p>

<blockquote>
  <p>TensorFlow represents a sparse tensor as three separate dense tensors: indices, values, and shape. In Python, the three tensors are collected into a SparseTensor class for ease of use. If you have separate indices, values, and shape tensors, wrap them in a SparseTensor object before passing to the ops below.</p>
</blockquote>

<p>My understandings are Tensors are used for operations, input and output. And Sparse Tensor is just another representation of a Tensor(dense?). Hope someone can further explain the differences, and the use cases for them.</p>
",4876765.0,,3924118.0,,2019-04-26 22:28:01,2020-07-17 21:50:11,What is the difference between tensors and sparse tensors?,<python><tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47662143
44452571,1,50780854,,2017-06-09 08:08:41,,25,56290,"<p>Since Adam Optimizer keeps an pair of running averages like mean/variance for the gradients, I wonder how it should properly handle weight decay. I have seen two ways of implementing it.</p>

<ol>
<li><p>Only update mean/variance from the gradients based on the objective loss, decay weight explicitly at each mini-batch.  (the following code is taken from <a href=""https://github.com/dmlc/mxnet/blob/v0.7.0/python/mxnet/optimizer.py"" rel=""noreferrer"">https://github.com/dmlc/mxnet/blob/v0.7.0/python/mxnet/optimizer.py</a>)</p>

<pre><code>weight[:] -= lr*mean/(sqrt(variance) + self.epsilon)

wd = self._get_wd(index)
if wd &gt; 0.:
    weight[:] -= (lr * wd) * weight
</code></pre></li>
<li><p>Update mean/variance from the gradients based on the objective loss + regularization loss, and update weights like usual. (the following code is taken from <a href=""https://github.com/dmlc/mxnet/blob/master/src/operator/optimizer_op-inl.h#L210"" rel=""noreferrer"">https://github.com/dmlc/mxnet/blob/master/src/operator/optimizer_op-inl.h#L210</a>)</p>

<pre><code>grad = scalar&lt;DType&gt;(param.rescale_grad) * grad +
scalar&lt;DType&gt;(param.wd) * weight;
// stuff
Assign(out, req[0],
   weight -
   scalar&lt;DType&gt;(param.lr) * mean /
   (F&lt;square_root&gt;(var) + scalar&lt;DType&gt;(param.epsilon)));
</code></pre></li>
</ol>

<p>These two approaches sometimes show significant difference in training results. And I actually think the first one makes more sense (and find it gives better results time to time).  Caffe and old version of mxnet follow the first approach, while torch, tensorflow and new version of mxnet follow the second one. </p>

<p>Really appreciate your help！</p>
",6238109.0,,,,,2019-11-20 10:24:13,What is the proper way to weight decay for Adam Optimizer,<tensorflow><deep-learning><caffe><torch><mxnet>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44452571
38292760,1,38297231,,2016-07-10 14:06:56,,25,23354,"<p>I am currently playing with ANN which is part of Udactity DeepLearning course.</p>

<p>I successful built and train network and introduced the L2 regularization on all weights and biases. Right now I am trying out the dropout for hidden layer in order to improve generalization. I wonder, does it makes sense to both introduce the L2 regularization into the hidden layer and dropout on that same layer? If so, how to do this properly?</p>

<p>During dropout we literally switch off half of the activations of hidden layer and double the amount outputted by rest of the neurons. While using the L2 we compute the L2 norm on all hidden weights. But I am not sure how  to compute L2 in case we use dropout. We switch off some activations, shouldn't we remove the weights which are 'not used' now from the L2 calculation? Any references on that matter will be useful, I haven't found any info.</p>

<p>Just in case you are interested, my code for ANN with L2 regularization is below:</p>

<pre class=""lang-py prettyprint-override""><code>#for NeuralNetwork model code is below
#We will use SGD for training to save our time. Code is from Assignment 2
#beta is the new parameter - controls level of regularization. Default is 0.01
#but feel free to play with it
#notice, we introduce L2 for both biases and weights of all layers

beta = 0.01

#building tensorflow graph
graph = tf.Graph()
with graph.as_default():
      # Input data. For the training data, we use a placeholder that will be fed
  # at run time with a training minibatch.
  tf_train_dataset = tf.placeholder(tf.float32,
                                    shape=(batch_size, image_size * image_size))
  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))
  tf_valid_dataset = tf.constant(valid_dataset)
  tf_test_dataset = tf.constant(test_dataset)

  #now let's build our new hidden layer
  #that's how many hidden neurons we want
  num_hidden_neurons = 1024
  #its weights
  hidden_weights = tf.Variable(
    tf.truncated_normal([image_size * image_size, num_hidden_neurons]))
  hidden_biases = tf.Variable(tf.zeros([num_hidden_neurons]))

  #now the layer itself. It multiplies data by weights, adds biases
  #and takes ReLU over result
  hidden_layer = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)

  #time to go for output linear layer
  #out weights connect hidden neurons to output labels
  #biases are added to output labels  
  out_weights = tf.Variable(
    tf.truncated_normal([num_hidden_neurons, num_labels]))  

  out_biases = tf.Variable(tf.zeros([num_labels]))  

  #compute output  
  out_layer = tf.matmul(hidden_layer,out_weights) + out_biases
  #our real output is a softmax of prior result
  #and we also compute its cross-entropy to get our loss
  #Notice - we introduce our L2 here
  loss = (tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
    out_layer, tf_train_labels) +
    beta*tf.nn.l2_loss(hidden_weights) +
    beta*tf.nn.l2_loss(hidden_biases) +
    beta*tf.nn.l2_loss(out_weights) +
    beta*tf.nn.l2_loss(out_biases)))

  #now we just minimize this loss to actually train the network
  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

  #nice, now let's calculate the predictions on each dataset for evaluating the
  #performance so far
  # Predictions for the training, validation, and test data.
  train_prediction = tf.nn.softmax(out_layer)
  valid_relu = tf.nn.relu(  tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)
  valid_prediction = tf.nn.softmax( tf.matmul(valid_relu, out_weights) + out_biases) 

  test_relu = tf.nn.relu( tf.matmul( tf_test_dataset, hidden_weights) + hidden_biases)
  test_prediction = tf.nn.softmax(tf.matmul(test_relu, out_weights) + out_biases)



#now is the actual training on the ANN we built
#we will run it for some number of steps and evaluate the progress after 
#every 500 steps

#number of steps we will train our ANN
num_steps = 3001

#actual training
with tf.Session(graph=graph) as session:
  tf.initialize_all_variables().run()
  print(""Initialized"")
  for step in range(num_steps):
    # Pick an offset within the training data, which has been randomized.
    # Note: we could use better randomization across epochs.
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    # Generate a minibatch.
    batch_data = train_dataset[offset:(offset + batch_size), :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    # Prepare a dictionary telling the session where to feed the minibatch.
    # The key of the dictionary is the placeholder node of the graph to be fed,
    # and the value is the numpy array to feed to it.
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 500 == 0):
      print(""Minibatch loss at step %d: %f"" % (step, l))
      print(""Minibatch accuracy: %.1f%%"" % accuracy(predictions, batch_labels))
      print(""Validation accuracy: %.1f%%"" % accuracy(
        valid_prediction.eval(), valid_labels))
      print(""Test accuracy: %.1f%%"" % accuracy(test_prediction.eval(), test_labels))
</code></pre>
",3633250.0,,429322.0,,2016-08-08 10:00:22,2017-05-28 05:09:38,TensorFlow - introducing both L2 regularization and dropout into the network. Does it makes any sense?,<machine-learning><neural-network><tensorflow><deep-learning><regularized>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38292760
40416056,1,40418913,,2016-11-04 05:46:26,,25,89611,"<p>For some reason, I want to use some previous version of tensorflow('tensorflow-**-.whl', not source code on github) and where can I download the previous version and how can I know the corresponding <code>cuda version</code> that is compatible.</p>
",4696856.0,,,,,2020-10-21 12:47:49,How to download previous version of tensorflow?,<tensorflow>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40416056
34235557,1,34243895,,2015-12-12 02:26:40,,25,12479,"<p>The API discusses <a href=""https://www.tensorflow.org/versions/master/api_docs/python/framework.html#graph-collections"">Graph Collections</a> which judging from the <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L2071"">code</a> are a general purpose key/data storage. What is the purpose of those collections?</p>
",1576602.0,,,,,2018-12-05 12:11:41,What is the purpose of graph collections in TensorFlow?,<python><tensorflow>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34235557
36844909,1,36847703,,2016-04-25 15:28:46,,25,9575,"<p>I'm trying to implement a Siamese Neural Network in TensorFlow but I cannot really find any working example on the Internet (see <a href=""https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf"" rel=""noreferrer"">Yann LeCun paper</a>).</p>

<p><a href=""https://i.stack.imgur.com/qfxH8.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qfxH8.png"" alt=""enter image description here""></a></p>

<p>The architecture I'm trying to build would consist of two LSTMs sharing weights and only connected at the end of the network.</p>

<p>My question is: how to build two different neural networks sharing their weights (tied weights) in TensorFlow and how to connect them at the end?</p>

<p>Thanks :)</p>

<p><strong>Edit</strong>: I implemented a simple and working example of a siamese network <a href=""https://github.com/benmyara/deeplearning-tensorflow/blob/master/notebooks/1_siamese.ipynb"" rel=""noreferrer"">here</a> on MNIST.</p>
",6246880.0,,6246880.0,,2018-12-16 15:50:06,2019-10-09 21:01:12,Siamese Neural Network in TensorFlow,<neural-network><tensorflow><deep-learning><lstm>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/36844909
38836269,1,38836390,,2016-08-08 18:38:25,,25,22413,"<p>From the experiments I run, it seems like TensorFlow uses automatically all CPUs on one machine. Furthermore, it seems like TensorFlow refers to all CPUs as /cpu:0. </p>

<p>Am I right, that only the different GPUs of one machine get indexed and viewed as separate devices, but all the CPUs on one machine get viewed as a single device? </p>

<p>Is there any way that a machine can have multiple CPUs viewing it from TensorFlows perspective? </p>
",5737561.0,,,,,2016-08-08 18:45:55,Does TensorFlow view all CPUs of one machine as ONE device?,<python><tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38836269
50744565,1,72377349,,2018-06-07 15:05:32,,25,9816,"<p>While tuning the hyperparameters to get my model to perform better, I noticed that the score I get (and hence the model that is created) is different every time I run the code despite fixing all the seeds for random operations. This problem does not happen if I run on CPU.</p>

<p>I googled and found out that this is a common issue when using a GPU to train. <a href=""https://www.twosigma.com/insights/article/a-workaround-for-non-determinism-in-tensorflow/"" rel=""noreferrer"">Here is a very good/detailed example with short code snippets to verify the existence of that problem.</a></p>

<p>They pinpointed the non-determinism to ""tf.reduce_sum"" function. However, that is not the case for me. it could be because I'm using different hardware (1080 TI) or a different version of CUDA libraries or Tensorflow. It seems like there are many different parts of the CUDA libraries that are non-deterministic and it doesn't seem easy to figure out exactly which part and how to get rid of it. Also, this must have been by design, so it's likely that there is a sufficient efficiency increase in exchange for non-determinism.</p>

<p>So, my question is:</p>

<p>Since GPUs are popular for training NNs, people in this field must have a way to deal with non-determinism, because I can't see how else you'd be able to reliably tune the hyperparameters. What is the standard way to handle non-determinism when using a GPU?</p>
",331021.0,,6117017.0,,2022-05-27 07:25:45,2022-05-27 07:25:45,How to handle non-determinism when training on a GPU?,<python><tensorflow><machine-learning><deep-learning>,3,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50744565
38114534,1,38117279,,2016-06-30 05:20:57,,25,37843,"<p>OK, I'd like to do a 1-dimensional convolution of time series data in Tensorflow. This is apparently supported using <code>tf.nn.conv2d</code>, according to <a href=""https://github.com/tensorflow/tensorflow/issues/2165"" rel=""noreferrer"">these</a> <a href=""https://github.com/tensorflow/tensorflow/issues/1136"" rel=""noreferrer"">tickets</a>, and <a href=""https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#convolution"" rel=""noreferrer"">the manual</a>. the only requirement is to set <code>strides=[1,1,1,1]</code>. Sounds simple!</p>

<p>However, I cannot work out how to do this in even a very minimal test case. What am I doing wrong?</p>

<p>Let's set this up.</p>

<pre><code>import tensorflow as tf
import numpy as np
print(tf.__version__)
&gt;&gt;&gt; 0.9.0
</code></pre>

<p>OK, now generate a basic convolution test on two small arrays. I will make it easy by using a batch size of 1, and since time series are 1-dimensional, I will have an ""image height"" of 1. And since it's a univariate time series, clearly the number of ""channels"" is also 1, so this will be simple, right?</p>

<pre><code>g = tf.Graph()
with g.as_default():
    # data shape is ""[batch, in_height, in_width, in_channels]"",
    x = tf.Variable(np.array([0.0, 0.0, 0.0, 0.0, 1.0]).reshape(1,1,-1,1), name=""x"")
    # filter shape is ""[filter_height, filter_width, in_channels, out_channels]""
    phi = tf.Variable(np.array([0.0, 0.5, 1.0]).reshape(1,-1,1,1), name=""phi"")
    conv = tf.nn.conv2d(
        phi,
        x,
        strides=[1, 1, 1, 1],
        padding=""SAME"",
        name=""conv"")
</code></pre>

<p>BOOM. Error.</p>

<pre><code>ValueError: Dimensions 1 and 5 are not compatible
</code></pre>

<p>OK, For a start, I don't understand how this should happen with <em>any</em> dimension, since I've specified that I'm padding the arguments in the convolution OP. </p>

<p>but fine, maybe there are limits to that. I must have got the documentation confused and set up this convolution on the wrong axes of the tensor. I'll try all possible permutations:</p>

<pre><code>for i in range(4):
    for j in range(4):
        shape1 = [1,1,1,1]
        shape1[i] = -1
        shape2 = [1,1,1,1]
        shape2[j] = -1
        x_array = np.array([0.0, 0.0, 0.0, 0.0, 1.0]).reshape(*shape1)
        phi_array = np.array([0.0, 0.5, 1.0]).reshape(*shape2)
        try:
            g = tf.Graph()
            with g.as_default():
                x = tf.Variable(x_array, name=""x"")
                phi = tf.Variable(phi_array, name=""phi"")
                conv = tf.nn.conv2d(
                    x,
                    phi,
                    strides=[1, 1, 1, 1],
                    padding=""SAME"",
                    name=""conv"")
                init_op = tf.initialize_all_variables()
            sess = tf.Session(graph=g)
            sess.run(init_op)
            print(""SUCCEEDED!"", x_array.shape, phi_array.shape, conv.eval(session=sess))
            sess.close()
        except Exception as e:
            print(""FAILED!"", x_array.shape, phi_array.shape, type(e), e.args or e._message)
</code></pre>

<p>Result:</p>

<pre><code>FAILED! (5, 1, 1, 1) (3, 1, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (3, 1) Input: (1, 1)',)
FAILED! (5, 1, 1, 1) (1, 3, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (1, 3) Input: (1, 1)',)
FAILED! (5, 1, 1, 1) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 1 and 3 are not compatible',)
FAILED! (5, 1, 1, 1) (1, 1, 1, 3) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 5, 1, 1) (3, 1, 1, 1) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 5, 1, 1) (1, 3, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (1, 3) Input: (5, 1)',)
FAILED! (1, 5, 1, 1) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 1 and 3 are not compatible',)
FAILED! (1, 5, 1, 1) (1, 1, 1, 3) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 1, 5, 1) (3, 1, 1, 1) &lt;class 'ValueError'&gt; ('Filter must not be larger than the input: Filter: (3, 1) Input: (1, 5)',)
FAILED! (1, 1, 5, 1) (1, 3, 1, 1) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 1, 5, 1) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 1 and 3 are not compatible',)
FAILED! (1, 1, 5, 1) (1, 1, 1, 3) &lt;class 'tensorflow.python.framework.errors.InvalidArgumentError'&gt; No OpKernel was registered to support Op 'Conv2D' with these attrs
     [[Node: conv = Conv2D[T=DT_DOUBLE, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](x/read, phi/read)]]
FAILED! (1, 1, 1, 5) (3, 1, 1, 1) &lt;class 'ValueError'&gt; ('Dimensions 5 and 1 are not compatible',)
FAILED! (1, 1, 1, 5) (1, 3, 1, 1) &lt;class 'ValueError'&gt; ('Dimensions 5 and 1 are not compatible',)
FAILED! (1, 1, 1, 5) (1, 1, 3, 1) &lt;class 'ValueError'&gt; ('Dimensions 5 and 3 are not compatible',)
FAILED! (1, 1, 1, 5) (1, 1, 1, 3) &lt;class 'ValueError'&gt; ('Dimensions 5 and 1 are not compatible',)
</code></pre>

<p>Hmm. OK, it looks like there are two problems now. Firstly, the <code>ValueError</code> is about applying the filter along the wrong axis, I guess, although there are two forms.</p>

<p>But then the axes along which I can apply the filter are confusing too - notice that it actually constructs the graph with input shape (5, 1, 1, 1)  and filter shape (1, 1, 1, 3). AFAICT from the documentation, this should be a filter that looks at on example from the batch, one ""pixel"" and one ""channel"" and outputs 3 ""channels"". Why does that one work, then, when others do not?</p>

<p>Anyway, sometimes it does not fail while constructing the graph.
Sometime it constructs the graph; then we get the <code>tensorflow.python.framework.errors.InvalidArgumentError</code>. From some <a href=""https://github.com/tensorflow/tensorflow/issues/524"" rel=""noreferrer"">confusing github tickets</a> I gather this is probably due to <del>the fact that I'm running on CPU instead of GPU, or vice versa</del> the fact that the convolution Op is only defined for 32 bit floats, not 64 bit floats. If anyone could throw some light on <em>which</em> axes I should be aligning <em>what</em> on, in order to convolve a time series with a kernel, I'd be very grateful.</p>
",11730.0,,11730.0,,2016-07-12 09:07:53,2019-10-24 01:17:53,Basic 1d convolution in tensorflow,<python><tensorflow>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38114534
50702395,1,50717696,,2018-06-05 14:17:05,,25,15566,"<p>I am working with two docker images of tensorflow (latest and latest-gpu tags):</p>

<p><code>FROM tensorflow/tensorflow:latest-gpu
</code></p>

<p>and:</p>

<p><code>FROM tensorflow/tensorflow:latest
</code></p>

<p>In order to not have surprises in the future, I would like to set the version of these two images.</p>

<p>On docker hub, I can't find this information in <a href=""https://hub.docker.com/r/tensorflow/tensorflow/tags/"" rel=""noreferrer"">the tags pages</a>: for example, <code>latest</code> would correspond to the <code>1.8.0-gpu</code> tag.</p>

<p>Do you know if and where I can find this information?</p>

<p>Thank you,</p>

<p>Alexandre</p>
",9517183.0,,,,,2023-02-09 11:33:59,How to know which version of docker image is behind latest tag?,<docker><tensorflow><version>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50702395
33785936,1,33786141,,2015-11-18 16:57:38,,25,20277,"<p>Dare I even ask? This is such a new technology at this point that I can't find a way to solve this seemingly simple error. The tutorial I'm going over can be found here- <a href=""http://www.tensorflow.org/tutorials/mnist/pros/index.html#deep-mnist-for-experts"">http://www.tensorflow.org/tutorials/mnist/pros/index.html#deep-mnist-for-experts</a></p>

<p>I literally copied and pasted all of the code into IPython Notebook and at the very last chunk of code I get an error.</p>

<pre><code># To train and evaluate it we will use code that is nearly identical to that for the simple one layer SoftMax network above.
# The differences are that: we will replace the steepest gradient descent optimizer with the more sophisticated ADAM optimizer.

cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
sess.run(tf.initialize_all_variables())
for i in range(20000):
    batch = mnist.train.next_batch(50)
    if i%100 == 0:
        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})
    print ""step %d, training accuracy %g""%(i, train_accuracy)
    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

print ""test accuracy %g""%accuracy.eval(feed_dict={
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})
</code></pre>

<p>After running this code, I receive this error.</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-46-a5d1ab5c0ca8&gt; in &lt;module&gt;()
     15 
     16 print ""test accuracy %g""%accuracy.eval(feed_dict={
---&gt; 17     x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})

/root/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in eval(self, feed_dict, session)
    403 
    404     """"""
--&gt; 405     return _eval_using_default_session(self, feed_dict, self.graph, session)
    406 
    407 

/root/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in _eval_using_default_session(tensors, feed_dict, graph, session)
   2712     session = get_default_session()
   2713     if session is None:
-&gt; 2714       raise ValueError(""Cannot evaluate tensor using eval(): No default ""
   2715                        ""session is registered. Use 'with ""
   2716                        ""DefaultSession(sess)' or pass an explicit session to ""

ValueError: Cannot evaluate tensor using eval(): No default session is registered. Use 'with DefaultSession(sess)' or pass an explicit session to eval(session=sess)
</code></pre>

<p>I thought that I may need to install or reinstall TensorFlow via conda install <a href=""https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl"">https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl</a> but conda doesn't even know how to install it.</p>

<p>Does anyone have any idea of how to work around this error?</p>
",3849791.0,,,,,2017-12-30 06:44:58,TensorFlow Error found in Tutorial,<python><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33785936
36916690,1,36927672,,2016-04-28 13:49:12,,25,6845,"<p>While working on Udacity Deep Learning assignments, I encountered memory problem. I need to switch to a cloud platform. I worked with AWS EC2 before but now I would like to try Google Cloud Platform (GCP). I will need at least 8GB memory. I know how to use docker locally but never tried it on the cloud.</p>

<ol>
<li>Is there any ready-made solution for running Tensorflow on GCP?</li>
<li>If not, which service (Compute Engine or Container Engine) would make it easier to get started?</li>
<li>Any other tip is also appreciated!</li>
</ol>
",3274693.0,,21539.0,,2019-08-02 23:05:57,2019-08-02 23:05:57,Which Google Cloud Platform service is the easiest for running Tensorflow?,<tensorflow><google-cloud-platform><google-compute-engine><google-cloud-ml><gcp-ai-platform-notebook>,6,8,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36916690
45749024,1,46069075,,2017-08-18 05:20:45,,25,10542,"<p>How can I use multiple <code>tensorflow</code> models? 
I use docker container.</p>

<pre><code>model_config_list: {

  config: {
    name: ""model1"",
    base_path: ""/tmp/model"",
    model_platform: ""tensorflow""
  },
  config: {
     name: ""model2"",
     base_path: ""/tmp/model2"",
     model_platform: ""tensorflow""
  }
}
</code></pre>
",8392832.0,,2370483.0,,2020-10-25 20:13:57,2020-10-25 20:13:57,How can I use tensorflow serving for multiple models,<docker><tensorflow><tensorflow-serving>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45749024
59787897,1,59788222,,2020-01-17 13:00:55,,25,25609,"<p>I'm trying to understand this loss function in TensorFlow but I don't get it. It's <strong>SparseCategoricalCrossentropy</strong>. All other loss functions need outputs and labels of the same shape, this specific loss function doesn't.</p>

<p>Source code:</p>

<pre><code>import tensorflow as tf;

scce = tf.keras.losses.SparseCategoricalCrossentropy();
Loss = scce(
  tf.constant([ 1,    1,    1,    2   ], tf.float32),
  tf.constant([[1,2],[3,4],[5,6],[7,8]], tf.float32)
);
print(""Loss:"", Loss.numpy());
</code></pre>

<p>The error is:</p>

<pre><code>InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  
Label values: 1 1 1 2 [Op:SparseSoftmaxCrossEntropyWithLogits]
</code></pre>

<p>How to provide proper params to the loss function SparseCategoricalCrossentropy?</p>
",5581893.0,,,,,2020-01-23 06:12:30,How does TensorFlow SparseCategoricalCrossentropy work?,<tensorflow><machine-learning><deep-learning><loss-function><cross-entropy>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59787897
41475180,1,44099690,,2017-01-04 23:54:19,,25,15899,"<p>I am trying to understand the NCE loss function in Tensorflow. NCE loss is employed for a word2vec task, for instance:</p>

<pre><code># Look up embeddings for inputs.
embeddings = tf.Variable(
    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
embed = tf.nn.embedding_lookup(embeddings, train_inputs)

# Construct the variables for the NCE loss
nce_weights = tf.Variable(
    tf.truncated_normal([vocabulary_size, embedding_size],
                        stddev=1.0 / math.sqrt(embedding_size)))
nce_biases = tf.Variable(tf.zeros([vocabulary_size]))

# Compute the average NCE loss for the batch.
# tf.nce_loss automatically draws a new sample of the negative labels each
# time we evaluate the loss.
loss = tf.reduce_mean(
    tf.nn.nce_loss(weights=nce_weights,
                   biases=nce_biases,
                   labels=train_labels,
                   inputs=embed,
                   num_sampled=num_sampled,
                   num_classes=vocabulary_size))
</code></pre>

<p>more details, please reference Tensorflow <a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py"" rel=""noreferrer"">word2vec_basic.py</a></p>

<ol>
<li>What are the input and output matrices in the NCE function? </li>
</ol>

<p>In a word2vec model, we are interested in building representations for words. In the training process, given a slid window, every word will have two embeddings: 1) when the word is a centre word; 2) when the word is a context word. These two embeddings are called input and output vectors, respectively. (<a href=""http://www-personal.umich.edu/~ronxin/pdf/w2vexp.pdf"" rel=""noreferrer"">more explanations of input and output matrices</a>)</p>

<p>In my opinion, the input matrix is <code>embeddings</code> and the output matrix is <code>nce_weights</code>. Is it right?</p>

<ol start=""2"">
<li>What is the final embedding?</li>
</ol>

<p>According to a <a href=""https://stackoverflow.com/questions/37982478/what-is-the-purpose-of-weights-and-biases-in-tensorflow-word2vec-example"">post</a> by s0urcer also relating to <code>nce</code>, it says the final embedding matrix is just the input matrix. While, <a href=""https://stats.stackexchange.com/questions/177667/input-vector-representation-vs-output-vector-representation-in-word2vec"">some others saying</a>, the <code>final_embedding=input_matrix+output_matrix</code>. Which is right/more common?</p>
",6733064.0,,1150961.0,,2018-04-06 16:58:27,2020-11-05 08:01:32,Understanding `tf.nn.nce_loss()` in tensorflow,<python><tensorflow>,5,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41475180
39324520,1,39325925,,2016-09-05 05:43:29,,25,24377,"<p>I have a dataset X which consists <strong>N = 4000 samples</strong>, each sample consists of <strong>d = 2 features</strong> (continuous values) spanning back <strong>t = 10 time steps</strong>. I also have the  corresponding 'labels' of each sample which are also continuous values, at time step 11. </p>

<p>At the moment my dataset is in the shape X: [4000,20], Y: [4000].</p>

<p>I want to train an LSTM using TensorFlow to predict the value of Y (regression), given the 10 previous inputs of d features, but I am having a tough time implementing this in TensorFlow.</p>

<p>The main problem I have at the moment is understanding how TensorFlow is expecting the input to be formatted. I have seen various examples such as <a href=""http://mourafiq.com/2016/05/15/predicting-sequences-using-rnn-in-tensorflow.html"" rel=""noreferrer"">this</a>, but these examples deal with one big string of continuous time series data. My data is different samples, each an independent time series.</p>
",3801648.0,,3924118.0,,2018-01-03 22:33:57,2020-01-14 13:17:06,Understanding Tensorflow LSTM Input shape,<python><tensorflow><regression><lstm>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39324520
34670112,1,34675264,,2016-01-08 05:29:21,,25,47990,"<p>I was trying to use an RNN (specifically, LSTM) for sequence prediction. However, I ran into an issue with variable sequence lengths. For example,</p>

<pre><code>sent_1 = ""I am flying to Dubain""
sent_2 = ""I was traveling from US to Dubai""
</code></pre>

<p>I am trying to predicting the next word after the current one with a simple RNN based on this <a href=""https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py"" rel=""noreferrer"">Benchmark for building a PTB LSTM model</a>.</p>

<p>However, the <code>num_steps</code> parameter (used for unrolling to the previous hidden states), should remain the same in each Tensorflow's epoch. Basically, batching sentences is not possible as the sentences vary in length. </p>

<pre><code> # inputs = [tf.squeeze(input_, [1])
 #           for input_ in tf.split(1, num_steps, inputs)]
 # outputs, states = rnn.rnn(cell, inputs, initial_state=self._initial_state)
</code></pre>

<p>Here, <code>num_steps</code> need to be changed in my case for every sentence. I have tried several hacks, but nothing seems working.</p>
",4763311.0,,1419865.0,,2019-02-07 02:57:54,2019-02-07 02:57:54,How to deal with batches with variable-length sequences in TensorFlow?,<python><tensorflow><lstm><recurrent-neural-network>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/34670112
50632258,1,50652415,,2018-05-31 20:24:29,,25,61117,"<p>I have an tensorflow .pb file which I would like to load into python DNN, restore the graph and get the predictions. I am doing this to test out whether the .pb file created can make the predictions similar to the normal Saver.save() model. </p>

<p>My basic problem is am getting a very different value of predictions when I make them on Android using the above mentioned .pb file</p>

<p>My .pb file creation code:</p>

<pre><code>frozen_graph = tf.graph_util.convert_variables_to_constants(
        session,
        session.graph_def,
        ['outputLayer/Softmax']
    )
with open('frozen_model.pb', 'wb') as f:
  f.write(frozen_graph.SerializeToString())
</code></pre>

<p>So I have two major concerns:</p>

<ol>
<li>How can I load the above mentioned .pb file to python Tensorflow model ?</li>
<li>Why am I getting completely different values of prediction in python and android ? </li>
</ol>
",4120518.0,,4120518.0,,2019-09-28 07:31:56,2020-05-07 11:48:53,How to restore Tensorflow model from .pb file in python?,<android><python><tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50632258
42329059,1,42859256,,2017-02-19 15:28:09,,25,2186,"<p>TensorFlow provides a <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/tensor_summary"" rel=""noreferrer""><code>tf.summary.tensor_summary()</code></a> function that appears to be a multidimensional variant of <a href=""https://www.tensorflow.org/api_docs/python/tf/summary/scalar"" rel=""noreferrer""><code>tf.summary.scalar()</code></a>:</p>

<pre class=""lang-py prettyprint-override""><code>tf.summary.tensor_summary(name, tensor, summary_description=None, collections=None)
</code></pre>

<p>I thought it could be useful for summarizing inferred probabilities per class ... somewhat like</p>

<pre class=""lang-py prettyprint-override""><code>op_summary = tf.summary.tensor_summary('classes', some_tensor)
# ...
summary = sess.run(op_summary)
writer.add_summary(summary)
</code></pre>

<p>However it appears that TensorBoard doesn't provide a way to display these summaries at all. How are they meant to be used?</p>
",195651.0,,195651.0,,2017-02-20 20:47:23,2018-04-04 16:26:01,How is tf.summary.tensor_summary meant to be used?,<tensorflow>,1,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42329059
46098863,1,46139198,,2017-09-07 14:24:58,,24,25245,"<p>I have save the model using tf.estimator .method export_savedmodel as follows:</p>

<pre><code>export_dir=""exportModel/""

feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)

input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)

classifier.export_savedmodel(export_dir, input_receiver_fn, as_text=False, checkpoint_path=""Model/model.ckpt-400"") 
</code></pre>

<p>How can I import this saved model and use for predictions?</p>
",8386780.0,,5235574.0,,2017-09-07 15:15:57,2020-11-10 11:12:33,How to import an saved Tensorflow model train using tf.estimator and predict on input data,<tensorflow><tensorflow-serving>,4,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46098863
33662648,1,33664610,,2015-11-12 00:51:25,,24,5837,"<p>So I was playing around with Google's <a href=""http://www.tensorflow.org/"" rel=""noreferrer"">Tensorflow</a> library they published yesterday and encountered an annoying bug that keeps biting me.</p>

<p>What I did was setup the python logging functions as I usually do, and the result was that, if I import the tensorflow library, all messages in the console started doubling. Interestingly, this does <em>not</em> happen if you just use the <code>logging.warn/info/..()</code> function.</p>

<p>An example of a code that does <em>not</em> double the messages:</p>

<pre><code>import tensorflow as tf
import logging

logging.warn('test')
</code></pre>

<p>An example of a code that <em>does</em> double all messages:</p>

<pre><code>import tensorflow as tf
import logging

logger = logging.getLogger('TEST')
ch = logging.StreamHandler()
logger.addHandler(ch)

logger.warn('test')
</code></pre>

<p>Now, I'm a simple man. I like the functionality of <code>logging</code>, so I use it. The setup with the <code>logger</code> object and the adding of a <code>StreamHandler</code> is something I picked up looking at how other people did this, but it looks like it fits with how the thing was meant to be used. However, I do not have in-depth knowledge of the logging library, as it always just kind of worked.</p>

<p>So, any help explaining why the doubling of the messages occurs will be most helpful.</p>

<p>I am using Ubuntu 14.04.3 LTS with Python 2.7.6, but the error happens in all Python 2.7 versions I tried.</p>
",2381279.0,,5446749.0,,2023-04-12 08:16:00,2023-04-12 08:16:00,Tensorflow causes logging messages to double,<python><tensorflow><logging><python-logging>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33662648
39114832,1,39115010,,2016-08-24 05:07:54,,24,41312,"<p>I'm building a RNN loosely based on <a href=""https://www.tensorflow.org/versions/r0.10/tutorials/recurrent/index.html"" rel=""noreferrer"" title=""tutorial"">the TensorFlow tutorial</a>.</p>

<p>The relevant parts of my model are as follows:</p>

<pre><code>input_sequence = tf.placeholder(tf.float32, [BATCH_SIZE, TIME_STEPS, PIXEL_COUNT + AUX_INPUTS])
output_actual = tf.placeholder(tf.float32, [BATCH_SIZE, OUTPUT_SIZE])

lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(CELL_SIZE, state_is_tuple=False)
stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * CELL_LAYERS, state_is_tuple=False)

initial_state = state = stacked_lstm.zero_state(BATCH_SIZE, tf.float32)
outputs = []

with tf.variable_scope(""LSTM""):
    for step in xrange(TIME_STEPS):
        if step &gt; 0:
            tf.get_variable_scope().reuse_variables()
        cell_output, state = stacked_lstm(input_sequence[:, step, :], state)
        outputs.append(cell_output)

final_state = state
</code></pre>

<p>And the feeding:</p>

<pre><code>cross_entropy = tf.reduce_mean(-tf.reduce_sum(output_actual * tf.log(prediction), reduction_indices=[1]))
train_step = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(output_actual, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    numpy_state = initial_state.eval()

    for i in xrange(1, ITERATIONS):
        batch = DI.next_batch()

        print i, type(batch[0]), np.array(batch[1]).shape, numpy_state.shape

        if i % LOG_STEP == 0:
            train_accuracy = accuracy.eval(feed_dict={
                initial_state: numpy_state,
                input_sequence: batch[0],
                output_actual: batch[1]
            })

            print ""Iteration "" + str(i) + "" Training Accuracy "" + str(train_accuracy)

        numpy_state, train_step = sess.run([final_state, train_step], feed_dict={
            initial_state: numpy_state,
            input_sequence: batch[0],
            output_actual: batch[1]
            })
</code></pre>

<p>When I run this, I get the following error: </p>

<pre><code>Traceback (most recent call last):
  File ""/home/agupta/Documents/Projects/Image-Recognition-with-LSTM/RNN/feature_tracking/model.py"", line 109, in &lt;module&gt;
    output_actual: batch[1]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 698, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 838, in _run
    fetch_handler = _FetchHandler(self._graph, fetches)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 355, in __init__
    self._fetch_mapper = _FetchMapper.for_fetch(fetches)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 181, in for_fetch
    return _ListFetchMapper(fetch)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 288, in __init__
    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 178, in for_fetch
    (fetch, type(fetch)))
TypeError: Fetch argument None has invalid type &lt;type 'NoneType'&gt;
</code></pre>

<p>Perhaps the weirdest part is that this error gets thrown the <strong>second</strong> iteration, and the first works completely fine. I'm ripping my hair trying to fix this, so any help would be greatly appreciated.</p>
",3102725.0,,3881403.0,,2018-08-02 22:14:11,2018-11-21 05:09:46,Tensorflow TypeError: Fetch argument None has invalid type <type 'NoneType'>?,<python><artificial-intelligence><tensorflow><typeerror><recurrent-neural-network>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/39114832
52410484,1,53889821,,2018-09-19 16:32:34,,24,115385,"<p>There is a tensorflow-gpu version installed on Windows using Anaconda, how to check the CUDA and CUDNN version of it? Thanks.</p>
",297850.0,,681865.0,,2021-01-02 07:10:41,2021-04-27 17:48:04,get the CUDA and CUDNN version on windows with Anaconda installe,<python><tensorflow><anaconda><gpu>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52410484
47583501,1,48172033,,2017-11-30 22:11:59,,24,44406,"<p>I have a matrix (of vectors) X with shape [3,4], and I want to calculate the dot product between each pair of vectors (X[1].X[1]) and (X[1].X[2])...etc.</p>

<p>I saw a cosine similarity code were they use</p>

<p>tf.reduce_sum(tf.multyply(X, X),axis=1) </p>

<p>to calculate the dot product between the vectors in a matrix of vectors.However, this result in only calculates the dot product between (X[i], X[i]). </p>

<p>I used tf.matmul(X, X, transpose_b=True) which calculate the dot product between every two vectors but I am still confused why tf.multiply didn't do this I think the problem with my code.</p>

<p>the code is:</p>

<pre><code>data=[[1.0,2.0,4.0,5.0],[0.0,6.0,7.0,8.0],[8.0,1.0,1.0,1.0]]
X=tf.constant(data)
matResult=tf.matmul(X, X, transpose_b=True)

multiplyResult=tf.reduce_sum(tf.multiply(X,X),axis=1)
with tf.Session() as sess:
   print('matResult')
   print(sess.run([matResult]))
   print()
   print('multiplyResult')
   print(sess.run([multiplyResult]))
</code></pre>

<p>The output is:</p>

<pre><code>matResult
[array([[  46.,   80.,   19.],
       [  80.,  149.,   21.],
       [  19.,   21.,   67.]], dtype=float32)]

multiplyResult
 [array([  46.,  149.,   67.], dtype=float32)]
</code></pre>

<p>I would appreciate any advise</p>
",7879074.0,,,,,2022-04-04 17:16:02,tf.multiply vs tf.matmul to calculate the dot product,<python><tensorflow>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47583501
56072634,1,56073840,,2019-05-10 07:20:30,,24,13431,"<p>In tf 2.0 DC Gan example in <a href=""https://www.tensorflow.org/alpha/tutorials/generative/dcgan"" rel=""noreferrer"">tensorflow 2.0 guide</a>, there are two gradient tapes . See below.</p>

<pre class=""lang-py prettyprint-override""><code>@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
</code></pre>

<p>As you can see clearly that there are two gradient tapes. I was wondering what difference does using a single tape make and changed it to the following</p>

<pre class=""lang-py prettyprint-override""><code>@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as tape:
      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
</code></pre>

<p>This gives me the following error : </p>

<pre><code>RuntimeError: GradientTape.gradient can only be called once on non-persistent tapes.
</code></pre>

<p>I would like to know why two tapes are necessary.
As of now the documentation on tf2.0 APIs is scanty. Can anyone explain or point me to the right docs/tutorials? </p>
",3534616.0,,3534616.0,,2019-05-10 07:34:47,2021-02-16 08:45:22,Tf 2.0 : RuntimeError: GradientTape.gradient can only be called once on non-persistent tapes,<python><python-3.x><tensorflow><tensorflow2.0>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/56072634
40866675,1,40871108,,2016-11-29 13:06:36,,24,10716,"<p>First of all, I am aware that a related question has been asked <a href=""https://stackoverflow.com/questions/38556078/in-tensorflow-what-is-the-difference-between-a-variable-and-a-tensor"">here</a>.</p>

<p>However, this question is about the implementation and internals. 
I was reading the paper ""<a href=""https://arxiv.org/pdf/1610.01178.pdf"" rel=""noreferrer"">A Tour of TensorFlow</a>"". The following two points are quoted from there:</p>

<p>1.</p>

<blockquote>
  <p>A tensor itself does not hold or store values in memory, but provides
  only an interface for retrieving the value referenced by the tensor.</p>
</blockquote>

<p>This suggests to me that a Tensor is an object that simply stores the pointer to a result of an operation and, on retrieving the result or value of the tensor, it simply dereferences that pointer.</p>

<p>2.</p>

<blockquote>
  <p>Variables can be described as persistent, mutable handles to in-memory buffers storing tensors. As such, variables are  characterized by a certain shape and a fixed type.</p>
</blockquote>

<p>At this I get confused because I thought, based on the previous point, that Tensors simply store a pointer. If they were simply pointers, they could be mutable as well.</p>

<p>To be precise these are my questions:</p>

<ol>
<li>What is the meaning of ""in-memory buffers""?</li>
<li>What is the meaning of a ""handle""?</li>
<li>Is my initial assumption about the internals of a tensor correct? </li>
<li>What is the essential internal implementation difference between a tensor and a variable? Why are they declared differently  and why is that difference essential to TensorFlow?</li>
</ol>
",6842947.0,,-1.0,,2017-05-23 12:34:42,2016-11-29 16:54:06,Implementation difference between TensorFlow Variable and TensorFlow Tensor,<tensorflow>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40866675
45353389,1,45716062,,2017-07-27 14:14:04,,24,24574,"<p>Is there a way to let Tensorflow print extra training metrics (e.g. batch accuracy) when using the Estimator API?</p>

<p>One can add summaries and view the result in Tensorboard (see another post), but I was wondering if there is an elegant way to get the scalar summary values printed while training. This already happens for training loss, e.g.: </p>

<pre><code>loss = 0.672677, step = 2901 (52.995 sec)
</code></pre>

<p>but it would be nice to have e.g.</p>

<pre><code>loss = 0.672677, accuracy = 0.54678, step = 2901 (52.995 sec)
</code></pre>

<p>without to much trouble. I am aware that most of the time it is more useful to plot test set accuracy (I am already doing this with a validation monitor), but in this case I am also interested in training batch accuracy.</p>
",7405530.0,,,,,2020-11-04 15:15:44,Printing extra training metrics with Tensorflow Estimator,<logging><machine-learning><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45353389
41831214,1,41877617,,2017-01-24 14:51:16,,24,28069,"<p>I am trying to install tensorflow</p>

<pre><code>Please specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]: 
Invalid SYCL 1.2 library path. /usr/local/computecpp/lib/libComputeCpp.so cannot be found
</code></pre>

<p>What should I do?What is SYCL 1.2?</p>
",6871950.0,,,,,2019-11-02 13:25:27,What is SYCL 1.2?,<tensorflow>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41831214
43100679,1,43104527,,2017-03-29 17:51:04,,24,15555,"<p>In tensorflow, the functions <code>tf.einsum</code>, <code>tf.matmul</code>, and <code>tf.tensordot</code> can all be used for the same tasks. (I realize that <code>tf.einsum</code> and <code>tf.tensordot</code> have more general definitions; I also realize that <code>tf.matmul</code> has batch functionality.) In a situation where any of the three could be used, does one function tend to be fastest? Are there other recommendation rules?</p>
<p>For example, suppose that <code>A</code> is a rank-2 tensor, and <code>b</code> is rank-1 tensor, and you want to compute the product <code>c_j = A_ij b_j</code>. Of the three options:</p>
<p><code>c = tf.einsum('ij,j-&gt;i', A, b)</code></p>
<p><code>c = tf.matmul(A, tf.expand_dims(b,1))</code></p>
<p><code>c = tf.tensordot(A, b, 1)</code></p>
<p>Is any generally preferable to the others?</p>
",6392842.0,,9215780.0,,2022-01-05 01:19:43,2022-01-05 01:19:43,tensorflow einsum vs. matmul vs. tensordot,<python><tensorflow><numpy-einsum>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43100679
35382409,1,35382604,,2016-02-13 16:35:56,,24,37101,"<p>I get following error </p>

<pre><code>ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int32: 'Tensor(""Placeholder_1:0"", shape=TensorShape([Dimension(128), Dimension(2)]), dtype=int32)'
</code></pre>

<p>when I try to calculate cross entropy loss</p>

<pre><code>losses = tf.nn.softmax_cross_entropy_with_logits(scores, input_y)
</code></pre>

<p>I use Python 3.4.3. </p>

<p>Any ideas why? </p>
",5318180.0,,3924118.0,,2020-01-23 18:00:40,2022-01-10 20:34:38,ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int32,<neural-network><tensorflow><conv-neural-network>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/35382409
39366271,1,39367644,,2016-09-07 09:33:37,,24,13963,"<p>I'm looking at InceptionV3 (GoogLeNet) architecture and cannot understand why do we need conv1x1 layers?</p>

<p>I know how convolution works, but I see a profit with patch size > 1. </p>
",1251713.0,,,,,2017-09-30 05:02:03,For what reason Convolution 1x1 is used in deep neural networks?,<neural-network><tensorflow><deep-learning><convolution><conv-neural-network>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39366271
42758315,1,42758506,,2017-03-13 07:24:08,,24,54438,"<p>I'm looking for something similar to the effects of:</p>

<pre><code>x.get_shape()
</code></pre>

<p>that will give the type of <code>x</code>. Is there is any function for this?</p>
",2416553.0,,7579547.0,,2020-01-22 06:12:23,2020-03-06 20:27:56,How to get the type of a Tensor?,<python><tensorflow>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42758315
36110834,1,36113230,,2016-03-20 06:22:36,,24,15803,"<p>I am trying to use Tensorflow. Here is an very simple code.</p>

<pre><code>train = tf.placeholder(tf.float32, [1], name=""train"")
W1 = tf.Variable(tf.truncated_normal([1], stddev=0.1), name=""W1"")
loss = tf.pow(tf.sub(train, W1), 2)
step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)
</code></pre>

<p>Just ignore the optimization part (4th line). It will take a floating number and train W1 so as to increase squared difference.</p>

<p>My question is simple. If I use just minus sign instead of 
tf.sub"" as below, what is different? Will it cause a wrong result? </p>

<pre><code>loss = tf.pow(train-W1, 2)
</code></pre>

<p>When I replace it, the result looks the same. If they are the same, why do we need to use the ""tf.add/tf.sub"" things?</p>

<p>Built-in back propagation calculation can be done only by the ""tf.*"" things? </p>
",3251207.0,,,,,2021-02-07 05:15:03,What's difference between tf.sub and just minus operation in tensorflow?,<python><tensorflow>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36110834
46926809,1,47045795,,2017-10-25 07:49:19,,24,12602,"<p>I've written a custom loss function for my neural network but it can't compute any gradients. I thinks it is because I need the index of the highest value and are therefore using argmax to get this index.</p>

<p>As argmax is not differentiable I to get around this but I don't know how it is possible.</p>

<p>Can anyone help?</p>
",7199281.0,,,,,2023-03-31 15:31:05,Getting around tf.argmax which is not differentiable,<python><tensorflow>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46926809
50346017,1,50350684,,2018-05-15 08:53:01,,23,49320,"<p>My training data are saved in 3 files, each file is too large and cannot fit into memory.For each training example, the data are two dimensionality (2805 rows and 222 columns, the 222nd column is for label) and are numerical values. I would like to normalize the data before feeding into models for training. Below is my code for input_pipeline, and 
the data has not been normalized before creating dataset. Is there some functions in tensorflow that can do normalization for my case? </p>

<pre><code>dataset = tf.data.TextLineDataset([file1, file2, file3])
# combine 2805 lines into a single example
dataset = dataset.batch(2805)

def parse_example(line_batch):
    record_defaults = [[1.0] for col in range(0, 221)]
    record_defaults.append([1])
    content = tf.decode_csv(line_batch, record_defaults = record_defaults, field_delim = '\t')
    features = tf.stack(content[0:221])
    features = tf.transpose(features)
    label = content[-1][-1]
    label = tf.one_hot(indices = tf.cast(label, tf.int32), depth = 2)
    return features, label

dataset = dataset.map(parse_example)
dataset = dataset.shuffle(1000)
# batch multiple examples
dataset = dataset.batch(batch_size)
dataset = dataset.repeat(num_epochs)
iterator = dataset.make_one_shot_iterator()
data_batch, label_batch = iterator.get_next() 
</code></pre>
",9378677.0,,,,,2021-01-20 02:03:34,how to normalize input data for models in tensorflow,<tensorflow>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50346017
41600321,1,41601168,,2017-01-11 20:41:51,,23,7745,"<p>I got confused about the two concepts: <code>In-graph replication</code> and <code>Between-graph replication</code> when reading the <a href=""https://www.tensorflow.org/versions/master/how_tos/distributed/#replicated_training"" rel=""noreferrer"">Replicated training</a> in tensorflow's official How-to. </p>

<ol>
<li><p>It's said in above link that </p>

<blockquote>
  <p><strong>In-graph replication.</strong> In this approach, the client builds a single
  tf.Graph that contains one set of parameters (in tf.Variable nodes
  pinned to /job:ps); ...</p>
</blockquote>

<p>Does this mean there are <strong>multiple</strong> <code>tf.Graph</code>s in <code>Between-graph
replication</code> approach? If yes, where are the corresponding codes in
the provided examples?</p></li>
<li><p>While there is already a <code>Between-graph replication</code> example in above link, could anyone provide a <code>In-graph replication</code>
implementation (pseudo code is fine)  and highlight its main
differences from <code>Between-graph replication</code>?</p>

<p>Thanks in advance! </p>

<hr></li>
</ol>

<h2><strong>Edit_1: more questions</strong></h2>

<p>Thanks a lot for your detailed explanations and gist code @mrry @YaroslavBulatov ! After looking
    your responses, I have the following two questions:</p>

<ol start=""3"">
<li><p>There is the following statement in <a href=""https://www.tensorflow.org/versions/master/how_tos/distributed/#replicated_training"" rel=""noreferrer"">Replicated training</a>:</p>

<blockquote>
  <p><strong>Between-graph replication.</strong> In this approach, there is a separate
  client for each /job:worker task, typically in the same process as the
  worker task. Each client builds a <strong>similar graph</strong> containing the
  parameters (pinned to /job:ps as before using
  tf.train.replica_device_setter() to map them deterministically to the
  same tasks); and a <strong>single copy</strong> of the compute-intensive part of the
  model, pinned to the local task in /job:worker.</p>
</blockquote>

<p>I have two sub-questions related to above words in bold.</p>

<p>(A) Why do we say each client builds <strong>similar graph</strong>, but not <strong>same graph</strong>?
I wonder the graph built in each client in the example of <a href=""https://www.tensorflow.org/versions/master/how_tos/distributed/#replicated_training"" rel=""noreferrer"">Replicated training</a>
should be the same because below graph construction codes are shared within all <code>worker</code>s.:</p>

<p><code># Build model...</code></p>

<p><code>loss = ...</code></p>

<p><code>global_step = tf.Variable(0)</code></p>

<p>(B) Shouldn't it be <strong>multiple copies</strong> of compute-intensive part of
the model, since we have multiple <code>workers</code>?</p></li>
<li><p>Does the example in <a href=""https://www.tensorflow.org/versions/master/how_tos/distributed/#replicated_training"" rel=""noreferrer"">Replicated training</a> support training on multiple machines, each of which has multiple GPUs? If not, can we
use simultaneously both the <code>In-graph replication</code> to support training on multiple
GPUs on each machine and <code>Between-graph replication</code> for
cross-machine training? I ask this question because
@mrry indicated that the <code>In-graph replication</code> is essentially same to the way
used in <a href=""https://github.com/tensorflow/models/blob/91c7b91f834a5a857e8168b96d6db3b93d7b9c2a/tutorials/image/cifar10/cifar10_multi_gpu_train.py"" rel=""noreferrer"">CIFAR-10 example model for multiple GPUs</a>.</p></li>
</ol>
",4394807.0,,4394807.0,,2017-01-11 22:51:50,2019-02-07 04:17:42,Distributed tensorflow: the difference between In-graph replication and Between-graph replication,<graph><tensorflow><distributed>,1,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41600321
38376478,1,38377600,,2016-07-14 14:08:44,,23,30593,"<p>Sorry if I messed up the title, I didn't know how to phrase this. Anyways, I have a tensor of a set of values, but I want to make sure that every element in the tensor has a range from 0 - 255, (or 0 - 1 works too). However, I don't want to make all the values add up to 1 or 255 like softmax, I just want to down scale the values.</p>

<p>Is there any way to do this?</p>

<p>Thanks!</p>
",3102725.0,,,,,2022-01-04 23:13:43,Changing the scale of a tensor in tensorflow,<python><tensorflow><conv-neural-network>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38376478
58972225,1,58973855,,2019-11-21 10:05:47,,23,29339,"<p>This example code from Tensorflow 2</p>

<pre><code>writer = tf.summary.create_file_writer(""/tmp/mylogs/tf_function"")

@tf.function
def my_func(step):
  with writer.as_default():
    # other model code would go here
    tf.summary.scalar(""my_metric"", 0.5, step=step)

for step in range(100):
  my_func(step)
  writer.flush()
</code></pre>

<p>but it is throwing warnings. </p>

<blockquote>
  <p>WARNING:tensorflow:5 out of the last 5 calls to  triggered tf.function retracing. Tracing is expensive
  and the excessive number of tracings is likely due to passing python
  objects instead of tensors. Also, tf.function has
  experimental_relax_shapes=True option that relaxes argument shapes
  that can avoid unnecessary retracing. Please refer to
  <a href=""https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args"" rel=""noreferrer"">https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args</a>
  and <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/function</a> for more
  details.</p>
</blockquote>

<p>Is there a better way to do this?</p>
",1128171.0,,1128171.0,,2019-11-21 10:13:41,2022-11-30 00:27:03,Tensorflow2 warning using @tffunction,<tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58972225
33654754,1,33655736,,2015-11-11 16:08:49,,23,30685,"<p><a href=""http://www.tensorflow.org/how_tos/variables/index.md#creation"">TensorFlow tutorial</a> says that at creation time we need to specify the shape of tensors.  That shape automatically becomes the shape of the tensor.  It also says that TensorFlow provides advanced mechanisms to reshape variables. How can I do that? Any code example?</p>
",2701950.0,,,,,2020-06-18 07:58:04,How can I change the shape of a variable in TensorFlow?,<matrix><reshape><tensorflow>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33654754
45315545,1,45319706,,2017-07-26 00:33:30,,23,28408,"<p>I have a tensor which is simply a vector, <code>vector = [0.5 0.4]</code> and tf.shape indicates that it has shape=(1,), I would like to replicate the vector m times and have the shape of [m, 2], so for m = 2, <code>matrix = [[0.5 0.4], [0.5 0.4]]</code>. How do I achieve that using tf.tile?</p>
",253800.0,,253800.0,,2017-07-26 01:02:09,2019-11-21 13:15:31,replicate a row tensor using tf.tile?,<tensorflow>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45315545
41890549,1,42405657,,2017-01-27 09:23:44,,23,98797,"<p>I have a laptop with a GeForce 940 MX. I want to get Tensorflow up and running on the gpu. I installed everything from their tutorial page, now when I import Tensorflow, I get</p>

<pre><code>&gt;&gt;&gt; import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened  CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH: 
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: workLaptop
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: Permission denied: could not open driver version path for reading: /proc/driver/nvidia/version
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1092] LD_LIBRARY_PATH: 
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1093] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so.1; dlerror: libnvidia-fatbinaryloader.so.367.57: cannot open shared object file: No such file or directory
 I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
&gt;&gt;&gt; 
</code></pre>

<p>after which I think it just switches to running on the cpu. </p>

<p>EDIT: After I nuked everything , started from scratch. Now I get this:</p>

<pre><code>&gt;&gt;&gt; import tensorflow
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:119] Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: workLaptop
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: Permission denied: could not open driver version path for reading: /proc/driver/nvidia/version
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1092] LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1093] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so.1; dlerror: libnvidia-fatbinaryloader.so.367.57: cannot open shared object file: No such file or directory
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
</code></pre>
",5016028.0,,5016028.0,,2017-01-27 11:57:04,2020-07-11 10:52:21,Tensorflow cannot open libcuda.so.1,<cuda><tensorflow><nvidia>,3,10,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41890549
48001759,1,48006315,,2017-12-28 04:56:56,,23,18141,"<p>In tensorflow 1.4, I found two functions that do batch normalization and they look same:</p>

<ol>
<li><code>tf.layers.batch_normalization</code> (<a href=""https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization"" rel=""noreferrer"">link</a>)</li>
<li><code>tf.contrib.layers.batch_norm</code> (<a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm"" rel=""noreferrer"">link</a>)</li>
</ol>

<p>Which function should I use? Which one is more stable?</p>
",6279632.0,,712995.0,,2017-12-28 12:13:01,2017-12-28 12:13:01,What is right batch normalization function in Tensorflow?,<python><tensorflow><neural-network><deep-learning><batch-normalization>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48001759
59514268,1,59514437,,2019-12-28 19:38:16,,23,26155,"<p>I've got TensorFlow installed on my machine however I'm keep getting the error: <code>UsageError: Line magic function `%tensorflow_version` not found.</code></p>

<p>Any ideas as to why this is? The code I ran is below (Jupyter Notebook)</p>

<pre><code>%tensorflow_version 1.x
import tensorflow as tf
print(tf.__version__)
</code></pre>
",11698918.0,,,,,2021-06-14 20:36:13,UsageError: Line magic function `%tensorflow_version` not found,<python><tensorflow><jupyter-notebook>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59514268
33651810,1,33686846,,2015-11-11 13:41:25,,23,13336,"<p>After installing TensorFlow and its dependencies on a g2.2xlarge EC2 instance I tried to run an MNIST example from the getting started page: </p>

<pre><code>python tensorflow/models/image/mnist/convolutional.py
</code></pre>

<p>But I get the following warning:</p>

<pre><code>I tensorflow/core/common_runtime/gpu/gpu_device.cc:611] Ignoring gpu device 
(device: 0, name: GRID K520, pci bus id: 0000:00:03.0) with Cuda compute 
capability 3.0. The minimum required Cuda capability is 3.5.
</code></pre>

<p>Is this a hard requirement? Any chance I could comment that check out in a fork of TensorFlow? It would be super nice to be able to train models in AWS.</p>
",2448716.0,,4244993.0,,2017-08-24 16:31:31,2017-08-24 16:31:31,The minimum required Cuda capability is 3.5,<amazon-ec2><tensorflow>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/33651810
43708616,1,43745667,,2017-04-30 16:25:38,,23,30671,"<p>I've been digging around on this for a while. I have found a ton of articles; but none really show just tensorflow inference as a plain inference.  Its always ""use the serving engine"" or using a graph that is pre-coded/defined.</p>

<p>Here is the problem: I have a device which occasionally checks for updated models. It then needs to load that model and run input predictions through the model.</p>

<p>In keras this was simple: build a model; train the model and the call model.predict(). In scikit-learn same thing.</p>

<p>I am able to grab a new model and load it; I can print out all of the weights; but how in the world do I run inference against it?</p>

<p>Code to load model and print weights:</p>

<pre><code>    with tf.Session() as sess:
        new_saver = tf.train.import_meta_graph(MODEL_PATH + '.meta', clear_devices=True)
        new_saver.restore(sess, MODEL_PATH)
        for var in tf.trainable_variables():
            print(sess.run(var))
</code></pre>

<p>I printed out all of my collections and I have:
['queue_runners', 'variables', 'losses', 'summaries', 'train_op', 'cond_context', 'trainable_variables']</p>

<p>I tried using <code>sess.run(train_op)</code>; however that just started kicking up a full training session; which is not what I want to do. I just want to run inference against a different set of inputs that I provide which are not TF Records.</p>

<p>Just a little more detail:</p>

<p>The device can use C++ or Python; as long as I can produce a .exe.  I can set up a feed dict if I want to feed the system.  I trained with <code>TFRecords</code>; but in production I'm not going to use <code>TFRecords</code>; its a real/near real time system.</p>

<p>Thanks for any input.  I am posting sample code to this repo: <a href=""https://github.com/drcrook1/CIFAR10/TensorFlow"" rel=""noreferrer"">https://github.com/drcrook1/CIFAR10/TensorFlow</a> which does all the training and sample inference.</p>

<p>Any hints are greatly appreciated! </p>

<p>------------EDITS-----------------
I rebuilt the model to be as below:</p>

<pre><code>def inference(images):
    '''
    Portion of the compute graph that takes an input and converts it into a Y output
    '''
    with tf.variable_scope('Conv1') as scope:
        C_1_1 = ld.cnn_layer(images, (5, 5, 3, 32), (1, 1, 1, 1), scope, name_postfix='1')
        C_1_2 = ld.cnn_layer(C_1_1, (5, 5, 32, 32), (1, 1, 1, 1), scope, name_postfix='2')
        P_1 = ld.pool_layer(C_1_2, (1, 2, 2, 1), (1, 2, 2, 1), scope)
    with tf.variable_scope('Dense1') as scope:
        P_1 = tf.reshape(C_1_2, (CONSTANTS.BATCH_SIZE, -1))
        dim = P_1.get_shape()[1].value
        D_1 = ld.mlp_layer(P_1, dim, NUM_DENSE_NEURONS, scope, act_func=tf.nn.relu)
    with tf.variable_scope('Dense2') as scope:
        D_2 = ld.mlp_layer(D_1, NUM_DENSE_NEURONS, CONSTANTS.NUM_CLASSES, scope)
    H = tf.nn.softmax(D_2, name='prediction')
    return H
</code></pre>

<p>notice I add the name <code>'prediction'</code> to the TF operation so I can retrieve it later.</p>

<p>When training I used the input pipeline for <code>tfrecords</code> and input queues.</p>

<pre><code>GRAPH = tf.Graph()
with GRAPH.as_default():
    examples, labels = Inputs.read_inputs(CONSTANTS.RecordPaths,
                                          batch_size=CONSTANTS.BATCH_SIZE,
                                          img_shape=CONSTANTS.IMAGE_SHAPE,
                                          num_threads=CONSTANTS.INPUT_PIPELINE_THREADS)
    examples = tf.reshape(examples, [CONSTANTS.BATCH_SIZE, CONSTANTS.IMAGE_SHAPE[0],
                                     CONSTANTS.IMAGE_SHAPE[1], CONSTANTS.IMAGE_SHAPE[2]])
    logits = Vgg3CIFAR10.inference(examples)
    loss = Vgg3CIFAR10.loss(logits, labels)
    OPTIMIZER = tf.train.AdamOptimizer(CONSTANTS.LEARNING_RATE)
</code></pre>

<p>I am attempting to use <code>feed_dict</code> on the loaded operation in the graph; however now it is just simply hanging....</p>

<pre><code>MODEL_PATH = 'models/' + CONSTANTS.MODEL_NAME + '.model'

images = tf.placeholder(tf.float32, shape=(1, 32, 32, 3))

def run_inference():
    '''Runs inference against a loaded model'''
    with tf.Session() as sess:
        #sess.run(tf.global_variables_initializer())
        new_saver = tf.train.import_meta_graph(MODEL_PATH + '.meta', clear_devices=True)
        new_saver.restore(sess, MODEL_PATH)
        pred = tf.get_default_graph().get_operation_by_name('prediction')
        rand = np.random.rand(1, 32, 32, 3)
        print(rand)
        print(pred)
        print(sess.run(pred, feed_dict={images: rand}))
        print('done')

run_inference()
</code></pre>

<p>I believe this is not working because the original network was trained using TFRecords.  In the sample CIFAR data set the data is small; our real data set is huge and it is my understanding TFRecords the the default best practice for training a network.  The <code>feed_dict</code> makes great perfect sense from a productionizing perspective; we can spin up some threads and populate that thing from our input systems.</p>

<p>So I guess I have a network that is trained, I can get the predict operation; but how do I tell it to stop using the input queues and start using the <code>feed_dict</code>?  Remember that from the production perspective I do not have access to whatever the scientists did to make it.  They do their thing; and we stick it in production using whatever agreed upon standard.</p>

<p>-------INPUT OPS--------</p>

<p>tf.Operation 'input/input_producer/Const' type=Const, tf.Operation 'input/input_producer/Size' type=Const, tf.Operation 'input/input_producer/Greater/y' type=Const, tf.Operation 'input/input_producer/Greater' type=Greater, tf.Operation 'input/input_producer/Assert/Const' type=Const, tf.Operation 'input/input_producer/Assert/Assert/data_0' type=Const, tf.Operation 'input/input_producer/Assert/Assert' type=Assert, tf.Operation 'input/input_producer/Identity' type=Identity, tf.Operation 'input/input_producer/RandomShuffle' type=RandomShuffle, tf.Operation 'input/input_producer' type=FIFOQueueV2, tf.Operation 'input/input_producer/input_producer_EnqueueMany' type=QueueEnqueueManyV2, tf.Operation 'input/input_producer/input_producer_Close' type=QueueCloseV2, tf.Operation 'input/input_producer/input_producer_Close_1' type=QueueCloseV2, tf.Operation 'input/input_producer/input_producer_Size' type=QueueSizeV2, tf.Operation 'input/input_producer/Cast' type=Cast, tf.Operation 'input/input_producer/mul/y' type=Const, tf.Operation 'input/input_producer/mul' type=Mul, tf.Operation 'input/input_producer/fraction_of_32_full/tags' type=Const, tf.Operation 'input/input_producer/fraction_of_32_full' type=ScalarSummary, tf.Operation 'input/TFRecordReaderV2' type=TFRecordReaderV2, tf.Operation 'input/ReaderReadV2' type=ReaderReadV2,</p>

<p>------END INPUT OPS-----</p>

<p>----UPDATE 3----</p>

<p>I believe what I need to do is to kill the input section of the graph trained with TF Records and rewire the input to the first layer to a new input.  Its kinda like performing surgery; but this is the only way I can find to do inference if I trained using TFRecords as crazy as it sounds...</p>

<p>Full Graph:</p>

<p><a href=""https://i.stack.imgur.com/xFrYN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/xFrYN.png"" alt=""enter image description here""></a></p>

<p>Section to kill:</p>

<p><a href=""https://i.stack.imgur.com/mRpEf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/mRpEf.png"" alt=""enter image description here""></a></p>

<p>So I think the question becomes: How does one kill the input section of the graph and replace it with a <code>feed_dict</code>?</p>

<p>A follow up to this would be: is this really the right way to do it?  This seems bonkers.</p>

<p>----END UPDATE 3----</p>

<p>---link to checkpoint files---</p>

<p><a href=""https://drcdata.blob.core.windows.net/checkpoints/CIFAR_10_VGG3_50neuron_1pool_1e-3lr_adam.model.zip?st=2017-05-01T21%3A56%3A00Z&amp;se=2020-05-02T21%3A56%3A00Z&amp;sp=rl&amp;sv=2015-12-11&amp;sr=b&amp;sig=oBCGxlOusB4NOEKnSnD%2FTlRYa5NKNIwAX1IyuZXAr9o%3D"" rel=""noreferrer"">https://drcdata.blob.core.windows.net/checkpoints/CIFAR_10_VGG3_50neuron_1pool_1e-3lr_adam.model.zip?st=2017-05-01T21%3A56%3A00Z&amp;se=2020-05-02T21%3A56%3A00Z&amp;sp=rl&amp;sv=2015-12-11&amp;sr=b&amp;sig=oBCGxlOusB4NOEKnSnD%2FTlRYa5NKNIwAX1IyuZXAr9o%3D</a></p>

<p>--end link to checkpoint files---</p>

<p>-----UPDATE 4 -----</p>

<p>I gave in and just gave a shot at the 'normal' way of performing inference assuming I could have the scientists simply just pickle their models and we could grab the model pickle; unpack it and then run inference on it.  So to test I tried the normal way assuming we already unpacked it...It doesn't work worth a beans either...</p>

<pre><code>import tensorflow as tf
import CONSTANTS
import Vgg3CIFAR10
import numpy as np
from scipy import misc
import time

MODEL_PATH = 'models/' + CONSTANTS.MODEL_NAME + '.model'
imgs_bsdir = 'C:/data/cifar_10/train/'

images = tf.placeholder(tf.float32, shape=(1, 32, 32, 3))

logits = Vgg3CIFAR10.inference(images)

def run_inference():
'''Runs inference against a loaded model'''
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        new_saver = tf.train.import_meta_graph(MODEL_PATH + '.meta')#, import_scope='1', input_map={'input:0': images})
        new_saver.restore(sess, MODEL_PATH)
        pred = tf.get_default_graph().get_operation_by_name('prediction')
        enq = sess.graph.get_operation_by_name(enqueue_op)
        #tf.train.start_queue_runners(sess)
        print(rand)
        print(pred)
        print(enq)
        for i in range(1, 25):
            img = misc.imread(imgs_bsdir + str(i) + '.png').astype(np.float32) / 255.0
            img = img.reshape(1, 32, 32, 3)
            print(sess.run(logits, feed_dict={images : img}))
            time.sleep(3)
        print('done')

run_inference()
</code></pre>

<p>Tensorflow ends up building a new graph with the inference function from the loaded model; then it appends all the other stuff from the other graph to the end of it.  So then when I populate a <code>feed_dict</code> expecting to get inferences back; I just get a bunch of random garbage as if it were the first pass through the network...</p>

<p>Again; this seems nuts; do I really need to write my own framework for serializing and deserializing random networks?  This has had to have been done before...</p>

<p>-----UPDATE 4 -----</p>

<p>Again; thanks!</p>
",3005995.0,,4772009.0,,2019-05-19 02:54:30,2019-05-19 02:54:30,TensorFlow Inference,<python><c++><tensorflow>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43708616
42559222,1,42559223,,2017-03-02 15:18:43,,23,36879,"<p>When following the Installing TensorFlow for Windows guide <a href=""https://www.tensorflow.org/install/install_windows"" rel=""noreferrer"">https://www.tensorflow.org/install/install_windows</a>, after executing</p>

<pre><code>C:\&gt; pip3 install --upgrade tensorflow
</code></pre>

<p>I get the following error:</p>

<pre><code>'pip3' is not recognized as an internal or external command,
</code></pre>

<p>It looks like pip3 isn't recognized at all (although PATH to python is set)</p>
",2979749.0,,,,,2018-09-20 10:02:51,"Installation of TensorFlow on windows 7 - 'pip3' is not recognized as an internal or external command,",<python><tensorflow>,8,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42559222
34175174,1,34175683,,2015-12-09 09:31:30,,23,21370,"<p>Deep Learning has been applied successfully on several large data sets for the classification of a handful of classes (cats, dogs, cars, planes, etc), with performances beating simpler descriptors like Bags of Features over SIFT, color histograms, etc.</p>

<p>Nevertheless, training such a network requires a lot of data per class and a lot of training time. However, very often one doesn't have enough data or just wants to get an idea of how well a convolutional neural network might do, before spending time one designing and training such a device and gathering the training data.</p>

<p>In this particular case, it might be ideal to have a network configured and trained using some benchmark data set used by the state of the art publications, and to simply apply it to some data set that you might have as a feature extractor.</p>

<p>This results in a set of features for each image, which one could feed to a classical classification method like SVM's, logistic regression, neural networks, etc.</p>

<p>In particular when one does not have enough data to train the CNN, I may expect this to outperform a pipeline where the CNN was trained on few samples.</p>

<p>I was looking at the tensorflow tutorials, but they always seem to have a clear training / testing phase. I couldn't find a pickle file (or similar) with a pre-configured CNN feature extractor.</p>

<p>My questions are: do such pre-trained networks exist and where can I find them. Alternatively: does this approach make sense? Where could I find a CNN+weights ?</p>

<p><strong>EDIT</strong>
W.r.t. @john's comment I tried using <code>'DecodeJpeg:0'</code> and <code>'DecodeJpeg/contents:0'</code> and checked the outputs, which are different (:S)</p>



<pre class=""lang-py prettyprint-override""><code>import cv2, requests, numpy
import tensorflow.python.platform
import tensorflow as tf


response = requests.get('https://i.stack.imgur.com/LIW6C.jpg?s=328&amp;g=1')
data = numpy.asarray(bytearray(response.content), dtype=np.uint8)
image = cv2.imdecode(data,-1)

compression_worked, jpeg_data = cv2.imencode('.jpeg', image)
if not compression_worked:
    raise Exception(""Failure when compressing image to jpeg format in opencv library"")
jpeg_data = jpeg_data.tostring()

with open('./deep_learning_models/inception-v3/classify_image_graph_def.pb', 'rb') as graph_file:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(graph_file.read())
    tf.import_graph_def(graph_def, name='')

with tf.Session() as sess:
    softmax_tensor = sess.graph.get_tensor_by_name('pool_3:0')

    arr0 = numpy.squeeze(sess.run(
        softmax_tensor,
        {'DecodeJpeg:0': image}
    ))

    arr1 = numpy.squeeze(sess.run(
        softmax_tensor,
        {'DecodeJpeg/contents:0': jpeg_data}
    ))

    print(numpy.abs(arr0 - arr1).max())
</code></pre>

<p>So the max absolute difference is <code>1.27649</code>, and in general all the elements differ (especially since the average value of the <code>arr0</code> and <code>arr1</code> themselves lies between 0 - 0.5).</p>

<p>I also would expect that <code>'DecodeJpeg:0'</code> needs a jpeg-string, not a numpy array, why else does the name contain 'Jpeg'. @john: Could you state how
 sure you are about your comment?</p>

<p>So I guess I'm not sure what is what, as I would expect a trained neural network to be deterministic (but chaotic at most).</p>
",853462.0,,853462.0,,2016-05-09 12:22:16,2017-06-02 18:04:46,Extract features using pre-trained (Tensorflow) CNN,<machine-learning><computer-vision><deep-learning><tensorflow>,1,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34175174
56820327,1,56820328,,2019-06-29 19:29:51,,23,44663,"<p>I got the following deprecation warning in my tensorflow code: </p>

<blockquote>
  <p>The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.</p>
</blockquote>

<ul>
<li>Why I got this warning</li>
<li>What will happen in tensorflow 2.0. instead of <code>tf.session</code></li>
<li>Is it okay to use <code>tf.compat.v1.Session</code></li>
</ul>
",3604079.0,,,,,2019-06-29 19:29:51,The name tf.Session is deprecated. Please use tf.compat.v1.Session instead,<tensorflow><tensorflow2.0>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/56820327
44796793,1,44798131,,2017-06-28 08:00:03,,23,12909,"<p>Want to understand the difference in roles of <code>tf.clip_by_value</code> and <code>tf.clip_by_global_norm</code> during the implementation of Gradient Clipping in TensorFlow. Which one is preferred and how to decide the max value to clip on?</p>
",7730199.0,,5634636.0,,2020-02-22 10:05:02,2020-02-22 10:05:02,Difference between tf.clip_by_value and tf.clip_by_global_norm for RNN's and how to decide max value to clip on?,<python><tensorflow><deep-learning>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44796793
45029977,1,45115503,,2017-07-11 09:03:09,,23,9376,"<p>I was playing with TensorFlow's brand new <a href=""https://github.com/tensorflow/models/tree/master/research/object_detection"" rel=""noreferrer"">Object Detection API</a> and decided to train it on some other publicly available datasets.</p>

<p>I happened to stumble upon <a href=""https://github.com/gulvarol/grocerydataset"" rel=""noreferrer"">this</a> grocery dataset which consists of images of various brands of cigarette boxes on the supermarket shelf along with a text file which lists out the bounding boxes of each cigarette box in each image. 10 major brands have been labeled in the dataset and all other brands fall into the 11th ""miscellaneous"" category.</p>

<p>I followed their <a href=""https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md"" rel=""noreferrer"">tutorial</a> and managed to train the model on this dataset. Due to limitations on processing power, I used only a third of the dataset and performed a 70:30 split for training and testing data. I used the faster_rcnn_resnet101 model. All parameters in my config file are the same as the default parameters provided by TF.</p>

<p>After 16491 global steps, I tested the model on some images but I am not too happy with the results -</p>

<p><a href=""https://i.stack.imgur.com/vJSm1.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/vJSm1.png"" alt=""""></a>
Failed to detect the Camels in top-shelf whereas it detects the product in other images</p>

<p><a href=""https://i.stack.imgur.com/cc6hV.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cc6hV.jpg"" alt=""""></a>
Why does it fail to detect the Marlboros in the top row?</p>

<p><a href=""https://i.stack.imgur.com/bsiCP.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bsiCP.png"" alt=""""></a>
Another issue I had is that the model never detected any other label except for label 1</p>

<p><a href=""https://i.stack.imgur.com/AKKsx.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/AKKsx.png"" alt=""""></a></p>

<p>Doesn't detected a crop instance of the product from the training data</p>

<p><a href=""https://i.stack.imgur.com/oi4Ax.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/oi4Ax.png"" alt=""""></a></p>

<p>It detects cigarette boxes with 99% confidence even in negative images!</p>

<p>Can somebody help me with what is going wrong? What can I do to improve the accuracy? And why does it detect all products to belong in category 1 even though I have mentioned that there are 11 classes in total?</p>

<p><strong>Edit</strong> Added my label map:</p>

<pre><code>item {
  id: 1
  name: '1'
}

item {
  id: 2
  name: '2'
}

item {
  id: 3
  name: '3'
}

item {
  id: 4
  name: '4'
}

item {
  id: 5
  name: '5'
}

item {
  id: 6
  name: '6'
}

item {
  id: 7
  name: '7'
}

item {
  id: 8
  name: '8'
}

item {
  id: 9
  name: '9'
}

item {
  id: 10
  name: '10'
}

item {
  id: 11
  name: '11'
}
</code></pre>
",3760132.0,,5330223.0,,2018-01-03 07:57:18,2020-04-21 06:11:52,TensorFlow Object Detection API Weird Behavior,<python><machine-learning><tensorflow><classification><object-detection>,5,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45029977
34718736,1,34725458,,2016-01-11 10:06:11,,23,15834,"<p>Consider the following code:</p>

<pre class=""lang-py prettyprint-override""><code>x = tf.placeholder(""float"", shape=[42, 4])
y = tf.zeros([42, 4], ""float"")
xy_stacked = tf.concat(1, [x, y])

print(x.get_shape())
print(y.get_shape())
print(xy_stacked.get_shape())
</code></pre>

<p>This will produce the following output, as expected:</p>

<pre class=""lang-py prettyprint-override""><code>TensorShape([Dimension(42), Dimension(4)])
TensorShape([Dimension(42), Dimension(4)])
TensorShape([Dimension(42), Dimension(8)])
</code></pre>

<p>However, what if the placeholder has a dynamic dimension that is determined at run-time by the value passed to <code>feed_dict=</code>, as placeholders often do:</p>

<pre class=""lang-py prettyprint-override""><code>x = tf.placeholder(""float"", shape=[None, 4])
y = tf.zeros([None, 4], ""float"")
xy_stacked = tf.concat(1, [x, y])
</code></pre>

<p>This will produce an error for <code>tf.zeros([None, 4], ""float"")</code>. Apparently <code>Dimension(None)</code> is not allowed for <code>tf.zeros</code>:</p>

<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-24-277eca38a392&gt; in &lt;module&gt;()
      2 
      3 x = tf.placeholder(""float"", shape=[None, 4])
----&gt; 4 y = tf.zeros([None, 4], ""float"")
      5 xy_stacked = tf.concat(1, [x, y])
      6 
[...]

/usr/local/lib/python3.4/dist-packages/numpy/core/_methods.py in _prod(a, axis, dtype, out, keepdims)
     33 
     34 def _prod(a, axis=None, dtype=None, out=None, keepdims=False):
---&gt; 35     return umr_prod(a, axis, dtype, out, keepdims)
     36 
     37 def _any(a, axis=None, dtype=None, out=None, keepdims=False):

TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'
</code></pre>

<p>I have figured out that it does not produce an error if I set the first dimension of my zeros tensor to non-None, such as 1:</p>

<pre class=""lang-py prettyprint-override""><code>x = tf.placeholder(""float"", shape=[None, 4])
y = tf.zeros([1, 4], ""float"")
xy_stacked = tf.concat(1, [x, y])
</code></pre>

<p>but then the resulting <code>xy_stacked</code> tensor is truncated to this size:</p>

<pre class=""lang-py prettyprint-override""><code>TensorShape([Dimension(None), Dimension(4)])
TensorShape([Dimension(1), Dimension(4)])
TensorShape([Dimension(1), Dimension(8)])
</code></pre>

<p>How can I pad the placeholder tensor with zeros so I get a tensor of shape <code>TensorShape([Dimension(None), Dimension(8)])</code> in this example?</p>

<p>The only ""solutions"" I found so far is either something like the following:</p>

<pre class=""lang-py prettyprint-override""><code>x = tf.placeholder(""float"", shape=[None, 4])
y = 0 * x
xy_stacked = tf.concat(1, [x, y])
</code></pre>

<p>Or simply declaring <code>y</code> as a placeholder and always passing a zero array of the right size.</p>

<p>But neither looks like a clean solution to the problem and hacks like that get out of hand quickly in an application more complex than this simple example..</p>

<p>I'm using <code>tensorflow-0.6.0-py3</code>.</p>
",2213720.0,,1243762.0,,2016-01-11 12:31:14,2017-10-16 01:17:47,Dynamic size for tf.zeros() (for use with placeholders with None dimensions),<tensorflow>,1,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34718736
45226950,1,45231064,,2017-07-21 00:01:41,,23,11452,"<p>I am a beginner in neural nets and TensorFlow, and I am trying to understand the role of <a href=""https://www.tensorflow.org/api_docs/python/tf/contrib/framework/arg_scope"" rel=""noreferrer""><code>arg_scope</code></a>.</p>

<p>It seems to me that it is a way to put together a dictionary of ""things you want to do"" to a certain layer with certain variables. Please correct me if I am wrong. How would you explain exactly what it is for, to a beginner?</p>
",5759234.0,,1735003.0,,2017-07-21 07:00:05,2017-07-21 07:05:18,what does arg_scope actually do?,<python><tensorflow><neural-network><conv-neural-network>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45226950
