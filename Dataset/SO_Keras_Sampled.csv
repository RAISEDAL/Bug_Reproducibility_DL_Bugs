Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense
63886762,1,64376619.0,,2020-09-14 14:52:50,,76,80809,"<p>I am using a very small model for testing purposes using tensorflow 2.3 and keras.
Looking at my terminal, I get the following warning:</p>
<pre><code>I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
</code></pre>
<p>However, the code works as expected. But what does this message mean?</p>
<p>Thanks.</p>
",13804443.0,,13804443.0,,2020-09-14 15:25:08,2022-08-08 16:50:21,Tensorflow: None of the MLIR optimization passes are enabled (registered 1),<python><tensorflow><keras><deep-learning>,3,2,0.0,,,CC BY-SA 4.0
68836551,1,68841446.0,,2021-08-18 17:01:31,,67,158146,"<p>Im attempting to find model performance metrics (F1 score, accuracy, recall) following this guide <a href=""https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/"" rel=""noreferrer"">https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/</a></p>
<p>This exact code was working a few months ago but now returning all sorts of errors, very confusing since i havent changed one character of this code. Maybe a package update has changed things?</p>
<p>I fit the sequential model with model.fit, then used model.evaluate to find test accuracy. Now i am attempting to use model.predict_classes to make class predictions (model is a multi-class classifier). Code shown below:</p>
<pre><code>model = Sequential()
model.add(Dense(24, input_dim=13, activation='relu'))
model.add(Dense(18, activation='relu'))
model.add(Dense(6, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

-

history = model.fit(X_train, y_train, batch_size = 256, epochs = 10, verbose = 2, validation_split = 0.2)

-

score, acc = model.evaluate(X_test, y_test,verbose=2, batch_size= 256)
print('test accuracy:', acc)

-

yhat_classes = model.predict_classes(X_test)
 
</code></pre>
<p>last line returns error &quot;AttributeError: 'Sequential' object has no attribute 'predict_classes'&quot;</p>
<p>This exact code was working not long ago so struggling a bit, thanks for any help</p>
",10377186.0,,,,,2023-02-21 13:22:51,Keras AttributeError: 'Sequential' object has no attribute 'predict_classes',<python><keras>,10,1,0.0,,,CC BY-SA 4.0
72326025,1,,,2022-05-21 01:28:00,,48,91258,"<p>i'm trying to import these :</p>
<pre><code>from numpy import array
from keras.preprocessing.text import one_hot

from keras.preprocessing.sequence import pad_sequences


from keras.models import Sequential
from keras.layers.core import Activation, Dropout, Dense
from keras.layers import Flatten, LSTM
from keras.layers import GlobalMaxPooling1D
from keras.models import Model
</code></pre>
<p>But i'm getting error as cannot import name 'pad_sequences' from 'keras.preprocessing.sequence'</p>
<p>Can anyone help me here please?</p>
",15460921.0,,9747182.0,,2022-05-21 17:25:41,2023-04-17 02:18:12,cannot import name 'pad_sequences' from 'keras.preprocessing.sequence',<python><keras><python-import>,7,0,0.0,,,CC BY-SA 4.0
66964492,1,67599606.0,,2021-04-06 07:34:31,,41,154835,"<p>My notebook was working up till today. At the beginning of my colab notebook I install tf-nightly, but now it is giving me this error:</p>
<pre><code>---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-1-589c442233c5&gt; in &lt;module&gt;()
      7 import tensorflow as tf
      8 from tensorflow.keras import datasets, layers, models
----&gt; 9 from keras.preprocessing import image
     10 from keras_preprocessing.image import ImageDataGenerator #check underscore or not
     11 from tensorflow.keras.preprocessing import image_dataset_from_directory

2 frames
/usr/local/lib/python3.7/dist-packages/keras/backend.py in &lt;module&gt;()
     35 from tensorflow.python.distribute import distribute_coordinator as dc
     36 from tensorflow.python.distribute import distribute_coordinator_context as dc_context
---&gt; 37 from tensorflow.python.eager.context import get_config
     38 from tensorflow.python.framework import config
     39 from keras import backend_config

ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/context.py)
</code></pre>
<p>My code:</p>
<pre><code>!pip install tf-nightly

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from keras.preprocessing import image
from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image_dataset_from_directory
from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
</code></pre>
<p>Installing tensorflow==2.1.0 did not work either.</p>
",5111234.0,,365102.0,,2022-04-19 02:17:06,2022-10-31 07:13:59,ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context',<python><tensorflow><keras>,15,2,0.0,,,CC BY-SA 4.0
67703871,1,,,2021-05-26 11:22:19,,33,74958,"<p>I have just got below error from an import that use to work fine few hours ago going downward.</p>
<pre><code>---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-33-4c52b67c20bf&gt; in &lt;module&gt;()
      1 import keras
----&gt; 2 from keras.utils import to_categorical

ImportError: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)

---------------------------------------------------------------------------
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
&quot;Open Examples&quot; button below.
---------------------------------------------------------------------------
</code></pre>
<p>Is Keras busy with Update to have this method deprecated?</p>
<p><a href=""https://i.stack.imgur.com/LHsm9.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/LHsm9.png"" alt=""enter image description here"" /></a></p>
",15946347.0,,4420967.0,,2021-05-26 14:12:50,2022-04-04 22:51:36,ImportError: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py),<tensorflow><keras><python-import>,1,0,0.0,,,CC BY-SA 4.0
67018079,1,67018610.0,,2021-04-09 08:58:22,,33,92540,"<p>I have probem with this code , why ?</p>
<p>the code :</p>
<pre><code>import cv2
import numpy as np
from PIL import Image
import os
import numpy as np
import cv2
import os
import h5py
import dlib
from imutils import face_utils
from keras.models import load_model
import sys
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D,Dropout
from keras.layers import Dense, Activation, Flatten
from keras.utils import to_categorical
from keras import backend as K 
from sklearn.model_selection import train_test_split
from Model import model
from keras import callbacks

# Path for face image database
path = 'dataset'

recognizer = cv2.face.LBPHFaceRecognizer_create()
detector = cv2.CascadeClassifier(&quot;haarcascade_frontalface_default.xml&quot;);


def downsample_image(img):
    img = Image.fromarray(img.astype('uint8'), 'L')
    img = img.resize((32,32), Image.ANTIALIAS)
    return np.array(img)



# function to get the images and label data
def getImagesAndLabels(path):
    
    path = 'dataset'
    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     
    faceSamples=[]
    ids = []

    for imagePath in imagePaths:
        
        #if there is an error saving any jpegs
        try:
            PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale
        except:
            continue    
        img_numpy = np.array(PIL_img,'uint8')

        id = int(os.path.split(imagePath)[-1].split(&quot;.&quot;)[1])
        faceSamples.append(img_numpy)
        ids.append(id)
    return faceSamples,ids

print (&quot;\n [INFO] Training faces now.&quot;)
faces,ids = getImagesAndLabels(path)

K.clear_session()
n_faces = len(set(ids))
model = model((32,32,1),n_faces)
faces = np.asarray(faces)
faces = np.array([downsample_image(ab) for ab in faces])
ids = np.asarray(ids)
faces = faces[:,:,:,np.newaxis]
print(&quot;Shape of Data: &quot; + str(faces.shape))
print(&quot;Number of unique faces : &quot; + str(n_faces))


ids = to_categorical(ids)

faces = faces.astype('float32')
faces /= 255.

x_train, x_test, y_train, y_test = train_test_split(faces,ids, test_size = 0.2, random_state = 0)

checkpoint = callbacks.ModelCheckpoint('trained_model.h5', monitor='val_acc',
                                           save_best_only=True, save_weights_only=True, verbose=1)
                                    
model.fit(x_train, y_train,
             batch_size=32,
             epochs=10,
             validation_data=(x_test, y_test),
             shuffle=True,callbacks=[checkpoint])
             

# Print the numer of faces trained and end program
print(&quot;enter code here`\n [INFO] &quot; + str(n_faces) + &quot; faces trained. Exiting Program&quot;)
</code></pre>
<hr />
<pre><code>the output:
------------------
File &quot;D:\my hard sam\ماجستير\سنة ثانية\البحث\python\Real-Time-Face-Recognition-Using-CNN-master\Real-Time-Face-Recognition-Using-CNN-master\02_face_training.py&quot;, line 16, in &lt;module&gt;
    from keras.utils import to_categorical
ImportError: cannot import name 'to_categorical' from 'keras.utils' (C:\Users\omar\PycharmProjects\SnakGame\venv\lib\site-packages\keras\utils\__init__.py)
</code></pre>
",15558831.0,,9215780.0,,2021-04-09 09:01:26,2022-03-03 11:32:17,"Error in ""from keras.utils import to_categorical""",<python><keras>,4,3,0.0,,,CC BY-SA 4.0
66741778,1,,,2021-03-22 07:24:23,,32,13585,"<p>I have an M1 MacBook. I have installed python 3.9.1 using pyenv, and have pip3 version 21.0.1.
I have installed homebrew and hdf5 1.12.0_1 via <code>brew install hdf5</code>.</p>
<p>When I type</p>
<pre><code>pip3 install h5py
</code></pre>
<p>I get the error:</p>
<pre><code>Requirement already satisfied: numpy&gt;=1.19.3 in /Users/.../.pyenv/versions/3.9.1/lib/python3.9/site-packages (from h5py) (1.20.0)
Building wheels for collected packages: h5py
  Building wheel for h5py (PEP 517) ... error

  Loading library to get build settings and version: libhdf5.dylib
  error: Unable to load dependency HDF5, make sure HDF5 is installed properly
  error: dlopen(libhdf5.dylib, 6): image not found
  ----------------------------------------
  ERROR: Failed building wheel for h5py
</code></pre>
<p>I saw that <code>libhdf5.dylib</code> is present in <code>/opt/homebrew/opt/hdf5/lib</code>, so I tried <code>export LDFLAGS=&quot;-L/opt/homebrew/opt/hdf5/lib&quot;</code> and <code>export CPPFLAGS=&quot;-L/opt/homebrew/opt/hdf5/include&quot;</code> beforehand but they don't help.</p>
<p>How can I install h5py?</p>
<p>I am actually installing h5py as a requirement to install Keras.</p>
<p>Thanks!</p>
",905720.0,,,,,2023-04-02 00:06:32,How to install h5py (needed for Keras) on MacOS with M1?,<python><keras><hdf5><h5py><apple-m1>,3,1,0.0,,,CC BY-SA 4.0
69471749,1,69472316.0,,2021-10-06 19:36:38,,30,84199,"<p>i have an import problem when executing my code:</p>
<pre><code>from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
</code></pre>
<pre><code>2021-10-06 22:27:14.064885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-10-06 22:27:14.064974: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File &quot;C:\Data\breast-cancer-classification\train_model.py&quot;, line 10, in &lt;module&gt;
    from cancernet.cancernet import CancerNet
  File &quot;C:\Data\breast-cancer-classification\cancernet\cancernet.py&quot;, line 2, in &lt;module&gt;
    from keras.layers.normalization import BatchNormalization
ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (C:\Users\Catalin\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\layers\normalization\__init__.py)
</code></pre>
<ul>
<li>Keras version: 2.6.0</li>
<li>Tensorflow: 2.6.0</li>
<li>Python version: 3.9.7</li>
</ul>
<p>The library it is installed also with</p>
<pre><code>pip install numpy opencv-python pillow tensorflow keras imutils scikit-learn matplotlib
</code></pre>
<p>Do you have any ideas?</p>
<p><a href=""https://i.stack.imgur.com/Qup45.png"" rel=""noreferrer"">library path</a></p>
",8483107.0,,4685471.0,,2021-10-09 23:36:29,2021-11-13 07:14:12,ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization',<python><tensorflow><keras>,2,1,0.0,,,CC BY-SA 4.0
69783897,1,69788484.0,,2021-10-31 04:13:28,,27,33109,"<p>The classifier script I wrote is working fine and recently added weight balancing to the fitting. Since I added the weight estimate function using 'sklearn' library I get the following error :</p>
<pre><code>compute_class_weight() takes 1 positional argument but 3 were given
</code></pre>
<p>This error does not make sense per documentation. The script should have three inputs but not sure why it says expecting only one variable. Full error and code information is shown below. Apparently, this is failing only in VS code. I tested in the Jupyter notebook and working fine. So it seems an issue with VS code compiler. Any one notice? ( I am using Python 3.8 with other latest other libraries)</p>
<pre><code>from sklearn.utils import compute_class_weight

train_classes = train_generator.classes

class_weights = compute_class_weight(
                                        &quot;balanced&quot;,
                                        np.unique(train_classes),
                                        train_classes                                                    
                                    )
class_weights = dict(zip(np.unique(train_classes), class_weights)),
class_weights
</code></pre>
<p>In Jupyter Notebook,</p>
<p><a href=""https://i.stack.imgur.com/r35GZ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/r35GZ.png"" alt=""enter image description here"" /></a></p>
<p><a href=""https://i.stack.imgur.com/zBnqH.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/zBnqH.png"" alt=""enter image description here"" /></a></p>
",7788402.0,,7788402.0,,2021-10-31 16:06:10,2023-01-25 20:39:20,"Compute class weight function issue in 'sklearn' library when used in 'Keras' classification (Python 3.8, only in VS code)",<python><keras><scikit-learn><classification>,4,0,0.0,,,CC BY-SA 4.0
63006575,1,63008981.0,,2020-07-21 02:44:40,,27,13430,"<p>I just started working with <a href=""/questions/tagged/keras"" class=""post-tag"" title=""show questions tagged &#39;keras&#39;"" rel=""tag"">keras</a> and noticed that there are two layers with very similar names for max-pooling: <code>MaxPool</code> and <code>MaxPooling</code>. I was surprised that I couldn't find the difference between these two on Google; so I am wondering what the difference is between the two if any.</p>
",11502399.0,,10375049.0,,2022-01-13 08:47:18,2022-08-10 18:27:55,What is the difference between MaxPool and MaxPooling layers in Keras?,<python><tensorflow><machine-learning><keras><deep-learning>,3,0,0.0,,,CC BY-SA 4.0
63390725,1,63481422.0,,2020-08-13 08:04:12,,27,8416,"<p>I'm learning keras API in tensorflow(2.3). In this <a href=""https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_losses"" rel=""noreferrer"">guide</a> on tensorflow website, I found an example of custom loss funciton:</p>
<pre><code>    def custom_mean_squared_error(y_true, y_pred):
        return tf.math.reduce_mean(tf.square(y_true - y_pred))
</code></pre>
<p>The <code>reduce_mean</code> function in this custom loss function will return an scalar.</p>
<p>Is it right to define loss function like this? As far as I know, the first dimension of the shapes of <code>y_true</code> and <code>y_pred</code> is the batch size. I think the loss function should return loss values for every sample in the batch. So the loss function shoud give an array of shape <code>(batch_size,)</code>. But the above function gives a single value for the whole batch.</p>
<p>Maybe the above example is wrong? Could anyone give me some help on this problem?</p>
<hr />
<p>p.s. <strong>Why do I think the loss function should return an array rather than a single value?</strong></p>
<p>I read the source code of <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/engine/training.py#L159-L2634"" rel=""noreferrer"">Model</a> class. When you provide a loss function (please note it's a <strong>function</strong>, not a loss <strong>class</strong>) to <code>Model.compile()</code> method, ths loss function is used to construct a <code>LossesContainer</code> object, which is stored in <code>Model.compiled_loss</code>. This loss function passed to the constructor of <code>LossesContainer</code> class is used once again to construct a <code>LossFunctionWrapper</code> object, which is stored in <code>LossesContainer._losses</code>.</p>
<p><strong>According to the source code of <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/losses.py"" rel=""noreferrer"">LossFunctionWrapper</a> class, the overall loss value for a training batch is calculated by the <code>LossFunctionWrapper.__call__()</code> method (inherited from <code>Loss</code> class), i.e. it returns a single loss value for the whole batch.</strong> But the <code>LossFunctionWrapper.__call__()</code> first calls the <code>LossFunctionWrapper.call()</code> method to obtain an array of losses for every sample in the training batch. Then these losses are fianlly averaged to get the single loss value for the whole batch. It's in the <code>LossFunctionWrapper.call()</code> method that the loss function provided to the <code>Model.compile()</code> method is called.</p>
<p>That's why I think the custom loss funciton should return an array of losses, insead of a single scalar value. Besides, if we write a custom <code>Loss</code> class for the <code>Model.compile()</code> method, the <code>call()</code> method of our custom <code>Loss</code> class should also return an array, rather than a signal value.</p>
<hr />
<p>I opened an <a href=""https://github.com/tensorflow/tensorflow/issues/42446"" rel=""noreferrer"">issue</a> on github. It's confirmed that custom loss function is required to return one loss value per sample. The example will need to be updated to reflect this.</p>
",4151926.0,,2099607.0,,2020-08-19 07:04:41,2022-12-19 12:56:21,Should the custom loss function in Keras return a single loss value for the batch or an arrary of losses for every sample in the training batch?,<tensorflow><machine-learning><keras><tensorflow2.0><loss-function>,7,0,0.0,,,CC BY-SA 4.0
63068639,1,63085142.0,,2020-07-24 07:14:19,,24,44442,"<p>I made a CNN in colab and saved the models at every epoch. I exported the h5 file and now am trying to run the model on some test images. Here's the main error:</p>
<pre><code>ValueError: Unknown layer: Functional
</code></pre>
<p>Here's the code I used to run the model and save at each epoch:</p>
<pre><code>epochs = 50

callbacks = [
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
    keras.callbacks.ModelCheckpoint(&quot;save_at_{epoch}.h5&quot;),
]
model.compile(
    optimizer=keras.optimizers.Adam(1e-3),
    loss=&quot;binary_crossentropy&quot;,
    metrics=[&quot;accuracy&quot;],
)
model.fit(
    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,
)
</code></pre>
<p>After the model ran I just downloaded the h5 file from the colab sidebar locally. I re-uploaded the file from the local disk, and here's how I'm trying to load the model:</p>
<pre><code># load and evaluate a saved model
from tensorflow.keras.models import load_model

# load model#
loaded_model = load_model('save_at_47.h5')
loaded_model.layers[0].input_shape
</code></pre>
<p>Here's the full traceback:</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-4-6af7396280fa&gt; in &lt;module&gt;()
      3 
      4 # load model#
----&gt; 5 loaded_model = load_model('save_at_47.h5')
      6 loaded_model.layers[0].input_shape

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    182     if (h5py is not None and (
    183         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--&gt; 184       return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
    185 
    186     if sys.version_info &gt;= (3, 4) and isinstance(filepath, pathlib.Path):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    176     model_config = json.loads(model_config.decode('utf-8'))
    177     model = model_config_lib.model_from_config(model_config,
--&gt; 178                                                custom_objects=custom_objects)
    179 
    180     # set weights

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)
     53                     '`Sequential.from_config(config)`?')
     54   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
---&gt; 55   return deserialize(config, custom_objects=custom_objects)
     56 
     57 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    107       module_objects=globs,
    108       custom_objects=custom_objects,
--&gt; 109       printable_module_name='layer')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    360     config = identifier
    361     (cls, cls_config) = class_and_config_for_serialized_keras_object(
--&gt; 362         config, module_objects, custom_objects, printable_module_name)
    363 
    364     if hasattr(cls, 'from_config'):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
    319   cls = get_registered_object(class_name, custom_objects, module_objects)
    320   if cls is None:
--&gt; 321     raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
    322 
    323   cls_config = config['config']

ValueError: Unknown layer: Functional
</code></pre>
<p>It seems there have been several similar <a href=""https://stackoverflow.com/questions/53051274/i-trained-a-keras-model-on-google-colab-now-not-able-to-load-it-locally-on-my-s"">questions here</a>,and <a href=""https://stackoverflow.com/questions/53183865/unknown-initializer-glorotuniform-when-loading-keras-model"">here</a>. Changing the import method hasn't helped yet, and trying to make some <a href=""https://stackoverflow.com/questions/54286368/valueerror-unknown-layername-when-loading-a-keras-model"">kind of custom</a> object has not worked either.</p>
",10777776.0,,10777776.0,,2020-07-24 07:33:42,2022-04-06 06:38:54,ValueError: Unknown layer: Functional,<python><tensorflow><keras>,7,8,0.0,,,CC BY-SA 4.0
67905185,1,,,2021-06-09 13:32:37,,24,60442,"<p>I tried to run <a href=""https://github.com/matterport/Mask_RCNN"" rel=""noreferrer"">matterport/MaskRCNN</a> code but faced the following error</p>
<pre><code>----&gt; 6 from mrcnn.model import MaskRCNN

/usr/local/lib/python3.7/dist-packages/mrcnn/model.py in &lt;module&gt;()
    253 
    254 
--&gt; 255 class ProposalLayer(KE.Layer):
    256     &quot;&quot;&quot;Receives anchor scores and selects a subset to pass as proposals
    257     to the second stage. Filtering is done based on anchor scores and

AttributeError: module 'keras.engine' has no attribute 'Layer'
</code></pre>
",15376965.0,,9215780.0,,2022-06-26 09:32:29,2023-03-16 15:25:21,module 'keras.engine' has no attribute 'Layer',<python><machine-learning><keras><conv-neural-network><artificial-intelligence>,12,0,0.0,,,CC BY-SA 4.0
67703817,1,,,2021-05-26 11:18:32,,23,39056,"<p>When I run this line in my code,</p>
<p><code>from keras.utils import plot_model</code></p>
<p>I get the following:</p>
<pre><code>&quot;ImportError: cannot import name 'plot_model' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)&quot;
</code></pre>
<p>When I went to bed last night it was working. This morning it throws an error. What happened and what should I do? Thank you.
Any suggestion would be appreciated</p>
",15975596.0,,5602871.0,,2021-05-27 15:37:14,2022-03-14 20:56:25,Can't import plot_model from keras.utils?,<python><keras>,4,0,0.0,,,CC BY-SA 4.0
72383347,1,,,2022-05-25 19:43:07,,22,65882,"<pre><code>    import numpy as np
    from keras.preprocessing import image
    import matplotlib.pyplot as plt
    import matplotlib.image as mpimg
    import matplotlib.pyplot as plt
    import matplotlib.image as mpimg
    
    
    %matplotlib inline
    
    
    
    path = './test/paper2.png'
    
    img = image.load_img(path, target_size=(150,150))
    imgplot = plt.imshow(img)
    x = image.img_to_array(img)
    img_test = np.expand_dims(x, axis=0)
    
    classes = model.predict(img_test, batch_size=10)
    
    print(classes)
    paper, rock, scissors = classes[0]
    
    if paper==1.:
        print('paper')
    elif rock==1.:
        print('rock')
    else:
        print('scissors')

</code></pre>
<p>output :</p>
<hr />
<pre><code>AttributeError: module 'keras.preprocessing.image' has no attribute 'load_img'
</code></pre>
<p>when I try to run. What does the error mean and how can I fix it?
help guys :)
I'm trying to learn
I don't know anymore which one is wrong</p>
",19201072.0,,19201072.0,,2022-05-25 21:31:39,2023-02-24 14:19:19,HOW TO FIX IT? AttributeError: module 'keras.preprocessing.image' has no attribute 'load_img',<python><tensorflow><keras><jupyter-lab><image-preprocessing>,13,1,0.0,,,CC BY-SA 4.0
63279168,1,63300341.0,,2020-08-06 07:55:53,,22,61335,"<p>I keep on getting this error related to input shape. Any help would be highly appreciated. Thanks!</p>
<pre><code>import tensorflow as tf

(xtrain, ytrain), (xtest, ytest) = tf.keras.datasets.mnist.load_data()

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
    ])

model.compile(loss='categorical_crossentropy', 
              optimizer='adam',
              metrics='accuracy')

history = model.fit(xtrain, ytrain,
                    validation_data=(xtest, ytest),
                    epochs=10, batch_size=8)
</code></pre>
<blockquote>
<p>ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [8, 28, 28]</p>
</blockquote>
",11144416.0,,10908375.0,,2021-01-13 14:58:57,2022-03-01 15:29:45,"ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [8, 28, 28]",<python><tensorflow><keras><deep-learning>,3,0,0.0,,,CC BY-SA 4.0
62948332,1,62949137.0,,2020-07-17 06:28:31,,21,10156,"<p>I am developing a Bi-LSTM model and want to add a attention layer to it. But I am not getting how to add it.</p>
<p>My current code for the model is</p>
<pre><code>model = Sequential()
model.add(Embedding(max_words, 1152, input_length=max_len, weights=[embeddings]))
model.add(BatchNormalization())
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Bidirectional(LSTM(32)))
model.add(BatchNormalization())
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))
model.summary()
</code></pre>
<p>And the model summary is</p>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 1152, 1152)        278396928 
_________________________________________________________________
batch_normalization_1 (Batch (None, 1152, 1152)        4608      
_________________________________________________________________
activation_1 (Activation)    (None, 1152, 1152)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 1152, 1152)        0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, 64)                303360    
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 65        
=================================================================
Total params: 278,705,217
Trainable params: 278,702,785
Non-trainable params: 2,432
</code></pre>
",10097229.0,,10375049.0,,2020-10-06 16:44:40,2021-06-24 18:02:36,How to add attention layer to a Bi-LSTM,<python-3.x><tensorflow><machine-learning><keras><nlp>,2,0,0.0,,,CC BY-SA 4.0
72043662,1,,,2022-04-28 12:25:43,,20,33882,"<p>I get an error when I import the TensorFlow. I tried to reinstall it but still, I keep getting this error---&gt; TypeError: Unable to convert function return value to a Python type! The signature was    () -&gt; handle.</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Add, Input, Dense, Dropout
from tensorflow.keras.layers import BatchNormalization, Embedding
from tensorflow.keras.layers import Flatten, Concatenate
from tensorflow.keras import regularizers
from keras.regularizers import l1
from keras.regularizers import l2
from tensorflow.keras import regularizers
from keras.models import Sequential
from keras.wrappers.scikit_learn import KerasClassifier
</code></pre>
",17300752.0,,,,,2023-04-09 23:00:31,TypeError: Unable to convert function return value to a Python type! The signature was () -> handle,<python><tensorflow><keras><import>,3,2,0.0,,,CC BY-SA 4.0
71316443,1,,,2022-03-02 01:25:17,,18,37681,"<pre><code>import tensorflow as tf
tf.__version__

!sudo pip3 install keras

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
</code></pre>
<p>Error message:</p>
<pre><code>Import &quot;tensorflow.keras.models&quot; could not be resolved(reportMissingImports)
&gt;Import &quot;tensorflow.keras.layers&quot; could not be resolved(reportMissingImports)
&gt;&gt;Import &quot;tensorflow.keras.preprocessing.image&quot; could not be resolved(reportMissingImports)
</code></pre>
",18348977.0,,1367454.0,,2022-03-02 01:26:46,2023-06-23 13:39:48,"Google Colab error: Import ""tensorflow.keras.models"" could not be resolved(reportMissingImports)",<python><tensorflow><keras>,7,3,,,,CC BY-SA 4.0
67604780,1,67605337.0,,2021-05-19 14:02:44,,17,80337,"<p><strong>Trying to run---</strong><br />
<code>from keras.optimizers import SGD, Adam</code>,<br />
<strong>I get this error---</strong></p>
<blockquote>
<p>Traceback (most recent call last):<br />
  File &quot;C:\Users\usn\Downloads\CNN-Image-Denoising-master ------after the stopping\CNN-Image-Denoising-master\CNN_Image_Denoising.py&quot;, line 15, in &lt;module&gt;<br />
    from keras.optimizers import SGD, Adam<br />
ImportError: cannot import name 'SGD' from 'keras.optimizers'</p>
</blockquote>
<p><strong>as well as this error, if I remove the SGD from import statement---</strong></p>
<blockquote>
<p>ImportError: cannot import name 'Adam' from 'keras.optimizers'</p>
</blockquote>
<p>I can't find a single solution for this.<br />
I have Keras and TensorFlow installed. I tried running the program in a virtualenv (no idea how that would help, but a guide similar to what I want mentioned it) but it still doesn't work. If anything, virtualenv makes it worse because it doesn't recognize any of the installed modules. I am using Python 3.9. Running the program in cmd because all the IDEs just create more trouble.</p>
<p>I am stumped. My knowledge of Python is extremely basic; I just found this thing on GitHub. Any help would be greatly appreciated.</p>
",14890835.0,,3789665.0,,2021-05-19 15:09:51,2022-02-21 00:50:09,Unable to import SGD and Adam from 'keras.optimizers',<python><tensorflow><keras>,5,0,0.0,,,CC BY-SA 4.0
71153492,1,,,2022-02-17 06:37:59,,17,104298,"<p>I'm having multiple errors while running this VGG training code (code and errors shown below). I don't know if its because of my dataset or is it something else.</p>
<pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics.pairwise import cosine_similarity
import os
import scipy

train_directory = 'sign_data/train' #To be changed
test_directory = 'sign_data/test' #To be changed

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 0.1,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    shear_range = 0.1
)

train_generator = train_datagen.flow_from_directory(
    train_directory,
    target_size = (224, 224),
    color_mode = 'rgb',
    shuffle = True,
    batch_size=32
    
)


test_datagen = ImageDataGenerator(
    rescale = 1./255,
)

test_generator = test_datagen.flow_from_directory(
    test_directory,
    target_size = (224, 224),
    color_mode = 'rgb',
    shuffle = True,
    batch_size=32
)

from tensorflow.keras.applications.vgg16 import VGG16   
vgg_basemodel = VGG16(include_top=True)

from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)

vgg_model = tf.keras.Sequential(vgg_basemodel.layers[:-1])
vgg_model.add(tf.keras.layers.Dense(10, activation = 'softmax'))

# Freezing original layers
for layer in vgg_model.layers[:-1]:
    layer.trainable = False

vgg_model.compile(loss='categorical_crossentropy',
                  optimizer=tf.keras.optimizers.SGD(momentum=0.9, learning_rate=0.001, decay=0.01),
                  metrics=['accuracy'])

history = vgg_model.fit(train_generator,
              epochs=30,
              batch_size=64,
              validation_data=test_generator,
              callbacks=[early_stopping])

# finetuning with all layers set trainable

for layer in vgg_model.layers:
    layer.trainable = True

vgg_model.compile(loss='categorical_crossentropy',
                  optimizer=tf.keras.optimizers.SGD(momentum=0.9, lr=0.0001),
                  metrics=['accuracy'])

history2 = vgg_model.fit(train_generator,
              epochs=5,
              batch_size=64,
              validation_data=test_generator,
              callbacks=[early_stopping])

vgg_model.save('saved_models/vgg_finetuned_model')
</code></pre>
<p>First error: Invalid Argument Error</p>
<pre><code>    InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-13-292bf57ef59f&gt; in &lt;module&gt;()
     14               batch_size=64,
     15               validation_data=test_generator,
---&gt; 16               callbacks=[early_stopping])
     17 
     18 # finetuning with all layers set trainable

    /usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---&gt; 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     53     ctx.ensure_initialized()
     54     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---&gt; 55                                         inputs, attrs, num_outputs)
     56   except core._NotOkStatusException as e:
     57     if name is not None:
</code></pre>
<p>Second Error: Graph Execution Error</p>
<pre><code>    InvalidArgumentError: Graph execution error:
Detected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):
    File &quot;/usr/lib/python3.7/runpy.py&quot;, line 193, in _run_module_as_main
      &quot;__main__&quot;, mod_spec)
    File &quot;/usr/lib/python3.7/runpy.py&quot;, line 85, in _run_code
      exec(code, run_globals)
    File &quot;/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py&quot;, line 16, in &lt;module&gt;
      app.launch_new_instance()
    File &quot;/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py&quot;, line 846, in launch_instance
      app.start()
    File &quot;/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py&quot;, line 499, in start
      self.io_loop.start()
    File &quot;/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py&quot;, line 132, in start
      self.asyncio_loop.run_forever()
    File &quot;/usr/lib/python3.7/asyncio/base_events.py&quot;, line 541, in run_forever
      self._run_once()
    File &quot;/usr/lib/python3.7/asyncio/base_events.py&quot;, line 1786, in _run_once
      handle._run()
    File &quot;/usr/lib/python3.7/asyncio/events.py&quot;, line 88, in _run
      self._context.run(self._callback, *self._args)
    File &quot;/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py&quot;, line 122, in _handle_events
      handler_func(fileobj, events)
    File &quot;/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py&quot;, line 300, in null_wrapper
      return fn(*args, **kwargs)
    File &quot;/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py&quot;, line 452, in _handle_events
      self._handle_recv()
    File &quot;/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py&quot;, line 481, in _handle_recv
      self._run_callback(callback, msg)
    File &quot;/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py&quot;, line 431, in _run_callback
      callback(*args, **kwargs)
    File &quot;/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py&quot;, line 300, in null_wrapper
      return fn(*args, **kwargs)
    File &quot;/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py&quot;, line 283, in dispatcher
      return self.dispatch_shell(stream, msg)
    File &quot;/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py&quot;, line 233, in dispatch_shell
      handler(stream, idents, msg)
    File &quot;/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py&quot;, line 399, in execute_request
      user_expressions, allow_stdin)
    File &quot;/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py&quot;, line 208, in do_execute
      res = shell.run_cell(code, store_history=store_history, silent=silent)
    File &quot;/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py&quot;, line 537, in run_cell
      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
    File &quot;/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py&quot;, line 2718, in run_cell
      interactivity=interactivity, compiler=compiler, result=result)
    File &quot;/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py&quot;, line 2822, in run_ast_nodes
      if self.run_code(code, result):
    File &quot;/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py&quot;, line 2882, in run_code
      exec(code_obj, self.user_global_ns, self.user_ns)
    File &quot;&lt;ipython-input-13-292bf57ef59f&gt;&quot;, line 16, in &lt;module&gt;
      callbacks=[early_stopping])
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py&quot;, line 64, in error_handler
      return fn(*args, **kwargs)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 1384, in fit
      tmp_logs = self.train_function(iterator)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 1021, in train_function
      return step_function(self, iterator)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 1010, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 1000, in run_step
      outputs = model.train_step(data)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 860, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/training.py&quot;, line 919, in compute_loss
      y, y_pred, sample_weight, regularization_losses=self.losses)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py&quot;, line 201, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/losses.py&quot;, line 141, in __call__
      losses = call_fn(y_true, y_pred)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/losses.py&quot;, line 245, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/losses.py&quot;, line 1790, in categorical_crossentropy
      y_true, y_pred, from_logits=from_logits, axis=axis)
    File &quot;/usr/local/lib/python3.7/dist-packages/keras/backend.py&quot;, line 5099, in categorical_crossentropy
      labels=target, logits=output, axis=axis)
Node: 'categorical_crossentropy/softmax_cross_entropy_with_logits'
logits and labels must be broadcastable: logits_size=[32,10] labels_size=[32,128]
     [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_11227]
</code></pre>
<p>I'm running this on google colaboratory. Is there a module that I should install? Or is it purely an error on the code itself?</p>
",15336528.0,,15336528.0,,2022-02-17 06:56:02,2023-03-12 14:48:32,Invalid Argument Error / Graph Execution Error,<python><tensorflow><keras>,6,4,0.0,,,CC BY-SA 4.0
64687375,1,64689000.0,,2020-11-04 20:37:05,,17,28286,"<p>I wrote a simple CNN using tensorflow (v2.4) + keras in python (v3.8.3). I am trying to optimize the network, and I want more info on what it is failing to predict. I am trying to add a confusion matrix, and I need to feed tensorflow.math.confusion_matrix() the test labels.</p>
<p>My problem is that I cannot figure out how to access the labels from the dataset object created by tf.keras.preprocessing.image_dataset_from_directory()</p>
<p>My images are organized in directories having the label as the name. The documentation says the function returns a tf.data.Dataset object.</p>
<blockquote>
<pre><code>If label_mode is None, it yields float32 tensors of shape (batch_size, image_size[0], image_size[1], num_channels), encoding
</code></pre>
<p>images (see below for rules regarding num_channels).
Otherwise, it yields a tuple (images, labels), where images has shape (batch_size, image_size[0], image_size[1], num_channels), and
labels follows the format described below.</p>
</blockquote>
<p>Here is the code:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras import layers
#import matplotlib.pyplot as plt
import numpy as np
import random

import PIL
import PIL.Image

import os
import pathlib

#load the IMAGES
dataDirectory = '/p/home/username/tensorflow/newBirds'

dataDirectory = pathlib.Path(dataDirectory)
imageCount = len(list(dataDirectory.glob('*/*.jpg')))
print('Image count: {0}\n'.format(imageCount))

#test display an image
# osprey = list(dataDirectory.glob('OSPREY/*'))
# ospreyImage = PIL.Image.open(str(osprey[random.randint(1,100)]))
# ospreyImage.show()

# nFlicker = list(dataDirectory.glob('NORTHERN FLICKER/*'))
# nFlickerImage = PIL.Image.open(str(nFlicker[random.randint(1,100)]))
# nFlickerImage.show()

#set parameters
batchSize = 32
height=224
width=224

(trainData, trainLabels) = tf.keras.preprocessing.image_dataset_from_directory(
    dataDirectory,
    labels='inferred',
    label_mode='categorical',
    validation_split=0.2,
    subset='training',
    seed=324893,
    image_size=(height,width),
    batch_size=batchSize)

testData = tf.keras.preprocessing.image_dataset_from_directory(
    dataDirectory,
    labels='inferred',
    label_mode='categorical',
    validation_split=0.2,
    subset='validation',
    seed=324893,
    image_size=(height,width),
    batch_size=batchSize)

#class names and sampling a few images
classes = trainData.class_names
testClasses = testData.class_names
#plt.figure(figsize=(10,10))
# for images, labels in trainData.take(1):
#     for i in range(9):
#         ax = plt.subplot(3, 3, i+1)
#         plt.imshow(images[i].numpy().astype(&quot;uint8&quot;))
#         plt.title(classes[labels[i]])
#         plt.axis(&quot;off&quot;)
# plt.show()

#buffer to hold the data in memory for faster performance
autotune = tf.data.experimental.AUTOTUNE
trainData = trainData.cache().shuffle(1000).prefetch(buffer_size=autotune)
testData = testData.cache().prefetch(buffer_size=autotune)

#augment the dataset with zoomed and rotated images
#use convolutional layers to maintain spatial information about the images
#use max pool layers to reduce
#flatten and then apply a dense layer to predict classes
model = tf.keras.Sequential([
    #layers.experimental.preprocessing.RandomFlip('horizontal', input_shape=(height, width, 3)),
    #layers.experimental.preprocessing.RandomRotation(0.1),
    #layers.experimental.preprocessing.RandomZoom(0.1),
    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(height, width, 3)),
    layers.Conv2D(16, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(256, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    # layers.Conv2D(512, 3, padding='same', activation='relu'),
    # layers.MaxPooling2D(),
    #layers.Conv2D(1024, 3, padding='same', activation='relu'),
    #layers.MaxPooling2D(),
    #dropout prevents overtraining by not allowing each node to see each datapoint
    #layers.Dropout(0.5),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dense(len(classes))
    ])

model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.summary()
    
epochs=2
history = model.fit(
    trainData,
    validation_data=testData,
    epochs=epochs
    )

#create confusion matrix
predictions = model.predict_classes(testData)
confusionMatrix = tf.math.confusion_matrix(labels=testClasses, predictions=predictions).numpy()
</code></pre>
<p>I have tried using (foo, foo1) = tf.keras.preprocessing.image_dataset_from_directory(dataDirectory, etc), but I get
(trainData, trainLabels) = tf.keras.preprocessing.image_dataset_from_directory(
ValueError: too many values to unpack (expected 2)</p>
<p>And if I try to return as one variable and then split it as so:</p>
<pre><code>train = tf.keras.preprocessing.image_dataset_from_directory(
    dataDirectory,
    labels='inferred',
    label_mode='categorical',
    validation_split=0.2,
    subset='training',
    seed=324893,
    image_size=(height,width),
    batch_size=batchSize)
trainData = train[0]
trainLabels = train[1]
</code></pre>
<p>I get TypeError: 'BatchDataset' object is not subscriptable</p>
<p>I can access the labels via testClasses = testData.class_names, but I get:</p>
<blockquote>
<p>2020-11-03 14:15:14.643300: W
tensorflow/core/framework/op_kernel.cc:1740] OP_REQUIRES failed at
cast_op.cc:121 : Unimplemented: Cast string to int64 is not supported
Traceback (most recent call last):   File &quot;birdFake.py&quot;, line 115, in

confusionMatrix = tf.math.confusion_matrix(labels=testClasses, predictions=predictions).numpy()   File
&quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py&quot;,
line 201, in wrapper
return target(*args, **kwargs)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/confusion_matrix.py&quot;,
line 159, in confusion_matrix
labels = math_ops.cast(labels, dtypes.int64)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py&quot;,
line 201, in wrapper
return target(*args, **kwargs)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py&quot;,
line 966, in cast
x = gen_math_ops.cast(x, base_type, name=name)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py&quot;,
line 1827, in cast
_ops.raise_from_not_ok_status(e, name)   File &quot;/p/home/username/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py&quot;,
line 6862, in raise_from_not_ok_status
six.raise_from(core._status_to_exception(e.code, message), None)   File &quot;&quot;, line 3, in raise_from
tensorflow.python.framework.errors_impl.UnimplementedError: Cast
string to int64 is not supported [Op:Cast]</p>
</blockquote>
<p>I am open to any method to get those labels into the confusion matrix. Any ideas as to why what I am doing is not working would also be appreciated.</p>
<p>UPDATE: I tried the method proposed by Alexandre Catalano, and I get the following error</p>
<blockquote>
<p>Traceback (most recent call last):   File &quot;./birdFake.py&quot;, line 118,
in 
labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])   File &quot;&lt;<strong>array_function</strong> internals&gt;&quot;, line 5, in concatenate
ValueError: all the input arrays must have same number of dimensions,
but the array at index 0 has 1 dimension(s) and the array at index 1
has 0 dimension(s)</p>
</blockquote>
<p>I printed the first element of the labels array, and it is zero</p>
",6419985.0,,6419985.0,,2020-11-05 20:16:12,2022-09-26 01:05:18,Get labels from dataset when using tensorflow image_dataset_from_directory,<python><tensorflow><keras>,5,0,0.0,,,CC BY-SA 4.0
69687794,1,69692664.0,,2021-10-23 11:40:25,,17,11847,"<p>First, I tried to load using:</p>
<pre><code>(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()
</code></pre>
<p>But it gave an error:</p>
<pre><code>Exception: URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1125)
</code></pre>
<p>So I manually downloaded the dataset and put it in <code>C:\Users\SAHAN\.keras\datasets</code> and renamed it to <code>cifar-10-batches-py.tar.gz</code>.</p>
<p>But then it gives an error:</p>
<pre><code>PermissionError: [Errno 13] Permission denied: 'C:\\Users\\SAHAN\\.keras\\datasets\\cifar-10-batches-py.tar.gz'
</code></pre>
<p>How can I load this dataset?</p>
",14526839.0,,8438866.0,,2021-10-24 02:47:25,2022-05-31 06:05:29,Unable to (manually) load cifar10 dataset,<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0
65366442,1,,,2020-12-19 03:38:22,,16,28224,"<p>I'm trying to train a word embedding classifier using TF2.4 with Keras and using the <code>tf.nn.sampled_softmax_loss</code>. However, when calling the <code>fit</code> method of the model, &quot;Cannot convert a symbolic Keras input/output to a numpy array&quot; TypeError occurs. Please help me to fix the error or with an alternative approach to do candidate sampling.</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np

 
TextVectorization = tf.keras.layers.experimental.preprocessing.TextVectorization

class SampledSoftmaxLoss: #(tf.keras.losses.Loss):

  def __init__(self, model, n_classes):
    self.model = model
    output_layer = model.layers[-1]
    self.input = output_layer.input
    self.weights = output_layer.weights
    self.n_classes = n_classes


  def loss(self, y_true, y_pred, **kwargs):
    labels = tf.argmax(y_true, axis=1)
    labels = tf.expand_dims(labels, -1)
    loss = tf.nn.sampled_softmax_loss(
        weights=self.weights[0],
        biases=self.weights[1],
        labels=labels,
        inputs=self.input,
        num_sampled = 3,
        num_classes = self.n_classes
    )
    return loss


max_features = 50  # Maximum vocab size.
max_len = 10  # Sequence length to pad the outputs to.
embedding_dims = 5

input_data = np.array([ 
    &quot;Python Machine Learning&quot;,
    &quot;Data Science from Scratch: First Principles with Python&quot;, 
    &quot;Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for Building Intelligent Systems&quot;,
    &quot;Introduction to Machine Learning with Python: A Guide for Data Scientists&quot;,
    &quot;Vital Introduction to Machine Learning with Python: Best Practices to Improve and Optimize Machine Learning Systems and Algorithms&quot;,
    &quot;Machine Learning in Python: Essential Techniques for Predictive Analysis&quot;,
    &quot;Python Data Science Handbook: Essential Tools for Working with Data&quot;,
    &quot;Introducing Data Science: Big Data, Machine Learning, and more, using Python tools&quot;,
    &quot;Real-World Machine Learning&quot;])

labels_one_hot = []
for i in range(len(input_data)):
    labels = np.random.randint(0, 6, max_features)
    labels[labels&gt;1] = 1
    labels_one_hot.append(labels)

labels_one_hot = np.array(labels_one_hot)
 
# Create the text categorical encoding layer.
vectorize_layer = TextVectorization(
         max_tokens=max_features,
         output_mode='int',
         output_sequence_length=max_len)
 
vectorize_layer.adapt(text_dataset)
inp = tf.keras.Input(shape=(1,), dtype=tf.string)
idxs = vectorize_layer(inp)
embed = tf.keras.layers.Embedding(max_features + 1, embedding_dims,input_length=max_len)(idxs)
flat = tf.keras.layers.Flatten()(embed)
out = tf.keras.layers.Dense(labels_one_hot.shape[1])(flat)

model = tf.keras.models.Model(inp, out)

softmax = SampledSoftmaxLoss(model, labels_one_hot.shape[1])

model.compile('adam', loss=softmax.loss)
model.summary()
model.fit(input_data, labels_one_hot)
model.predict(input_data)
</code></pre>
<p>This is the log:</p>
<pre class=""lang-py prettyprint-override""><code>INFO:tensorflow:Assets written to: model/assets
Model: &quot;model_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_84 (InputLayer)        [(None, 1)]               0         
_________________________________________________________________
text_vectorization_83 (TextV (None, 10)                0         
_________________________________________________________________
embedding_83 (Embedding)     (None, 10, 5)             255       
_________________________________________________________________
flatten_25 (Flatten)         (None, 50)                0         
_________________________________________________________________
dense_69 (Dense)             (None, 50)                2550      
=================================================================
Total params: 2,805
Trainable params: 2,805
Non-trainable params: 0
_________________________________________________________________

---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-87-c35b8d1321a1&gt; in &lt;module&gt;()
    106 model.compile('adam', loss=softmax.loss)
    107 model.summary()
--&gt; 108 model.fit(input_data, labels_one_hot)
    109 # Now, the model can map strings to integers, and you can add an embedding
    110 # layer to map these integers to learned embeddings.

9 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    975           except Exception as e:  # pylint:disable=broad-except
    976             if hasattr(e, &quot;ag_error_metadata&quot;):
--&gt; 977               raise e.ag_error_metadata.to_exception(e)
    978             else:
    979               raise

TypeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:238 __call__
        total_loss_metric_value, sample_weight=batch_dim)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated
        update_op = update_state_fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:177 update_state_fn
        return ag_update_state(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py:364 update_state  **
        sample_weight, values)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/weights_broadcast_ops.py:155 broadcast_weights
        values = ops.convert_to_tensor(values, name=&quot;values&quot;)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped
        return func(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function
        return constant(v, dtype=dtype, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:265 constant
        allow_broadcast=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl
        allow_broadcast=allow_broadcast))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:435 make_tensor_proto
        values = np.asarray(values)
    /usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83 asarray
        return array(a, dtype, copy=False, order=order)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/keras_tensor.py:274 __array__
        'Cannot convert a symbolic Keras input/output to a numpy array. '

    TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.
</code></pre>
",3101193.0,,2464597.0,,2022-08-03 17:45:28,2022-10-16 20:46:31,Cannot convert a symbolic Keras input/output to a numpy array TypeError when using sampled_softmax in tensorflow 2.4,<python-3.x><keras><deep-learning><tensorflow2.0>,5,2,0.0,,,CC BY-SA 4.0
65322700,1,,,2020-12-16 11:49:33,,16,12931,"<p>While training a model in keras / tensorflow:</p>
<p>The code snippet:</p>
<pre><code>strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
</code></pre>
<p>I got the below error / warning:</p>
<pre><code>Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
    2020-12-16 17:12:20.885741: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:127] None of the MLIR optimization passes are enabled (registered 2)
    2020-12-16 17:12:20.905570: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3593105000 Hz
    Epoch 1/40
</code></pre>
<p>Any help is appreciated.</p>
",3178879.0,,,,,2021-06-10 17:32:47,Tensorflow - Keras: Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset,<tensorflow><keras>,1,1,0.0,,,CC BY-SA 4.0
63660618,1,,,2020-08-30 18:11:34,,16,6449,"<p>I am trying to write a Custom Model in which I am writing a custom <code>train_step</code> function</p>
<p>I am creating a 'tf.data.Dataset` from a Custom Datagenerator like</p>
<pre><code>tds = tf.data.Dataset.from_generator(tdg.__iter__,args=None,output_types = (tf.float32,tf.int32),output_shapes = (tf.TensorShape([16,64,64,3]),tf.TensorShape([16])))
tds = tds.batch(1)
</code></pre>
<p>In the custom DataGenerator the <code>__iter__</code> method is defined as</p>
<pre><code>def __iter__(self):
    for item in (self[i] for i in range(len(self))):
        yield item
</code></pre>
<p>However, when I am trying to retrive the data inside the <code>train_step</code> function,
with <code>x,y = data</code> I am getting</p>
<p><code>Tensor(&quot;IteratorGetNext:0&quot;, shape=(None, 16, 64, 64, 3), dtype=float32)</code></p>
<p>and</p>
<p><code>Tensor(&quot;IteratorGetNext:1&quot;, shape=(None, 16), dtype=int32)</code> as output</p>
<p>If I run <code>print(x[0])</code> then I am getting</p>
<p><code>Tensor(&quot;strided_slice:0&quot;, shape=(16,), dtype=int32)</code></p>
<p>I am not getting the Tensors with <code>numpy()</code> attribute</p>
<p>Where is this going wrong??</p>
",5337505.0,,5337505.0,,2020-08-30 19:49:39,2022-11-11 18:18:26,"tf.data.Dataset iterator returning Tensor(""IteratorGetNext:1"", shape=(None, 16), dtype=int32) but cannot get the values of the Tensors",<tensorflow><keras><tensorflow2.0><tensorflow-datasets><tf.keras>,3,4,0.0,,,CC BY-SA 4.0
67696519,1,67708260.0,,2021-05-25 22:56:07,,15,55619,"<p>I'm trying to use TensorFlow as backend yesterday I can use it, but today when I use it to show some error message when I'm trying to import Keras, so here's my code:</p>
<pre><code># Install required libs  
# NOTE: Run this one code, then restart this runtime and run again for next all... (PENTING!!!) 
 
### please update Albumentations to version&gt;=0.3.0 for `Lambda` transform support
!pip install -U segmentation-models

!pip install q tensorflow==2.1
!pip install q keras==2.3.1
!pip install tensorflow-estimator==2.1.

## Imports libs
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'


import cv2
import Keras
import NumPy as np
import matplotlib.pyplot as plt
</code></pre>
<p>it shows this error:</p>
<pre><code>AttributeError                            Traceback (most recent call last)

&lt;ipython-input-3-9c78a7be919d&gt; in &lt;module&gt;()
      5 
      6 import cv2
----&gt; 7 import keras
      8 import numpy as np
      9 import matplotlib.pyplot as plt

8 frames

/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py in populate_deserializable_objects()
     47 
     48   LOCAL.ALL_OBJECTS = {}
---&gt; 49   LOCAL.GENERATED_WITH_V2 = tf.__internal__.tf2.enabled()
     50 
     51   # Compatibility aliases (need to exist in both V1 and V2).

AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2'
</code></pre>
<p>while therefore I was using TensorFlow version 2.2 and Keras version 2.3.1, yesterday I can run, but today it seems can't. did I was the wrong version import for my Keras and TensorFlow for today?</p>
<p>Edit:
when I use <code>from tensorFlow import keras</code> the output I want <code>using tensorflow backend</code> doesn't show up, And then when I load <code>import segmentation_models as sm</code> it shows the same error when I use <code>import Keras</code> like on above.</p>
",15521910.0,,9215780.0,,2021-05-26 18:55:35,2022-05-26 05:45:20,module 'tensorflow.compat.v2.__internal__' has no attribute 'tf2',<python><tensorflow><machine-learning><keras><deep-learning>,4,0,0.0,,,CC BY-SA 4.0
65277758,1,,,2020-12-13 16:12:53,,15,31198,"<p>I have a code was shown below:</p>
<pre><code>history['test_acc'].append(results.history['val_dense_5_accuracy'][0]) 
</code></pre>
<p>then I want to print like below:</p>
<pre><code> print('Epoch: '+str(epoch)+'/'+str(epochs-1), 'Learning rate:', 
      'Test_acc:', history['test_acc'][-1].round(4),
      'Test_loss:', history['test_loss'][-1].round(4))`
</code></pre>
<p>but in this this line:</p>
<pre><code>'Test_acc:', history['test_acc'][-1].round(4)
</code></pre>
<p>i have this error: 'float' object has no attribute 'round'
what's the problem?</p>
",14778965.0,,3929826.0,,2020-12-13 16:14:42,2020-12-13 16:15:23,'float' object has no attribute 'round',<python><keras>,1,0,0.0,,,CC BY-SA 4.0
65451045,1,65604874.0,,2020-12-25 19:17:40,,15,2955,"<p>I am trying to build a <code>conditional CNN</code> model. The model is,</p>
<p><a href=""https://i.stack.imgur.com/ww0dP.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ww0dP.png"" alt=""enter image description here"" /></a></p>
<p>At the <code>first stage</code> of my model, I feed my data to <code>Model 1</code> then, <code>based on the prediction of Model 1</code>, I want to <code>train the model to Conditional Cat model or Conditional Dog model</code> and finally, give the output from Conditional Cat model or Conditional Dog model. <strong>How Can I do this?</strong></p>
<p><strong>Note:</strong>
My effort is,</p>
<pre><code>import keras
from keras.layers import *
from keras.models import *
from keras.utils import *

img_rows,img_cols,number_of_class = 256,256,2
input = Input(shape=(img_rows,img_cols,3))

#----------- main model (Model 1) ------------------------------------
conv_01 = Convolution2D(64, 3, 3, activation='relu',name = 'conv_01') (input)
conv_02 = Convolution2D(64, 3, 3, activation='relu',name = 'conv_02') (conv_01)

skip_dog =  conv_02

conv_03 = Convolution2D(64, 3, 3, activation='relu',name = 'conv_03') (conv_02)

skip_cat =  conv_03

conv_04 = Convolution2D(64, 3, 3, activation='relu',name = 'conv_04') (conv_03)


flatten_main_model =  Flatten() (conv_04)
Output_main_model = Dense(units = number_of_class , activation = 'softmax', name = &quot;Output_layer&quot;)(flatten_main_model)


#----------- Conditional  Cat model ------------------------------------ 
conv_05 = Convolution2D(64, 3, 3, activation='relu',name = 'conv_05') (skip_cat)
flatten_cat_model =  Flatten() (conv_05)
Output_cat_model = Dense(units = number_of_class , activation = 'softmax', name = &quot;Output_layer_cat&quot;)(flatten_cat_model)

#----------- Conditional  Dog model ------------------------------------ 
conv_06 = Convolution2D(64, 3, 3, activation='relu',name = 'conv_06') (skip_dog)
flatten_dog_model =  Flatten() (conv_06)
Output_dog_model = Dense(units = number_of_class , activation = 'softmax', name = &quot;Output_layer_dog&quot;)(flatten_dog_model)

#----------------------------- My discrete 3 models --------------------------------
model_01 = Model(inputs = input , outputs = Output_main_model,name = 'model_main')
model_02_1 = Model(inputs = input , outputs = Output_cat_model ,name = 'Conditional_cat_model')
model_02_2 = Model(inputs = input , outputs = Output_dog_model ,name = 'Conditional_dog_model')
</code></pre>
<p>How can I merge these 3 models (<code>model_01, model_02_1, model_02_2</code>) based on these conditions?</p>
<p>**Conditions are: **</p>
<ol>
<li>Feed data to model <code>model_01</code></li>
<li>Based on <code>model_01</code> result feed data to <code>model_02_1 or model_02_2</code></li>
<li>Next, predict the final output from <code>model_02_1 or model_02_2</code></li>
</ol>
",13621630.0,,13621630.0,,2021-01-26 13:43:23,2021-01-26 13:43:23,CNN model conditional layer in Keras,<python><machine-learning><keras><deep-learning><neural-network>,2,4,0.0,,,CC BY-SA 4.0
67549661,1,,,2021-05-15 17:46:55,,14,48235,"<p>I am using Python 3.8, Tensorflow 2.5.0 and keras 2.3.1 and I am trying to make a model, but I get error from keras.</p>
<p>This is my code :</p>
<pre><code>import cv2
import os
import numpy as np
from keras.layers import Conv2D,Dropout, Flatten, Dense,MaxPooling2D, MaxPool2D
import keras.layers.normalization
#from tensorflow.keras.layers import Conv2D,Dropout, Flatten, Dense,MaxPooling2D, MaxPool2D
from keras_preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from keras.models import Sequential
import pandas as pd
import random
from tensorflow.python.keras.utils.np_utils import to_categorical

count = 0
images = []
classNo = []
labelFile = 'signnames.csv'
classes = 43
testRatio = 0.2  # if 1000 images split will 200 for testing
validationRatio = 0.2  # if 1000 images 20% from remaining 800 will be 160 for valid
path_current = os.getcwd()
imageDim = (32, 32, 3)

####IMPORTING THE IMAGES FROM TRAIN FOLDER

for j in range(classes):
    path = os.path.join(path_current, 'train', str(j))
    imagesList = os.listdir(path)
    for i in imagesList:
        image = cv2.imread(path + '\\' + i)
        imageResized = cv2.resize(image, (32, 32))
        imageResized = np.array(imageResized)
        images.append(imageResized)
        classNo.append(count)
    count += 1

images = np.array(images)
classNo = np.array(classNo)

print(images.shape, classNo.shape)

##### Split Data - make the train
X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)


#####processing all the images from train, test, validation
X_train = np.array(list(map(preprocessing, X_train)))  # for all the images
X_validation = np.array(list(map(preprocessing, X_validation)))
X_test = np.array(list(map(preprocessing, X_test)))
cv2.imshow(&quot;GrayScale Images&quot;, X_train[random.randint(0, len(X_train) - 1)])  # just to verify the tain
# cv2.waitKey(5000)


##### add a depth of 1 - for better lines
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)
X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)

####augmentation of images : to make from some images more images, making it more generic, creating various similar images
dataGen = ImageDataGenerator(width_shift_range=0.1,  # 10%
                             height_shift_range=0.1,
                             zoom_range=0.2,
                             shear_range=0.1,  # distorted along an axis(aplecata)
                             rotation_range=10)  # degrees

dataGen.fit(X_train)
batches = dataGen.flow(X_train, y_train, batch_size=20)  # generate 20 images when it s called
X_batch, y_batch = next(batches)

#######from label to one encoding(making matrix with 0 and 1 based on classes number)
y_test = to_categorical(y_test, classes)
y_train = to_categorical(y_train, classes)
y_validation = to_categorical(y_validation, classes)


###########convolution neural network model
def myModel():
    nodesNr = 500
    filterNr = 60  ##to dont remove pixels based on filter size
    filterSize = (5, 5)  ##the kernel that move around the image to get the features
    # making padding
    filterSize2 = (3, 3)
    poolSize = (
    2, 2)  # for more generalize, to reduce overfitting(when detail and noise in training and go to negative result)

    model = Sequential();
    model.add(Conv2D(filterNr, filterSize, activation='relu', input_shape=X_train.shape[1:]))
    model.add(Conv2D(filterNr, filterSize, activation='relu'))
    model.add(MaxPooling2D(pool_size=poolSize))

    model.add(Conv2D(filterNr // 2, filterSize2, activation='relu'))
    model.add(Conv2D(filterNr // 2, filterSize2, activation='relu'))
    model.add(MaxPool2D(pool_size=poolSize))
    model.add(Dropout(0.5))

    model.add(Flatten())
    model.add(Dense(nodesNr, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(classes, activation='softmax'))  # output layer

    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])
    return model


####TRAIN

model = myModel()
print(model.summary())

model.save('traffic_classifier.h5')
</code></pre>
<p>I am using PyCharm and I get error from first keras import, at line 8.</p>
<p>There are the errors:</p>
<pre><code>Using TensorFlow backend.
2021-05-15 20:43:16.281415: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
Traceback (most recent call last):
  File &quot;E:/FACULTATE ANUL 3 SEMESTRUL 2/Procesarea Imaginilor/proiect/main.py&quot;, line 8, in &lt;module&gt;
    from keras.layers import Conv2D,Dropout, Flatten, Dense,MaxPooling2D, MaxPool2D
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\__init__.py&quot;, line 3, in &lt;module&gt;
    from . import utils
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\utils\__init__.py&quot;, line 6, in &lt;module&gt;
    from . import conv_utils
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\utils\conv_utils.py&quot;, line 9, in &lt;module&gt;
    from .. import backend as K
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\backend\__init__.py&quot;, line 1, in &lt;module&gt;
    from .load_backend import epsilon
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\backend\load_backend.py&quot;, line 90, in &lt;module&gt;
    from .tensorflow_backend import *
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\backend\tensorflow_backend.py&quot;, line 5, in &lt;module&gt;
    import tensorflow as tf
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\__init__.py&quot;, line 41, in &lt;module&gt;
    from tensorflow.python.tools import module_util as _module_util
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\__init__.py&quot;, line 48, in &lt;module&gt;
    from tensorflow.python import keras
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\__init__.py&quot;, line 25, in &lt;module&gt;
    from tensorflow.python.keras import models
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\models.py&quot;, line 20, in &lt;module&gt;
    from tensorflow.python.keras import metrics as metrics_module
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\metrics.py&quot;, line 37, in &lt;module&gt;
    from tensorflow.python.keras import activations
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\activations.py&quot;, line 18, in &lt;module&gt;
    from tensorflow.python.keras.layers import advanced_activations
  File &quot;C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\layers\__init__.py&quot;, line 146, in &lt;module&gt;
    from tensorflow.python.keras.layers.normalization import LayerNormalization
ImportError: cannot import name 'LayerNormalization' from 'tensorflow.python.keras.layers.normalization' (C:\Users\My-Pc\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\layers\normalization\__init__.py)
</code></pre>
",15936369.0,,13726668.0,,2021-05-15 17:51:30,2022-01-06 19:10:43,ImportError: cannot import name 'LayerNormalization' from 'tensorflow.python.keras.layers.normalization',<python><python-3.x><tensorflow><keras>,7,3,,,,CC BY-SA 4.0
63220597,1,63440092.0,,2020-08-02 20:14:19,,14,17222,"<p>I don't understand how R handles the Python environment and Python version and keep getting the error <code>Error: could not find a Python environment for /usr/bin/python</code>. I installed Miniconda and created a conda environment in the shell:</p>
<pre class=""lang-sh prettyprint-override""><code>conda activate r-reticulate
</code></pre>
<p>Then, in R, I try to install keras (same problem with package tensorflow):</p>
<pre class=""lang-r prettyprint-override""><code>library(keras)
reticulate::use_condaenv()
install_keras(method = &quot;conda&quot;, conda = reticulate::conda_binary())
</code></pre>
<p>... and get the following error:</p>
<pre class=""lang-r prettyprint-override""><code>Error: could not find a Python environment for /usr/bin/python
</code></pre>
<p>I tried to figure out what Python R should be using by</p>
<pre class=""lang-r prettyprint-override""><code>reticulate::py_config()
</code></pre>
<p>and get</p>
<pre class=""lang-r prettyprint-override""><code>python:         /usr/bin/python
libpython:      /System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/config/libpython2.7.dylib
pythonhome:     /System/Library/Frameworks/Python.framework/Versions/2.7:/System/Library/Frameworks/Python.framework/Versions/2.7
version:        2.7.16 (default, Jul  5 2020, 02:24:03)  [GCC 4.2.1 Compatible Apple LLVM 11.0.3 (clang-1103.0.29.21) (-macos10.15-objc-
numpy:          /Users/bestocke/Library/Python/2.7/lib/python/site-packages/numpy
numpy_version:  1.16.6
tensorflow:     [NOT FOUND]

python versions found: 
 /usr/bin/python3
 /usr/local/bin/python3
 /usr/bin/python
</code></pre>
<p>I don't understand this. This seems to be using Python 2.7. When trying to figure out which Python is being used in the shell, I get:</p>
<pre class=""lang-sh prettyprint-override""><code>&gt; which python
/opt/miniconda3/envs/r-reticulate/bin/python
</code></pre>
<p>and</p>
<pre><code>&gt; ls -l /opt/miniconda3/envs/r-reticulate/bin/python
lrwxr-xr-x  1 username  wheel  9 Aug  2 15:21 /opt/miniconda3/envs/r-reticulate/bin/python -&gt; python3.6
</code></pre>
<p>Suggesting Python 3.6 should be used.</p>
<p>What am I getting wrong here?</p>
",4177310.0,,4177310.0,,2020-08-02 20:20:44,2021-12-09 15:15:27,Python in R - Error: could not find a Python environment for /usr/bin/python,<python><r><tensorflow><keras><reticulate>,3,0,0.0,,,CC BY-SA 4.0
64199384,1,,,2020-10-04 20:07:31,,14,10634,"<p>Working on google colab. Using <code>tf.keras</code> and tensorflow version 2.3.0
I'm getting crazy because I can't use the model I've trained to run predictions with <code>model.predict</code> because it runs out of CPU RAM. I've been able to reproduce the issue with a very minimal example.</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input,Conv2D, Activation

matrixSide = 512 #define a big enough matrix to give memory issues

inputL = Input([matrixSide,matrixSide,12]) #create a toy model
l1 = Conv2D(32,3,activation='relu',padding='same') (inputL) #120
l1 = Conv2D(64,1,activation='relu',padding='same')(l1)
l1 = Conv2D(64,3,activation='relu',padding='same')(l1)
l1 = Conv2D(1,1,padding='same')(l1)
l1 = Activation('linear')(l1)
model = Model(inputs= inputL,outputs = l1)


#run predictions
inImm = np.zeros((64,matrixSide,matrixSide,12))
for i in range (60):
  print(i)
  outImm = model.predict(inImm)
# K.clear_session() #somebody suggested it...
</code></pre>
<p>Basically, when working on GPU, it uses 3.0 GB of CPU RAM in the first 4 iterations,then it goes up to 7, then to 10 then it crashes because it exhausted all the available RAM!
When running on CPU it lasts for more iterations, sometimes it even decreases the amount of RAM it's using from 9 GB back to 3 GB but in the end it still crashes after 20 or so iterations.</p>
<p>This previous example ( <a href=""https://stackoverflow.com/questions/56910950/keras-predict-loop-memory-leak-using-tf-data-dataset-but-not-with-a-numpy-array"">Keras predict loop memory leak using tf.data.Dataset but not with a numpy array</a> ) had similar issues when using <code>tf.data</code> but not with numpy. Somebody suggested on github issues for tensorflow 1.14 to do a <code>K.clear_session</code> in each loop... but it doesn't help!</p>
<p>Any idea on how to fix this?</p>
",13103982.0,,10396469.0,,2020-10-04 20:12:20,2023-06-22 02:48:15,tf.keras model.predict results in memory leak,<python><tensorflow><keras><google-colaboratory>,5,4,0.0,,,CC BY-SA 4.0
65023353,1,,,2020-11-26 13:50:28,,14,6174,"<p>I have been testing different approaches in building nn models (tensorflow, keras) and I saw that there was something strange with metric during compile model.</p>
<p>I checked two ways:</p>
<pre><code>    model.compile(
        loss=keras.losses.CategoricalCrossentropy(),
        optimizer=keras.optimizers.Adam(),
        metrics=keras.metrics.Accuracy()
    )
</code></pre>
<p>and</p>
<pre><code>    model.compile(
        loss=keras.losses.CategoricalCrossentropy(),
        optimizer=keras.optimizers.Adam(),
        metrics=[&quot;accuracy&quot;]
    )

</code></pre>
<p>Result of first approach:</p>
<pre><code>    Epoch 1/2
    1875/1875 - 2s - loss: 0.0494 - accuracy: 0.0020
    Epoch 2/2
    1875/1875 - 2s - loss: 0.0401 - accuracy: 0.0030

    &lt;tensorflow.python.keras.callbacks.History at 0x7f9c00bc06d8&gt;
</code></pre>
<p>Result of second approach:</p>
<pre><code>    Epoch 1/2
    1875/1875 - 2s - loss: 0.0368 - accuracy: 0.9884
    Epoch 2/2
    1875/1875 - 2s - loss: 0.0303 - accuracy: 0.9913

    &lt;tensorflow.python.keras.callbacks.History at 0x7f9bfd7d35c0&gt;
</code></pre>
<p>This is quite strange, I thought that &quot;accuracy&quot; is exactly the same as keras.metrics.Accuracy().
At least this is the case in arguments &quot;loss&quot; and &quot;optimizer&quot;, e.g. &quot;adam&quot; is the same as keras.optimizers.Adam().
Does anybody know why is this so weird or I missed something?</p>
<p>Edit:</p>
<p>Approach with metric in [] gives strange results too:</p>
<pre><code>    model.compile(
        loss=keras.losses.CategoricalCrossentropy(),
        optimizer=keras.optimizers.Adam(),
        metrics=[keras.metrics.Accuracy()]
    )

    Epoch 1/2
    1875/1875 - 2s - loss: 0.2996 - accuracy: 0.0000e+00
    Epoch 2/2
    1875/1875 - 2s - loss: 0.1431 - accuracy: 1.8333e-05

    &lt;tensorflow.python.keras.callbacks.History at 0x7f9bfd1045f8&gt;

</code></pre>
",12135668.0,,12135668.0,,2020-11-26 14:10:03,2020-11-27 00:02:34,"Difference between keras.metrics.Accuracy() and ""accuracy""",<python><tensorflow><machine-learning><keras><deep-learning>,2,1,0.0,,,CC BY-SA 4.0
63682454,1,,,2020-09-01 06:26:00,,14,2481,"<p>I used <a href=""https://www.tensorflow.org/tutorials/keras/classification"" rel=""noreferrer"">this script to train a model &amp; predict</a> on a machine with GPU installed and enabled and it seems that it's using only the CPU in the prediction stage.</p>
<p>The device placement log I'm seeing during the <code>.predict()</code> part is the following:</p>
<pre><code>2020-09-01 06:08:19.085400: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op RangeDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.085617: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.089558: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.090003: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.097064: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.097647: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.097802: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.097957: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.101284: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0
2020-09-01 06:08:19.101865: I tensorflow/core/common_runtime/eager/execute.cc:573] Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0
</code></pre>
<p>even though that when I run:</p>
<pre><code>print(tf.config.experimental.list_physical_devices('GPU'))
</code></pre>
<p>I receive:</p>
<pre><code>[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]
</code></pre>
<p>The code I used <a href=""https://gist.github.com/georgehdd/4bfd9d6110eefd26821bdcd5bce8c08c"" rel=""noreferrer"">can be found here</a>. The <a href=""https://gist.github.com/georgehdd/44cc8900024985a7f3ad07de5b969378"" rel=""noreferrer"">full output logs can be seen here</a>.</p>
<p>More context:<br />
Python: <code>3.7.7</code><br />
Tensorflow: <code>2.1.0</code><br />
GPU: <code>Nvidia Tesla V100-PCIE-16GB</code><br />
CPU: <code>Intel Xeon Gold 5218 CPU @ 2.30GHz</code><br />
RAM: <code>394851272 KB</code><br />
OS: <code>Linux</code></p>
",1600851.0,,1600851.0,,2020-09-03 04:56:48,2023-04-29 22:35:59,.predict() runs only on CPU even though GPU is available,<python><tensorflow><keras><gpu>,6,6,0.0,,,CC BY-SA 4.0
63383594,1,63386626.0,,2020-08-12 19:35:33,,14,5113,"<p>I was wondering if anyone knew how the <code>build()</code> function works from the <code>tf.keras.layers.Layer</code> class under the hood. According to the <a href=""https://www.tensorflow.org/tutorials/customization/custom_layers"" rel=""noreferrer"">documentation</a>:</p>
<blockquote>
<p><em>build is called when you know the shapes of the input tensors and can
do the rest of the initialization</em></p>
</blockquote>
<p>so to me it seems like the class is behaving similar to this:</p>
<pre><code>class MyDenseLayer:
  def __init__(self, num_outputs):
    self.num_outputs = num_outputs

  def build(self, input_shape):
    self.kernel = self.add_weight(&quot;kernel&quot;,
                                  shape=[int(input_shape[-1]), self.num_outputs])

  def __call__(self, input):
    self.build(input.shape) ## build is called here when input shape is known
    return tf.matmul(input, self.kernel)
</code></pre>
<p>I can't imagine <code>build()</code> would be called for ever <code>__call__</code>, but it is the only place where the input is passed in. Does anyone know how exactly this works under the hood?</p>
",11065415.0,,11065415.0,,2020-08-13 00:56:17,2020-08-13 01:14:31,How does Tensorflow build() work from tf.keras.layers.Layer,<python><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0
65718126,1,65718538.0,,2021-01-14 11:27:56,,14,22845,"<p>I am working on pre-trained vgg16 model, for that I need to have input size of image file to be (224,224,3).</p>
<p>The code I am working on is:</p>
<pre><code>from tensorflow.keras.preprocessing import image
import cv2
import matplotlib.pyplot as plt

img = image.load_img('abc.jpg',target_size=(224,224))
img = image.img_to_array(img)

print(img.shape)
## output : (224,224,3)
img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#plt.imshow(img_grey)

th3 = cv2.adaptiveThreshold(img_grey,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)
plt.figure(figsize=(20,10))
plt.imshow(th3)
</code></pre>
<pre><code>error                                     Traceback (most recent call last)
&lt;ipython-input-88-2a8a27b965ed&gt; in &lt;module&gt;
     17 #plt.imshow(img_grey)
     18 
---&gt; 19 th3 = cv2.adaptiveThreshold(img_grey,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)
     20 plt.figure(figsize=(20,10))
     21 plt.imshow(th3)

error: OpenCV(4.1.0) /io/opencv/modules/imgproc/src/thresh.cpp:1627: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'adaptiveThreshold'
</code></pre>
<p>Help me in resolving the issue.</p>
",15004921.0,,,,,2022-06-08 08:04:39,Adaptive Threshold error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'adaptiveThreshold',<python><opencv><keras><adaptive-threshold>,3,0,0.0,,,CC BY-SA 4.0
64681232,1,64843441.0,,2020-11-04 13:43:11,,13,4011,"<p>In Keras, why is it that <code>input_shape</code> does not include the batch dimension when passed as an argument to layers like <code>Dense</code> but DOES include the batch dimension when <code>input_shape</code> is passed to the <code>build</code> method of a model?</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
from tensorflow.keras.layers import Dense

if __name__ == &quot;__main__&quot;:
    model1 = tf.keras.Sequential([Dense(1, input_shape=[10])])
    model1.summary()

    model2 = tf.keras.Sequential([Dense(1)])
    model2.build(input_shape=[None, 10])  # why [None, 10] and not [10]?
    model2.summary()
</code></pre>
<p>Is this a conscious choice of API design? If it is, why?</p>
",8410806.0,,,,,2020-11-16 12:25:13,Why is it that `input_shape` does not include the batch dimension when passed as an argument to the `Dense` layer?,<python><tensorflow><keras>,2,1,0.0,,,CC BY-SA 4.0
68776790,1,,,2021-08-13 18:17:41,,13,26486,"<p>I have been trying to revisit my python code for prediction on neural network and i realized after running the code that <code>model.predict_classes</code> is deprecated since 1st Jan 2021.</p>
<p>Kindly can you support me to know what i can use instead for my code ?</p>
<p>The code line is:</p>
<pre><code>y_pred_nn = model.predict_classes(X_test)
</code></pre>
<p>The issue:</p>
<pre><code>NameError
Traceback (most recent call last)
&lt;ipython-input-11-fc1ddbecb622&gt; in &lt;module&gt;
----&gt; 1 print(y_pred_nn)

NameError: name 'y_pred_nn' is not defined
</code></pre>
",16661159.0,,2423278.0,,2021-08-13 18:25:53,2023-06-07 16:01:09,model.predict_classes is deprecated - What to use instead?,<python><tensorflow><keras><neural-network>,5,2,0.0,,,CC BY-SA 4.0
65549053,1,65683459.0,,2021-01-03 11:02:14,,12,3634,"<p>I have built a sequential model with a customized f1 score metric. I pass this during the compilation of my model and then save it in <code>*.hdf5</code> format. Whenever I load the model for testing purposes using the <code>custom_objects</code> attribute</p>
<p><code>model = load_model('app/model/test_model.hdf5', custom_objects={'f1':f1})</code></p>
<p>Keras throws the following error</p>
<blockquote>
<pre><code>TypeError: '&lt;' not supported between instances of 'function' and 'str'
</code></pre>
</blockquote>
<p>Note: No errors are shown if I don't include the f1 metric during compilation, and the testing process works well.</p>
<p><strong>Train method</strong></p>
<pre><code>from metrics import f1

...

# GRU with glove embeddings and two dense layers
model = Sequential()
model.add(Embedding(len(word_index) + 1,
                    100,
                    weights=[embedding_matrix],
                    input_length=max_len,
                    trainable=False))
model.add(SpatialDropout1D(0.3))
model.add(GRU(100, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))
model.add(GRU(100, dropout=0.3, recurrent_dropout=0.3))

model.add(Dense(1024, activation='relu'))
#model.add(Dropout(0.8))

model.add(Dense(1024, activation='relu'))
#model.add(Dropout(0.8))

model.add(Dense(2))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', f1])

# Fit the model with early stopping callback
earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')
model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, 
        verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])

model.save('app/model/test_model.hdf5')
</code></pre>
<p><strong>Test method</strong></p>
<pre><code>from metrics import f1

...

model = load_model('app/model/test_model.hdf5', custom_objects={'f1':f1}) 
print(model.summary())

model.evaluate(xtest_pad, ytest_enc) # &lt;-- error happens
</code></pre>
<p><strong>Custom f1 metric</strong></p>
<pre><code>from keras import backend as K

def f1(y_true, y_pred):
    def recall(y_true, y_pred):
        &quot;&quot;&quot;Recall metric.

        Only computes a batch-wise average of recall.

        Computes the recall, a metric for multi-label classification of
        how many relevant items are selected.
        &quot;&quot;&quot;
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())
        return recall

    def precision(y_true, y_pred):
        &quot;&quot;&quot;Precision metric.

        Only computes a batch-wise average of precision.

        Computes the precision, a metric for multi-label classification of
        how many selected items are relevant.
        &quot;&quot;&quot;
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision 
    
    precision = precision(y_true, y_pred)
    recall = recall(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))
</code></pre>
<p><strong>EDIT</strong></p>
<p><strong>test</strong></p>
<p>The preprocessed data used for evaluating the model</p>
<pre><code>normalized_dataset = pd.read_pickle(DATA['preprocessed_test_path'])

lbl_enc = preprocessing.LabelEncoder()
y = lbl_enc.fit_transform(normalized_dataset.label.values)

xtest = normalized_dataset.preprocessed_tweets.values
ytest_enc = np_utils.to_categorical(y)

token = text.Tokenizer(num_words=None)
max_len = 70

token.fit_on_texts(list(xtest))
xtest_seq = token.texts_to_sequences(xtest)
xtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)
</code></pre>
<p><strong>EDIT2</strong></p>
<p>This is my full traceback that triggers the stated error</p>
<pre><code>Traceback (most recent call last):
  File &quot;app/main.py&quot;, line 67, in &lt;module&gt;
    main()
  File &quot;app/main.py&quot;, line 64, in main
    test(embedding_dict)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/app/test.py&quot;, line 50, in test
    model.evaluate(xtest_pad, ytest_enc)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py&quot;, line 1389, in evaluate
    tmp_logs = self.test_function(iterator)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 828, in __call__
    result = self._call(*args, **kwds)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 725, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py&quot;, line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py&quot;, line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py&quot;, line 3196, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;/Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *
        return step_function(self, iterator)
    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica
        return fn(*args, **kwargs)
    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1219 run_step  **
        with ops.control_dependencies(_minimum_control_deps(outputs)):
    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2793 _minimum_control_deps
        outputs = nest.flatten(outputs, expand_composites=True)
    /Users/justauser/Desktop/sentiment-analysis/env/lib/python3.8/site-packages/tensorflow/python/util/nest.py:341 flatten
        return _pywrap_utils.Flatten(structure, expand_composites)

    TypeError: '&lt;' not supported between instances of 'function' and 'str'

</code></pre>
",7450491.0,,7450491.0,,2021-01-03 13:22:32,2021-08-10 03:30:27,TypeError: '<' not supported between instances of 'function' and 'str',<python><keras><model>,3,4,,,,CC BY-SA 4.0
69590274,1,,,2021-10-15 20:29:12,,12,12346,"<p>I created a model from sequential. when I saved it I got this warning message</p>
<pre><code>home/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  warnings.warn('Custom mask layers require a config and must override 
</code></pre>
<p>I tested one image and the prediction was good the I saved my model when I loaded it again it started giving me wrong values and the prediction was all wrong.what is the correct way to say the model and load it</p>
<pre><code>import numpy as np 
import matplotlib.pyplot as plt
import glob
import cv2
import os
from tensorflow import keras

from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Input, Dropout, Flatten, Dense

from tensorflow.keras.layers import UpSampling2D
from tensorflow.keras.models import Model
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Sequential

input_shape = (3,1134,1134,3)
base_model = tf.keras.applications.ResNet50(
include_top=False,
weights=&quot;imagenet&quot;,
input_shape=(1134,1134,3),
pooling=max,  
)
for layer in base_model.layers[:-4]:
    layer.trainable = False
model = Sequential()
model.add(Conv2D(3,(3,3),activation='relu',padding='same'))
model.add(base_model)
model.add(Conv2D(3,(3,3),activation='relu',padding='same'))
# model.add(Convolution2D(3,(4,4),activation='relu',padding='same'))
model.add(UpSampling2D(size =(16,16)))
model.add(UpSampling2D())
model.add(BatchNormalization())
model.add(Conv2D(3,(3,3),activation='relu',padding='same'))
model.build(input_shape)
model.summary()
</code></pre>
<p>this is how I save it</p>
<pre><code>model.save(&quot;/media/TOSHIBA EXT/trained_model/UAV_01.h5&quot;)

enter code here

model=keras.models.load_model(
    &quot;/media/TOSHIBA EXT/trained_model/UAV_01.h5&quot;)
</code></pre>
",14944419.0,,,,,2021-12-08 01:17:23,Warning : Custom mask layers require a config and must override when saving the model in keras,<python><tensorflow><keras>,2,2,0.0,,,CC BY-SA 4.0
64556120,1,64560928.0,,2020-10-27 14:00:44,,12,4495,"<p>I am doing multi-class classification for a recommender system (item recommendations), and I'm currently training my network using <code>sparse_categorical_crossentropy</code> loss. Therefore, it is reasonable to perform <code>EarlyStopping</code> by monitoring my validation loss, <code>val_loss</code> as such:</p>
<pre><code>tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
</code></pre>
<p>which works as expected. However, the performance of the network (recommender system) is measured by Average-Precision-at-10, and is tracked as a metric during training, as <code>average_precision_at_k10</code>. Because of this, I could also perform early stopping with this metric as such:</p>
<pre><code>tf.keras.callbacks.EarlyStopping(monitor='average_precision_at_k10', patience=10)
</code></pre>
<p>which also works as expected.</p>
<p><strong>My problem:</strong>
Sometimes the validation loss increases, whilst the Average-Precision-at-10 is improving and vice-versa. Because of this, I would need to monitor <strong>both</strong>, and perform early stopping, <strong>if and only if</strong> both are deteriorating. What I would like to do:</p>
<pre><code>tf.keras.callbacks.EarlyStopping(monitor=['val_loss', 'average_precision_at_k10'], patience=10)
</code></pre>
<p>which obviously does not work. Any ideas how this could be done?</p>
",11764097.0,,10908375.0,,2020-10-27 17:38:23,2020-10-27 19:01:19,Early stopping with multiple conditions,<python><python-3.x><tensorflow><keras><recommendation-engine>,4,3,0.0,,,CC BY-SA 4.0
67303001,1,67304828.0,,2021-04-28 15:15:57,,12,16973,"<p>Sklearn clearly defines how to plot a confusion matrix using its own classification model with <a href=""https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"" rel=""nofollow noreferrer""><code>plot_confusion_matrix</code></a>.
But what about using it with Keras model using data generators? Let's have a look at an example code:</p>
<p>First we need to train the model.</p>
<pre><code>import numpy as np
from keras import backend as K
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix

#Start
train_data_path = 'F://data//Train'
test_data_path = 'F://data//Validation'
img_rows = 150
img_cols = 150
epochs = 30
batch_size = 32
num_of_train_samples = 3000
num_of_test_samples = 600

#Image Generator
train_datagen = ImageDataGenerator(rescale=1. / 255,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(train_data_path,
                                                    target_size=(img_rows, img_cols),
                                                    batch_size=batch_size,
                                                    class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(test_data_path,
                                                        target_size=(img_rows, img_cols),
                                                        batch_size=batch_size,
                                                        class_mode='categorical')

# Build model
model = Sequential()
model.add(Convolution2D(32, (3, 3), input_shape=(img_rows, img_cols, 3), padding='valid'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(32, (3, 3), padding='valid'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(64, (3, 3), padding='valid'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(5))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

#Train
model.fit_generator(train_generator,
                    steps_per_epoch=num_of_train_samples // batch_size,
                    epochs=epochs,
                    validation_data=validation_generator,
                    validation_steps=num_of_test_samples // batch_size)
</code></pre>
<p>Now after the model is trained let's build a confusion matrix.</p>
<pre><code>#Confution Matrix and Classification Report
Y_pred = model.predict_generator(validation_generator, num_of_test_samples // batch_size+1)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
print(confusion_matrix(validation_generator.classes, y_pred))
print('Classification Report')
target_names = ['Cats', 'Dogs', 'Horse']
print(classification_report(validation_generator.classes, y_pred, target_names=target_names))
</code></pre>
<p>Now this works fine so far. But how do I save it as png in the same layout as in the above sklearn example?</p>
",5152497.0,,4685471.0,,2022-04-07 09:13:19,2022-04-07 09:13:19,Plot confusion matrix with Keras data generator using sklearn,<python><keras><scikit-learn><tensorflow2.0>,1,0,0.0,,,CC BY-SA 4.0
69955838,1,69975495.0,,2021-11-13 15:48:12,,12,3450,"<p>I am getting an error when trying to save a model with data augmentation layers with Tensorflow version 2.7.0.</p>
<p>Here is the code of data augmentation:</p>
<pre><code>input_shape_rgb = (img_height, img_width, 3)
data_augmentation_rgb = tf.keras.Sequential(
  [ 
    layers.RandomFlip(&quot;horizontal&quot;),
    layers.RandomFlip(&quot;vertical&quot;),
    layers.RandomRotation(0.5),
    layers.RandomZoom(0.5),
    layers.RandomContrast(0.5),
    RandomColorDistortion(name='random_contrast_brightness/none'),
  ]
)
</code></pre>
<p>Now I build my model like this:</p>
<pre><code># Build the model
input_shape = (img_height, img_width, 3)

model = Sequential([
  layers.Input(input_shape),
  data_augmentation_rgb,
  layers.Rescaling((1./255)),

  layers.Conv2D(16, kernel_size, padding=padding, activation='relu', strides=1, 
     data_format='channels_last'),
  layers.MaxPooling2D(),
  layers.BatchNormalization(),

  layers.Conv2D(32, kernel_size, padding=padding, activation='relu'), # best 4
  layers.MaxPooling2D(),
  layers.BatchNormalization(),

  layers.Conv2D(64, kernel_size, padding=padding, activation='relu'), # best 3
  layers.MaxPooling2D(),
  layers.BatchNormalization(),

  layers.Conv2D(128, kernel_size, padding=padding, activation='relu'), # best 3
  layers.MaxPooling2D(),
  layers.BatchNormalization(),

  layers.Flatten(),
  layers.Dense(128, activation='relu'), # best 1
  layers.Dropout(0.1),
  layers.Dense(128, activation='relu'), # best 1
  layers.Dropout(0.1),
  layers.Dense(64, activation='relu'), # best 1
  layers.Dropout(0.1),
  layers.Dense(num_classes, activation = 'softmax')
 ])

 model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=metrics)
 model.summary()
</code></pre>
<p>Then after the training is done I just make:</p>
<pre><code>model.save(&quot;./&quot;)
</code></pre>
<p>And I'm getting this error:</p>
<pre><code>---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
&lt;ipython-input-84-87d3f09f8bee&gt; in &lt;module&gt;()
----&gt; 1 model.save(&quot;./&quot;)


/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py in 
 error_handler(*args, **kwargs)
 65     except Exception as e:  # pylint: disable=broad-except
 66       filtered_tb = _process_traceback_frames(e.__traceback__)
 ---&gt; 67       raise e.with_traceback(filtered_tb) from None
 68     finally:
 69       del filtered_tb

 /usr/local/lib/python3.7/dist- 
 packages/tensorflow/python/saved_model/function_serialization.py in 
 serialize_concrete_function(concrete_function, node_ids, coder)
 66   except KeyError:
 67     raise KeyError(
 ---&gt; 68         f&quot;Failed to add concrete function '{concrete_function.name}' to 
 object-&quot;
 69         f&quot;based SavedModel as it captures tensor {capture!r} which is 
 unsupported&quot;
 70         &quot; or not reachable from root. &quot;

 KeyError: &quot;Failed to add concrete function 
 'b'__inference_sequential_46_layer_call_fn_662953'' to object-based SavedModel as it 
 captures tensor &lt;tf.Tensor: shape=(), dtype=resource, value=&lt;Resource Tensor&gt;&gt; which 
 is unsupported or not reachable from root. One reason could be that a stateful 
 object or a variable that the function depends on is not assigned to an attribute of 
 the serialized trackable object (see SaveTest.test_captures_unreachable_variable).&quot;
</code></pre>
<p>I inspected the reason of getting this error by changing the architecture of my model and I just found that reason came from the data_augmentation layer since the <code>RandomFlip</code> and <code>RandomRotation</code> and others are changed from <code>layers.experimental.prepocessing.RandomFlip</code> to <code>layers.RandomFlip</code>, but still the error appears.</p>
",14427533.0,,9657861.0,,2021-11-29 15:50:10,2022-02-04 17:25:07,Saving model on Tensorflow 2.7.0 with data augmentation layer,<python><tensorflow><keras><deep-learning><data-augmentation>,2,0,0.0,,,CC BY-SA 4.0
63364588,1,,,2020-08-11 18:50:56,,12,6299,"<p>I am writing machine learning code using Keras to grade the severity of prostate cancer. After running it the following error appears:</p>
<pre><code>---------------------------------------------------------------------------
UnboundLocalError                         Traceback (most recent call last)
&lt;ipython-input-14-0e08590512ec&gt; in &lt;module&gt;
      8     for file in column:
      9         data = generate_tiles(file)
---&gt; 10         prediction = model.predict(data)
     11         max_score = prediction.max()
     12 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     86       raise ValueError('{} is not supported in multi-worker mode.'.format(
     87           method.__name__))
---&gt; 88     return method(self, *args, **kwargs)
     89 
     90   return tf_decorator.make_decorator(

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1283             callbacks.on_predict_batch_end(step, {'outputs': batch_outputs})
   1284       callbacks.on_predict_end()
-&gt; 1285     all_outputs = nest.map_structure_up_to(batch_outputs, concat, outputs)
   1286     return tf_utils.to_numpy_or_python_type(all_outputs)
   1287 

UnboundLocalError: local variable 'batch_outputs' referenced before assignment
</code></pre>
<p>Does anyone know what batch outputs would be refering too? I don't have such a variable in my code.</p>
",10055134.0,,,,,2020-08-28 13:23:43,UnboundLocalError: local variable 'batch_outputs' referenced before assignment,<python><machine-learning><keras>,1,3,,,,CC BY-SA 4.0
70660544,1,,,2022-01-11 01:04:50,,12,2057,"<p>Adapting my code from TF1 to TF2.6 I run into trouble.
I am trying to add some custom layers to an inception resnet, save the model, and then load and run it.</p>
<pre><code>from tensorflow.keras.layers import Dense                                                                                                                       
from tensorflow.keras.models import Model                                                                                                                       
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2                                                                                 
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D                                                                                               
import tensorflow as tf                                                                                                                                         
import numpy as np                                                                                                                                              
from PIL import Image                                                                                                                                           
                                                                                                                                                                
export_path = &quot;./save_test&quot;                                                                                                                                     
                                                                                                                                                                
# Get model without top and add two layers                                                                                                                      
base_model = InceptionResNetV2(weights='imagenet', input_tensor=None, include_top=False)                                                                        
out = base_model.output                                                                                                                                         
out = GlobalAveragePooling2D()(out)                                                                                                                             
predictions = Dense(7, activation='softmax', name=&quot;output&quot;)(out)                                                                                                
                                                                                                                                                                
# Make new model using inputs from base model and custom outputs                                                                                                
model = Model(inputs=base_model.input, outputs=[predictions])                                                                                                   
                                                                                                                                                                
# save model                                                                                                                                                    
tf.saved_model.save(model, export_path)                                                                                                                         
                                                                                                                                                                
# load model and run                                                                                                                                            
with tf.compat.v1.Session(graph=tf.Graph()) as sess:                                                                                                            
    tf.compat.v1.saved_model.loader.load(sess, ['serve'], export_path)                                                                                          
    graph = tf.compat.v1.get_default_graph()                                                                                                                    
                                                                                                                                                                
    img = Image.new('RGB', (299, 299))                                                                                                                          
    x = tf.keras.preprocessing.image.img_to_array(img)                                                                                                          
    x = np.expand_dims(x, axis=0)                                                                                                                               
    x = x[..., :3]                                                                                                                                              
    x /= 255.0                                                                                                                                                  
    x = (x - 0.5) * 2.0                                                                                                                                         
                                                                                                                                                                
    y_pred = sess.run('output/Softmax:0', feed_dict={'serving_default_input_1:0': x})                                                                           
</code></pre>
<p>Error:
<code>KeyError: &quot;The name 'output/Softmax:0' refers to a Tensor which does not exist. The operation, 'output/Softmax', does not exist in the graph.&quot;</code></p>
<p>What I don't understand:
<code>predictions.name</code> is <code>'output/Softmax:0'</code>, but
<code>graph.get_tensor_by_name('output/Softmax:0')</code> tells me it does not exist!</p>
<p><strong>Note:</strong> I am aware that I can save and load with TF2's <code>tf.keras.models.save</code> and <code>tf.keras.models.load_model</code> and then run the model with <code>model(x)</code>. However, in my application I have multiple models in memory and I have found that the inference takes much longer than in my TF1 code using the <code>session</code> object. I would therefore like to use the TF1 approach with the <code>session</code> object in compatibility mode.</p>
<p>How can I control the names of input/output when saving? What am I missing?</p>
",1981275.0,,9657861.0,,2022-02-10 12:17:51,2022-02-10 12:17:51,Inference using saved model in Tensorflow 2: how to control in/output?,<python><tensorflow><machine-learning><keras><tensorflow2.0>,1,0,,,,CC BY-SA 4.0
67693712,1,67693955.0,,2021-05-25 18:30:08,,11,6302,"<p>I am trying to define a model happyModel()</p>
<pre><code># GRADED FUNCTION: happyModel

def happyModel():
    &quot;&quot;&quot;
    Implements the forward propagation for the binary classification model:
    ZEROPAD2D -&gt; CONV2D -&gt; BATCHNORM -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; DENSE

Note that for simplicity and grading purposes, you'll hard-code all the values
such as the stride and kernel (filter) sizes. 
Normally, functions should take these values as function parameters.

Arguments:
None

Returns:
model -- TF Keras model (object containing the information for the entire training process) 
&quot;&quot;&quot;
model = tf.keras.Sequential(
    [
        ## ZeroPadding2D with padding 3, input shape of 64 x 64 x 3
        tf.keras.layers.ZeroPadding2D(padding=(3,3), data_format=(64,64,3)),
    
        ## Conv2D with 32 7x7 filters and stride of 1            
        tf.keras.layers.Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0'),
        
        ## BatchNormalization for axis 3
        
        tf.keras.layers.BatchNormalization(axis = 3, name = 'bn0'),
        
        ## ReLU            
        tf.keras.layers.Activation('relu'),
        
        ## Max Pooling 2D with default parameters            
        tf.keras.layers.MaxPooling2D((2, 2), name='max_pool0'),
    
        ## Flatten layer            
        tf.keras.layers.Flatten(),
    
        ## Dense layer with 1 unit for output &amp; 'sigmoid' activation            
        tf.keras.layers.Dense(1, activation='sigmoid', name='fc'),
        
        # YOUR CODE STARTS HERE
        
        
        # YOUR CODE ENDS HERE
    ]
)

return model
</code></pre>
<p>and following code is for creating the object of this model defined above:</p>
<pre><code>happy_model = happyModel()
# Print a summary for each layer
for layer in summary(happy_model):
    print(layer)
    
output = [['ZeroPadding2D', (None, 70, 70, 3), 0, ((3, 3), (3, 3))],
            ['Conv2D', (None, 64, 64, 32), 4736, 'valid', 'linear', 'GlorotUniform'],
            ['BatchNormalization', (None, 64, 64, 32), 128],
            ['ReLU', (None, 64, 64, 32), 0],
            ['MaxPooling2D', (None, 32, 32, 32), 0, (2, 2), (2, 2), 'valid'],
            ['Flatten', (None, 32768), 0],
            ['Dense', (None, 1), 32769, 'sigmoid']]
    
comparator(summary(happy_model), output)
</code></pre>
<p>I got following error:</p>
<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-67-f33284fd82fe&gt; in &lt;module&gt;
      1 happy_model = happyModel()
      2 # Print a summary for each layer
----&gt; 3 for layer in summary(happy_model):
      4     print(layer)
      5 

~/work/release/W1A2/test_utils.py in summary(model)
     30     result = []
     31     for layer in model.layers:
---&gt; 32         descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]
     33         if (type(layer) == Conv2D):
     34             descriptors.append(layer.padding)

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in output_shape(self)
   2177     &quot;&quot;&quot;
   2178     if not self._inbound_nodes:
-&gt; 2179       raise AttributeError('The layer has never been called '
   2180                            'and thus has no defined output shape.')
   2181     all_output_shapes = set(

AttributeError: The layer has never been called and thus has no defined output shape.
</code></pre>
<p>I suspect my calling of <code>ZeroPadding2D()</code> is not right. The project seems to require the input shape of <code>ZeroPadding2D()</code> to be 64X64X3. I tried many formats but could not fix the problem. Anyone can give a pointer? Thanks a lot.</p>
",1277239.0,,,,,2023-03-31 11:06:48,AttributeError: The layer has never been called and thus has no defined output shape,<tensorflow><keras><model>,4,0,,,,CC BY-SA 4.0
63906723,1,63910375.0,,2020-09-15 17:05:57,,11,9686,"<p>I want to load the data from the directory where I have around 5000 images (type 'png'). But it returns me an error saying that there are no images when obviusly there are images.
This code:</p>
<pre><code>width=int(wb-wa)
height=int(hb-ha)
directory = '/content/drive/My Drive/Colab Notebooks/Hair/Images'
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory, labels=densitat, label_mode='int',
    color_mode='rgb', batch_size=32, image_size=(width, height), shuffle=True, seed=1,
    validation_split=0.2, subset='training', follow_links = False)
</code></pre>
<p>Returns:</p>
<pre><code>ValueError: Expected the lengths of `labels` to match the number of files in the target directory. len(labels) is 5588 while we found 0 files in /content/drive/My Drive/Colab Notebooks/Hair/Images.
</code></pre>
<p>I can see the images:
<a href=""https://i.stack.imgur.com/STKao.png"" rel=""noreferrer"">Colab view of the folder structure with the images</a></p>
<p>Where is the problem? I need to use this function to load data in batchs as i have a large dataset</p>
",10079841.0,,,,,2022-12-13 11:52:48,Keras image_dataset_from_directory not finding images,<tensorflow><keras><tensorflow-datasets><image-preprocessing>,3,0,,,,CC BY-SA 4.0
73304934,1,,,2022-08-10 10:48:44,,11,5258,"<p>I use the data augmentation according to the official TensorFlow <a href=""https://www.tensorflow.org/tutorials/images/data_augmentation"" rel=""noreferrer"">tutorial</a>.
First, I create a sequential model with augmenting layers:</p>
<pre><code>def _getAugmentationFunction(self):
    if not self.augmentation:
        return None
    pipeline = []
    
    pipeline.append(layers.RandomFlip('horizontal_and_vertical'))
    pipeline.append(layers.RandomRotation(30))
    pipeline.append(layers.RandomTranslation(0.1, 0.1, fill_mode='nearest'))
    pipeline.append(layers.RandomBrightness(0.1, value_range=(0.0, 1.0)))

    model =  Sequential(pipeline)
    return lambda x, y: (model(x, training=True), y)
</code></pre>
<p>Then, I use the map function on the dataset:</p>
<pre><code>data_augmentation = self._getAugmentationFunction()
self.train_data = self.train_data.map(data_augmentation,
                                      num_parallel_calls=AUTOTUNE)
</code></pre>
<p>The code works as expected but I get the following warning:</p>
<pre><code>WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
</code></pre>
<p>What is the reason of the warnings and how to fix it?
I'm using TF v2.9.1</p>
",3975218.0,,13546426.0,,2022-08-10 13:10:43,2023-02-22 21:45:04,Tensorflow Data Augmentation gives a warning: Using a while_loop for converting,<tensorflow><keras><data-augmentation>,4,0,0.0,,,CC BY-SA 4.0
66472201,1,66524901.0,,2021-03-04 09:31:15,,11,4079,"<p>Please add a minimum comment on your thoughts so that I can improve my query. Thank you. -)</p>
<hr />
<p>I'm trying to train a <code>tf.keras</code> model with <strong>Gradient Accumulation</strong> (GA). But I don't want to use it in the custom training loop (<a href=""https://stackoverflow.com/questions/59893850/how-to-accumulate-gradients-in-tensorflow-2-0"">like</a>) but customize the <code>.fit()</code> method by overriding the <code>train_step</code>.Is it possible? How to accomplish this?  The reason is if we want to get the benefit of <code>keras</code> built-in functionality like <code>fit</code>, <code>callbacks</code>, we don't want to use the custom training loop but at the same time if we want to override <code>train_step</code> for some reason (like GA or else) we can customize the <code>fit</code> method and still get the leverage of using those built-in functions.</p>
<p>And also, I know the pros of using <strong>GA</strong> but what are the major cons of using it? Why does it's not come as a default but an optional feature with the framework?</p>
<pre><code># overriding train step 
# my attempt 
# it's not appropriately implemented 
# and need to fix 
class CustomTrainStep(keras.Model):
    def __init__(self, n_gradients, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.n_gradients = n_gradients
        self.gradient_accumulation = [
            tf.zeros_like(this_var) for this_var in  self.trainable_variables
        ]

    def train_step(self, data):
        x, y = data
        batch_size = tf.cast(tf.shape(x)[0], tf.float32)  
        # Gradient Tape
        with tf.GradientTape() as tape:
            y_pred = self(x, training=True)
            loss = self.compiled_loss(
                y, y_pred, regularization_losses=self.losses
            )
            
        # Calculate batch gradients
        gradients = tape.gradient(loss, self.trainable_variables)
        # Accumulate batch gradients
        accum_gradient = [
            (acum_grad+grad) for acum_grad, grad in \
            zip(self.gradient_accumulation, gradients)
        ]
        accum_gradient = [
            this_grad/batch_size for this_grad in accum_gradient
        ]
        
        # apply accumulated gradients
        self.optimizer.apply_gradients(
            zip(accum_gradient, self.trainable_variables)
        )
        # TODO: reset self.gradient_accumulation 
        # update metrics
        self.compiled_metrics.update_state(y, y_pred)
        return {m.name: m.result() for m in self.metrics}
</code></pre>
<p>Please, run and check with the following toy setup.</p>
<pre><code># Model 
size = 32

input = keras.Input(shape=(size,size,3))
efnet = keras.applications.DenseNet121(
    weights=None,
    include_top = False, 
    input_tensor = input
)
base_maps = keras.layers.GlobalAveragePooling2D()(efnet.output) 
base_maps = keras.layers.Dense(
    units=10, activation='softmax', 
    name='primary'
)(base_maps)

custom_model = CustomTrainStep(
    n_gradients=10, inputs=[input], outputs=[base_maps]
)
# bind all
custom_model.compile(
    loss = keras.losses.CategoricalCrossentropy(),
    metrics = ['accuracy'],
    optimizer = keras.optimizers.Adam()
)
</code></pre>
<pre><code># data 
(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()
x_train = tf.expand_dims(x_train, -1)
x_train = tf.repeat(x_train, 3, axis=-1)
x_train = tf.divide(x_train, 255)
x_train = tf.image.resize(x_train, [size,size]) # if we want to resize 
y_train = tf.one_hot(y_train , depth=10) 

# customized fit 
custom_model.fit(x_train, y_train, batch_size=64, epochs=3, verbose = 1)
</code></pre>
<hr />
<h3>Update</h3>
<p>I've found that some others also tried to achieve this and ended up with the same issue. One has got some workaround, <a href=""https://github.com/keras-team/keras/issues/14483"" rel=""nofollow noreferrer"">here</a>, but it's too messy and I think there should be some better approach.</p>
<h3>Update 2</h3>
<p>The accepted answer (by Mr.For Example) is fine and works well in single strategy. Now, I like to start 2nd bounty to extend it to support multi-gpu, tpu, and with mixed-precision techniques. There are some complications, see <a href=""https://github.com/keras-team/keras/issues/17429"" rel=""nofollow noreferrer"">details</a>.</p>
",9215780.0,,9215780.0,,2023-01-16 07:03:34,2023-01-16 07:03:34,Gradient Accumulation with Custom model.fit in TF.Keras?,<python><tensorflow><machine-learning><keras><deep-learning>,2,0,0.0,,,CC BY-SA 4.0
64337087,1,64338121.0,,2020-10-13 14:22:05,,11,33395,"<p>I made a custom layer in keras for reshaping the outputs of a CNN before feeding to ConvLSTM2D layer</p>
<pre><code>class TemporalReshape(Layer):
    def __init__(self,batch_size,num_patches):
        super(TemporalReshape,self).__init__()
        self.batch_size = batch_size
        self.num_patches = num_patches

    def call(self,inputs):
        nshape = (self.batch_size,self.num_patches)+inputs.shape[1:]
        return tf.reshape(inputs, nshape)

    def get_config(self):
        config = super().get_config().copy()
        config.update({'batch_size':self.batch_size,'num_patches':self.num_patches})
        return config
</code></pre>
<p>When I try to load the best model using</p>
<pre><code>model = tf.keras.models.load_model('/content/saved_models/model_best.h5',custom_objects={'TemporalReshape':TemporalReshape})
</code></pre>
<p>I get the error</p>
<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-83-40b46da33e91&gt; in &lt;module&gt;()
----&gt; 1 model = tf.keras.models.load_model('/content/saved_models/model_best.h5',custom_objects={'TemporalReshape':TemporalReshape})


/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)
    180     if (h5py is not None and (
    181         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--&gt; 182       return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
    183 
    184     filepath = path_to_string(filepath)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    176     model_config = json.loads(model_config.decode('utf-8'))
    177     model = model_config_lib.model_from_config(model_config,
--&gt; 178                                                custom_objects=custom_objects)
    179 
    180     # set weights

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)
     53                     '`Sequential.from_config(config)`?')
     54   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
---&gt; 55   return deserialize(config, custom_objects=custom_objects)
     56 
     57 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    173       module_objects=LOCAL.ALL_OBJECTS,
    174       custom_objects=custom_objects,
--&gt; 175       printable_module_name='layer')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    356             custom_objects=dict(
    357                 list(_GLOBAL_CUSTOM_OBJECTS.items()) +
--&gt; 358                 list(custom_objects.items())))
    359       with CustomObjectScope(custom_objects):
    360         return cls.from_config(cls_config)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in from_config(cls, config, custom_objects)
    615     &quot;&quot;&quot;
    616     input_tensors, output_tensors, created_layers = reconstruct_from_config(
--&gt; 617         config, custom_objects)
    618     model = cls(inputs=input_tensors, outputs=output_tensors,
    619                 name=config.get('name'))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in reconstruct_from_config(config, custom_objects, created_layers)
   1202   # First, we create all layers and enqueue nodes to be processed
   1203   for layer_data in config['layers']:
-&gt; 1204     process_layer(layer_data)
   1205   # Then we process nodes in order of layer depth.
   1206   # Nodes that cannot yet be processed (if the inbound node

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in process_layer(layer_data)
   1184       from tensorflow.python.keras.layers import deserialize as deserialize_layer  # pylint: disable=g-import-not-at-top
   1185 
-&gt; 1186       layer = deserialize_layer(layer_data, custom_objects=custom_objects)
   1187       created_layers[layer_name] = layer
   1188 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    173       module_objects=LOCAL.ALL_OBJECTS,
    174       custom_objects=custom_objects,
--&gt; 175       printable_module_name='layer')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    358                 list(custom_objects.items())))
    359       with CustomObjectScope(custom_objects):
--&gt; 360         return cls.from_config(cls_config)
    361     else:
    362       # Then `cls` may be a function returning a class.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in from_config(cls, config)
    695         A layer instance.
    696     &quot;&quot;&quot;
--&gt; 697     return cls(**config)
    698 
    699   def compute_output_shape(self, input_shape):

TypeError: __init__() got an unexpected keyword argument 'name'
</code></pre>
<p>When building the model, I used the custom layer like the following :</p>
<p><code>x = TemporalReshape(batch_size = 8, num_patches = 16)(x)</code></p>
<p>What is causing the error and how to load the model without this error?</p>
",5337505.0,,,,,2022-12-22 17:03:33,TypeError: __init__() got an unexpected keyword argument 'name' when loading a model with Custom Layer,<python><tensorflow><keras><tensorflow2.0><tf.keras>,2,3,,,,CC BY-SA 4.0
63308383,1,63332066.0,,2020-08-07 19:52:32,,11,16775,"<p>After training a model using Google Colab, I downloaded it using the following command (inside Google Colab):</p>
<pre><code>model.save('model.h5')
from google.colab import files
files.download('model.h5')
</code></pre>
<p>My problem is that when I try to load the downloaded <em>model.h5</em> using my local machine (outside Google Colab), I get the following error:</p>
<p>[input]</p>
<pre><code>from keras.models import load_model
model = load_model(model.h5)
</code></pre>
<p>[output]</p>
<pre><code>Traceback (most recent call last):
  File &quot;test.py&quot;, line 2, in &lt;module&gt;
    model = load_model(filepath = 'saved_model/model2.h5',custom_objects=None,compile=True, )
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py&quot;, line 184, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py&quot;, line 177, in load_model_from_hdf5
    model = model_config_lib.model_from_config(model_config,
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/saving/model_config.py&quot;, line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py&quot;, line 105, in deserialize
    return deserialize_keras_object(
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py&quot;, line 369, in deserialize_keras_object
    return cls.from_config(
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py&quot;, line 397, in from_config
    layer = layer_module.deserialize(layer_config,
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py&quot;, line 105, in deserialize
    return deserialize_keras_object(
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py&quot;, line 375, in deserialize_keras_object
    return cls.from_config(cls_config)
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py&quot;, line 655, in from_config
    return cls(**config)
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py&quot;, line 582, in __init__
    super(Conv2D, self).__init__(
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py&quot;, line 121, in __init__
    super(Conv, self).__init__(
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py&quot;, line 456, in _method_wrapper
    result = method(self, *args, **kwargs)
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py&quot;, line 294, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File &quot;/home/lucasmirachi/anaconda3/envs/myenviron/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py&quot;, line 792, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'groups')
</code></pre>
<p>Does anyone know what is this <strong>'groups'</strong> keyword argument not understood?
Instead of using <code>from keras.models</code> I have tried using <code>from tensorflow.keras.models</code> but I had no success, I got the same error.
In both Google Colab and on my local machine I'm running Keras '2.4.3'</p>
<p><em>Thank you all in advance!</em></p>
",14068093.0,,14068093.0,,2020-08-07 20:05:22,2023-01-07 11:18:54,"TypeError('Keyword argument not understood:', 'groups') in keras.models load_model",<python><tensorflow><keras><google-colaboratory>,5,5,,,,CC BY-SA 4.0
69058596,1,,,2021-09-04 20:05:27,,11,783,"<p>I am trying to save a model and then load it later to make some predictions; what happens is that the accuracy of the model after training is <code>95%+</code>, but when I save it and then load it, the accuracy drops to nearly <code>10%</code> on the <strong>same</strong> dataset.</p>
<p>To reproduce this erroneous result, you can run <a href=""https://colab.research.google.com/drive/1wy3nNtRo-JEmFtFKi2IqNfrDtgy7cI8-?usp=sharing"" rel=""nofollow noreferrer"">this</a> really small notebook.</p>
<p>The model is defined as follows:</p>
<pre><code>model_scratch_auto = models.Sequential()
model_scratch_auto.add(Flatten(input_shape=(28,28)))
model_scratch_auto.add(Dense(80, activation='relu'))
model_scratch_auto.add(Dense(100, activation='relu'))
model_scratch_auto.add(Dense(120, activation='relu'))
model_scratch_auto.add(Dense(100, activation='relu'))
auto_srelu=AutoSRELU()
model_scratch_auto.add(auto_srelu)
model_scratch_auto.add(Dense(120, activation='relu'))
model_scratch_auto.add(auto_srelu)
model_scratch_auto.add(BatchNormalization())
model_scratch_auto.add(Dense(10, activation='softmax'))
model_scratch_auto.compile(optimizer = tf.optimizers.Adam(),loss='categorical_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])

model_scratch_auto.fit(X_train, y_train , batch_size=64, epochs=5, validation_data=(X_test, y_test),verbose=1)
</code></pre>
<p>Where the custom layer, <code>AutoSRELU</code> is defined as follows:</p>
<pre><code>initializer0 = keras.initializers.RandomUniform(minval = -1, maxval =1)
initializer1 = keras.initializers.RandomUniform(minval = 0.5, maxval =3)

 
class MinMaxConstraint(keras.constraints.Constraint):
    def __init__(self, minval, maxval):
        self.minval = tf.constant(minval ,dtype='float32')
        self.maxval = tf.constant(maxval ,dtype='float32')
    def __call__(self, w):
        tf.cond(tf.greater(self.minval,w)
                , lambda: w + (self.minval - w)
                , lambda: tf.cond(tf.greater(w,self.maxval)
                                  , lambda: w - (w - self.maxval)
                                  , lambda: w))
    def get_config(self):
        return {'Lower Bound': self.minval, 'Upper Bound':self.maxval}
 
 

def srelu(inputs, k1, k2):
    cond1 = tf.cast(tf.math.less(inputs, 0.0), tf.float32)
    cond2 = tf.cast(tf.math.greater_equal(inputs, 0.0), tf.float32)
    a = tf.math.multiply(cond1, tf.add(k1,tf.multiply(0.3, inputs)))
    b = tf.math.multiply(cond2, tf.add(k1,tf.multiply(k2, inputs)))
    outputs = a + b
    return outputs
    

class AutoSRELU(keras.layers.Layer):
    def __init__(self, trainable = True, **kwargs):
        super(AutoSRELU, self).__init__()
        self.k1 = self.add_weight(name='k', shape = (), initializer=initializer0, trainable=trainable)#, constraint=keras.constraints.NonNeg())
        self.k2 = self.add_weight(name='n', shape = (), initializer=initializer1, trainable=trainable)#, constraint=MinMaxConstraint(1,10))
    def call(self, inputs):
        return srelu(inputs, self.k1, self.k2)
</code></pre>
<p>Then I evaluate the model performance using the <code>evaluate()</code> function and get the following result:</p>
<pre><code>model_scratch_auto.evaluate(X_train, y_train)
</code></pre>
<p><em>Output:</em></p>
<pre><code>1875/1875 [==============================] - 4s 2ms/step - loss: 0.0517 - acc: 0.9834 - f1_m: 0.9836 - precision_m: 0.9851 - recall_m: 0.9823
[0.05167238786816597,
 0.9834166765213013,
 0.983639121055603,
 0.9850572943687439,
 0.9822666645050049]
</code></pre>
<p>Then I save the model as:</p>
<pre><code>model_scratch_auto.save('test_model.h5')
</code></pre>
<p>And when I load the same model by setting the dependencies as follows:</p>
<pre><code>dependencies = {
     'f1_m': f1_m,
     'precision_m': precision_m,
     'recall_m': recall_m,
     'AutoSRELU': AutoSRELU
}

test_model = models.load_model('test_model.h5', custom_objects=dependencies)
</code></pre>
<p>And when I evaluate this model on the same dataset, I get the following result:</p>
<pre><code>test_model.evaluate(X_train, y_train)
</code></pre>
<p><em>Output:</em></p>
<pre><code>1875/1875 [==============================] - 2s 1ms/step - loss: 8.5696 - acc: 0.1047 - f1_m: 0.1047 - precision_m: 0.1047 - recall_m: 0.1047
[8.569587707519531,
 0.10468333214521408,
 0.10468332469463348,
 0.10468333214521408,
 0.10468333214521408]
</code></pre>
<p>As you can see, saving the same model and evaluating it on the same dataset <strong>significantly</strong> reduces the performance. I tried many things to see why this must be happening and I found out that removing <code>BatchNormalization()</code> and <code>AutoSRELU</code> corrected the issue, but I can't seem to understand why they are causing this issue. To see if the <code>RandomUniform</code> function was maybe causing some problems, I re-ran the loading part along with the class definition multiple times to see if there was some randomness in the loaded model but that was returning an identical worse result every time. I then saw that removing the batch normalization layer gave almost identical results.</p>
<p>So I was able to narrow down the problem to <code>BatchNormalization</code> <code>AutoSRELU</code> but I can't understand how to correct it. How do I save and load the model correctly so that it gives the same results?</p>
",13100489.0,,13100489.0,,2021-09-07 18:01:32,2021-09-07 18:01:32,How do I save and load BatchNormalization Layer in this Tensorflow model?,<python><tensorflow><keras><tf.keras><keras-layer>,1,3,0.0,,,CC BY-SA 4.0
70240387,1,,,2021-12-06 02:48:29,,11,20762,"<pre><code>from keras.preprocessing.text import text_to_word_sequence
import pandas as pd
from keras.preprocessing.text import Tokenizer
import numpy as np
# from __future__ import print_function
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.layers import Embedding
from keras.layers import Conv1D, GlobalMaxPooling1D
x = df_f.iloc[:, 1].values
y = df_f.iloc[:, 0].values
tk = Tokenizer(num_words= 200, filters = '!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n',lower=True, 
split=&quot; &quot;)
tk.fit_on_texts(x)
x = tk.texts_to_sequences(x)
x = sequence.pad_sequences(x, maxlen=200)
from keras import utils as np_utils
y =np_utils.to_categorical(y, num_classes= 24)
</code></pre>
<p>I am using keras version 2.5 and tenser flow version 2.5 I import  utils from keras</p>
",16408315.0,,,,,2022-07-18 11:53:59,AttributeError: module 'keras.utils' has no attribute 'to_categorical',<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0
68381733,1,68397927.0,,2021-07-14 16:20:06,,11,27588,"<p>I am running this code below and it returned an error AttributeError: module 'keras.optimizers' has no attribute 'RMSprop'. I download tensorflow using <code>pip install tensorflow</code>.</p>
<pre><code>from keras import layers
from keras import models

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu',
                        input_shape=(150, 150, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.summary()

from keras import optimizers

model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])
</code></pre>
<p>Could anyone please help explain to me what's wrong with this? Thank you for your time.</p>
",14468209.0,,,,,2022-09-10 17:19:12,Error module 'keras.optimizers' has no attribute 'RMSprop',<python><tensorflow><keras>,5,6,0.0,,,CC BY-SA 4.0
64844140,1,,,2020-11-15 12:01:19,,11,38238,"<p>can anybody help me. when I try to run my codes they an error
ImportError: cannot import name 'rmsprop' from 'keras.optimizers'</p>
<p>bellow are the libraries and all imports I used.</p>
<pre><code>import gym
import random
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import rmsprop, Adam
import numpy as np
import matplotlib.pyplot as plt
from collections import deque
from statistics import mean
import h5py
</code></pre>
",14192624.0,,,,,2021-11-09 09:34:07,ImportError: cannot import name 'rmsprop' from 'keras.optimizers',<python><keras>,4,0,,,,CC BY-SA 4.0
65464463,1,65464464.0,,2020-12-27 09:37:12,,10,28119,"<p>I'm getting this error while loading the tensorflow addons library</p>
<pre><code>import tensorflow_addons as tfa

ImportError: cannot import name 'keras_tensor' from 'tensorflow.python.keras.engine'
</code></pre>
",10933598.0,,2230844.0,,2021-05-05 02:33:38,2023-01-20 07:12:10,ImportError: cannot import name 'keras_tensor' from 'tensorflow.python.keras.engine',<python><tensorflow><keras><deep-learning><tf.keras>,1,0,0.0,,,CC BY-SA 4.0
63760734,1,63760764.0,,2020-09-06 04:35:56,,10,112774,"<p>I'm working in a project that isolate vocal parts from an audio. I'm using the DSD100 dataset, but for doing tests I'm using the DSD100subset <a href=""https://sigsep.github.io/datasets/dsd100.html"" rel=""noreferrer"">dataset</a> from I only use the mixtures and the vocals. I'm basing this work on this <a href=""https://towardsdatascience.com/audio-ai-isolating-vocals-from-stereo-music-using-convolutional-neural-networks-210532383785"" rel=""noreferrer"">article</a></p>
<p>First I process the audios to extract a spectrogram and put it on a list, with all the audios forming four lists (trainMixed, trainVocals, testMixed, testVocals). Like this:</p>
<pre><code>def to_spec(wav, n_fft=1024, hop_length=256):
    return librosa.stft(wav, n_fft=n_fft, hop_length=hop_length)

def prepareData(filename, sr=22050, hop_length=256, n_fft=1024):
  audio_wav = librosa.load(filename, sr=sr, mono=True, duration=30)[0]
  audio_spec=to_spec(audio_wav, n_fft=n_fft, hop_length=hop_length)
  audio_spec_mag = np.abs(audio_spec)
  maxVal = np.max(audio_spec_mag)

  return audio_spec_mag, maxVal


# FOR EVERY LIST (trainMixed, trainVocals, testMixed, testVocals)
trainMixed = []
trainMixedNum = 0
for (root, dirs, files) in walk('./Dev-subset-mix/Dev/'):
  for d in dirs:
    filenameMix = './Dev-subset-mix/Dev/'+d+'/mixture.wav'
    spec_mag, maxVal = prepareData(filenameMix, n_fft=1024, hop_length=256)
    trainMixed.append(spec_mag/maxVal)
</code></pre>
<p>Next i build the model:</p>
<pre><code>import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.optimizers import SGD
from keras.layers.advanced_activations import LeakyReLU

model = Sequential()
model.add(Conv2D(16, (3,3), padding='same', input_shape=(513, 25, 1)))
model.add(LeakyReLU())
model.add(Conv2D(16, (3,3), padding='same'))
model.add(LeakyReLU())
model.add(MaxPooling2D(pool_size=(3,3)))
model.add(Dropout(0.25))
model.add(Conv2D(16, (3,3), padding='same'))
model.add(LeakyReLU())
model.add(Conv2D(16, (3,3), padding='same'))
model.add(LeakyReLU())
model.add(MaxPooling2D(pool_size=(3,3)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(64))
model.add(LeakyReLU())
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))
sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss=keras.losses.binary_crossentropy, optimizer=sgd, metrics=['accuracy'])
</code></pre>
<p>And run the model:</p>
<pre><code>model.fit(trainMixed, trainVocals,epochs=10, validation_data=(testMixed, testVocals))
</code></pre>
<p>But I'm getting this result:</p>
<pre><code>ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step
        y_pred = self(x, training=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__
        self.name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:158 assert_input_compatibility
        ' input tensors. Inputs received: ' + str(inputs))

    ValueError: Layer sequential_1 expects 1 inputs, but it received 2 input tensors. Inputs received: [&lt;tf.Tensor 'IteratorGetNext:0' shape=(None, 2584) dtype=float32&gt;, &lt;tf.Tensor 'IteratorGetNext:1' shape=(None, 2584) dtype=float32&gt;]
</code></pre>
<p>I am new to this topic, thanks for the help provided in advance.</p>
",13994659.0,,,,,2021-10-07 09:45:08,"ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 2584]",<python><tensorflow><machine-learning><keras><deep-learning>,2,2,0.0,,,CC BY-SA 4.0
65103526,1,65225240.0,,2020-12-02 06:57:55,,10,5974,"<p>I have trained a TextVectorization layer (see below), and I want to save it to disk, so that I can reload it next time? I have tried <code>pickle</code> and <code>joblib.dump()</code>. It does not work.</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras.layers.experimental.preprocessing import TextVectorization 

text_dataset = tf.data.Dataset.from_tensor_slices(text_clean) 
    
vectorizer = TextVectorization(max_tokens=100000, output_mode='tf-idf',ngrams=None)
    
vectorizer.adapt(text_dataset.batch(1024))
</code></pre>
<p>The generated error is the following:</p>
<pre class=""lang-py prettyprint-override""><code>InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array
</code></pre>
<p>How can I save it?</p>
",6407393.0,,1021819.0,,2021-12-03 11:49:03,2021-12-31 17:34:30,How to save TextVectorization to disk in tensorflow?,<tensorflow><keras><tensorflow2.0><pickle>,4,5,0.0,,,CC BY-SA 4.0
66113224,1,66114345.0,,2021-02-09 04:56:52,,10,11818,"<p>I am trying to create a CNN model using RandomSearch but its very slow and pops this error <code>tensorflow:Callback method on_train_batch_end is slow compared to the batch time</code>
I am running my code in google colab with hardware acceleration set on gpu
this is my code</p>
<pre><code>def model_builder(hp):
    model=Sequential([
        Conv2D(filters=hp.Int('conv_1_filter',min_value=32,max_value=128,step=32),
               kernel_size=hp.Int('conv_1_filter',min_value=2,max_value=3,step=1),
               activation='relu',
               padding='same',
               input_shape=(200,200,3)),
        MaxPooling2D(pool_size=(2,2),strides=(2,2)),
        
        Conv2D(filters=hp.Int('conv_2_filter',min_value=32,max_value=128,step=32),
               kernel_size=hp.Int('conv_2_filter',min_value=2,max_value=3,step=1),
               padding='same',
               activation='relu'),
        MaxPooling2D(pool_size=(2,2),strides=(2,2)),
        
        Flatten(),
        
        Dense(units=hp.Int('dense_1_units',min_value=32,max_value=512,step=128),
              activation='relu'),
        
        Dense(units=10,
              activation='softmax')
               
    ])
    
    model.compile(optimizer=Adam(hp.Choice('learning_rate',values=[1e-1,1e-3,3e-2])),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model
</code></pre>
<p>then RandomSearch and Fit</p>
<pre><code>tuner=RandomSearch(model_builder,
                   objective='val_accuracy',
                   max_trials=2,
                   directory='projects',
                   project_name='Hypercars CNN'
                  )
tuner.search(X_train,Y_train,epochs=2,validation_split=0.2)
</code></pre>
",14899587.0,,,,,2023-01-27 16:43:05,tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time,<tensorflow><keras><conv-neural-network>,2,0,0.0,,,CC BY-SA 4.0
66667080,1,,,2021-03-17 04:39:40,,10,726,"<p>I am writing a custom on_train_end callback function for model.fit() method of tensorflow keras sequential model. The callback function is about plotting the predictions that the model makes, so it involves converting the inputs of the model to a numpy array and feeds it into model.predict(). I use self.model.inputs to access the inputs, which is a list of KerasTensor objects and the one at 0th index is what I want. I tried the following approach</p>
<pre><code>class my_visualizer(tf.keras.callbacks.Callback):

    def on_train_end(self, logs=None):

        x = tf.keras.backend.eval(self.model.inputs[0])
        y_predictions = self.model.predict(x)
        
</code></pre>
<p>but got the error</p>
<pre><code>AttributeError: 'KerasTensor' object has no attribute 'numpy'
</code></pre>
<p>So this method is for another type of tensor rather than KerasTensor. Other solutions I found work for tensorflow's Tensor object but not keras' KerasTensor object, and I did not find any mentioning of the ways to achieve the desired feature in keras documentation. Thanks for your help!</p>
",12345152.0,,9657861.0,,2021-12-10 15:17:47,2022-01-13 12:12:54,Convert a KerasTensor object to a numpy array to visualize predictions in Callback,<python><tensorflow><keras><tf.keras>,1,0,0.0,,,CC BY-SA 4.0
63869134,1,63869558.0,,2020-09-13 09:23:31,,10,11672,"<h1>Problem Description</h1>
<p>I am trying to write a custom loss function in TensorFlow 2.3.0. To calculate the loss, I need the <code>y_pred</code> parameter to be converted to a numpy array. However, I can't find a way to convert it from <code>&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;</code> to numpy array, even though there seem to TensorFlow functions to do so.</p>
<h1>Code Example</h1>
<pre><code>def custom_loss(y_true, y_pred):
    print(type(y_pred))
    npa = y_pred.make_ndarray()
    ...
    

if __name__ == '__main__':
    ...
    model.compile(loss=custom_loss, optimizer=&quot;adam&quot;)
    model.fit(x=train_data, y=train_data, epochs=10)
</code></pre>
<p>gives the error message: <code>AttributeError: 'Tensor' object has no attribute 'make_ndarray</code>
after printing the type of the <code>y_pred</code> parameter: <code>&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;</code></p>
<h1>What I have tried so far</h1>
<p>Looking for a solution I found this seems to be a common issue and there a couple of suggestions, but they did not work for me so far:</p>
<p><strong>1. &quot; ... so just call .numpy() on the Tensor object.&quot;: <a href=""https://www.thetopsites.net/article/51302819.shtml"" rel=""noreferrer"">How can I convert a tensor into a numpy array in TensorFlow?</a></strong></p>
<p>so I tried:</p>
<pre><code>def custom_loss(y_true, y_pred):
    npa = y_pred.numpy()
    ...
</code></pre>
<p>giving me <code>AttributeError: 'Tensor' object has no attribute 'numpy'</code></p>
<p><strong>2. &quot;Use tensorflow.Tensor.eval() to convert a tensor to an array&quot;: <a href=""https://www.kite.com/python/answers/how-to-convert-a-tensorflow-tensor-to-a-numpy-array-in-python"" rel=""noreferrer"">How to convert a TensorFlow tensor to a NumPy array in Python</a></strong></p>
<p>so I tried:</p>
<pre><code>def custom_loss(y_true, y_pred):
    npa = y_pred.eval(session=tf.compat.v1.Session())
    ...
</code></pre>
<p>giving me one of the longest trace of error messages I ever have seen with the core being:</p>
<pre><code>InvalidArgumentError: 2 root error(s) found.
      (0) Invalid argument: You must feed a value for placeholder tensor 'functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource' with dtype resource
         [[node functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource (defined at main.py:303) ]]
         [[functional_1/cropping2d/strided_slice/_1]]
      (1) Invalid argument: You must feed a value for placeholder tensor 'functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource' with dtype resource
         [[node functional_1/conv2d_2/BiasAdd/ReadVariableOp/resource (defined at main.py:303) ]]
</code></pre>
<p>also having to call TensorFlow Compatibility Functions from Version 1.x does not feel very future-proof, so I do not like this approach too much anyhow.</p>
<p><strong>3. Looking at the TensorFlow Docs there seemed to be the function I needed just waiting: <a href=""https://www.tensorflow.org/api_docs/python/tf/make_ndarray"" rel=""noreferrer"">tf.make_ndarray</a> Create a numpy ndarray from a tensor.</strong></p>
<p>so I tried:</p>
<pre><code>def custom_loss(y_true, y_pred):
    npa = tf.make_ndarray(y_pred)
    ...
</code></pre>
<p>giving me <code>AttributeError: 'Tensor' object has no attribute 'tensor_shape'</code></p>
<p>Looking at the example in the TF documentation they use this on a proto_tensor, so I tried converting to a proto first:</p>
<pre><code>def custom_loss(y_true, y_pred):
    proto_tensor = tf.make_tensor_proto(y_pred)
    npa = tf.make_ndarray(proto_tensor)
    ...
</code></pre>
<p>but already the <code>tf.make_tensor_proto(y_pred)</code> raises the error: <code>TypeError: Expected any non-tensor type, got a tensor instead.</code></p>
<p>Also trying to make a const tensor first gives the same error:</p>
<pre><code>def custom_loss(y_true, y_pred):
    a = tf.constant(y_pred)
    proto_tensor = tf.make_tensor_proto(a)
    npa = tf.make_ndarray(proto_tensor)
    ...
</code></pre>
<p>There are many more posts around this but it seems they are all coming back to these three basic ideas. Looking forward to your suggestions!</p>
",12207268.0,,,,,2020-09-13 13:23:07,Converting TensorFlow tensor into Numpy array,<python><tensorflow><keras><tensorflow2.0>,1,0,0.0,,,CC BY-SA 4.0
66237656,1,66238161.0,,2021-02-17 07:46:13,,10,1406,"<p>As a newbie for TF, I feel a little confused about the usage of BatchDataset in training a model.</p>
<p>Let's use the MNIST as an example. In this classification task, we can load the data and feed the ndarray of x_trian, y_train directly into the model.</p>
<pre><code>mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train,y_train, epochs=5)

</code></pre>
<p>The training results are:</p>
<pre><code>Epoch 1/5
2021-02-17 15:43:02.621749: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
   1/1875 [..............................] - ETA: 0s - loss: 2.2977 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
1875/1875 [==============================] - 2s 1ms/step - loss: 0.3047 - accuracy: 0.9117
Epoch 2/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.1473 - accuracy: 0.9569
Epoch 3/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.1097 - accuracy: 0.9673
Epoch 4/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.0905 - accuracy: 0.9724
Epoch 5/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.0759 - accuracy: 0.9764
</code></pre>
<p>And we can also use tf.data.Dataset.from_tensor_slices to generate a BatchDataset and feed it in to fit function.</p>
<pre><code>mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

train_ds = tf.data.Dataset.from_tensor_slices(
    (x_train, y_train)).shuffle(10000).batch(32)

test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_ds, epochs=5)
</code></pre>
<p>The results in training process is as follows.</p>
<pre><code>Epoch 1/5
2021-02-17 15:30:34.698718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
1875/1875 [==============================] - 3s 1ms/step - loss: 0.2969 - accuracy: 0.9140
Epoch 2/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.1462 - accuracy: 0.9566
Epoch 3/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.1087 - accuracy: 0.9669
Epoch 4/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.0881 - accuracy: 0.9730
Epoch 5/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.0765 - accuracy: 0.9759
</code></pre>
<p>The model can be trained successfully with 2 methods, but is there any difference between them? Does using Dataset for training have some additional advantages? If there is no difference between the 2 methods in this case, what the typical usage of generating a Dataset for training and when should this method be used?</p>
<p>Thank you.</p>
",15024599.0,,,,,2021-03-01 22:46:23,What's the difference between using Dataset and ndarray in fit method in Tensorflow 2?,<tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0
63542803,1,63542911.0,,2020-08-23 02:18:29,,10,50273,"<p><strong>Below the code</strong></p>
<pre><code>import numpy as np
np.random.seed(0)
from sklearn import datasets
import matplotlib.pyplot as plt
%matplotlib inline
%config InlineBackend.figure_format ='retina'

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD
</code></pre>
<p><strong>below the Error message</strong></p>
<pre><code>---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
      2 try:
----&gt; 3     from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
      4 except ImportError:

ModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental.preprocessing'

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
&lt;ipython-input-5-943507dd87a6&gt; in &lt;module&gt;
      6 get_ipython().run_line_magic('config', &quot;InlineBackend.figure_format ='retina'&quot;)
      7 
----&gt; 8 from keras.models import Sequential
      9 from keras.layers import Dense
     10 from keras.optimizers import SGD

~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
      4 except ImportError:
      5     raise ImportError(
----&gt; 6         'Keras requires TensorFlow 2.2 or higher. '
      7         'Install TensorFlow via `pip install tensorflow`')
      8 

ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow
</code></pre>
<p><strong>Note:`</strong> I think, the main problem is Tensorflow version. I used somes command and that's are bellow,</p>
<pre><code>conda create -n tf tensorflow
conda activate tf
</code></pre>
<p><strong>and I also used the below command</strong></p>
<pre><code>conda create -n tf-gpu tensorflow-gpu
conda activate tf-gpu
</code></pre>
<p>But it don't works , Please help for solve the error.</p>
",14065992.0,,14065992.0,,2020-08-23 02:23:37,2023-05-25 07:20:29,No module named 'tensorflow.keras.layers.experimental.preprocessing',<tensorflow><machine-learning><keras><deep-learning><neural-network>,2,1,0.0,,,CC BY-SA 4.0
63146892,1,63147104.0,,2020-07-29 05:32:30,,10,30394,"<p>I'd like to load a keras model that i've trained and saved it as <strong>.pb</strong>.<br> Here's the code, <br>
<a href=""https://i.stack.imgur.com/PVE0U.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/PVE0U.jpg"" alt=""enter image description here"" /></a></p>
<p>Am using a jupyter notebook. <br>
The model is successfully saved as <strong>saved_model.pb</strong> under the same directory. But the code is unable to access it. <br><br>
Can anybody see to it, how can i access this keras model that's saved in <strong>.pb</strong> extension. <br>I checked at several other places for solution but no luck. <br>
<br></p>
<p>Model is saved at <strong>model/saved_model.pb</strong>. <br>
I've taken out the <strong>.pb</strong> file and placed it in the same directory where my code file exists.</p>
",11283911.0,,11283911.0,,2020-07-29 05:45:38,2021-07-28 15:25:12,How to load a keras model saved as .pb,<python><tensorflow><machine-learning><keras><deep-learning>,2,4,0.0,,,CC BY-SA 4.0
63006475,1,,,2020-07-21 02:28:41,,10,38113,"<p>I get this error when I try to import Keras into my project.</p>
<blockquote>
<p>How to solve ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via <code>pip install tensorflow</code></p>
</blockquote>
<p>I verified the versions I have installed (with pip) for everything and I have:</p>
<ul>
<li>Python 3.7.7</li>
<li>Tensorflow 2.2.0</li>
<li>keras 2.4.3</li>
</ul>
<p>I have linked a picture of the full error. There is some stuff about Dll but I'm not sure if this is what creates the error.</p>
<p><a href=""https://i.stack.imgur.com/tZ7wp.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/tZ7wp.png"" alt=""Error"" /></a></p>
",9059082.0,,10358768.0,,2020-07-21 03:44:52,2021-01-17 09:25:35,How to solve ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`?,<python><tensorflow><keras>,3,0,,,,CC BY-SA 4.0
66845924,1,66849164.0,,2021-03-28 20:31:16,,10,14323,"<p>As described in figure 1, I have 3 models which each apply to a particular domain.</p>
<p>The 3 models are trained separately with different datasets.
<a href=""https://i.stack.imgur.com/HaNeY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/HaNeY.png"" alt=""enter image description here"" /></a></p>
<p>And inference is sequential :</p>
<p><a href=""https://i.stack.imgur.com/li5m1.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/li5m1.png"" alt=""enter image description here"" /></a></p>
<p>I tried to parallelize the call of these 3 models thanks to the Multiprocess library of python but it is very unstable and it is not advised.</p>
<p>Here's the idea I got to make sure to do this all at once:</p>
<p>As the 3 models share a common pretrained-model, I want to make a single model that has multiple inputs and multiple outputs.</p>
<p>As the following drawing shows:
<a href=""https://i.stack.imgur.com/mDZj0.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/mDZj0.png"" alt=""enter image description here"" /></a></p>
<p>Like that during the inference, I will call a single model which will do all 3 operations at the same time.</p>
<p><a href=""https://i.stack.imgur.com/FvG4u.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/FvG4u.png"" alt=""enter image description here"" /></a></p>
<p>I saw that with The Functional API of KERAS, it is possible but I have no idea how to do that.
The inputs of the datasets have the same dimension. These are pictures of (200,200,3).</p>
<p>If anyone has an example of a Multi-Input Multi-output model that shares a common structure, I'm all ok.</p>
<h2>UPADE</h2>
<p>Here is the example of my code but it returns an error because of the <code>layers. concatenate (...)</code> line which propagates a shape that is not taken into account by the <code>EfficientNet</code> model.</p>
<pre><code>age_inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=&quot;age_inputs&quot;)
    
gender_inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)
                               , name=&quot;gender_inputs&quot;)
    
emotion_inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), 
                                name=&quot;emotion_inputs&quot;)


inputs = layers.concatenate([age_inputs, gender_inputs, emotion_inputs])
inputs = layers.Conv2D(3, (3, 3), activation=&quot;relu&quot;)(inputs)    
model = EfficientNetB0(include_top=False, 
                   input_tensor=inputs, weights=&quot;imagenet&quot;)
    

model.trainable = False

inputs = layers.GlobalAveragePooling2D(name=&quot;avg_pool&quot;)(model.output)
inputs = layers.BatchNormalization()(inputs)

top_dropout_rate = 0.2
inputs = layers.Dropout(top_dropout_rate, name=&quot;top_dropout&quot;)(inputs)

age_outputs = layers.Dense(1, activation=&quot;linear&quot;, 
                          name=&quot;age_pred&quot;)(inputs)
gender_outputs = layers.Dense(GENDER_NUM_CLASSES, 
                              activation=&quot;softmax&quot;, 
                              name=&quot;gender_pred&quot;)(inputs)
emotion_outputs = layers.Dense(EMOTION_NUM_CLASSES, activation=&quot;softmax&quot;, 
                             name=&quot;emotion_pred&quot;)(inputs)

model = keras.Model(inputs=[age_inputs, gender_inputs, emotion_inputs], 
              outputs =[age_outputs, gender_outputs, emotion_outputs], 
              name=&quot;EfficientNet&quot;)

optimizer = keras.optimizers.Adam(learning_rate=1e-2)
model.compile(loss={&quot;age_pred&quot; : &quot;mse&quot;, 
                   &quot;gender_pred&quot;:&quot;categorical_crossentropy&quot;, 
                    &quot;emotion_pred&quot;:&quot;categorical_crossentropy&quot;}, 
                   optimizer=optimizer, metrics=[&quot;accuracy&quot;])

(age_train_images, age_train_labels), (age_test_images, age_test_labels) = reg_data_loader.load_data(...)
(gender_train_images, gender_train_labels), (gender_test_images, gender_test_labels) = cat_data_loader.load_data(...)
(emotion_train_images, emotion_train_labels), (emotion_test_images, emotion_test_labels) = cat_data_loader.load_data(...)

 model.fit({'age_inputs':age_train_images, 'gender_inputs':gender_train_images, 'emotion_inputs':emotion_train_images},
         {'age_pred':age_train_labels, 'gender_pred':gender_train_labels, 'emotion_pred':emotion_train_labels},
                 validation_split=0.2, 
                       epochs=5, 
                            batch_size=16)
</code></pre>
",1953160.0,,9215780.0,,2023-04-07 08:26:47,2023-04-07 08:26:47,Multi-input Multi-output Model with Keras Functional API,<python><tensorflow><keras><deep-learning><functional-api>,1,0,0.0,,,CC BY-SA 4.0
62744659,1,62877076.0,,2020-07-05 18:19:31,,10,12034,"<p>I want to build a Neural Network with two inputs: for image data and for numeric data. So I wrote custom data generator for that. The <code>train</code> and <code>validation</code> dataframes contain 11 columns:</p>
<ol>
<li><code>image_name</code> — path to the image;</li>
<li>9 numeric features;</li>
<li><code>target</code> — class for the item (last column).</li>
</ol>
<p>The code for custom generator  (based on <a href=""https://stackoverflow.com/a/60562073/1821692"">this answer</a>):</p>
<pre class=""lang-py prettyprint-override""><code>target_size = (224, 224)
batch_size = 1

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(
    train,
    x_col='image_name',
    y_col=train.columns[1:],
    target_size=target_size,
    batch_size=batch_size,
    shuffle=True,
    class_mode='raw')

validation_generator = val_datagen.flow_from_dataframe(
    validation,
    x_col='image_name',
    y_col=validation.columns[1:],
    target_size=target_size,
    shuffle=False,
    batch_size=batch_size,
    class_mode='raw')

def train_generator_func():
    count = 0
    while True:
        if count == len(train.index):
            train_generator.reset()
            break
        count += 1
        data = train_generator.next()
        
        imgs = []
        cols = []
        targets = []
        
        for k in range(batch_size):
            imgs.append(data[0][k])
            cols.append(data[1][k][:-1])
            targets.append(data[1][k][-1])
            
        yield [imgs, cols], targets
        
def validation_generator_func():
    count = 0
    while True:
        if count == len(validation.index):
            validation_generator.reset()
            break
        count += 1
        data = validation_generator.next()
                
        imgs = []
        cols = []
        targets = []
        
        for k in range(batch_size):
            imgs.append(data[0][k])
            cols.append(data[1][k][:-1])
            targets.append(data[1][k][-1])
            
        yield [imgs, cols], targets
</code></pre>
<p>Model building:</p>
<pre class=""lang-py prettyprint-override""><code>def mlp_model(dim):
    model = Sequential()
    model.add(Dense(8, input_dim=dim, activation=&quot;relu&quot;))
    model.add(Dense(4, activation=&quot;relu&quot;))
    return model


def vgg16_model():
    model = VGG16(weights='imagenet', include_top=False, input_shape=target_size+(3,))
    x=Flatten()(model.output)
    output=Dense(1,activation='sigmoid')(x) # because we have to predict the AUC
    model=Model(model.input,output)
    return model


def concatenated_model(cnn, mlp):
    combinedInput = concatenate([cnn.output, mlp.output])
    x = Dense(4, activation=&quot;relu&quot;)(combinedInput)
    x = Dense(1, activation=&quot;sigmoid&quot;)(x)    
    model = Model(inputs=[cnn.input, mlp.input], outputs=x)
    return model


def focal_loss(alpha=0.25,gamma=2.0):
    def focal_crossentropy(y_true, y_pred):
        bce = K.binary_crossentropy(y_true, y_pred)
        
        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())
        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))
        
        alpha_factor = 1
        modulating_factor = 1

        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))
        modulating_factor = K.pow((1-p_t), gamma)

        # compute the final loss and return
        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)
    return focal_crossentropy

cnn = vgg16_model()
mlp = mlp_model(9)

model = concatenated_model(cnn, mlp)

opt = Adam(lr=1e-5)
model.compile(loss=focal_loss(), metrics=[tf.keras.metrics.AUC()],optimizer=opt)

nb_epochs = 2
nb_train_steps = train.shape[0]//batch_size
nb_val_steps = validation.shape[0]//batch_size

model.fit(
    train_generator_func(),
    steps_per_epoch=nb_train_steps,
    epochs=nb_epochs,
    validation_data=validation_generator_func(),
    validation_steps=nb_val_steps)
</code></pre>
<p>And fitting doesn't work with error message:</p>
<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-53-253849fd34d6&gt; in &lt;module&gt;
      9     epochs=nb_epochs,
     10     validation_data=validation_generator_func(),
---&gt; 11     validation_steps=nb_val_steps)

d:\pyenv\keras-gpu\lib\site-packages\tensorflow\python\keras\engine\training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--&gt; 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

d:\pyenv\keras-gpu\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1061           use_multiprocessing=use_multiprocessing,
   1062           model=self,
-&gt; 1063           steps_per_execution=self._steps_per_execution)
   1064 
   1065       # Container that configures and calls `tf.keras.Callback`s.

d:\pyenv\keras-gpu\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)
   1108         use_multiprocessing=use_multiprocessing,
   1109         distribution_strategy=ds_context.get_strategy(),
-&gt; 1110         model=model)
   1111 
   1112     strategy = ds_context.get_strategy()

d:\pyenv\keras-gpu\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py in __init__(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)
    796       return tensor_shape.TensorShape([None for _ in shape.as_list()])
    797 
--&gt; 798     output_shapes = nest.map_structure(_get_dynamic_shape, peek)
    799     output_types = nest.map_structure(lambda t: t.dtype, peek)
    800 

d:\pyenv\keras-gpu\lib\site-packages\tensorflow\python\util\nest.py in map_structure(func, *structure, **kwargs)
    633 
    634   return pack_sequence_as(
--&gt; 635       structure[0], [func(*x) for x in entries],
    636       expand_composites=expand_composites)
    637 

d:\pyenv\keras-gpu\lib\site-packages\tensorflow\python\util\nest.py in &lt;listcomp&gt;(.0)
    633 
    634   return pack_sequence_as(
--&gt; 635       structure[0], [func(*x) for x in entries],
    636       expand_composites=expand_composites)
    637 

d:\pyenv\keras-gpu\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py in _get_dynamic_shape(t)
    792       shape = t.shape
    793       # Unknown number of dimensions, `as_list` cannot be called.
--&gt; 794       if shape.rank is None:
    795         return shape
    796       return tensor_shape.TensorShape([None for _ in shape.as_list()])

AttributeError: 'tuple' object has no attribute 'rank'
</code></pre>
<p>So I tried to look at Keras sources but without any success.</p>
<p>If I use modified <code>train_generator</code> and <code>validation_generator</code> (<code>y_col='target'</code> instead of <code>y_col=train.columns[1:]</code>) everything works fine.</p>
",1821692.0,,2099607.0,,2020-07-13 13:45:02,2022-11-22 17:31:34,AttributeError: 'tuple' object has no attribute 'rank' when calling fit on a Keras model with custom generator,<python><tensorflow><keras><deep-learning><neural-network>,2,14,,,,CC BY-SA 4.0
67116476,1,,,2021-04-15 21:52:59,,10,2214,"<p>I am trying to write my own training loop for <code>TF2/Keras</code>, following the official Keras walkthrough. The vanilla version works like a charm, but when I try to add the <code>@tf.function</code> decorator to my training step, some memory leak grabs all my memory and I lose control of my machine, does anyone know what is going on?.</p>
<p>The important parts of the code look like this:</p>
<pre><code>@tf.function
def train_step(x, y):
    with tf.GradientTape() as tape:
        logits = siamese_network(x, training=True)
        loss_value = loss_fn(y, logits)
    grads = tape.gradient(loss_value, siamese_network.trainable_weights)
    optimizer.apply_gradients(zip(grads, siamese_network.trainable_weights))
    train_acc_metric.update_state(y, logits)
    return loss_value

@tf.function
def test_step(x, y):
    val_logits = siamese_network(x, training=False)
    val_acc_metric.update_state(y, val_logits)
    val_prec_metric.update_state(y_batch_val, val_logits)
    val_rec_metric.update_state(y_batch_val, val_logits)


for epoch in range(epochs):
        step_time = 0
        epoch_time = time.time()
        print(&quot;Start of {} epoch&quot;.format(epoch))
        for step, (x_batch_train, y_batch_train) in enumerate(train_ds):
            if step &gt; steps_epoch:
                break
           
            loss_value = train_step(x_batch_train, y_batch_train)
        train_acc = train_acc_metric.result()
        train_acc_metric.reset_states()
        
        for val_step,(x_batch_val, y_batch_val) in enumerate(test_ds):
            if val_step&gt;validation_steps:
                break
            test_step(x_batch_val, y_batch_val)
         
        val_acc = val_acc_metric.result()
        val_prec = val_prec_metric.result()
        val_rec = val_rec_metric.result()

        val_acc_metric.reset_states()
        val_prec_metric.reset_states()
        val_rec_metric.reset_states()
</code></pre>
<p>If I comment on the <code>@tf.function</code> lines, the memory leak doesn't occur, but the step time is 3 times slower. My guess is that somehow the graph is bean created again within each epoch or something like that, but I have no idea how to solve it.</p>
<p>This is the tutorial I am following: <a href=""https://keras.io/guides/writing_a_training_loop_from_scratch/"" rel=""noreferrer"">https://keras.io/guides/writing_a_training_loop_from_scratch/</a></p>
",15651990.0,,9215780.0,,2021-05-01 10:19:31,2021-10-11 13:35:19,Memory leak for custom tensorflow training using @tf.function,<python><tensorflow><keras><custom-training>,1,2,0.0,,,CC BY-SA 4.0
64622210,1,64622975.0,,2020-10-31 13:29:17,,10,13573,"<p>I was trying to plot a confusion matrix for my image classifier with the following code but I got an error message: 'PrefetchDataset' object has no attribute 'classes'</p>
<pre><code>Y_pred = model.predict(validation_dataset)
y_pred = np.argmax(Y_pred, axis=1)

print('Confusion Matrix')
print(confusion_matrix(validation_dataset.classes, y_pred)) # ERROR message generated
</code></pre>
<blockquote>
<p>PrefetchDataset' object has no attribute 'classes'</p>
</blockquote>
",12003811.0,,10908375.0,,2022-03-11 14:04:45,2022-03-11 14:12:18,How to extract classes from prefetched dataset in Tensorflow for confusion matrix,<python><tensorflow><machine-learning><image-processing><keras>,2,0,0.0,,,CC BY-SA 4.0
67047026,1,,,2021-04-11 15:49:03,,10,23491,"<p>I'm trying to apply Conv1D layers for a classification model which has a numeric dataset. The neural network of my model is as follows:</p>
<pre><code>model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv1D(8,kernel_size = 3, strides = 1,padding = 'valid', activation = 'relu',input_shape = (14999,7)))
model.add(tf.keras.layers.Conv1D(16,kernel_size = 3, strides = 1,padding = 'valid', activation = 'relu'))
model.add(tf.keras.layers.MaxPooling1D(2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Conv1D(32,kernel_size = 3, strides = 1,padding = 'valid', activation = 'relu'))
model.add(tf.keras.layers.Conv1D(64,kernel_size = 3, strides = 1,padding = 'valid', activation = 'relu'))
model.add(tf.keras.layers.MaxPooling1D(2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Conv1D(128,kernel_size = 3, strides = 1,padding = 'valid', activation = 'relu'))
model.add(tf.keras.layers.Conv1D(256,kernel_size = 3, strides = 1,padding = 'valid', activation = 'relu'))
model.add(tf.keras.layers.MaxPooling1D(2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(512,activation = 'relu'))
model.add(tf.keras.layers.Dense(128,activation = 'relu'))
model.add(tf.keras.layers.Dense(32,activation = 'relu'))
model.add(tf.keras.layers.Dense(3, activation = 'softmax'))
</code></pre>
<p>And the model's input shape is (14999, 7).</p>
<p>model.summary() gives the following output</p>
<pre><code>Model: &quot;sequential_8&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_24 (Conv1D)           (None, 14997, 8)          176       
_________________________________________________________________
conv1d_25 (Conv1D)           (None, 14995, 16)         400       
_________________________________________________________________
max_pooling1d_10 (MaxPooling (None, 7497, 16)          0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 7497, 16)          0         
_________________________________________________________________
conv1d_26 (Conv1D)           (None, 7495, 32)          1568      
_________________________________________________________________
conv1d_27 (Conv1D)           (None, 7493, 64)          6208      
_________________________________________________________________
max_pooling1d_11 (MaxPooling (None, 3746, 64)          0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 3746, 64)          0         
_________________________________________________________________
conv1d_28 (Conv1D)           (None, 3744, 128)         24704     
_________________________________________________________________
conv1d_29 (Conv1D)           (None, 3742, 256)         98560     
_________________________________________________________________
max_pooling1d_12 (MaxPooling (None, 1871, 256)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 1871, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 478976)            0         
_________________________________________________________________
dense_14 (Dense)             (None, 512)               245236224 
_________________________________________________________________
dense_15 (Dense)             (None, 128)               65664     
_________________________________________________________________
dense_16 (Dense)             (None, 32)                4128      
_________________________________________________________________
dense_17 (Dense)             (None, 3)                 99        
=================================================================
Total params: 245,437,731
Trainable params: 245,437,731
Non-trainable params: 0
</code></pre>
<p>The code for model fitting is:</p>
<pre><code>model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
history = model.fit(xtrain_scaled, ytrain_scaled, epochs = 30, batch_size = 5, validation_data = (xval_scaled, yval_scaled))
</code></pre>
<p>While executing, I'm facing the following error:</p>
<pre><code>ValueError: Input 0 is incompatible with layer model: expected shape=(None, 14999, 7), found shape=(None, 7)
</code></pre>
<p>Could anyone help to sort out this issue?</p>
",15605257.0,,9805238.0,,2021-08-03 13:56:49,2021-08-03 13:56:49,"ValueError: Input 0 is incompatible with layer model: expected shape=(None, 14999, 7), found shape=(None, 7)",<tensorflow><machine-learning><keras><deep-learning><multiclass-classification>,1,0,0.0,,,CC BY-SA 4.0
72350446,1,,,2022-05-23 14:42:52,,10,8529,"<p>I am training a keras sequential model and now wish to predict a value. I run the following single line</p>
<pre class=""lang-py prettyprint-override""><code>agent.model.predict(np.array([0,0,0,0]).reshape(1,4))
</code></pre>
<p>and get the following output displayed in my notebook</p>
<pre><code>1/1 [==============================] - 0s 29ms/step
array([[0.00760011, 0.01811639]], dtype=float32)
</code></pre>
<p>How do I stop Keras from showing the first line in the output?</p>
",19181494.0,,,,,2023-04-02 20:41:19,How can I stop Keras from printing after calling model.predict,<python><tensorflow><keras>,3,1,,,,CC BY-SA 4.0
66879748,1,66880334.0,,2021-03-30 23:31:57,,10,6958,"<p>In some <code>tf. keras</code> tutorials, I've seen them instantiated their model class like this:</p>
<p><code>model = tf.keras.Sequential()</code></p>
<p>While in some places, they use something like this:</p>
<p><code>model = tf.keras.Model(inputs=input, outputs=output)</code></p>
<p>But seeing here in the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""noreferrer"">docs</a>, they do seem the same, but I am not sure nor is it explicitly mentioned. What are the differences between the two?</p>
",8648710.0,,9215780.0,,2021-03-31 01:56:34,2021-03-31 02:27:29,What is the difference between tf.keras.model and tf.keras.sequential?,<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0
69470332,1,69478545.0,,2021-10-06 17:40:34,,9,14547,"<p>I use</p>
<pre><code>layers.Normalization()
</code></pre>
<p>in Keras, in <code>keras.Sequential</code>
When I try to run it, I get the following error:</p>
<blockquote>
<p>module 'tensorflow.keras.layers' has no attribute 'Normalization'</p>
</blockquote>
<p>I've seen the command <code>layers.Normalization()</code> being used in many codes, so I don't know what's wrong. Did something change?</p>
",7926878.0,,,,,2021-10-08 07:50:34,I get error: module 'tensorflow.keras.layers' has no attribute 'Normalization',<tensorflow><keras>,2,4,0.0,,,CC BY-SA 4.0
66182884,1,66189774.0,,2021-02-13 07:43:24,,9,12562,"<p>I have already trained a network and I have saved it in the form of mynetwork.model. I want to apply gradcam using my own model and not VGG16 or ResNet etc.</p>
<p><strong>apply_gradcam.py</strong></p>
<pre><code># import the necessary packages
from Grad_CAM.gradcam import GradCAM
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.applications import imagenet_utils
from tensorflow.keras.models import load_model
import numpy as np
import argparse
import imutils
import cv2


# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument(&quot;-i&quot;, &quot;--image&quot;, required=True,
    help=&quot;path to the input image&quot;)
ap.add_argument(&quot;-m&quot;, &quot;--model&quot;, type=str, default=&quot;vgg&quot;,
    #choices=(&quot;vgg&quot;, &quot;resnet&quot;),
    help=&quot;model to be used&quot;)
args = vars(ap.parse_args())


# initialize the model to be VGG16
Model = VGG16
# check to see if we are using ResNet
if args[&quot;model&quot;] == &quot;resnet&quot;:
    Model = ResNet50
# load the pre-trained CNN from disk
print(&quot;[INFO] loading model...&quot;)
model = Model(weights=&quot;imagenet&quot;)

# load the original image from disk (in OpenCV format) and then
# resize the image to its target dimensions
orig = cv2.imread(args[&quot;image&quot;])
resized = cv2.resize(orig, (224, 224))
# load the input image from disk (in Keras/TensorFlow format) and
# preprocess it
image = load_img(args[&quot;image&quot;], target_size=(224, 224))
image = img_to_array(image)
image = np.expand_dims(image, axis=0)
image = imagenet_utils.preprocess_input(image)

# use the network to make predictions on the input image and find
# the class label index with the largest corresponding probability
preds = model.predict(image)
i = np.argmax(preds[0])
# decode the ImageNet predictions to obtain the human-readable label
decoded = imagenet_utils.decode_predictions(preds)
(imagenetID, label, prob) = decoded[0][0]
label = &quot;{}: {:.2f}%&quot;.format(label, prob * 100)
print(&quot;[INFO] {}&quot;.format(label))

# initialize our gradient class activation map and build the heatmap
cam = GradCAM(model, i)
heatmap = cam.compute_heatmap(image)
# resize the resulting heatmap to the original input image dimensions
# and then overlay heatmap on top of the image
heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))
(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)

cv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)
cv2.putText(output, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX,
    0.8, (255, 255, 255), 2)
# display the original image and resulting heatmap and output image
# to our screen
output = np.vstack([orig, heatmap, output])
output = imutils.resize(output, height=700)
cv2.imshow(&quot;Output&quot;, output)
cv2.waitKey(0)
</code></pre>
<p><strong>gradcam.py</strong></p>
<pre><code>from tensorflow.keras.models import Model
import tensorflow as tf
import numpy as np
import cv2


class GradCAM:
    def __init__(self, model, classIdx, layerName=None):
        # store the model, the class index used to measure the class
        # activation map, and the layer to be used when visualizing
        # the class activation map
        self.model = model
        self.classIdx = classIdx
        self.layerName = layerName
        # if the layer name is None, attempt to automatically find
        # the target output layer
        if self.layerName is None:
            self.layerName = self.find_target_layer()


    def find_target_layer(self):
        # attempt to find the final convolutional layer in the network
        # by looping over the layers of the network in reverse order
        for layer in reversed(self.model.layers):
            # check to see if the layer has a 4D output
            if len(layer.output_shape) == 4:
                return layer.name
        # otherwise, we could not find a 4D layer so the GradCAM
        # algorithm cannot be applied
        raise ValueError(&quot;Could not find 4D layer. Cannot apply GradCAM.&quot;)


    def compute_heatmap(self, image, eps=1e-8):
        # construct our gradient model by supplying (1) the inputs
        # to our pre-trained model, (2) the output of the (presumably)
        # final 4D layer in the network, and (3) the output of the
        # softmax activations from the model
        gradModel = Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.layerName).output,
                     self.model.output])

        # record operations for automatic differentiation
        with tf.GradientTape() as tape:
            # cast the image tensor to a float-32 data type, pass the
            # image through the gradient model, and grab the loss
            # associated with the specific class index
            inputs = tf.cast(image, tf.float32)
            (convOutputs, predictions) = gradModel(inputs)
            loss = predictions[:, self.classIdx]
        # use automatic differentiation to compute the gradients
        grads = tape.gradient(loss, convOutputs)

        # compute the guided gradients
        castConvOutputs = tf.cast(convOutputs &gt; 0, &quot;float32&quot;)
        castGrads = tf.cast(grads &gt; 0, &quot;float32&quot;)
        guidedGrads = castConvOutputs * castGrads * grads
        # the convolution and guided gradients have a batch dimension
        # (which we don't need) so let's grab the volume itself and
        # discard the batch
        convOutputs = convOutputs[0]
        guidedGrads = guidedGrads[0]

        # compute the average of the gradient values, and using them
        # as weights, compute the ponderation of the filters with
        # respect to the weights
        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))
        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)

        # grab the spatial dimensions of the input image and resize
        # the output class activation map to match the input image
        # dimensions
        (w, h) = (image.shape[2], image.shape[1])
        heatmap = cv2.resize(cam.numpy(), (w, h))
        # normalize the heatmap such that all values lie in the range
        # [0, 1], scale the resulting values to the range [0, 255],
        # and then convert to an unsigned 8-bit integer
        numer = heatmap - np.min(heatmap)
        denom = (heatmap.max() - heatmap.min()) + eps
        heatmap = numer / denom
        heatmap = (heatmap * 255).astype(&quot;uint8&quot;)
        # return the resulting heatmap to the calling function
        return heatmap

    def overlay_heatmap(self, heatmap, image, alpha=0.5,
                        colormap=cv2.COLORMAP_VIRIDIS):
        # apply the supplied color map to the heatmap and then
        # overlay the heatmap on the input image
        heatmap = cv2.applyColorMap(heatmap, colormap)
        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)
        # return a 2-tuple of the color mapped heatmap and the output,
        # overlaid image
        return (heatmap, output)
</code></pre>
<p>As you can see in apply_gradcam.py, the VGG16 or ResNet pretrained models are used. I want to perform gradcam by using my own trained model. For this reason I commented these lines:</p>
<pre><code>   # initialize the model to be VGG16
    Model = VGG16
    # check to see if we are using ResNet
    if args[&quot;model&quot;] == &quot;resnet&quot;:
        Model = ResNet50
    # load the pre-trained CNN from disk
    print(&quot;[INFO] loading model...&quot;)
    model = Model(weights=&quot;imagenet&quot;)
</code></pre>
<p>and I used</p>
<pre><code>model = load_model(args[&quot;model&quot;]) 
</code></pre>
<p>in order to use my own model. Then I executed:</p>
<pre><code> python apply_gradcam.py --image /home/antonis/IM0001.jpeg --model /home/antonis/mynetwork.model
</code></pre>
<p>However, I get the following error:</p>
<pre><code>ValueError: `decode_predictions` expects a batch of predictions (i.e.
a 2D array of shape (samples, 1000)). Found array with shape: (1, 3)
</code></pre>
<p>which is expected as the model outputs the ImageNet classes (1000-dimensional) while my model  returns predictions over 2 classes.</p>
<p>I wonder how to fix this and apply gradcam using my own model.</p>
",4132795.0,,4685471.0,,2021-02-13 12:31:57,2022-07-30 13:31:00,How to implement Grad-CAM on a trained network,<python><tensorflow><keras><deep-learning><conv-neural-network>,1,0,0.0,,,CC BY-SA 4.0
66802860,1,,,2021-03-25 15:38:33,,9,9735,"<p>I have been training a unet model for multiclass semantic segmentation in python using Tensorflow and Tensorflow Datasets.</p>
<p>I've noticed that one of my classes seems to be underrepresented in training. After doing some research, I found out about sample weights and thought it might be a good solution to my problem, but I've been having trouble deciphering the documentation on how to use it or find examples of it being used.</p>
<p>Could someone help explain how sample weights come into play with datasets for training or point me to an example where it is being implemented? Or even what type of input the model.fit function is expecting would be helpful.</p>
",15479507.0,,4685471.0,,2021-03-27 14:14:16,2021-03-27 14:14:16,How to use sample weights with tensorflow datasets?,<tensorflow><machine-learning><keras><tensorflow-datasets><tf.keras>,1,0,,,,CC BY-SA 4.0
64610447,1,,,2020-10-30 14:37:47,,9,633,"<p>Each time I run a Python code using TensorFlow (CPU), such as:</p>
<pre><code>import keras
</code></pre>
<p>I see this:</p>
<pre><code>2020-10-30 15:27:20.518894: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-10-30 15:27:20.518894: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-10-30 15:27:23.713077: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-10-30 15:27:23.713077: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2020-10-30 15:27:23.716077: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: User1-PC
2020-10-30 15:27:23.716077: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: User1-PC
2020-10-30 15:27:23.729078: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10cad0c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-30 15:27:23.729078: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
</code></pre>
<p>If I sum all the waiting time, there is ~ 10 seconds of waiting time.</p>
<p><strong>Is there a way to speed up this process?</strong> Especially if I'm using TensorFlow for inference (and not training), I don't want to have to wait 10 seconds on each startup of the engine.</p>
<hr />
<p>NB: Of course, when my code will be ready, I'll keep the process using TensorFlow constantly running, and I'll use some sort of inter-process communication, to avoid restart the whole program.</p>
<p>My question here is mostly for the <strong>prototyping</strong> stages, when you <em>often</em> need to restart the program: when prototyping, having to wait 10 or 15 seconds on each script start is highly unconvenient.</p>
",1422096.0,,1422096.0,,2020-11-17 22:13:14,2020-11-17 22:13:30,Speed up the initial TensorFlow startup,<python><tensorflow><keras>,1,2,0.0,,,CC BY-SA 4.0
66221788,1,66222183.0,,2021-02-16 09:29:54,,9,19568,"<pre><code>from tensorflow.keras.applications import VGG16
from tensorflow.keras import backend as K

model = VGG16(weights='imagenet',
              include_top=False)

layer_name = 'block3_conv1'
filter_index = 0

layer_output = model.get_layer(layer_name).output
loss = K.mean(layer_output[:, :, :, filter_index])

grads = K.gradients(loss, model.input)[0]
</code></pre>
<p>I am unable to execute <code>grads = K.gradients(loss, model.input)[0]</code>, it generates an error : <code>tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead</code></p>
",15218838.0,,7370153.0,,2021-02-16 09:46:42,2022-07-15 10:50:07,tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead,<python><tensorflow><keras>,1,0,,,,CC BY-SA 4.0
64796163,1,64796379.0,,2020-11-12 00:27:54,,9,6572,"<p>I'm trying to train a Tensorflow model with a very large dataset (much larger than my memory).</p>
<p>To fully utilize all the available training data, I'm thinking about separating them into several small &quot;shards&quot; and train on one shard at a time.</p>
<p>After a little research, I found this method is often referred to as &quot;incremental learning&quot;. And based on <a href=""https://en.wikipedia.org/wiki/Incremental_learning#:%7E:text=In%20computer%20science%2C%20incremental%20learning,to%20further%20train%20the%20model."" rel=""noreferrer"">this Wiki page</a>, NOT all algorithms support incremental learning.</p>
<p>I'm building my model using tf.keras.Model. In this case, is incremental learning possible?</p>
",2659869.0,,4685471.0,,2020-11-12 01:01:39,2021-11-26 02:54:04,Is incremental learning possible with Tensorflow?,<tensorflow><machine-learning><keras><tensorflow2.0>,1,0,0.0,,,CC BY-SA 4.0
63734956,1,,,2020-09-04 04:42:11,,9,2444,"<p>I use efficient-net with tensorflow2.3 API (keras==2.4.3)
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet</a></p>
<p>I could train and prediction on jupyterlab.
On the other hand, while Flask implementation, model checkpoint could be loaded but model.predict(numpy_img_array) doesn't work, and the following error occured. What does this error mean ?</p>
<p>And I used docker image <code>tensorflow/tensorflow:2.3.0-gpu-jupyter</code> is used, and I checked model.summary() works correctly.</p>
<p>Sincerely</p>
<pre><code> 2020-09-04 11:22:40.559654: E tensorflow/stream_executor/cuda/cuda_driver.cc:951] could not synchronize on CUDA context: CUDA_ERROR_NOT_INITIALIZED: initialization error :: *** Begin stack trace ***
   tensorflow::CurrentStackTrace()
   stream_executor::gpu::GpuDriver::SynchronizeContext(stream_executor::gpu::GpuContext*)
   stream_executor::StreamExecutor::SynchronizeAllActivity()
   tensorflow::GPUUtil::SyncAll(tensorflow::Device*)
   tensorflow::BaseGPUDevice::Sync()
   tensorflow::TensorHandle::CopyToDevice(tensorflow::EagerContext const&amp;, tensorflow::Device*, tensorflow::Tensor*)
   tensorflow::TensorHandle::Resolve(tensorflow::Status*)
   TFE_TensorHandleResolve
   _PyEval_EvalFrameDefault
   _PyFunction_FastCallDict
   _PyObject_FastCallKeywords
   _PyEval_EvalFrameDefault
   PyObject_Call
   _PyFunction_FastCallDict
   _PyObject_FastCallKeywords
   _PyEval_EvalFrameDefault
   PyEval_EvalCode
   PyRun_FileExFlags
   PyRun_SimpleFileExFlags
   Py_Main
   main
   __libc_start_main
   _start
 *** End stack trace ***
</code></pre>
",9898597.0,,,,,2020-09-04 05:25:23,CUDA_ERROR_NOT_INITIALIZED by model.predict() using tensorflow2.3,<python><keras><tensorflow2.x>,0,4,,,,CC BY-SA 4.0
65361359,1,65361719.0,,2020-12-18 17:29:38,,9,8610,"<p>I created a simple model for binary classification with Keras. The code is:</p>
<pre class=""lang-py prettyprint-override""><code>    # create model
    model = Sequential()
    model.add(Dense(250, input_dim=1, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    # Compile model
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'binary_accuracy'])
</code></pre>
<p>My purpose was check the result of <code>accuracy</code> and <code>binary_accuracy</code> is understand difference between them.</p>
<p>As Keras says <code>binary_accuracy</code> accuracy have threshold that default is <code>.5</code>, that `accuracy' haven't. When I test them with sample data the result is difference but in the train of model thy have same results in each epoch.</p>
<p>for this true and predicted sample I tested <code>accuracy</code> and <code>binary_accuracy</code>:</p>
<pre class=""lang-py prettyprint-override""><code>   y_true = [[1], [1], [0], [0]]
   y_pred = [[0.51], [1], [0], [0.4]]
</code></pre>
<p>For  <code>binary_accuracy</code> is:</p>
<pre class=""lang-py prettyprint-override""><code>m = tf.keras.metrics.BinaryAccuracy()
m.update_state(y_true, y_pred)
m.result().numpy()
</code></pre>
<p>that result is:
<code>1</code></p>
<p>For  <code>accuracy</code> is:</p>
<pre class=""lang-py prettyprint-override""><code>m = tf.keras.metrics.Accuracy()
m.update_state(y_true, y_pred)
m.result().numpy()
</code></pre>
<p>and the result is:
'.5'</p>
<p>But in the above model it is same for each of them in each epoch.</p>
<p><strong>Edit</strong></p>
<p>By changing the compile to this the result changed:</p>
<pre class=""lang-py prettyprint-override""><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.BinaryAccuracy(threshold=.7)])
</code></pre>
<p>Why <code>accuracy</code> work like <code>binary_accuracy</code> with <code>threshold=0.5</code> in model but not in out of model?</p>
",806160.0,,806160.0,,2020-12-18 17:56:21,2020-12-18 17:56:21,Why the accuracy and binary_accuracy in keras have same result?,<tensorflow><keras><classification>,1,0,,,,CC BY-SA 4.0
66036271,1,,,2021-02-03 21:53:55,,9,11679,"<p>I'm new to tensorflow/keras and I have a file structure with 3000 folders containing 200 images each to be loaded in as data. I know that <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"" rel=""noreferrer"">keras.preprocessing.image_dataset_from_directory</a> allows me to load the data and split it into training/validation set as below:</p>
<pre><code>val_data = tf.keras.preprocessing.image_dataset_from_directory('etlcdb/ETL9G_IMG/', 
                                                           image_size = (128, 127),
                                                           validation_split = 0.3,
                                                           subset = &quot;validation&quot;,
                                                           seed = 1,
                                                           color_mode = 'grayscale',
                                                           shuffle = True)
</code></pre>
<blockquote>
<p>Found 607200 files belonging to 3036 classes.
Using 182160 files for validation.</p>
</blockquote>
<p>But then I'm not sure how to further split my validation into a test split while maintaining proper classes. From what I can tell (through the GitHub <a href=""https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/data/ops/dataset_ops.py#L3848"" rel=""noreferrer"">source code</a>), the take method simply takes the first x elements of the dataset, and skip does the same. I am unsure if this maintains stratification of the data or not, and I'm not quite sure how to return labels from the dataset to test it.</p>
<p>Any help would be appreciated.</p>
",14199995.0,,,,,2022-11-29 07:04:54,"Splitting a tensorflow dataset into training, test, and validation sets from keras.preprocessing API",<python><tensorflow><keras>,3,0,0.0,,,CC BY-SA 4.0
69040420,1,69086432.0,,2021-09-03 06:28:22,,9,3376,"<p>I wrote a unit-test in order to safe a model after noticing that I am not able to do so (anymore) during training.</p>
<pre class=""lang-py prettyprint-override""><code>@pytest.mark.usefixtures(&quot;maybe_run_functions_eagerly&quot;)
def test_save_model(speech_model: Tuple[TransducerBase, SpeechFeaturesConfig]):
    model, speech_features_config = speech_model
    speech_features_config: SpeechFeaturesConfig
    channels = 3 if speech_features_config.add_delta_deltas else 1
    num_mel_bins = speech_features_config.num_mel_bins
    enc_inputs = np.random.rand(1, 50, num_mel_bins, channels)
    dec_inputs = np.expand_dims(np.random.randint(0, 25, size=10), axis=1)
    inputs = enc_inputs, dec_inputs
    model(inputs)

    # Throws KeyError:
    # graph = tf.compat.v1.get_default_graph()
    # tensor = graph.get_tensor_by_name(&quot;77040:0&quot;)

    directory = tempfile.mkdtemp(prefix=f&quot;{model.__class__.__name__}_&quot;)
    try:
        model.save(directory)
    finally:
        shutil.rmtree(directory)
</code></pre>
<p>Trying to save the model will always throw the following error:</p>
<pre class=""lang-none prettyprint-override""><code>E         AssertionError: Tried to export a function which references untracked resource Tensor(&quot;77040:0&quot;, shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
E         
E         Trackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):
E         &lt;tf.Variable 'transformer_transducer/transducer_encoder/inputs_embedding/convolution_stack/conv2d/kernel:0' shape=(3, 3, 3, 32) dtype=float32&gt;
</code></pre>
<blockquote>
<p><strong>Note:</strong> As you can see in the code above, but I am not able to retrieve this tensor with <code>tf.compat.v1.get_default_graph().get_tensor_by_name(&quot;77040:0&quot;)</code>.</p>
<p>I tried the following too, but the result is always empty:</p>
<pre class=""lang-py prettyprint-override""><code>model(batch)  # Build the model

tensor_name = &quot;77040&quot;

var_names = [var.name for var in model.trainable_weights]
weights = list(filter(lambda var: tensor_name in var, var_names))

var_names = [var.name for var in model.trainable_variables]
variables = list(filter(lambda var: tensor_name in var, var_names))

print(weights)
print(variables)
</code></pre>
</blockquote>
<p>The problem is that I do not understand why I am getting this because the affected layer <em>is</em> tracked by Keras as you can see in the screenshot below. I took it during a debug-session in the <code>call()</code> function.</p>
<p><a href=""https://i.stack.imgur.com/Y3hRu.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Y3hRu.png"" alt=""enter image description here"" /></a></p>
<p>I have no explanation for this and I am running out of ideas what the issue might be here.</p>
<p>The <code>transformations</code> list in the screenshot is a property of and getting constructed by a layer <code>InputsEmbedding</code> like so:</p>
<pre class=""lang-py prettyprint-override""><code>class InputsEmbedding(layers.Layer, TimeReduction):
    def __init__(self, config: InputsEmbeddingConfig, **kwargs):
        super().__init__(**kwargs)

        if config.transformations is None or not len(config.transformations):
            raise RuntimeError(&quot;No transformations provided.&quot;)

        self.config = config

        self.transformations = list()
        for transformation in self.config.transformations:
            layer_name, layer_params = list(transformation.items())[0]
            layer = _get_layer(layer_name, layer_params)
            self.transformations.append(layer)

        self.init_time_reduction_layer()

    def get_config(self):
        return self.config.dict()


def _get_layer(name: str, params: dict) -&gt; layers.Layer:
    if name == &quot;conv2d_stack&quot;:
        return ConvolutionStack(**params)
    elif name == &quot;stack_frames&quot;:
        return StackFrames(**params)
    else:
        raise RuntimeError(f&quot;Unsupported or unknown time-reduction layer {name}&quot;)
</code></pre>
<hr />
<p>In order to verify that the problem is not the <code>InputsEmbedding</code>, I created a unit-text for saving a model that is using just this particular layer.</p>
<pre class=""lang-py prettyprint-override""><code>@pytest.mark.usefixtures(&quot;maybe_run_functions_eagerly&quot;)
def test_inputs_embedding_save_model():
    convolutions = [
        &quot;filters=2, kernel_size=(3, 3), strides=(2, 1)&quot;,
        &quot;filters=4, kernel_size=(3, 3), strides=(2, 1)&quot;,
        &quot;filters=8, kernel_size=(3, 4), strides=(1, 1)&quot;,
    ]

    config = InputsEmbeddingConfig()
    config.transformations = [dict(conv2d_stack=dict(convolutions=convolutions)), dict(stack_frames=dict(n=2))]

    num_features = 8
    num_channels = 3

    inputs = layers.Input(shape=(None, num_features, num_channels))
    x = inputs
    x, _ = InputsEmbedding(config)(x)
    model = keras.Model(inputs=inputs, outputs=x)
    model.build(input_shape=(1, 20, num_features, num_channels))

    directory = tempfile.mkdtemp(prefix=f&quot;{model.__class__.__name__}_&quot;)
    try:
        model.save(directory)
    finally:
        shutil.rmtree(directory)
</code></pre>
<p>Here I am able to save this layer without any issues:</p>
<p><a href=""https://i.stack.imgur.com/78ghQ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/78ghQ.png"" alt=""enter image description here"" /></a></p>
<h3><code>ConvolutionStack</code></h3>
<p>As it seems to be relevant, here is the (rather ugly) implementation of <code>ConvolutionStack</code>:</p>
<pre class=""lang-py prettyprint-override""><code>from typing import List

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.python.keras.layers import convolutional

from speech.lab.layers import InputsRequirements
from speech.lab.models import conv_util, models_util


class ConvolutionStack(layers.Layer):
    def __init__(
        self,
        convolutions: List[str],
        kernel_regularizer: dict = None,
        bias_regularizer: dict = None,
        **kwargs
    ):
        super().__init__(**kwargs)
        self.config = dict(
            convolutions=convolutions,
            kernel_regularizer=kernel_regularizer,
            bias_regularizer=bias_regularizer
        )
        self.conv_stack_config = [eval(f&quot;dict({convolution})&quot;) for convolution in convolutions]
        self.conv_blocks = list()

        if kernel_regularizer is not None:
            kernel_regularizer = models_util.maybe_to_regularizer(kernel_regularizer)
        if bias_regularizer is not None:
            bias_regularizer = models_util.maybe_to_regularizer(bias_regularizer)

        for block_config in self.conv_stack_config:
            block = _new_convolution_block(
                **block_config,
                kernel_regularizer=kernel_regularizer,
                bias_regularizer=bias_regularizer,
            )
            self.conv_blocks.append(block)

        self.drop_dim2 = layers.Lambda(tf.squeeze, arguments=dict(axis=-2))
        self.expand_last = layers.Lambda(tf.expand_dims, arguments=dict(axis=-1))

    @property
    def inputs_requirements(self) -&gt; InputsRequirements:
        requirements, frame_look_back = conv_util.get_conv2d_stack_requirements(self.conv_stack_config)
        first = requirements[0]
        t_min, f_size = first[&quot;min_size&quot;]
        t_grow, f_grow = first[&quot;grow_size&quot;]
        return InputsRequirements(
            frame_look_back=frame_look_back,
            t_min=t_min,
            t_grow=t_grow,
            f_min=f_size,
            f_grow=f_grow,
        )

    def call(self, inputs, training=None, mask=None, **kwargs):
        &quot;&quot;&quot;
        :param inputs:
            Tensor taking the form [batch, time, freq, channel]
        :param training:
        :param mask:
        :param kwargs:
        :return:
            Tensor taking the form [batch, time, freq, 1]
        &quot;&quot;&quot;

        if training:
            t_min = self.inputs_requirements.t_min
            t_grow = self.inputs_requirements.t_grow
            pad = conv_util.get_padding_for_loss(tf.shape(inputs)[1], t_min=t_min, t_grow=t_grow)
            inputs = tf.pad(inputs, ((0, 0), (0, pad), (0, 0), (0, 0)))

            if mask is not None:
                mask = tf.pad(mask, ((0, 0), (0, pad)))

        f_min = self.inputs_requirements.f_min
        f_grow = self.inputs_requirements.f_grow
        assert (inputs.shape[2] - f_min) % f_grow == 0, (
            f'Inputs dimension &quot;freq&quot; ' f&quot;expected to be {f_min} + n * {f_grow}  but got {inputs.shape[2]} instead.&quot;
        )

        x = inputs
        for block in self.conv_blocks:

            for layer in block:

                if mask is not None and isinstance(layer, convolutional.Conv):
                    st, _ = layer.strides
                    kt = tf.maximum(layer.kernel_size[0] - 1, 1)
                    mask = mask[:, :-kt][:, ::st]
                    mask = tf.pad(mask, ((0, 0), (0, tf.maximum(2 - layer.kernel_size[0], 0))))

                x = layer(x, training=training)

        return self.expand_last(self.drop_dim2(x)), mask

    def get_config(self):
        return self.config


def _new_convolution_block(
    filters: int,
    kernel_size: tuple,
    strides: tuple,
    use_bias: bool = False,
    use_norm: bool = True,
    kernel_regularizer=None,
    bias_regularizer=None,
    activation=None,
):
    assert strides[0] % 2 == 0 or strides[0] == 1, &quot;Strides on the time axis must be divisible by 2 or be exactly 1.&quot;

    if activation is not None:
        activation_layer = layers.Activation(activation)
    else:
        activation_layer = layers.Lambda(lambda x: x)

    if use_norm:
        norm_layer = layers.LayerNormalization()
    else:
        norm_layer = layers.Lambda(lambda x: x)

    return (
        layers.Conv2D(
            filters=filters,
            kernel_size=kernel_size,
            strides=strides,
            use_bias=use_bias,
            kernel_regularizer=kernel_regularizer,
            bias_regularizer=bias_regularizer,
        ),
        norm_layer,
        activation_layer,
    )
</code></pre>
<h3>See also</h3>
<ul>
<li><a href=""https://github.com/tensorflow/serving/issues/1719"" rel=""noreferrer"">tensorflow/serving #1719</a></li>
</ul>
",826983.0,,826983.0,,2021-09-07 07:25:09,2023-03-22 05:32:33,AssertionError: Tried to export a function which references untracked resource,<python><tensorflow><keras><tensorflow2.0>,5,0,0.0,,,CC BY-SA 4.0
67236747,1,,,2021-04-23 20:57:58,,9,15433,"<p>I want to run a code. It is written in Python3 using Tensorflow. I could run the code, but when the code was running, I tried to run another code with some changes in a separate Anaconda Prompt. Then I stopped the code. Now, when I try to run the similar code again without any changes, it gives me the following error:</p>
<pre><code>AttributeError: 'str' object has no attribute 'decode'
</code></pre>
<p>The error refers to the tensorflow\python\keras package as follow:</p>
<pre><code>hdf5_format.py. line 711, in load_weights_from_hdf5_group
original_keras_version = f.attrs['keras_version'].decode('utf8')
</code></pre>
<p>This is some parts of my code which rises the error:</p>
<pre><code>self.encoder.load_weights(weights_file, by_name = True)
</code></pre>
<p>I closed the program and reopened it, but the error still exits.</p>
<p>Does anyone know how to solve it?</p>
",12669129.0,,,,,2021-04-30 03:22:20,'str' object has no attribute 'decode' for Tensorflow in Python,<python><tensorflow><keras>,1,1,0.0,2021-04-30 04:36:48,,CC BY-SA 4.0
72701137,1,,,2022-06-21 12:51:52,,9,1810,"<p>After upgrading to tensorflow 2.9 I got the following Erro message
when calling model.fit()
with tf 2.8 there were no error.
The fit runs anways but its worrying.</p>
<pre><code>2022-06-21 12:42:58.930086: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_BOOL
    }
  }
}
 is neither a subtype nor a supertype of the combined inputs preceding it:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_LEGACY_VARIANT
    }
  }
}

    while inferring type of node 'calculate/cond/output/_10'
</code></pre>
<p>Any idea what can cause this or how to fix it?</p>
",12772563.0,,,,,2023-01-16 09:13:46,Type ERROR when upgrading to tensorflow 2.9,<tensorflow><keras><types><upgrade>,2,5,0.0,,,CC BY-SA 4.0
67695451,1,67697308.0,,2021-05-25 20:50:03,,9,8420,"<p>So i have been working on a notebook on Google Colab, and all of a sudden i get the following error.</p>
<pre><code>---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-1-bd6ec74ccf2e&gt; in &lt;module&gt;()
----&gt; 1 from keras.utils import to_categorical

ImportError: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)

---------------------------------------------------------------------------
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
&quot;Open Examples&quot; button below.
</code></pre>
<p>It's very strange since it was working just fine, and when i restarted my session, this happened. I tried with another google account too (in case there might be something wrong with my account's setup), but i still got the same error.</p>
<p>This is what i use to import the function.</p>
<pre><code>from keras.utils import to_categorical 
</code></pre>
<p>I'm wondering if anything change, and if anyone else experiences the same issue.
Thanks.</p>
",14857189.0,,,,,2021-06-05 12:16:51,Cannot import to_categorical from keras in Google Colab,<python><keras><google-colaboratory>,3,0,0.0,,,CC BY-SA 4.0
64132842,1,64133031.0,,2020-09-30 07:30:02,,8,1911,"<p>I want to use Keras Resnet50 model using OpenCV for reading and resizing the input image.
I'm using the same preprocessing code from Keras (with OpenCV I need to convert to RGB since this is the format expected by preprocess_input()).
I get slightly different predictions using OpenCV and Keras image loading. I don't understand why the predictions are not the same.</p>
<p>Here is my code:</p>
<pre><code>import numpy as np
import json
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
import cv2

model = ResNet50(weights='imagenet')

img_path = '/home/me/squirle.jpg'

# Keras prediction
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = model.predict(x)
print('Predicted Keras:', decode_predictions(preds, top=3)[0])

# OpenCV prediction
imgcv = cv2.imread(img_path)
dim = (224, 224)
imgcv_resized = cv2.resize(imgcv, dim, interpolation=cv2.INTER_LINEAR)
x = cv2.cvtColor(imgcv_resized , cv2.COLOR_BGR2RGB)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = model.predict(x)
print('Predicted OpenCV:', decode_predictions(preds, top=3)[0])

Predicted Keras: [('n02490219', 'marmoset', 0.28250763), ('n02356798', 'fox_squirrel', 0.25657368), ('n02494079', 'squirrel_monkey', 0.19992349)]
Predicted OpenCV: [('n02356798', 'fox_squirrel', 0.5161952), ('n02490219', 'marmoset', 0.21953616), ('n02494079', 'squirrel_monkey', 0.1160824)]

</code></pre>
<p>How can I use OpenCV <code>imread()</code> and <code>resize()</code> to get the same prediction as Keras image loading?</p>
",7252099.0,,4685471.0,,2020-09-30 09:19:10,2020-10-28 14:35:42,Resnet50 produces different prediction when image loading and resizing is done with OpenCV,<python><tensorflow><opencv><machine-learning><keras>,2,0,0.0,,,CC BY-SA 4.0
65438156,1,65440509.0,,2020-12-24 12:12:25,,8,11366,"<p>i'm training a classifier and i made sure all the pictures are jpg but still, this error occurs:
InvalidArgumentError:  Unknown image file format. One of JPEG, PNG, GIF, BMP required.
[[{{node decode_image/DecodeImage}}]]
[[IteratorGetNext]] [Op:__inference_train_function_1481]</p>
<p>i tried training on a smaller dataset and also they were all jpg and there was no problem</p>
<p>this is the code:</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow import keras

dataset = keras.preprocessing.image_dataset_from_directory(
  '/content/drive/MyDrive/fi_dataset/train', batch_size=64, image_size=(200, 200))

dense = keras.layers.Dense(units=16)
inputs = keras.Input(shape=(None, None, 3))

from tensorflow.keras import layers

x = CenterCrop(height=150, width=150)(inputs)
x = Rescaling(scale=1.0 / 255)(x)

x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=&quot;relu&quot;)(x)
x = layers.MaxPooling2D(pool_size=(3, 3))(x)
x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=&quot;relu&quot;)(x)
x = layers.MaxPooling2D(pool_size=(3, 3))(x)
x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=&quot;relu&quot;)(x)

x = layers.GlobalAveragePooling2D()(x)

num_classes = 1
outputs = layers.Dense(num_classes, activation=&quot;sigmoid&quot;)(x)

model = keras.Model(inputs=inputs, outputs=outputs)

data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(&quot;float32&quot;)
processed_data = model(data)

model.compile(optimizer='adam',
              loss='binary_crossentropy',
               metrics=[keras.metrics.binary_accuracy],)

history=model.fit(dataset, epochs=10)
</code></pre>
",12940096.0,,,,,2022-08-08 19:02:31,"Tensorflow Keras error: Unknown image file format. One of JPEG, PNG, GIF, BMP required",<python><image><tensorflow><keras><google-colaboratory>,3,0,0.0,,,CC BY-SA 4.0
75553614,1,75554398.0,,2023-02-24 07:22:13,,8,160,"<p>I am new to Tensorflow, and am trying to train a specific deep learning neural network. I am using Tensorflow (2.11.0) to get a deep neural network model which is described below. The data which I use is also given below:</p>
<p><strong>Data:</strong></p>
<p>Here is some example data. For sake of ease we can consider 10 samples in data. Here, each sample has shape: <code>(128,128)</code>.</p>
<p>One can consider the below code as example training data.</p>
<pre><code>x_train = np.random.rand(10, 128, 128, 1)
</code></pre>
<p><strong>Normalization layer:</strong></p>
<pre><code>normalizer = tf.keras.layers.Normalization(axis=-1)
normalizer.adapt(x_train)
</code></pre>
<p><strong>Build model:</strong></p>
<pre><code>def build_and_compile_model(norm):
    model = tf.keras.Sequential([
      norm,
      layers.Conv2D(128, 128, activation='relu'),
      layers.Conv2D(3, 3, activation='relu'),
      layers.Flatten(),
      layers.Dense(units=32, activation='relu'),
      layers.Dense(units=1)
    ])

    model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(0.001))
    
    return model
</code></pre>
<p>When I do</p>
<pre><code>dnn_model = build_and_compile_model(normalizer)
dnn_model.summary()
</code></pre>
<p>I get the below error:</p>
<pre><code>ValueError: The channel dimension of the inputs should be defined. The input_shape received is (None, None, None, None), where axis -1 (0-based) is the channel dimension, which found to be `None`.
</code></pre>
<p><strong>What am I doing wrong here?</strong></p>
<p>I have tried to get insights from <a href=""https://stackoverflow.com/questions/48264676/tensorflow-valueerror-the-channel-dimension-of-the-inputs-should-be-defined-fo"">this</a>, <a href=""https://stackoverflow.com/questions/66013918/valueerror-the-channel-dimension-of-the-inputs-should-be-defined-found-none"">this</a>, <a href=""https://stackoverflow.com/questions/68978375/the-channel-dimension-of-the-inputs-should-be-defined-found-none"">this</a> and <a href=""https://stackoverflow.com/questions/64881851/tensorflow-keras-model-load-error-valueerror-the-last-dimension-of-the-inputs"">this</a>. But, I have not found a workable solution yet.</p>
<p>What should I do to remove the error and get the model to work?</p>
<p>I will appreciate any help.</p>
",8151881.0,,9657861.0,,2023-03-08 06:07:25,2023-03-08 06:07:25,Tensorflow: The channel dimension of the inputs should be defined,<python><tensorflow><machine-learning><keras><deep-learning>,1,0,,,,CC BY-SA 4.0
69195950,1,69336070.0,,2021-09-15 15:28:40,,8,4213,"<p>I'm trying to build the model illustrated in this picture:
<a href=""https://i.stack.imgur.com/4eiAK.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/4eiAK.png"" alt=""enter image description here"" /></a></p>
<p>I obtained a pre-trained BERT and respective tokenizer from HuggingFace's <code>transformers</code> in the following way:</p>
<pre class=""lang-py prettyprint-override""><code>from transformers import AutoTokenizer, TFBertModel
model_name = &quot;dbmdz/bert-base-italian-xxl-cased&quot;
tokenizer = AutoTokenizer.from_pretrained(model_name)
bert = TFBertModel.from_pretrained(model_name)
</code></pre>
<p>The model will be fed a sequence of italian tweets and will need to determine if they are ironic or not.</p>
<p>I'm having problems building the initial part of the model, which takes the inputs and feeds them to the tokenizer in order to get a representation I can feed to BERT.</p>
<p>I can do it outside of the model-building context:</p>
<pre><code>my_phrase = &quot;Ciao, come va?&quot;
# an equivalent version is tokenizer(my_phrase, other parameters)
bert_input = tokenizer.encode(my_phrase, add_special_tokens=True, return_tensors='tf', max_length=110, padding='max_length', truncation=True) 
attention_mask = bert_input &gt; 0
outputs = bert(bert_input, attention_mask)['pooler_output']
</code></pre>
<p>but I'm having troubles building a model that does this. Here is the code for building such a model (the problem is in the first 4 lines ):</p>
<pre><code>def build_classifier_model():
  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
  encoder_inputs = tokenizer(text_input, return_tensors='tf', add_special_tokens=True, max_length=110, padding='max_length', truncation=True)
  outputs = bert(encoder_inputs)
  net = outputs['pooler_output']
  
  X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(net)
  X = tf.keras.layers.Concatenate(axis=-1)([X, input_layer])
  X = tf.keras.layers.MaxPooling1D(20)(X)
  X = tf.keras.layers.SpatialDropout1D(0.4)(X)
  X = tf.keras.layers.Flatten()(X)
  X = tf.keras.layers.Dense(128, activation=&quot;relu&quot;)(X)
  X = tf.keras.layers.Dropout(0.25)(X)
  X = tf.keras.layers.Dense(2, activation='softmax')(X)

  model = tf.keras.Model(inputs=text_input, outputs = X) 
  
  return model
</code></pre>
<p>And when I call the function for creating this model I get this error:</p>
<blockquote>
<p>text input must of type <code>str</code> (single example), <code>List[str]</code> (batch or single pretokenized example) or <code>List[List[str]]</code> (batch of pretokenized examples).</p>
</blockquote>
<p>One thing I thought was that maybe I had to use the <code>tokenizer.batch_encode_plus</code> function which works with lists of strings:</p>
<pre class=""lang-py prettyprint-override""><code>class BertPreprocessingLayer(tf.keras.layers.Layer):
  def __init__(self, tokenizer, maxlength):
    super().__init__()
    self._tokenizer = tokenizer
    self._maxlength = maxlength
  
  def call(self, inputs):
    print(type(inputs))
    print(inputs)
    tokenized = tokenizer.batch_encode_plus(inputs, add_special_tokens=True, return_tensors='tf', max_length=self._maxlength, padding='max_length', truncation=True)
    return tokenized

def build_classifier_model():
  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
  encoder_inputs = BertPreprocessingLayer(tokenizer, 100)(text_input)
  outputs = bert(encoder_inputs)
  net = outputs['pooler_output']
  # ... same as above
</code></pre>
<p>but I get this error:</p>
<blockquote>
<p>batch_text_or_text_pairs has to be a list (got &lt;class 'keras.engine.keras_tensor.KerasTensor'&gt;)</p>
</blockquote>
<p>and beside the fact I haven't found a way to convert that tensor to a list with a quick google search, it seems weird that I have to go in and out of tensorflow in this way.</p>
<p>I've also looked up on the huggingface's <a href=""https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel"" rel=""noreferrer"">documentation</a> but there is only a single usage example, with a single phrase, and what they do is analogous at my &quot;out of model-building context&quot; example.</p>
<p>EDIT:</p>
<p>I also tried with <code>Lambda</code>s in this way:</p>
<pre><code>tf.executing_eagerly()

def tokenize_tensor(tensor):
  t = tensor.numpy()
  t = np.array([str(s, 'utf-8') for s in t])
  return tokenizer(t.tolist(), return_tensors='tf', add_special_tokens=True, max_length=110, padding='max_length', truncation=True)

def build_classifier_model():
  text_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='text')
  
  encoder_inputs = tf.keras.layers.Lambda(tokenize_tensor, name='tokenize')(text_input)
  ...
  
  outputs = bert(encoder_inputs)
</code></pre>
<p>but I get the following error:</p>
<blockquote>
<p>'Tensor' object has no attribute 'numpy'</p>
</blockquote>
<p>EDIT 2:</p>
<p>I also tried the approach suggested by @mdaoust of wrapping everything in a <code>tf.py_function</code> and got this error.</p>
<pre class=""lang-py prettyprint-override""><code>def py_func_tokenize_tensor(tensor):
  return tf.py_function(tokenize_tensor, [tensor], Tout=[tf.int32, tf.int32, tf.int32])
</code></pre>
<blockquote>
<p>eager_py_func() missing 1 required positional argument: 'Tout'</p>
</blockquote>
<p>Then I defined Tout as the type of the value returned by the tokenizer:</p>
<p><code>transformers.tokenization_utils_base.BatchEncoding</code></p>
<p>and got the following error:</p>
<blockquote>
<p>Expected DataType for argument 'Tout' not &lt;class
'transformers.tokenization_utils_base.BatchEncoding'&gt;</p>
</blockquote>
<p>Finally I unpacked the value in the BatchEncoding in the following way:</p>
<pre class=""lang-py prettyprint-override""><code>def tokenize_tensor(tensor):
  t = tensor.numpy()
  t = np.array([str(s, 'utf-8') for s in t])
  dictionary = tokenizer(t.tolist(), return_tensors='tf', add_special_tokens=True, max_length=110, padding='max_length', truncation=True)
  #unpacking
  input_ids = dictionary['input_ids']
  tok_type = dictionary['token_type_ids']
  attention_mask = dictionary['attention_mask']
  return input_ids, tok_type, attention_mask
</code></pre>
<p>And get an error in the line below:</p>
<pre class=""lang-py prettyprint-override""><code>...
outputs = bert(encoder_inputs)
</code></pre>
<blockquote>
<p>ValueError: Cannot take the length of shape with unknown rank.</p>
</blockquote>
",11579184.0,,11579184.0,,2021-09-26 11:26:13,2022-09-08 11:11:12,Problem with inputs when building a model with TFBertModel and AutoTokenizer from HuggingFace's transformers,<tensorflow><keras><huggingface-transformers><bert-language-model><huggingface-tokenizers>,6,0,0.0,,,CC BY-SA 4.0
69694944,1,,,2021-10-24 08:12:05,,8,13001,"<p>When I am trying to run a Python code for deep learning utilizing the TensorFlow library, I am getting the following error:</p>
<pre><code>2021-10-24 10:07:13.619481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-10-24 10:07:13.619752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-10-24 10:07:18.797570: E tensorflow/core/lib/monitoring/collection_registry.cc:77] `Cannot register 2 metrics with the same name: /tensorflow/api/keras/optimizers`
Traceback (most recent call last):
  File &quot;C:\Users\Admin\Downloads\Compressed\Face-Mask-Detection-master\detect_mask_image.py&quot;, line 5, in &lt;module&gt;
    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
  File &quot;C:\Python39\lib\site-packages\keras\api\_v2\keras\__init__.py&quot;, line 8, in &lt;module&gt;
    from keras import __version__
  File &quot;C:\Python39\lib\site-packages\keras\__init__.py&quot;, line 25, in &lt;module&gt;
    from keras import models
  File &quot;C:\Python39\lib\site-packages\keras\models.py&quot;, line 20, in &lt;module&gt;
    from keras import metrics as metrics_module
  File &quot;C:\Python39\lib\site-packages\keras\metrics.py&quot;, line 26, in &lt;module&gt;
    from keras import activations
  File &quot;C:\Python39\lib\site-packages\keras\activations.py&quot;, line 20, in &lt;module&gt;
    from keras.layers import advanced_activations
  File &quot;C:\Python39\lib\site-packages\keras\layers\__init__.py&quot;, line 23, in &lt;module&gt;
    from keras.engine.input_layer import Input
  File &quot;C:\Python39\lib\site-packages\keras\engine\input_layer.py&quot;, line 21, in &lt;module&gt;
    from keras.engine import base_layer
  File &quot;C:\Python39\lib\site-packages\keras\engine\base_layer.py&quot;, line 43, in &lt;module&gt;
    from keras.mixed_precision import loss_scale_optimizer
  File &quot;C:\Python39\lib\site-packages\keras\mixed_precision\loss_scale_optimizer.py&quot;, line 18, in &lt;module&gt;
    from keras import optimizers
  File &quot;C:\Python39\lib\site-packages\keras\optimizers.py&quot;, line 26, in &lt;module&gt;
    from keras.optimizer_v2 import adadelta as adadelta_v2
  File &quot;C:\Python39\lib\site-packages\keras\optimizer_v2\adadelta.py&quot;, line 22, in &lt;module&gt;
    from keras.optimizer_v2 import optimizer_v2
  File &quot;C:\Python39\lib\site-packages\keras\optimizer_v2\optimizer_v2.py&quot;, line 36, in &lt;module&gt;
    keras_optimizers_gauge = tf.__internal__.monitoring.BoolGauge(
  File &quot;C:\Python39\lib\site-packages\tensorflow\python\eager\monitoring.py&quot;, line 360, in __init__
    super(BoolGauge, self).__init__('BoolGauge', _bool_gauge_methods,
  File &quot;C:\Python39\lib\site-packages\tensorflow\python\eager\monitoring.py&quot;, line 135, in __init__
    self._metric = self._metric_methods[self._label_length].create(*args)
tensorflow.python.framework.errors_impl.
AlreadyExistsError: Another metric with the same name already exists.
</code></pre>
<p>Environment:</p>
<p>Python version: 3.9</p>
<p>OS: Windows</p>
<p>Library: TensorFlow API</p>
",14339787.0,,681865.0,,2021-11-09 10:29:03,2022-03-19 13:22:20,How to fix error: Cannot register 2 metrics with the same name: /tensorflow/api/keras/optimizers,<tensorflow><keras><python-3.9>,5,2,0.0,,,CC BY-SA 4.0
64158898,1,64158991.0,,2020-10-01 15:49:48,,8,7113,"<p>Given this piece of code:</p>
<pre><code>from tensorflow.keras.preprocessing.text import Tokenizer

sentences = [
    'i love my dog',
    'I, love my cat',
    'You love my dog!'
]

tokenizer = Tokenizer(num_words = 1)
tokenizer.fit_on_texts(sentences)
word_index = tokenizer.word_index
print(word_index)
</code></pre>
<p>whether <code>num_words=1</code> or <code>num_words=100</code>, I get the same output when I run this cell on my jupyter notebook, and I can't seem to understand what difference it makes in tokenization.</p>
<blockquote>
<p>{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}</p>
</blockquote>
",10394568.0,,10375049.0,,2022-02-08 17:18:47,2022-02-08 17:18:47,What does Keras Tokenizer num_words specify?,<python><tensorflow><machine-learning><keras><nlp>,1,0,0.0,,,CC BY-SA 4.0
63493324,1,,,2020-08-19 18:56:29,,8,4402,"<p>According to <a href=""https://keras.io/api/models/model/"" rel=""noreferrer"">keras.io</a>:</p>
<blockquote>
<p>Once the model is created, you can config the model with losses and
metrics with <strong>model.compile()</strong>.</p>
</blockquote>
<p>But this explanation does not provide enough information about what exactly compiling model does.</p>
",,user14133226,,,,2021-12-09 14:44:23,What does model.compile() do in keras tensorflow?,<python><tensorflow><keras>,2,1,,,,CC BY-SA 4.0
67722362,1,,,2021-05-27 12:43:00,,8,3242,"<p>It was yesterday and I was training the model. Everything looked good.
Today 27/05/2021 I receive this warning:</p>
<p><em>WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.
Instructions for updating:
The <code>validate_indices</code> argument has no effect. Indices are always validated on CPU and never validated on GPU.</em></p>
<p>I'm running my CNN on GoogleColab pro.</p>
<p><strong>Does someone know what to do to fix it?</strong> I didn't change anything, and I thought that Tensorflow-Keras should handle the CPU-GPU computations.</p>
<p>After, the normal flow of model.fit:</p>
<p>Epoch 1/200</p>
<p>216/216 - 18s - loss: ...</p>
<p>Epoch 2/200</p>
<p>216/216 - 2s - loss: ...</p>
",16048701.0,,16048701.0,,2021-05-28 06:19:21,2021-07-18 22:03:57,TensorFlow Keras: The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU,<python><tensorflow><keras><conv-neural-network>,0,1,0.0,,,CC BY-SA 4.0
67615051,1,67616451.0,,2021-05-20 06:31:45,,8,10592,"<p>I am implementing the <strong>Binary Cross-Entropy</strong> loss function with Raw python but it gives me a very different answer than Tensorflow.
This is the answer I got from Tensorflow:-</p>
<pre><code>import numpy as np
from tensorflow.keras.losses import BinaryCrossentropy

y_true = np.array([1., 1., 1.])
y_pred = np.array([1., 1., 0.])
bce = BinaryCrossentropy()
loss = bce(y_true, y_pred)
print(loss.numpy())
</code></pre>
<p>Output:</p>
<pre><code>&gt;&gt;&gt; 5.1416497230529785
</code></pre>
<p>From my Knowledge, the formula of Binary Cross entropy is this:</p>
<p><a href=""https://i.stack.imgur.com/KjB4I.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/KjB4I.png"" alt=""enter image description here"" /></a></p>
<p>I implemented the same with raw python as follows:</p>
<pre><code>def BinaryCrossEntropy(y_true, y_pred):
    m = y_true.shape[1]
    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)
    # Calculating loss
    loss = -1/m * (np.dot(y_true.T, np.log(y_pred)) + np.dot((1 - y_true).T, np.log(1 - y_pred)))

    return loss

print(BinaryCrossEntropy(np.array([1, 1, 1]).reshape(-1, 1), np.array([1, 1, 0]).reshape(-1, 1)))
</code></pre>
<p>But from this function I get loss value to be:</p>
<pre><code>&gt;&gt;&gt; [[16.11809585]]
</code></pre>
<p>How can I get the right answer?</p>
",,user12188405,9215780.0,,2021-05-20 10:33:06,2021-05-20 10:33:06,Implementing Binary Cross Entropy loss gives different answer than Tensorflow's,<python><tensorflow><keras><loss-function>,2,0,0.0,,,CC BY-SA 4.0
67379519,1,67379586.0,,2021-05-04 05:58:29,,8,22494,"<p>I am trying to use Sequential model from keras of tensorflow. When I am executing following statement:</p>
<pre><code>model.fit(x_train, y_train, epochs=20, verbose=True, validation_data=(x_dev, y_dev), batch_size=10)
</code></pre>
<p>I am getting following errors:</p>
<pre><code>I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)

W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz

F tensorflow/core/grappler/costs/op_level_cost_estimator.cc:710] Check failed: 0 &lt; gflops (0 vs. 0)type: &quot;CPU&quot;
</code></pre>
<p>I am not able to understand how to fix it. Can anyone please help me.</p>
<p>From <a href=""https://github.com/tensorflow/tensorflow/issues/22116"" rel=""nofollow noreferrer"">this issue</a> on github, I understood that <code>device.frequency()</code> returned 0 probably because <code>NominalCPUFrequency()</code> returned 1.
However, this information seems too abstract for me and I cannot understand.</p>
",6252976.0,,7036713.0,,2023-01-30 19:15:17,2023-01-31 10:55:57,Cannot use keras models on Mac M1 with BigSur,<python><tensorflow><keras><tf.keras><apple-m1>,3,0,0.0,,,CC BY-SA 4.0
74586892,1,74588082.0,,2022-11-27 01:38:17,,8,6477,"<p>After <code>pip3 install</code>ing <code>tensorflow</code> and the <code>transformers</code> library, I'm receiving the titular error when I try loading <a href=""https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion"" rel=""noreferrer"">this</a></p>
<pre class=""lang-py prettyprint-override""><code>from transformers import pipeline
classifier = pipeline(&quot;text-classification&quot;,model='bhadresh-savani/distilbert-base-uncased-emotion')
</code></pre>
<p>The error traceback looks like:</p>
<pre class=""lang-bash prettyprint-override""><code>RuntimeError: Failed to import transformers.models.distilbert.modeling_tf_distilbert because of the following error (look up to see its traceback):
No module named 'keras.saving.hdf5_format'

</code></pre>
<p>I have ensured keras got installed with transformers, so I'm not sure why it isn't working</p>
",14743734.0,,,,,2023-02-07 15:49:15,No module named 'keras.saving.hdf5_format',<python><tensorflow><keras>,2,3,,,,CC BY-SA 4.0
67792138,1,,,2021-06-01 15:52:30,,8,15768,"<p>I'm trying to use segmentation models but I can't fix this error. I've searched for this particular
one but couldn't find an answer. I'm using pycharm and this error is linked to this specific line of code
BACKBONE = 'resnet34'</p>
<pre><code>model1 = sm.Unet(BACKBONE, weights=None,
                 encoder_weights='imagenet',
                 classes=num_classes,
                 activation='softmax',
                 decoder_block_type = 'upsampling') 
</code></pre>
<p>which is also the 83rd. I searched in the documentation and apparently the versions of tensorflow keras etc satisfy the requirements.I really don't know what to do given the fact that I really tried to install and uninstall everything in many combinations in order to get this piece of code to work.Thank you all for your help and time! Below there's the complete error, hoping it might help you!</p>
<pre><code>    `Traceback (most recent call last):
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\main.py&quot;, line 83, in &lt;module&gt;
        model1 = sm.Unet('resnet34', weights=None,
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\venv\lib\site- 
   packages\segmentation_models\__init__.py&quot;, line 34, in wrapper
        return func(*args, **kwargs)
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\venv\lib\site- 
   packages\segmentation_models\models\unet.py&quot;, line 221, in Unet
        backbone = Backbones.get_backbone(
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\venv\lib\site- 
   packages\segmentation_models\backbones\backbones_factory.py&quot;, line 103, in get_backbone
        model = model_fn(*args, **kwargs)
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\venv\lib\site- 
   packages\classification_models\models_factory.py&quot;, line 78, in wrapper
        return func(*args, **new_kwargs)
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\venv\lib\site- 
   packages\classification_models\models\resnet.py&quot;, line 314, in ResNet34
        return ResNet(
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\venv\lib\site- 
   packages\classification_models\models\resnet.py&quot;, line 280, in ResNet
        load_model_weights(model, model_params.model_name,
      File &quot;C:\Users\Giulia\PycharmProjects\multiclass_new\venv\lib\site- 
   packages\classification_models\weights.py&quot;, line 25, in load_model_weights
        weights_path = keras_utils.get_file(
    AttributeError: module 'keras.utils' has no attribute 'get_file'
</code></pre>
",16096906.0,,,,,2022-11-21 22:11:01,AttributeError: module 'keras.utils' has no attribute 'get_file' using segmentation_models,<python><keras>,4,1,0.0,,,CC BY-SA 4.0
63775936,1,65851992.0,,2020-09-07 10:39:32,,8,2346,"<p>After a lot of research, it seems like there is no good way to <em>properly</em> stop and resume training using a Tensorflow 2 / Keras model. This is true whether you are using <code>model.fit()</code> <em>or</em> using a custom training loop.</p>
<p>There seem to be 2 supported ways to save a model while training:</p>
<ol>
<li><p>Save just the weights of the model, using <code>model.save_weights()</code> or <code>save_weights_only=True</code> with <code>tf.keras.callbacks.ModelCheckpoint</code>. This seems to be preferred by most of the examples I've seen, however it has a number of major issues:</p>
<ul>
<li>The optimizer state is not saved, meaning training resumption will not be correct.</li>
<li>Learning rate schedule is reset - this can be catastrophic for some models.</li>
<li>Tensorboard logs go back to step 0 - making logging essentually useless unless complex workarounds are implemented.</li>
</ul>
</li>
<li><p>Save the entire model, optimizer, etc. using <code>model.save()</code> or <code>save_weights_only=False</code>. The optimizer state is saved (good) but the following issues remain:</p>
<ul>
<li>Tensorboard logs still go back to step 0</li>
<li>Learning rate schedule is still reset (!!!)</li>
<li>It is impossible to use custom metrics.</li>
<li>This doesn't work at all when using a custom training loop - custom training loops use a non-compiled model, and saving/loading a non-compiled model doesn't seem to be supported.</li>
</ul>
</li>
</ol>
<p>The best workaround I've found is to use a custom training loop, manually saving the step. This fixes the tensorboard logging, and the learning rate schedule can be fixed by doing something like <code>keras.backend.set_value(model.optimizer.iterations, step)</code>. However, since a full model save is off the table, the optimizer state is not preserved. I can see no way to save the state of the optimizer independently, at least without a lot of work. And messing with the LR schedule as I've done feels messy as well.</p>
<p>Am I missing something? How are people out there saving/resuming using this API?</p>
",6275101.0,,,,,2022-08-11 12:12:12,Keras - no good way to stop and resume training?,<python><tensorflow><keras><tensorflow2.0><tf.keras>,4,4,0.0,,,CC BY-SA 4.0
62839498,1,,,2020-07-10 17:30:56,,8,11570,"<p>Attempting to do the following:</p>
<pre><code>import tensorflow as tf
from keras.models import load_model, Model
from keras import backend as K

sess = tf.compat.v1.Session()
K.set_session(sess)
</code></pre>
<p>When I run this in Google Colab I get:</p>
<pre><code>RuntimeError: `set_session` is not available when using TensorFlow 2.0.
</code></pre>
<p>Does anyone know how to fix this?</p>
",9830958.0,,,,,2020-07-10 18:37:30,Keras 'set_session' not available for Tensorflow 2.0,<python-3.x><machine-learning><keras><tensorflow2.0>,1,1,0.0,,,CC BY-SA 4.0
72131638,1,,,2022-05-05 17:54:05,,8,816,"<p>validation_split parameter is able to allow ImageDataGenerator to split the data sets reading from the folder into 2 different disjoint sets. Is there any way to create 3 sets - of training, validation, and evaluation datasets using it?</p>
<p>I am thinking about splitting the dataset into 2 datasets, then splitting the 2nd dataset into another 2 datasets</p>
<pre><code>datagen = ImageDataGenerator(validation_split=0.5, rescale=1./255)

train_generator = datagen.flow_from_directory(
    TRAIN_DIR, 
    subset='training'
)

val_generator = datagen.flow_from_directory(
    TRAIN_DIR,
    subset='validation'
)
</code></pre>
<p>Here I am thinking about splitting the validation dataset into 2 sets using val_generator. One for validation and the other for evaluation? How should I do it?</p>
",304319.0,,304319.0,,2022-05-14 08:07:13,2022-05-14 08:07:13,How to split folders to 3 datasets with ImageDataGenerator?,<python><keras><imagedatagenerator>,2,3,0.0,,,CC BY-SA 4.0
72195156,1,72264322.0,,2022-05-11 03:43:56,,8,7970,"<p>I've been trying to experiment with <a href=""https://arxiv.org/pdf/1807.10097.pdf"" rel=""noreferrer"">Region Based: Dice Loss</a> but there have been a lot of variations on the internet to a varying degree that I could not find two identical implementations. The problem is that all of these produce varying results. Below are the implementations that I found. Some uses <code>smoothing</code> factor which <a href=""https://arxiv.org/pdf/1707.03237.pdf"" rel=""noreferrer"">the authors in this paper</a> have called <code>epsilon</code>, some use it in both numerator and denominator, one implementation used <code>Gamma</code> etc etc.</p>
<p>Could someone please help me with the correct implementation.</p>
<pre><code>import tensorflow as tf
import tensorflow.keras.backend as K
import numpy as np

def dice_loss1(y_true, y_pred, smooth=1e-6):
    '''
    https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook
    '''
    y_pred = tf.convert_to_tensor(y_pred)
    y_true = tf.cast(y_true, y_pred.dtype)
    smooth = tf.cast(smooth, y_pred.dtype)
    
    y_pred = K.flatten(y_pred)
    y_true = K.flatten(y_true)
    
    intersection = K.sum(K.dot(y_true, y_pred))    
    dice_coef = (2*intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth)
    dice_loss = 1-dice_coef
    return dice_loss
    

def dice_loss2(y_true, y_pred, smooth=1e-6): # Only Smooth
    &quot;&quot;&quot;
    https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a
    &quot;&quot;&quot;
    y_pred = tf.convert_to_tensor(y_pred)
    y_true = tf.cast(y_true, y_pred.dtype)
    smooth = tf.cast(smooth, y_pred.dtype)
    
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    dice_coef  = (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)
    return 1- dice_coef


def dice_loss3(y_true, y_pred): # No gamma, no smooth
    '''
    https://lars76.github.io/2018/09/27/loss-functions-for-segmentation.html
    '''
    y_pred = tf.convert_to_tensor(y_pred)
    y_true = tf.cast(y_true, y_pred.dtype)
    
    y_pred = tf.math.sigmoid(y_pred)
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)

    return 1 - numerator / denominator


def dice_loss4(y_true, y_pred, smooth=1e-6, gama=1): # Gama + Smooth is used
    '''
    https://dev.to/_aadidev/3-common-loss-functions-for-image-segmentation-545o
    '''
    y_pred = tf.convert_to_tensor(y_pred)
    y_true = tf.cast(y_true, y_pred.dtype)
    smooth = tf.cast(smooth, y_pred.dtype)
    gama = tf.cast(gama, y_pred.dtype)

    nominator = 2 * tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth
    denominator = tf.reduce_sum(y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth

    result = 1 - tf.divide(nominator, denominator)
    return result

y_true = np.array([[0,0,1,0],
                   [0,0,1,0],
                   [0,0,1.,0.]])

y_pred = np.array([[0,0,0.9,0],
                   [0,0,0.1,0],
                   [1,1,0.1,1.]])

# print(dice_loss1(y_true, y_pred)) # Gives you error in K.dot()
print(dice_loss2(y_true, y_pred))
print(dice_loss3(y_true, y_pred)) # provides array of values
print(dice_loss4(y_true, y_pred))
</code></pre>
",11725056.0,,,,,2022-05-16 19:00:03,Correct Implementation of Dice Loss in Tensorflow / Keras,<tensorflow><machine-learning><keras><deep-learning><computer-vision>,1,0,0.0,,,CC BY-SA 4.0
65862711,1,65863113.0,,2021-01-23 18:10:53,,8,7227,"<p>Is it possbible to get the expected input shape from a 'model.h5' file?
I have two models for the same dataset but with different options and shapes. The first one expects a dim of (None, 64, 48, 1) and the seconds model need input shape (None, 128, 96, 3). (Note: The width or the height are not fixed and can change when I train again).
The channels problem was easy to &quot;fix&quot; (or bypass rather) by just using try: and except because there are only two options (1 for grayscale image and 3 for rgb image):</p>
<pre><code>        channels = self.df[&quot;channels&quot;][0]
        file = &quot;&quot;
        try:
            images, src_images, data = self.get_images()
            images = self.preprocess_data(images, channels)
            predictions, file = self.load_model(images, file)
            self.predict_data(src_images, predictions, data)
        except:
            if channels == 1:
                print(&quot;Except channels =&quot;, channels)
                channels = 3
                images, src_images, data = self.get_images()
                images = self.preprocess_data(images, channels)
                predictions = self.load_model(images, file)
                self.predict_data(src_images, predictions, data)
            else:
                channels = 1
                print(&quot;Except channels =&quot;, channels)
                images, src_images, data = self.get_images()
                images = self.preprocess_data(images, channels)
                predictions = self.load_model(images, file)
                self.predict_data(src_images, predictions, data)
</code></pre>
<p>This workaround however cannot be used for the width and height of an image because there basically unlimited amount of options.
Besides that it is rather slow because I read all the data twice and preprocess it twice for no reason.</p>
<p><strong>Is there a way to load the model.h5 file and print the expected input shape in a form like this?:</strong></p>
<pre><code>[None, 128, 96, 3]
</code></pre>
",11159734.0,,11159734.0,,2021-09-28 07:11:57,2023-02-10 14:08:23,TF Keras how to get expected input shape when loading a model?,<python><tensorflow><keras>,2,0,,,,CC BY-SA 4.0
64797710,1,,,2020-11-12 03:57:03,,8,6872,"<p>Following my Studies in Machine learning I am now in the Neural network, I have an assignment - text Classification - using Neural Network.</p>
<p>In the following, I am showing what I have so far</p>
<ol>
<li>Process Data</li>
<li>Counter Vectorizer</li>
</ol>
<p>Now I'm trying to compile the NN However I am receiving the following
error</p>
<blockquote>
<p>TypeError: 'SparseTensor' object is not subscriptable
Traceback (most recent call last):
File &quot;/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py&quot;, line 242, in <strong>call</strong>
return func(device, token, args)
File &quot;/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py&quot;, line 131, in <strong>call</strong></p>
</blockquote>
<p>My data shape is the following</p>
<pre><code>X_train.shape = (17621, 8014)

type(X_train) = scipy.sparse.csr.csr_matrix
</code></pre>
<p>The model</p>
<pre><code>model = Sequential()
model.add(Dense(1015, input_shape=(17621, 8014) , activation = 'relu'))
model.add(Dense(5, activation = 'sigmoid'))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss = 'binary_crossentropy',metrics = ['accuracy'], optimizer = 'adam')
model.fit(x=X_train, y=y_train,epochs=500,batch_size=125,
          validation_data=(X_test,y_test))
</code></pre>
<p>in addition, I have 2 more question</p>
<ol>
<li>What are the differences between input_shape ~ Input_dimmension?</li>
<li>when I add the first Layer. How many perceptrons should I set?</li>
<li>the most important one what Am I doing wrong?</li>
</ol>
<p>Please feel free to give more suggestion</p>
",12692772.0,,1409165.0,,2020-11-12 12:43:31,2021-05-17 06:15:14,'SparseTensor' object is not subscriptable keras,<python><tensorflow><keras>,1,2,,,,CC BY-SA 4.0
67805117,1,,,2021-06-02 12:29:03,,8,4385,"<p>I am struggling to mask my input for the MultiHeadAttention Layer. I am using the Transformer Block from Keras documentation with self-attention. I could not find any example code online so far and would appreciate if someone could give me a code snippet.</p>
<p>The transformer block from <a href=""https://keras.io/examples/nlp/text_classification_with_transformer/"" rel=""noreferrer"">this</a> page:</p>
<pre><code>class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = keras.Sequential(
            [layers.Dense(ff_dim, activation=&quot;relu&quot;), layers.Dense(embed_dim),]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)
</code></pre>
<p>The documentation for masking one can find under <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention"" rel=""noreferrer"">this</a> link:</p>
<blockquote>
<p>attention_mask: a boolean mask of shape [B, T, S], that prevents
attention to certain positions. The boolean mask specifies which query
elements can attend to which key elements, 1 indicates attention and 0
indicates no attention. Broadcasting can happen for the missing batch
dimensions and the head dimension.</p>
</blockquote>
<p>The only thing, I could get running is a mask created outside of the layer class as numpy array:</p>
<pre><code>mask = np.ones((observations, sequence_length, sequence_length))
mask[X[:observations,:,0]==0]=0
</code></pre>
<p>Then input while calling the layer, with the only change in the transformer block being:</p>
<pre><code>def call(self, inputs, mask, training):
    attn_output = self.att(inputs, inputs, attention_mask=mask)
</code></pre>
<p>However, this does of course not work when given a batch_size while fitting and does only work for 5 observations with my memory, so it doesn't make any sense.
Apart from that, I don't think this is masking the input properly - In general I am quite confused about how to mask, given the shape of the attention_mask (observations, sequence_length, sequence_length). The shape of my input is (observation, sequence_length, features). This input is being padded by zeros, however, when it comes to the transformer block, it has been already through an embedding layer and CNN.
I have tried various ways to write a function, which creates the mask while training with different Tensor or Keras objects. However I am running each time into errors.</p>
<p>I hope someone more fluent in Tensorflow/Keras will be able to provide an example.
Or somebody tells me that masking is useless given my architecture. The model is performing well. However, I hoped masking could help speed up the computing.
And it just buggs me that I cannot get my head around it.</p>
",16036484.0,,16036484.0,,2021-06-02 14:19:43,2022-02-08 09:23:03,"MultiHeadAttention attention_mask [Keras, Tensorflow] example",<tensorflow><machine-learning><keras><transformer-model><attention-model>,1,0,0.0,,,CC BY-SA 4.0
70459884,1,,,2021-12-23 09:12:14,,8,2373,"<p><a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy"" rel=""noreferrer"">Focal Loss given in Tensorflow</a> is used for class imbalance. For Binary class classification, there are a lots of codes available but for Multiclass classification, a very little help is there. I ran the code with <code>One Hot Encoded</code> target variables of 250 classes and it gave me results without any error.</p>
<pre><code>y = pd.get_dummies(df['target']) # One hot encoded target classes
model.compile(
    optimizer=&quot;adam&quot;, loss=tfa.losses.SigmoidFocalCrossEntropy(), metrics= metric
)
</code></pre>
<p>I just want to know whoever wrote this code  or someone having enough knowledge of this code, can it be used be used for Multiclass Classification. If no then how come it did not give me errors, instead better results than <code>CrossEntropy</code>. Also, <a href=""https://github.com/artemmavrin/focal-loss"" rel=""noreferrer"">in other implementations like this one</a>, the value of <code>alpha</code> has to be given for every class but just one value in Tensorflow's implementations.</p>
<p><strong>What is the correct way to use this?</strong></p>
",11725056.0,,,,,2021-12-29 04:21:51,Can SigmoidFocalCrossEntropy in Tensorflow (tf-addons) be used in Multiclass Classification? ( What is the right way)?,<tensorflow><keras><tensorflow2.0><tf.keras><loss-function>,1,0,,,,CC BY-SA 4.0
66334784,1,,,2021-02-23 14:10:53,,8,3252,"<p><strong>This question is basically for the working of Keras or <code>tf.keras</code> for people who have the verty deep knowledge of the framework</strong></p>
<p>According to my knowledge, <code>tf.keras.optimizers.Adam</code> is an optimizer which has already an <strong>Adaptive</strong> Learning rate scheme. So if we are using <code>from keras.callbacks.ReduceLROnPlateau</code> with the <code>Adam</code> optimizer or any other, isn't it meaningless to do so? I don't have the very inner workings of <code>Keras</code> based <code>Optimizer</code> but it looks natural to me that if we are using the adaptive optimizer, why to to use this and <strong>If we use this given callback, what would be the effect on the training</strong>?</p>
",11725056.0,,4685471.0,,2021-02-23 14:24:39,2022-01-06 01:57:20,Is it meaningless to use ReduceLROnPlateau with Adam optimizer?,<tensorflow><machine-learning><keras><deep-learning><tf.keras>,1,9,,,,CC BY-SA 4.0
64689483,1,64694328.0,,2020-11-05 00:15:39,,8,16191,"<p>I want to make simple classifier with Keras that will classify my data. Features are numeric data and results are string/categorical data. I'm predicting 15 different categories/classes. This is how my code looks:</p>
<pre><code>model = Sequential()
model.add(Dense(16, input_dim = x_train.shape[1], activation = 'relu')) # input layer requires input_dim param
model.add(Dense(16, activation = 'relu'))
model.add(Dense(16, activation = 'relu'))
model.add(Dense(1, activation='relu'))

model.compile(loss=&quot;binary_crossentropy&quot;, optimizer= &quot;adam&quot;, metrics=['accuracy'])

#es = EarlyStopping(monitor='loss', min_delta=0.005, patience=1, verbose=1, mode='auto')
model.fit(x_train, y_train, epochs = 100, shuffle = True, batch_size=128, verbose=2)

scores = model.evaluate(x_test, y_test)
print(model.metrics_names[0], model.metrics_names[1])
</code></pre>
<p>the problem is that I'm always getting this error:</p>
<pre><code>ValueError: could not convert string to float 'category1'
</code></pre>
<p>What am I doing wrong?</p>
<p>When I replace my classes names &quot;category1&quot;, &quot;category2&quot; etc with integer numbers, my code works but it always give me accuracy of 0.
I have tried to change number of nodes and layers and activation functions  but the result is always 0. It seams like the model thinks that I'm doing regression not classification.</p>
<p>What is the correct way to do classification with Keras lib If my categorical values are not just 1 or 0?</p>
",9749124.0,,9749124.0,,2020-11-05 09:10:50,2020-11-05 09:27:44,How to do Multiclass classification with Keras?,<python><machine-learning><keras><neural-network>,2,2,,,,CC BY-SA 4.0
63757796,1,,,2020-09-05 19:30:58,,8,4256,"<p>I'm implementing a Keras model with a custom batch-renormalization layer, which has 4 weights (beta, gamma, running_mean, and running_std) and 3 state variables (r_max, d_max, and t):</p>
<pre><code>    self.gamma = self.add_weight(shape = shape, #NK - shape = shape
                                 initializer=self.gamma_init,
                                 regularizer=self.gamma_regularizer,
                                 name='{}_gamma'.format(self.name))
    self.beta = self.add_weight(shape = shape, #NK - shape = shape
                                initializer=self.beta_init,
                                regularizer=self.beta_regularizer,
                                name='{}_beta'.format(self.name))
    self.running_mean = self.add_weight(shape = shape, #NK - shape = shape
                                        initializer='zero',
                                        name='{}_running_mean'.format(self.name),
                                        trainable=False)
    # Note: running_std actually holds the running variance, not the running std.
    self.running_std = self.add_weight(shape = shape, initializer='one',
                                       name='{}_running_std'.format(self.name),
                                       trainable=False)
    self.r_max = K.variable(np.ones((1,)), name='{}_r_max'.format(self.name))

    self.d_max = K.variable(np.zeros((1,)), name='{}_d_max'.format(self.name))

    self.t = K.variable(np.zeros((1,)), name='{}_t'.format(self.name))
</code></pre>
<p>When I checkpoint the model, only gamma, beta, running_mean, and running_std are saved (as expected), but when I try to load the model, I get this error:</p>
<pre><code>Layer #1 (named &quot;batch_renormalization_1&quot; in the current model) was found to correspond to layer batch_renormalization_1 in the save file. However the new layer batch_renormalization_1 expects 7 weights, but the saved weights have 4 elements. 
</code></pre>
<p>So it looks like the model is expecting all 7 weights to be part of the saved file, even though some of them are state variables.</p>
<p>Any insights as to how to get around this?</p>
<p><strong>EDIT:</strong> I realize that the problem was that the model was trained and saved on Keras 2.1.0 (with Tensorflow 1.3.0 backend), and I only get the error when loading the model using Keras 2.4.3 (with Tensorflow 2.3.0 backend). I am able to load the model using Keras to 2.1.0.</p>
<p>So the real question is - what changed in Keras/Tensorflow, and is there a way to load older models without receiving this error?</p>
",13073845.0,,13073845.0,,2020-09-10 19:12:54,2020-09-10 19:12:54,Unable to load Keras model in Keras 2.4.3 (with Tensorflow 2.3.0) that was saved in Keras 2.1.0 (with Tensorflow 1.3.0),<python><machine-learning><keras><neural-network><batch-normalization>,2,0,0.0,,,CC BY-SA 4.0
72571954,1,,,2022-06-10 09:22:21,,7,24855,"<p>I'm trying to import imageai</p>
<pre><code>from imageai.Detection import VideoObjectDetection
</code></pre>
<p>but get error message below</p>
<pre><code>ModuleNotFoundError: No module named 'keras.layers.advanced_activations'
</code></pre>
<p>My tensorflow version       2.9.1,
keras version               2.9.0,
keras-preprocessing version 1.1.2,
image ai version            2.1.5,</p>
<p>I installed the imageai via <code>pip install imageai-2.0.2-py3-none-any.whl</code> and download from <a href=""https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl"" rel=""noreferrer"">here</a>.</p>
",16018714.0,,2602877.0,,2022-06-10 11:08:38,2022-12-27 16:42:38,"How to fix ""ModuleNotFoundError: No module named 'keras.layers.advanced_activations' """,<python><tensorflow><keras>,5,2,0.0,,,CC BY-SA 4.0
64096624,1,64097563.0,,2020-09-28 05:52:14,,7,1350,"<p>what is the difference between using softmax as a sequential layer in tf.keras and softmax as an activation function for a dense layer?</p>
<pre><code>tf.keras.layers.Dense(10, activation=tf.nn.softmax)
</code></pre>
<p>and</p>
<pre><code>tf.keras.layers.Softmax(10)
</code></pre>
",11995630.0,,4685471.0,,2020-09-28 07:23:36,2020-09-28 07:23:36,what is the difference between using softmax as a sequential layer in tf.keras and softmax as an activation function for a dense layer?,<python><tensorflow><machine-learning><keras><computer-vision>,1,0,,,,CC BY-SA 4.0
72334642,1,72334710.0,,2022-05-22 03:39:06,,7,63291,"<p>Im new here. I have problem with this code,</p>
<pre><code>#Library
import numpy as np
import pickle
import cv2
from os import listdir
from sklearn.preprocessing import LabelBinarizer
from keras.models import Sequential
from keras.layers import BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation, Flatten, Dropout, Dense
from keras import backend as K
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.preprocessing import image
#from tensorflow.keras.preprocessing.image import img_to_array
from keras.preprocessing.image import img_to_array
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
</code></pre>
<p>I got an error</p>
<p><a href=""https://i.stack.imgur.com/6knhx.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/6knhx.png"" alt=""enter image description here"" /></a></p>
<p>this code is from <a href=""https://github.com/marcosdhiman/leaf_disease_detection/blob/main/Leaf_Disease_Detection.ipynb"" rel=""noreferrer"">github link</a></p>
<p>Im using</p>
<ol>
<li>python 3.7.13</li>
<li>tensorflow 2.9</li>
<li>opencv 4.5.5</li>
<li>keras 2.9.0</li>
</ol>
",19171557.0,,2602877.0,,2022-05-22 12:21:26,2022-09-16 21:26:03,ImportError: cannot import name 'img_to_array' from 'keras.preprocessing.image',<python><keras>,3,0,,,,CC BY-SA 4.0
64118331,1,65088343.0,,2020-09-29 11:06:39,,7,6353,"<p>I tried to execute some project. But I've got an <code>attribute error</code>.
I checked my Tensorflow and Keras version.</p>
<pre><code>Name: tensorflow
Version: 2.3.1
Name: Keras
Version: 2.4.3
Summary: Deep Learning for humans
python 3.8.2 
</code></pre>
<p>The code is here.</p>
<pre><code>self.dim_ordering = K.common.image_dim_ordering()
</code></pre>
<p>Error message:</p>
<pre><code>self.dim_ordering = K.common.image_dim_ordering()
AttributeError: module 'keras.backend' has no attribute 'common'
</code></pre>
<p>Is it okay to use  <code>K.image_data_format()</code> instead of <code>k.common.image_dim_ordering()</code> ?</p>
",14360645.0,,14360645.0,,2020-09-30 11:21:07,2020-12-03 12:17:38,AttributeError: module 'keras.backend' has no attribute 'common',<python><tensorflow><keras><tensorflow2.0><keras-2>,1,0,,,,CC BY-SA 4.0
70226626,1,70377400.0,,2021-12-04 14:44:20,,7,153,"<p>I have created a working CNN model in Keras/Tensorflow, and have successfully used the CIFAR-10 &amp; MNIST datasets to test this model. The functioning code as seen below:</p>
<pre><code>import keras
from keras.datasets import cifar10
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Conv2D, Flatten, MaxPooling2D
from keras.layers.normalization import BatchNormalization

(X_train, y_train), (X_test, y_test) = cifar10.load_data()

#reshape data to fit model
X_train = X_train.reshape(50000,32,32,3)
X_test = X_test.reshape(10000,32,32,3)

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)


# Building the model 

#1st Convolutional Layer
model.add(Conv2D(filters=64, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

#2nd Convolutional Layer
model.add(Conv2D(filters=224, kernel_size=(5, 5), strides=(1,1), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

#3rd Convolutional Layer
model.add(Conv2D(filters=288, kernel_size=(3,3), strides=(1,1), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))

#4th Convolutional Layer
model.add(Conv2D(filters=288, kernel_size=(3,3), strides=(1,1), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))

#5th Convolutional Layer
model.add(Conv2D(filters=160, kernel_size=(3,3), strides=(1,1), padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))

model.add(Flatten())

# 1st Fully Connected Layer
model.add(Dense(4096, input_shape=(32,32,3,)))
model.add(BatchNormalization())
model.add(Activation('relu'))
# Add Dropout to prevent overfitting
model.add(Dropout(0.4))

#2nd Fully Connected Layer
model.add(Dense(4096))
model.add(BatchNormalization())
model.add(Activation('relu'))
#Add Dropout
model.add(Dropout(0.4))

#3rd Fully Connected Layer
model.add(Dense(1000))
model.add(BatchNormalization())
model.add(Activation('relu'))
#Add Dropout
model.add(Dropout(0.4))

#Output Layer
model.add(Dense(10))
model.add(BatchNormalization())
model.add(Activation('softmax'))


#compile model using accuracy to measure model performance
opt = keras.optimizers.Adam(learning_rate = 0.0001)
model.compile(optimizer=opt, loss='categorical_crossentropy', 
              metrics=['accuracy'])


#train the model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)
</code></pre>
<p>From this point after utilising the aforementioned datasets, I wanted to go one further and use a dataset with more channels than a greyscale or rgb presented, hence the inclusion of a hyperspectral dataset. When looking for a hyperspectral dataset I came across <a href=""http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes#Indian_Pines"" rel=""noreferrer"">this</a> one.</p>
<p>The issue at this stage was realising that this hyperspectral dataset was one image, with each value in the ground truth relating to each pixel. At this stage I reformatted the data from this into a collection of hyperspectral data/pixels.</p>
<p><strong>Code reformatting corrected dataset for x_train &amp; x_test:</strong></p>
<pre><code>import keras
import scipy
import numpy as np
import matplotlib.pyplot as plt
from keras.utils import to_categorical
from scipy import io

mydict = scipy.io.loadmat('Indian_pines_corrected.mat')
dataset = np.array(mydict.get('indian_pines_corrected'))


#This is creating the split between x_train and x_test from the original dataset 
# x_train after this code runs will have a shape of (121, 145, 200) 
# x_test after this code runs will have a shape of (24, 145, 200)
x_train = np.zeros((121,145,200), dtype=np.int)
x_test = np.zeros((24,145,200), dtype=np.int)    

xtemp = np.array_split(dataset, [121])
x_train = np.array(xtemp[0])
x_test = np.array(xtemp[1])

# x_train will have a shape of (17545, 200) 
# x_test will have a shape of (3480, 200)
x_train = x_train.reshape(-1, x_train.shape[-1])
x_test = x_test.reshape(-1, x_test.shape[-1])
</code></pre>
<p><strong>Code reformatting ground truth dataset for Y_train &amp; Y_test:</strong></p>
<pre><code>truthDataset = scipy.io.loadmat('Indian_pines_gt.mat')
gTruth = truthDataset.get('indian_pines_gt')

#This is creating the split between Y_train and Y_test from the original dataset 
# Y_train after this code runs will have a shape of (121, 145) 
# Y_test after this code runs will have a shape of (24, 145)

Y_train = np.zeros((121,145), dtype=np.int)
Y_test = np.zeros((24,145), dtype=np.int)    

ytemp = np.array_split(gTruth, [121])
Y_train = np.array(ytemp[0])
Y_test = np.array(ytemp[1])

# Y_train will have a shape of (17545) 
# Y_test will have a shape of (3480)
Y_train = Y_train.reshape(-1)
Y_test = Y_test.reshape(-1)


#17 binary categories ranging from 0-16

#Y_train one-hot encode target column
Y_train = to_categorical(Y_train)

#Y_test one-hot encode target column
Y_test = to_categorical(Y_test, num_classes = 17)
</code></pre>
<p>My thought process was that, despite the initial image being broken down into 1x1 patches, the large number of channels each patch possessed with their respective values would aid in categorisation of the dataset.</p>
<p>Essentially I'd want to input this reformatted data into my model (seen within the first code fragment in this post), however I'm uncertain if I am taking the wrong approach to this due to my inexperience with this area of expertise. I was expecting to input a shape of (1,1,200), i.e the shape of x_train &amp; x_test would be (17545,1,1,200) &amp; (3480,1,1,200) respectively.</p>
",5919958.0,,5919958.0,,2021-12-08 13:46:32,2021-12-17 09:08:02,Is it possible to use a collection of hyperspectral 1x1 pixels in a CNN model purposed for more conventional datasets (CIFAR-10/MNIST)?,<tensorflow><machine-learning><keras><deep-learning><conv-neural-network>,2,0,0.0,,,CC BY-SA 4.0
63364452,1,,,2020-08-11 18:41:09,,7,11494,"<p>When I try to run tensorboard using the command</p>
<pre><code>(tensorflow) C:\Users\ANVAY&gt;tensorboard --logdir=D:\Documents\Vs code python\my_log_dir
</code></pre>
<p>in the anaconda prompt after I have activated tensorflow, I get this error:</p>
<pre><code>(tensorflow) C:\Users\ANVAY&gt;tensorboard --logdir=D:\Documents\Vs code python\my_log_dir
2020-08-11 23:02:45.376116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]
                   [--host ADDR] [--bind_all] [--port PORT]
                   [--purge_orphaned_data BOOL] [--db URI] [--db_import]
                   [--inspect] [--version_tb] [--tag TAG] [--event_file PATH]
                   [--path_prefix PATH] [--window_title TEXT]
                   [--max_reload_threads COUNT] [--reload_interval SECONDS]
                   [--reload_task TYPE] [--reload_multifile BOOL]
                   [--reload_multifile_inactive_secs SECONDS]
                   [--generic_data TYPE]
                   [--samples_per_plugin SAMPLES_PER_PLUGIN]
                   [--debugger_data_server_grpc_port PORT]
                   [--debugger_port PORT]
                   {serve,dev} ...
tensorboard: error: invalid choice: 'code' (choose from 'serve', 'dev')
</code></pre>
<p><strong>Package versions:</strong><br />
Tensor Flow Version: 2.1.0<br />
Keras Version: 2.2.4-tf<br />
Python 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)]</p>
<p>I have also tried using the following commands but get the same error</p>
<pre><code>tensorboard --logdir D:\Documents\Vs code python\my_log_dir  
python -m tensorboard.main --logdir=D:\Documents\Vs code python\my_log_dir
</code></pre>
<p>One thing that I noticed while trying to make this work is, in the file <code>tensorboard-script.py</code> under the directory <code>C:\Users\ANVAY\miniconda3\envs\tensorflow\Scripts</code> I get this
<a href=""https://i.stack.imgur.com/8jNiy.png"" rel=""noreferrer"">warning</a> [ <code>unresolved import 'tensorboard.main'Python(unresolved-import)</code> ]<br />
and also in the file <code>main.py</code> under the directory<code>C:\Users\ANVAY\miniconda3\envs\tensorflow\Lib\site-packages\tensorboard</code>, I get a similar <a href=""https://i.stack.imgur.com/OPG1u.png"" rel=""noreferrer"">warning</a></p>
<p>I have no problems with training models and other stuff.</p>
",13639730.0,,,,,2022-03-11 00:57:17,"tensorboard: error: invalid choice: 'code' (choose from 'serve', 'dev') - while trying to run tensorboard",<tensorflow><keras><deep-learning><anaconda><tensorboard>,4,2,0.0,,,CC BY-SA 4.0
64541824,1,65237653.0,,2020-10-26 17:11:33,,7,2707,"<p>I am seeing a very strange situation. After training a convolutional network I get about 95% accuracy on the validation data. I save the model. Later I restore the model and run validation on the same validation data set. This time I barely get 10% accuracy. I have read the <a href=""https://www.tensorflow.org/guide/keras/save_and_serialize"" rel=""noreferrer"">documentation</a> but nothing seems to help. Is there something I am doing wrong?</p>
<pre class=""lang-py prettyprint-override""><code>def build_model_mnist(image_width, image_height, image_depth):
  model = keras.Sequential()
  model.add(keras.layers.Conv2D(5, (3, 3), activation='relu', input_shape=(image_width, image_height, image_depth)))
  model.add(keras.layers.MaxPooling2D((2, 2)))
  model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))
  model.add(keras.layers.MaxPooling2D((2, 2)))
  model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))

  model.add(keras.layers.Flatten())
  model.add(keras.layers.Dense(64, activation='relu'))
  model.add(keras.layers.Dense(10, activation='softmax'))

  model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
  
  return model

def train_mnist():
  model = build_model_mnist(image_width=train_images.shape[1], 
                    image_height=train_images.shape[2], 
                    image_depth=train_images.shape[3])
  # Start training              
  h = model.fit(train_images, train_labels, batch_size=500, epochs=5)

  model.save(&quot;minist&quot;)

  # Evaluate the model
  test_loss, test_acc = model.evaluate(test_images, test_labels)

  print(&quot;Accuracy:&quot;, test_acc)

train_mnist()
</code></pre>
<p>The above will show 95% accuracy. But the code below shows 10% accuracy.</p>
<pre class=""lang-py prettyprint-override""><code>def evaluate_mnist():
  # Load the model
  model = keras.models.load_model(&quot;minist&quot;)

  # Evaluate the model
  test_loss, test_acc = model.evaluate(test_images, test_labels)

  print(&quot;Accuracy:&quot;, test_acc)

evaluate_mnist()
</code></pre>
<p>If I save and restore just the weights then things work fine. In the code below we are saving the weights only. Later we recreate the model architecture using code and restore the weights. This approach produces the correct accuracy.</p>
<pre class=""lang-py prettyprint-override""><code>def train_mnist():
  #Create the network model
  model = build_model_mnist(image_width=train_images.shape[1], 
                    image_height=train_images.shape[2], 
                    image_depth=train_images.shape[3])
  # Start training              
  h = model.fit(train_images, train_labels, batch_size=500, epochs=5)

  # Evaluate the model
  test_loss, test_acc = model.evaluate(test_images, test_labels)

  print(&quot;Accuracy:&quot;, test_acc)

  model.save_weights(&quot;minist-weights&quot;)

train_mnist()

def evaluate_mnist():
  # Re-create the model architecture
  model = build_model_mnist(image_width=train_images.shape[1], 
                    image_height=train_images.shape[2], 
                    image_depth=train_images.shape[3])

  model.load_weights(&quot;minist-weights&quot;)
  
  # Evaluate the model
  test_loss, test_acc = model.evaluate(test_images, test_labels)

  print(&quot;Accuracy:&quot;, test_acc)

evaluate_mnist()
</code></pre>
",1036017.0,,1036017.0,,2020-10-26 17:53:15,2021-01-10 18:27:48,Keras giving low accuracy after loading model,<tensorflow><keras>,2,6,0.0,,,CC BY-SA 4.0
64200512,1,64786957.0,,2020-10-04 22:32:27,,7,3574,"<p>I a model as seen in the code below, but when trying to evaluate it or using earlystopping on it it gives me the following error:</p>
<pre><code>    numdigits = int(np.log10(self.target)) + 1
OverflowError: cannot convert float infinity to integer
</code></pre>
<p>I  must state that without using <code>.EarlyStopping</code> or <code>model.evaluate</code> everything works well.</p>
<p>I know that <code>np.log10(0)</code> gives <code>-inf</code> so that could be a potential cause, but why is there a <code>0</code> there in the first place and how can it be prevented? How can this problem be fixed?</p>
<p>NOTES</p>
<p>this is the code I use:</p>
<pre><code>import tensorflow as tf
from tensorflow import keras

TRAIN_PERCENT = 0.9

model = keras.Sequential([
    keras.layers.Dense(128, input_shape=(100,), activation='relu'),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(100)
])

earlystop_callback = keras.callbacks.EarlyStopping(min_delta=0.0001, patience=1
                                                   , monitor='accuracy'
                                                   )

optimizer = keras.optimizers.Adam(lr=0.01)
model.compile(optimizer=optimizer, loss=&quot;mse&quot;, metrics=['accuracy'])

X_set, Y_set = some_get_data_function()
sep = int(len(X_set)/TRAIN_PERCENT)
X_train, Y_train = X_set[:sep], Y_set[:sep]
X_test, Y_test = X_set[sep:], Y_set[sep:]

model.fit(X_train, Y_train, batch_size=16, epochs=5, callbacks=[earlystop_callback])
ev = model.evaluate(X_test, Y_test)
print(ev)
</code></pre>
<p>X,Y sets are  <code>np</code> arrays. X is an array of arrays of 100 integers between <code>0</code> and <code>10</code>. Y is an array  of arrays of 100 integers, all of them are either <code>0</code> or <code>1</code>.</p>
",14349010.0,,,,,2022-09-07 19:32:03,tensorflow evalutaion and earlystopping gives infinity overflow error,<python><numpy><tensorflow><keras><overflow>,2,2,0.0,,,CC BY-SA 4.0
65474081,1,65474713.0,,2020-12-28 07:11:45,,7,42789,"<p>This is a regression problem, where I want to generate 5 float values from each image of size 224 x 224. So I use fully connected networks with 5 nodes in the last layer. But doing so in keras gives me the following error:</p>
<pre><code>import keras, os
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.applications.inception_v3 import InceptionV3

## data_list = list of four 224x224 numpy arrays

inception = InceptionV3(weights='imagenet', include_top=False)
x = inception.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(5, activation='relu')(x)

y = [np.random.random(5),np.random.random(5),np.random.random(5),np.random.random(5)]

model = Model(inputs=inception.input, outputs=predictions)
opt = Adam(lr=0.001)
model.compile(optimizer=opt, loss=&quot;mae&quot;)
model.fit(data_list, y, verbose=0, epochs=100)
</code></pre>
<p>Error:</p>
<blockquote>
<p>ValueError: Data cardinality is ambiguous:<br />
      x sizes: 224, 224, 224, 224 <br />
      y sizes: 5, 5, 5, 5 <br />
Make sure all arrays contain the same number of samples.</p>
</blockquote>
<p>What could be going wrong?</p>
",5137827.0,,5137827.0,,2022-11-04 15:43:07,2023-01-28 10:43:05,ValueError: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples,<tensorflow><keras><deep-learning><regression><conv-neural-network>,2,0,,,,CC BY-SA 4.0
63201036,1,63692060.0,,2020-08-01 01:54:28,,7,7619,"<p>I want to add additional <code>Dense</code> layer after pretrained <code>TFDistilBertModel</code>, <code>TFXLNetModel</code> and <code>TFRobertaModel</code> Huggingface models. I have already seen how I can do this with the <code>TFBertModel</code>, e.g. <a href=""https://www.kaggle.com/dhruv1234/huggingface-tfbertmodel"" rel=""noreferrer"">in this notebook</a>:</p>
<pre><code>output = bert_model([input_ids,attention_masks])
output = output[1]
output = tf.keras.layers.Dense(32,activation='relu')(output)
</code></pre>
<p>So, here I need to use the second item(i.e. item with index <code>1</code>) of the <code>BERT</code> output tuple. According to the <a href=""https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel"" rel=""noreferrer"">docs</a> <code>TFBertModel</code> has <code>pooler_output</code> at this tuple index. But the other three models don't have <code>pooler_output</code>.</p>
<p>So, how can I add additional layers to the other three model outputs?</p>
",2274492.0,,,,,2020-09-22 07:56:04,Add additional layers to the Huggingface transformers,<python><tensorflow><keras><nlp><huggingface-transformers>,1,0,0.0,,,CC BY-SA 4.0
63166479,1,63170370.0,,2020-07-30 04:59:50,,7,29957,"<p>When I tried to add validation_split in my LSTM model, I got this error<br></p>
<pre><code>ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found: (&lt;tensorflow.python.keras.preprocessing.sequence.TimeseriesGenerator object)
</code></pre>
<p>This is the code <br></p>
<pre class=""lang-py prettyprint-override""><code>from keras.preprocessing.sequence import TimeseriesGenerator
train_generator = TimeseriesGenerator(df_scaled, df_scaled, length=n_timestamp, batch_size=1)

model.fit(train_generator, epochs=50,verbose=2,callbacks=[tensorboard_callback], validation_split=0.1)

----------
ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found: (&lt;tensorflow.python.keras.preprocessing.sequence.TimeseriesGenerator object)

</code></pre>
<p>One reason I could think of is, to use <em>validation_split</em> a tensor or numpy array is expected, as mentioned in the error, however, when passing train data through <em>TimeSeriesGenerator</em>, it changes the dimension of the train data to a 3D array <br>
And since <em>TimeSeriesGenerator</em> is mandatory to be used when using LSTM, does this means for LSTM we can't use validation_split</p>
",8560575.0,,,,,2021-08-19 09:25:38,"ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found: (keras.preprocessing.sequence.TimeseriesGenerator object)",<python><tensorflow><keras><lstm>,2,0,0.0,,,CC BY-SA 4.0
64297691,1,,,2020-10-10 19:57:29,,7,995,"<p>I am training the following model using Keras as shown:</p>
<pre><code>model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(256, 256, 3)),
tf.keras.layers.MaxPooling2D(2, 2),
tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Flatten(), 
tf.keras.layers.Dense(12, activation=tf.nn.relu),
tf.keras.layers.Dense(10, activation=tf.nn.relu),
tf.keras.layers.Dense(1, activation=tf.sigmoid)])

model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),loss,'binary_crossentropy, metrics=['accuracy'])

model.fit(X_train, y_train, epochs=20)

</code></pre>
<p>When running the following to check the accuracy on the test set</p>
<pre><code>model.evaluate(X_test,y_test)
</code></pre>
<p>I get the following warning:</p>
<p><em>WARNING:tensorflow:5 out of the last 13 calls to &lt;function Model.make_test_function..test_function at 0x000001E51AA92AE8&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to <a href=""https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args</a> and <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/function</a> for  more details.
2/2 [==============================] - 0s 94ms/step - loss: 0.6660 - accuracy: 0.5909</em></p>
<p><strong>Can you please help me understand why?</strong></p>
",1525553.0,,,,,2020-10-10 19:57:29,Keras model evaluate returns triggered tf.function retracing warning,<tensorflow><keras>,0,1,,,,CC BY-SA 4.0
63509657,1,,,2020-08-20 16:45:20,,7,17185,"<pre><code>from keras import backend as K
from tensorflow.keras.layers import MaxPooling2D,Conv2D,Input,Add,Flatten,AveragePooling2D,Dense,BatchNormalization,ZeroPadding2D,Activation
from tensorflow.keras.models import Model


def Dense_Layer(x,k):
    x = BatchNormalization(axis = 3)(x)
    x = Activation('relu')(x)
    x = Conv2D(4*k,(1,1),strides = (1,1))(x)
    x = BatchNormalization(axis = 3)(x)
    x = Activation('relu')(x)
    x = Conv2D(k,(1,1),strides = (1,1))(x)
    return x

def Dense_Block(x,k):
    
    x1 = Dense_Layer(x,k)
    x1_add = keras.layers.Concatenate()([x1,x])
    x2 = Dense_Layer(x1_add,k)
    x2_add = keras.layers.Concatenate()([x1,x2])
    
    return x2_add
def Dilated_Spatial_Pyramid_Pooling(x,k):
    x = BatchNormalization(axis = 3)(x)
    d1 = Conv2D(k, (1,1), dilation_rate = 2)(x)
    d2 = Conv2D(k, (1,1), dilation_rate = 4)(d1)
    d3 = Conv2D(k, (1,1), dilation_rate = 8)(d2)
    d4 = Conv2D(k, (1,1), dilation_rate = 16)(d3)
    c = keras.layers.Concatenate()([d1,d2,d3,d4])
    return c

    
        
    
def down_block(x,filters, kernel_size = (3, 3), padding = &quot;same&quot;,strides =1 ):
    c = Dense_Block(x,filters)
    c = Dense_Block(c,filters)
    p = keras.layers.MaxPool2D((2,2),(2,2))(c)
    return c,p
def up_block(x,skip,filters, kernel_size = (3, 3), padding = &quot;same&quot;,strides =1 ):
    us = keras.layers.UpSampling2D((2,2))(x)
    concat = keras.layers.Concatenate()([us,skip])
    c = Dense_Block(concat,filters)
    c = Dense_Block(c,filters)
    return c
def bottleneck(x,filters, kernel_size = (3, 3), padding = &quot;same&quot;,strides =1 ):
    c = Dense_Block(x,filters)
    c = Dense_Block(c,filters)
    c = Dilated_Spatial_Pyramid_Pooling(c,filters)
    return c

def UNet():
    f = [32,64,128,256]
    input = keras.layers.Input((128,128,1))
    
    
    p0 = input
    c1,p1 =  down_block(p0,f[0])
    c2,p2 =  down_block(p1,f[1])
    c3,p3 =  down_block(p2,f[2])

    
    bn = bottleneck(p3,f[3])
    
    u1 = up_block(bn,c3,f[2])
    u2 = up_block(u1,c2,f[1])
    u3 = up_block(u2,c1,f[0])
    
    
    outputs = keras.layers.Conv2D(1,(1,1),padding= &quot;same&quot;,activation = &quot;sigmoid&quot;)(u3)
    model = keras.models.Model(input,outputs)
    return model
model=UNet()
model.summary()

</code></pre>
<p>my versions are:</p>
<p>pip install q tensorflow==2.1</p>
<p>pip install q keras==2.3.1</p>
<p>pip install imgaug</p>
<p>pip install -U segmentation-models</p>
<p>I am using UNET using dense block instead of convulational layer with dilated spatial pooling layer in bottlenack layer.
but i am getting  ModuleNotFoundError: No module named 'tensorflow.python.keras.engine.base_layer_v1'</p>
",10476644.0,,530160.0,,2022-08-04 02:11:33,2022-08-04 02:11:33,ModuleNotFoundError: No module named 'tensorflow.python.keras.engine.base_layer_v1,<tensorflow><keras><neural-network><image-segmentation><unet-neural-network>,3,1,,,,CC BY-SA 4.0
65219970,1,65220971.0,,2020-12-09 15:39:22,,7,2231,"<p>I am trying to design a neural network to predict an array of the smooth underlying function from a dataset array with gaussian noise included. I have created a training and data set of 10000 arrays combined. Now I am trying to predict the array values for the actual function but it seems to fail and the accuracy isn't good either. Can someone guide me how to further improve my model to get better accuracy and be able to predict good data. My code used is below:</p>
<p>for generating test and training data:</p>
<pre><code>noisy_data = []
pure_data =[]
time = np.arange(1,100)
for i in tqdm(range(10000)):
    array = []
    noise = np.random.normal(0,1/10,99)
    for j in range(1,100):
        array.append( np.log(j))
    array = np.array(array)
    pure_data.append(array)
    noisy_data.append(array+noise)
    

pure_data=np.array(pure_data)
noisy_data=np.array(noisy_data)
    
print(noisy_data.shape)
print(pure_data.shape)

training_size=6000


x_train = noisy_data[:training_size]
y_train = pure_data[:training_size]
x_test = noisy_data[training_size:]
y_test = pure_data[training_size:]
print(x_train.shape)
</code></pre>
<p>My model:</p>
<pre><code>model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten(input_shape=(99,)))
model.add(tf.keras.layers.Dense(768, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(768, activation=tf.nn.relu))
model.add(tf.keras.layers.Dense(99, activation=tf.nn.softmax))

model.compile(optimizer = 'adam',
         loss = 'categorical_crossentropy',
         metrics = ['accuracy'])

model.fit(x_train, y_train, epochs = 20)

</code></pre>
<p>Outcome of bad accuracy:</p>
<pre><code>Epoch 1/20
125/125 [==============================] - 2s 16ms/step - loss: 947533.1875 - accuracy: 0.0000e+00
Epoch 2/20
125/125 [==============================] - 2s 15ms/step - loss: 9756863.0000 - accuracy: 0.0000e+00
Epoch 3/20
125/125 [==============================] - 2s 16ms/step - loss: 30837548.0000 - accuracy: 0.0000e+00
Epoch 4/20
125/125 [==============================] - 2s 15ms/step - loss: 63707028.0000 - accuracy: 0.0000e+00
Epoch 5/20
125/125 [==============================] - 2s 16ms/step - loss: 107545128.0000 - accuracy: 0.0000e+00
Epoch 6/20
125/125 [==============================] - 1s 12ms/step - loss: 161612192.0000 - accuracy: 0.0000e+00
Epoch 7/20
125/125 [==============================] - 1s 12ms/step - loss: 225245360.0000 - accuracy: 0.0000e+00
Epoch 8/20
125/125 [==============================] - 1s 12ms/step - loss: 297850816.0000 - accuracy: 0.0000e+00
Epoch 9/20
125/125 [==============================] - 1s 12ms/step - loss: 378894176.0000 - accuracy: 0.0000e+00
Epoch 10/20
125/125 [==============================] - 1s 12ms/step - loss: 467893216.0000 - accuracy: 0.0000e+00
Epoch 11/20
125/125 [==============================] - 2s 17ms/step - loss: 564412672.0000 - accuracy: 0.0000e+00
Epoch 12/20
125/125 [==============================] - 2s 15ms/step - loss: 668056384.0000 - accuracy: 0.0000e+00
Epoch 13/20
125/125 [==============================] - 2s 13ms/step - loss: 778468480.0000 - accuracy: 0.0000e+00
Epoch 14/20
125/125 [==============================] - 2s 18ms/step - loss: 895323840.0000 - accuracy: 0.0000e+00
Epoch 15/20
125/125 [==============================] - 2s 13ms/step - loss: 1018332672.0000 - accuracy: 0.0000e+00
Epoch 16/20
125/125 [==============================] - 1s 11ms/step - loss: 1147227136.0000 - accuracy: 0.0000e+00
Epoch 17/20
125/125 [==============================] - 2s 12ms/step - loss: 1281768448.0000 - accuracy: 0.0000e+00
Epoch 18/20
125/125 [==============================] - 2s 14ms/step - loss: 1421732608.0000 - accuracy: 0.0000e+00
Epoch 19/20
125/125 [==============================] - 1s 11ms/step - loss: 1566927744.0000 - accuracy: 0.0000e+00
Epoch 20/20
125/125 [==============================] - 1s 10ms/step - loss: 1717172480.0000 - accuracy: 0.0000e+00

</code></pre>
<p>and the prediction code I use:</p>
<pre><code>model.predict([noisy_data[0]])
</code></pre>
<p>This throws back the error:</p>
<pre><code>WARNING:tensorflow:Model was constructed with shape (None, 99) for input Tensor(&quot;flatten_5_input:0&quot;, shape=(None, 99), dtype=float32), but it was called on an input with incompatible shape (None, 1).


ValueError: Input 0 of layer dense_15 is incompatible with the layer: expected axis -1 of input shape to have value 99 but received input with shape [None, 1]
</code></pre>
",14795145.0,,4685471.0,,2020-12-09 16:10:04,2020-12-09 23:52:07,How to design a neural network to predict arrays from arrays,<python><tensorflow><machine-learning><keras><neural-network>,3,1,,,,CC BY-SA 4.0
69906416,1,69912334.0,,2021-11-09 23:47:07,,7,9938,"<p>This code predicts the values of a specified stock up to the current date but not a date beyond the training dataset. This code is from an earlier question I had asked and so my understanding of it is rather low. I assume the solution would be a simple variable change to add the extra time but I am unaware as to which value needs to be manipulated.</p>
<pre><code>import pandas as pd
import numpy as np
import yfinance as yf
import os
import matplotlib.pyplot as plt
from IPython.display import display
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

pd.options.mode.chained_assignment = None

# download the data
df = yf.download(tickers=['AAPL'], period='2y')

# split the data
train_data = df[['Close']].iloc[: - 200, :]
valid_data = df[['Close']].iloc[- 200:, :]

# scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaler.fit(train_data)

train_data = scaler.transform(train_data)
valid_data = scaler.transform(valid_data)

# extract the training sequences
x_train, y_train = [], []

for i in range(60, train_data.shape[0]):
    x_train.append(train_data[i - 60: i, 0])
    y_train.append(train_data[i, 0])

x_train = np.array(x_train)
y_train = np.array(y_train)

# extract the validation sequences
x_valid = []

for i in range(60, valid_data.shape[0]):
    x_valid.append(valid_data[i - 60: i, 0])

x_valid = np.array(x_valid)

# reshape the sequences
x_train = x_train.reshape(x_train.shape[0], 
x_train.shape[1], 1)
x_valid = x_valid.reshape(x_valid.shape[0], 
x_valid.shape[1], 1)

# train the model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, 
input_shape=x_train.shape[1:]))
model.add(LSTM(units=50))
model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(x_train, y_train, epochs=50, batch_size=128, verbose=1)

# generate the model predictions
y_pred = model.predict(x_valid)
y_pred = scaler.inverse_transform(y_pred)
y_pred = y_pred.flatten()

# plot the model predictions
df.rename(columns={'Close': 'Actual'}, inplace=True)
df['Predicted'] = np.nan
df['Predicted'].iloc[- y_pred.shape[0]:] = y_pred
df[['Actual', 'Predicted']].plot(title='AAPL')

display(df)

plt.show()
</code></pre>
",17351803.0,,11989081.0,,2021-12-21 20:43:55,2023-01-18 17:23:02,Forecast future values with LSTM in Python,<python><tensorflow><machine-learning><keras><lstm>,1,0,0.0,,,CC BY-SA 4.0
66679241,1,66684078.0,,2021-03-17 18:36:16,,7,2833,"<p>This question could seem difficult but I need to know how tom import ResNeXt model into Keras Tensor-flow, I have tried but there was no use</p>
<pre><code>from keras.applications.resnext import ResNeXt50

---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
&lt;ipython-input-1-ca380748170a&gt; in &lt;module&gt;
----&gt; 1 from keras.applications.resnext import ResNeXt50

~/opt/anaconda3/lib/python3.8/site-packages/keras/__init__.py in &lt;module&gt;
  1 from __future__ import absolute_import
  ----&gt; 2 from . import backend
  3 from . import datasets
  4 from . import engine
  5 from . import layers

 ~/opt/anaconda3/lib/python3.8/site-packages/keras/backend/__init__.py in &lt;module&gt;
 65 elif _BACKEND == 'tensorflow':
 66     sys.stderr.write('Using TensorFlow backend.\n')
 ---&gt; 67     from .tensorflow_backend import *
 68 else:
 69     raise ValueError('Unknown backend: ' + str(_BACKEND))

 ~/opt/anaconda3/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py in &lt;module&gt;
 ----&gt; 1 import tensorflow as tf
  2 
  3 from tensorflow.python.training import moving_averages
  4 from tensorflow.python.ops import tensor_array_ops
  5 from tensorflow.python.ops import control_flow_ops

  No module named 'keras.applications.resnext'
</code></pre>
",12381427.0,,,,,2021-03-18 02:49:53,Import ResNeXt into Keras,<tensorflow><keras><conv-neural-network>,1,0,0.0,,,CC BY-SA 4.0
66814523,1,66844039.0,,2021-03-26 09:49:53,,7,8998,"<p>I'm trying to compute shap values using DeepExplainer, but I get the following error:</p>
<blockquote>
<p>keras is no longer supported, please use tf.keras instead</p>
</blockquote>
<p>Even though i'm using tf.keras?</p>
<pre>
KeyError       Traceback (most recent call last)
 in 
6 # ...or pass tensors directly
7 explainer = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)
8 shap_values = explainer.shap_values(X_test[1:5])

C:\ProgramData\Anaconda3\lib\site-packages\shap\explainers\_deep\__init__.py in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)
122   were chosen as ""top"".
124   return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)
C:\ProgramData\Anaconda3\lib\site-packages\shap\explainers\_deep\deep_tf.py in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)
310                 # assign the attributions to the right part of the output arrays
311                 for l in range(len(X)):
312                     phis[l][j] = (sample_phis[l][bg_data[l].shape[0]:] * (X[l][j] - bg_data[l])).mean(0)
313 
314             output_phis.append(phis[0] if not self.multi_input else phis)

C:\ProgramData\Anaconda3\lib\site-packages\pandas\core\frame.py in __getitem__(self, key)

    2798 if self.columns.nlevels > 1:
    2799    return self._getitem_multilevel(key)
    2800    indexer = self.columns.get_loc(key)
    2801 if is_integer(indexer):
    2802    indexer = [indexer]
C:\ProgramData\Anaconda3\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance)
2646                 return self._engine.get_loc(key)
2647             except KeyError:
2648                 return self._engine.get_loc(self._maybe_cast_indexer(key))
2649         indexer = self.get_indexer([key], method=method, tolerance=tolerance)
2650         if indexer.ndim > 1 or indexer.size > 1:

pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc()

pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item()

KeyError: 0
</pre>
<pre><code>import shap
import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow.keras.backend as K

from keras.utils import to_categorical 
from sklearn.model_selection import train_test_split
from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras import Sequential
from tensorflow.keras import optimizers

# print the JS visualization code to the notebook
shap.initjs()

X_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)

Y_train = to_categorical(Y_train, num_classes=3) 
Y_test = to_categorical(Y_test, num_classes=3) 

# Define baseline model
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(8, input_dim=len(X_train.columns), activation=&quot;relu&quot;))
model.add(tf.keras.layers.Dense(3, activation=&quot;softmax&quot;))
model.summary()


# compile the model
model.compile(optimizer='adam', loss=&quot;categorical_crossentropy&quot;, metrics=['accuracy'])

hist = model.fit(X_train, Y_train, batch_size=5,epochs=200, verbose=0)

# select a set of background examples to take an expectation over
background = X_train.iloc[np.random.choice(X_train.shape[0], 100, replace=False)]

# Explain predictions of the model
#explainer = shap.DeepExplainer(model, background)
# ...or pass tensors directly
explainer = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)
shap_values = explainer.shap_values(X_test[1:5])


</code></pre>
",9250895.0,,4317058.0,,2022-05-25 07:29:36,2023-01-26 04:30:35,SHAP DeepExplainer with TensorFlow 2.4+ error,<python><tensorflow><keras><tf.keras><shap>,1,3,0.0,,,CC BY-SA 4.0
66084314,1,66278947.0,,2021-02-07 03:36:50,,7,1339,"<p>See <strong>EDIT</strong> below, the initial post almost has no meaning now but the question still remains.</p>
<hr />
<p>I developing a neural network to semantically segment imagery. I have worked through various loss functions (categorical cross entropy (CCE), weight CCE, focal loss, tversky loss, jaccard loss, focal tversky loss, etc) which attempt to handle highly skewed class representation, though none are producing the desired effect. My advisor mentioned attempting to create a custom loss function which ignores false negatives for a specific class (but still penalizes false positives).</p>
<p>I have a 6 class problem and my network is setup to work in/with one-hot encoded truth data. As a result my loss function will accept two tensors, <code>y_true, y_pred</code>, of shape <code>(batch, row, col, class)</code> (which is currently <code>(8, 128, 128, 6)</code>). To be able to utilize the losses I have already explored I would like to alter <code>y_pred</code> to set the predicted value for the specific class (the 0th class) to always be correct. That is where <code>y_true == class 0</code> set <code>y_pred == class 0</code>, otherwise do nothing.</p>
<p>I have spent way too much time attempting to create this loss function as a result of tensorflow tensors being immutable. My first attempt (which I was led to through my experience with <code>numpy</code>)</p>
<pre><code>def weighted_categorical_crossentropy_ignore(weights):
    weights = K.variable(weights)

    def loss(y_true, y_pred):
        y_pred[tf.where(y_true == [1, 0, 0, 0, 0, 0])] = [1, 0, 0, 0, 0, 0]

        # Scale predictions so that the class probs of each sample sum to 1
        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)
        # Clip to prevent NaN's and Inf's
        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())
        loss = y_true * K.log(y_pred) * weights
        loss = -K.sum(loss, -1)
        return loss
    return loss
</code></pre>
<p>Though obviously I cannot alter <code>y_pred</code> so this attempt failed. I ended up creating a few monstrosities attempting to &quot;build&quot; a tensor by iterating over <code>[batch, row, col]</code> and performing comparisons. While this(ese) attempts did not technically fail, they never actually began training. I assume it was taking on the order of minutes to compute the loss.</p>
<hr />
<p>After many more failed efforts I started attempting to perform the requisite computation in pure <code>numpy</code> in a SSCCE. But keeping cognizant I was essentially limited to instantiating &quot;simple&quot; tensors (ie <code>ones</code>, <code>zeros</code>) and only performing &quot;simple&quot; operations like element-wise multiply, addition, and reshaping. Thus I arrived at this SSCCE</p>
<pre><code>import numpy as np
from tensorflow.keras.utils import to_categorical

# Generate the &quot;images&quot; at random
true_flat = np.argmax(np.random.rand(1, 2, 2, 4), axis=3).astype('int')
true = to_categorical(true_flat, num_classes=4).astype('int')

pred_flat = np.argmax(np.random.rand(1, 2, 2, 4), axis=3).astype('int')
pred = to_categorical(pred_flat, num_classes=4).astype('int')

print('True:\n', true_flat)
print('Pred:\n', pred_flat)

# Create a mask representing an all &quot;class 0&quot; image
class_zero_label = np.array([1, 0, 0, 0])
czl_all = class_zero_label * np.ones(true.shape).astype('int')

# Mask both the truth and pred to locate class 0 pixels
czl_true_locs = czl_all * true
czl_pred_locs = czl_all * pred

# Subtract to create &quot;addition&quot; matrix
a  = (czl_true_locs - czl_pred_locs) * czl_true_locs
print('a:\n', a)

# Do this
m = ((a + 1) - (a * 2))
print('m - ', m.shape, ':\n', m)

# Pull the front entry from 'm' and &quot;expand&quot; its value
#x = (m[:, :, :, 0].flatten() * np.ones(pred.shape).astype('int')).T.reshape(pred.shape)
m_front = m[:, :, :, 0]
print('m_front - ', m_front.shape, ':\n', m_front)

#m_flat = m_front.flatten()
m_flat = m_front.reshape(m_front.shape[0], m_front.shape[1]*m_front.shape[2])
print('m_flat - ', m_flat.shape, ':\n', m_flat)

m_expand = m_flat * np.ones(pred.shape).astype('int')
print('m_expand - ', m_expand.shape, ':\n', m_expand)

m_trans = m_expand.T
m_fixT = m_trans.reshape(pred.shape)
print('m_fixT - ', m_fixT.shape, ':\n', m_fixT)

m = m_fixT
print('m:\n', m.shape)

# Perform the math as described
pred = (pred * m) + a
print('Pred:\n', np.argmax(pred, axis=3))
</code></pre>
<p>This SSCCE, is well, terrible and complex. Essentially my goal here was to create two matrices, the &quot;addition&quot; and &quot;multiplication&quot; matrices. The multiplication matrix is meant to &quot;zero out&quot; every pixel in the predicted values where the truth value was equal to class 0. That is no matter the pixel value (ie a one-hot encoded vector) zero it out to be equal to <code>[0, 0, 0, 0, 0, 0]</code>. The addition matrix is then meant to add the vector <code>[1, 0, 0, 0, 0, 0]</code> to each of the zero'ed out locations. In the end this would achieve the goal of setting the predicted value of every truly class 0 pixel to correct.</p>
<p>The issue is that this SSCCE does not translate fully to tensorflow operations. The first issue is with the generation of the multiplication matrix, it is not defined correctly for when <code>batch_size &gt; 1</code>. I thought no matter, just to see if it work I will break down and <code>tf.unstack</code> the <code>y_true</code> and <code>y_pred</code> tensors and iteration over them. Which has led me to the current instantiation of my loss function</p>
<pre><code>def weighted_categorical_crossentropy_ignore(weights):
    weights = K.variable(weights)

    def loss(y_true, y_pred):

        y_true_un = tf.unstack(y_true)
        y_pred_un = tf.unstack(y_pred)

        y_pred_new = []
        for i in range(0, y_true.shape[0]):
            yt = y_true_un[i]
            yp = y_pred_un[i]

            # Pred:
            # [[[0 3] * [[[1 0] + [[[0 1] = [[[0 0]
            #  [3 1]]]   [[1 1]]]  [[0 0]]]  [[3 1]]]
            # If we multiple pred by a tensor which zeros out only incorrect class 0 labelleling
            # Then add class zero to those zero'd out locations
            # We can negate the effect of mis-classified class 0 pixels but still punish for
            # incorrectly predicted class 0 labels for other classes.

            # Create a mask respresenting an all &quot;class 0&quot; image
            class_zero_label = K.variable([1.0, 0.0, 0.0, 0.0, 0.0, 0.0])
            czl_all = class_zero_label * K.ones(yt.shape)

            # Mask both true and pred to locate class 0 pixels
            czl_true = czl_all * yt
            czl_pred = czl_all * yp

            # Subtract to create &quot;addition matrix&quot;
            a = czl_true - czl_pred

            # Do this.
            m = ((a + 1) - (a * 2.))

            # And this.
            x = K.flatten(m[:, :, 0])
            x = x * K.ones(yp.shape)
            x = K.transpose(x)
            x = K.reshape(x, yp.shape)

            # Voila.
            ypnew = (yp * x) + a

            y_pred_new.append(ypnew)

        y_pred_new = tf.concat(y_pred_new, 0)


        # Continue calculating weighted categorical crossentropy
        # -------------------------------------------------------

        # Scale predictions so that the class probs of each sample sum to 1
        y_pred_new /= K.sum(y_pred_new, axis=-1, keepdims=True)
        # Clip to prevent NaN's and Inf's
        y_pred_new = K.clip(y_pred_new, K.epsilon(), 1 - K.epsilon())
        loss = y_true * K.log(y_pred_new) * weights
        loss = -K.sum(loss, -1)
        return loss
    return loss
</code></pre>
<p>The current issue with this loss function lies in the apparent difference in the behavior between <code>numpy</code> and <code>tensorflow</code> when performing the operation</p>
<pre><code>x = K.flatten(m[:, :, 0])
x = x * K.ones(yp.shape)
</code></pre>
<p>Which is meant to represent the behavior</p>
<pre><code>m_flat = m_front.flatten()
m_expand = m_flat * np.ones(pred.shape).astype('int')
</code></pre>
<p>from the SSCCE.</p>
<hr />
<p>So at this point I feel like I have delved so far into caveman coding I can't get out of it. I have to image there is some simple way akin to my initial attempt to perform the described behavior.</p>
<p>So, I guess my direct question is <strong>How do I implement</strong></p>
<pre><code>y_pred[tf.where(y_true == [1, 0, 0, 0, 0, 0])] = [1, 0, 0, 0, 0, 0]
</code></pre>
<p><strong>in a custom tensorflow loss function?</strong></p>
<hr />
<p><strong>EDIT:</strong> After fumbling around quite a bit more I have finally determined how to call <code>.numpy()</code> on the <code>y_true</code>, <code>y_pred</code> tensors to utilize <code>numpy</code> operations (Apparently setting <code>tf.compat.v1.enable_eager_execution</code> at the start of the program &quot;doesn't work&quot;. I had to pass <code>run_eagerly=True</code> to <code>Model().compile(...)</code>).</p>
<p>This has allowed me to implement essentially the first attempt outlined</p>
<pre><code>def weighted_categorical_crossentropy_ignore(weights):
    weights = K.variable(weights)

    def loss(y_true, y_pred):
        yp = y_pred.numpy()
        yt = y_true.numpy()
        yp[np.nonzero(np.all(yt == [1, 0, 0, 0, 0, 0], axis=3))] = [1, 0, 0, 0, 0, 0]
 
        # Continue calculating weighted categorical crossentropy
        # -------------------------------------------------------
        # Scale predictions so that the class probs of each sample sum to 1
        yp /= K.sum(yp, axis=-1, keepdims=True)
        # Clip to prevent NaN's and Inf's
        yp = K.clip(yp, K.epsilon(), 1 - K.epsilon())
        loss = y_true * K.log(yp) * weights
        loss = -K.sum(loss, -1)
        return loss
    return loss
</code></pre>
<p>Though it seems by calling <code>y_pred.numpy()</code> (or the use of it thereafter) I have apparently &quot;destroyed&quot; the path/flow through the network. Based on the error when attempting to <code>.fit</code></p>
<pre><code>ValueError: No gradients provided for any variable: ['conv3d/kernel:0', &lt;....&gt;
</code></pre>
<p>I assume I somehow need to &quot;remarshall&quot; the tensor back to GPU memory? I have tried</p>
<pre><code>yp = tf.convert_to_tensor(yp)
</code></pre>
<p>to no avail; same error. So I guess the same question still lies, but from a different motivation..</p>
<hr />
<p><strong>EDIT2:</strong> Well it seems from this <a href=""https://stackoverflow.com/questions/63874265/keras-custom-loss-function-error-no-gradients-provided"">SO Answer</a> that I can't actually use <code>numpy()</code> to marshall the <code>y_true</code>, <code>y_pred</code> to use vanilla <code>numpy</code> operations. This necessarily &quot;destroys&quot; the network path and thus gradients cannot be calculated.</p>
<p>As I result I had realized with <code>run_eagerly=True</code> I can <code>tf.Variable</code> my <code>y_true</code>/<code>y_pred</code> and perform assignment. So in pure tensorflow I attempted to recreate the same code again</p>
<pre><code>def weighted_categorical_crossentropy_ignore(weights):
    weights = K.variable(weights)

    def loss(y_true, y_pred):
        # yp = y_pred.numpy().copy()
        # yt = y_true.numpy().copy()
        # yp[np.nonzero(np.all(yt == [1, 0, 0, 0, 0, 0], axis=3))] = [1, 0, 0, 0, 0, 0]

        yp = K.variable(y_pred)
        yt = K.variable(y_true)
        #np.all
        x = K.all(yt == [1, 0, 0, 0, 0, 0], axis=3)
        #np.nonzero
        ne = tf.not_equal(x, tf.constant(False))
        y = tf.where(ne)

        # Perform the desired operation
        yp[y] = [1, 0, 0, 0, 0, 0]

        # Continue calculating weighted categorical crossentropy
        # -------------------------------------------------------
        # Scale predictions so that the class probs of each sample sum to 1
        #yp /= K.sum(yp, axis=-1, keepdims=True) # Cannot use \= on tf.var, must use var = var /
        yp = yp / K.sum(yp, axis=-1, keepdims=True)
        # Clip to prevent NaN's and Inf's
        yp = K.clip(yp, K.epsilon(), 1 - K.epsilon())
        loss = y_true * K.log(yp) * weights
        loss = -K.sum(loss, -1)
        return loss
    return loss
</code></pre>
<p>But alas, this apparently creates the same issue as when calling <code>.numpy()</code>; no gradients can be computed. So I am again seemingly back at square 1.</p>
<hr />
<p><strong>EDIT3:</strong> Using the solution proposed <a href=""https://stackoverflow.com/a/66278947/2985796"">by gobrewers14 in the answer posted below</a> but modified based on my knowledge of the problem I have produced this loss function</p>
<pre><code>def weighted_categorical_crossentropy_ignore(weights):
    weights = K.variable(weights)

    def loss(y_true, y_pred):
        print('y_true.shape: ', y_true.shape)
        print('y_pred.shape: ', y_pred.shape)

        # Generate modified y_pred where all truly class0 pixels are correct
        y_true_class0_indicies = tf.where(tf.math.equal(y_true, [1., 0., 0., 0., 0., 0.]))
        y_pred_updates = tf.repeat([
            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
            repeats=y_true_class0_indicies.shape[0],
            axis=0)
        yp = tf.tensor_scatter_nd_update(y_pred, y_true_class0_indicies, y_pred_updates)

        # Continue calculating weighted categorical crossentropy
        # -------------------------------------------------------
        # Scale predictions so that the class probs of each sample sum to 1
        yp /= K.sum(yp, axis=-1, keepdims=True)
        # Clip to prevent NaN's and Inf's
        yp = K.clip(yp, K.epsilon(), 1 - K.epsilon())
        loss = y_true * K.log(yp) * weights
        loss = -K.sum(loss, -1)
        return loss
    return loss
</code></pre>
<p>Provided the original answer assumed <code>y_true</code> to be of shape <code>[8, 128, 128]</code> (ie a &quot;flat&quot; class representation, versus a one-hot encoded representation <code>[8, 128, 128, 6]</code>) I first print the shapes of the <code>y_true</code> and <code>y_pred</code> input tensors for sanity</p>
<pre><code>y_true.shape:  (8, 128, 128, 6)
y_pred.shape:  (8, 128, 128, 6)
</code></pre>
<p>For further sanity, the output shape of the network, provided by the tail of <code>model.summary</code> is</p>
<pre><code>conv2d_18 (Conv2D)              (None, 128, 128, 6)  1542        dropout_5[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 128, 128, 6)  0           conv2d_18[0][0]                  
==================================================================================================
Total params: 535,551,494
Trainable params: 535,529,478
Non-trainable params: 22,016
__________________________________________________________________________________________________
</code></pre>
<p>I then follow &quot;the pattern&quot; in the proposed solution and replace the original <code>tf.math.equal(y_true, 0)</code> with <code>tf.math.equal(y_true, [1., 0., 0., 0., 0., 0.])</code> to handle the one-hot encoded case. From my understanding of the proposed solution currently (after ~10min of inspecting it) I assumed this should work. Though when attempting to train a model the following exception is thrown</p>
<pre><code>InvalidArgumentError: Inner dimensions of output shape must match inner dimensions of updates shape. Output: [8,128,128,6] updates: [684584,6] [Op:TensorScatterUpdate]
</code></pre>
<p>Thus it seems as if the production of the (as I have named them) <code>y_pred_updates</code> produces a &quot;collapsed&quot; tensor with &quot;too many&quot; elements. I understand the motivation of the use of <code>tf.repeat</code> but its specific use seems to be incorrect. I assume it should produce a tensor with shape <code>(8, 128, 128, 6)</code> based on what I understand <code>tf.tensor_scatter_nd_update</code> to do. I assume this most likely is just based on the selection of the <code>repeats</code> and <code>axis</code> during the call to <code>tf.repeat</code>.</p>
",2985796.0,,2985796.0,,2021-02-19 16:57:59,2021-02-19 18:36:24,Keras custom loss function to ignore false negatives of a specific class during semantic segmentation?,<python><tensorflow><machine-learning><keras>,1,0,0.0,,,CC BY-SA 4.0
66057733,1,66060156.0,,2021-02-05 04:51:11,,7,6136,"<p>I'm trying to create variational autoencoder and that means I need custom loss function. The problem is that inside loss function I have 2 different losses - mse and divergence. And mse is Tensor and divergence is KerasTensor ( because of dispersion and mu, I get out from encoder ). And I get such errors:</p>
<blockquote>
<p>TypeError: Cannot convert a symbolic Keras input/output to a numpy
array. This error may indicate that you're trying to pass a symbolic
value to a NumPy call, which is not supported. Or, you may be trying
to pass Keras symbolic inputs/outputs to a TF API that does not
register dispatching, preventing Keras from automatically converting
the API call to a lambda layer in the Functional Model.</p>
</blockquote>
<p>So here is my architecture:</p>
<pre><code>import tensorflow.keras as keras
from keras.layers import Input, Dense, Flatten, Reshape
from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose
from keras.models import Model
import tensorflow as tf
import keras.backend as K


encoded_dim = 2

class Sampling(keras.layers.Layer):
    &quot;&quot;&quot;Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.&quot;&quot;&quot;

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = K.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon


img = Input((28,28,1), name='img')

x = Conv2D(32, (3,3), padding='same', activation='relu')(img)
x = MaxPooling2D()(x)
x = Conv2D(64, (3,3), padding='same', activation='relu')(x)
x = MaxPooling2D()(x)
x = Flatten()(x)
x = Dense(16, activation='relu')(x)
mu = Dense(encoded_dim, name='mu')(x)
sigma = Dense(encoded_dim, name='sigma')(x)
z = Sampling()([mu,sigma])
# print(mu)
xx = Input((encoded_dim,))

x = Dense(7*7*64, activation='relu')(xx)
x = Reshape((7,7,64))(x)

x = Conv2DTranspose(64, 3, activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;)(x)
x = Conv2DTranspose(32, 3, activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;)(x)

out = Conv2DTranspose(1, 3, activation=&quot;sigmoid&quot;, padding=&quot;same&quot;)(x)

encoder = Model(img,z, name='encoder')
decoder = Model(xx,out,name='decoder')

autoencoder = Model(img,decoder(encoder(img)),name='autoencoder')
</code></pre>
<p>And the loss function:</p>
<pre><code>def vae_loss(x, y):
    loss = tf.reduce_mean(K.square(x-y))
    kl_loss = -0.5 * tf.reduce_mean(1 + sigma - tf.square(mu) - tf.exp(sigma))
    print(type(loss))
    print(type(kl_loss))
    return loss + kl_loss

autoencoder.compile(optimizer='adam',
                    loss = vae_loss)

autoencoder.fit(train,train,
                epochs=1,
                batch_size=60,
                shuffle=True,
                verbose = 2)
</code></pre>
<p>Types of loss and lk_loss:</p>
<blockquote>
<p>class 'tensorflow.python.framework.ops.Tensor'</p>
<p>class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'</p>
</blockquote>
",13781254.0,,,,,2021-02-05 08:51:25,How to deal with KerasTensor and Tensor?,<python><tensorflow><keras><deep-learning><autoencoder>,1,0,,,,CC BY-SA 4.0
67806604,1,67816434.0,,2021-06-02 13:57:41,,7,1575,"<p>As the title clearly describes the issue I've been experiencing, no <code>Pipfile.lock</code> is being generated as I get the following error when I execute the recommended command <code>pipenv lock --clear</code>:</p>
<pre><code>ERROR: ERROR: Could not find a version that matches keras-nightly~=2.5.0.dev
Skipped pre-versions: 2.5.0.dev2021020510, 2.5.0.dev2021020600, 2.5.0.dev2021020700, 2.5.0.dev2021020800, 2.5.0.dev2021020900, 2.5.0.dev2021021000, 2.5.0.dev2021021100, 2.5.0.dev2021021200, 2.5.0.dev2021021300, 2.5.0.dev2021021400, 2.5.0.dev2021021500, 2.5.0.dev2021021600, 2.5.0.dev2021021700, 2.5.0.dev2021021800, 2.5.0.dev2021021900, 2.5.0.dev2021022000, 2.5.0.dev2021022100, 2.5.0.dev2021022200, 2.5.0.dev2021022300, 2.5.0.dev2021022317, 2.5.0.dev2021022400, 2.5.0.dev2021022411, 2.5.0.dev2021022500, 2.5.0.dev2021022600, 2.5.0.dev2021022700, 2.5.0.dev2021022800, 2.5.0.dev2021030100, 2.5.0.dev2021030200, 2.5.0.dev2021030300, 2.5.0.dev2021030400, 2.5.0.dev2021030500, 2.5.0.dev2021030600, 2.5.0.dev2021030700, 2.5.0.dev2021030800, 2.5.0.dev2021030900, 2.5.0.dev2021031000, 2.5.0.dev2021031100, 2.5.0.dev2021031200, 2.5.0.dev2021031300, 2.5.0.dev2021031400, 2.5.0.dev2021031500, 2.5.0.dev2021031600, 2.5.0.dev2021031700, 2.5.0.dev2021031800, 2.5.0.dev2021032213, 2.5.0.dev2021032300, 2.5.0.dev2021032413, 2.5.0.dev2021032500, 2.5.0.dev2021032600, 2.5.0.dev2021032610, 2.5.0.dev2021032700, 2.5.0.dev2021032800, 2.5.0.dev2021032900, 2.6.0.dev2021033000, 2.6.0.dev2021033100, 2.6.0.dev2021040100, 2.6.0.dev2021040200, 2.6.0.dev2021040300, 2.6.0.dev2021040400, 2.6.0.dev2021040500, 2.6.0.dev2021040600, 2.6.0.dev2021040714, 2.6.0.dev2021040800, 2.6.0.dev2021040900, 2.6.0.dev2021041000, 2.6.0.dev2021041100, 2.6.0.dev2021041200, 2.6.0.dev2021041300, 2.6.0.dev2021041400, 2.6.0.dev2021041500, 2.6.0.dev2021041600, 2.6.0.dev2021041700, 2.6.0.dev2021041800, 2.6.0.dev2021041900, 2.6.0.dev2021042000, 2.6.0.dev2021042100, 2.6.0.dev2021042200, 2.6.0.dev2021042300, 2.6.0.dev2021042500, 2.6.0.dev2021042600, 2.6.0.dev2021042700, 2.6.0.dev2021042800, 2.6.0.dev2021042900, 2.6.0.dev2021043000, 2.6.0.dev2021050100, 2.6.0.dev2021050200, 2.6.0.dev2021050300, 2.6.0.dev2021050400, 2.6.0.dev2021050500, 2.6.0.dev2021050600, 2.6.0.dev2021051200, 2.6.0.dev2021051300, 2.6.0.dev2021051400, 2.6.0.dev2021051500, 2.6.0.dev2021051600, 2.6.0.dev2021051700, 2.6.0.dev2021051800, 2.6.0.dev2021051900, 2.6.0.dev2021052000, 2.6.0.dev2021052100, 2.6.0.dev2021052200, 2.6.0.dev2021052300, 2.6.0.dev2021052400, 2.6.0.dev2021052500, 2.6.0.dev2021052600, 2.6.0.dev2021052700
There are incompatible versions in the resolved dependencies.
</code></pre>
<p>So, how can I overcome this situation? I'm basically developing a deep neural network using <code>Keras</code>. I simply installed the following dependencies without explicitly declaring versions:</p>
<pre><code>tensorflow = &quot;*&quot;
nltk = &quot;*&quot;
pandas = &quot;*&quot;
tweepy = &quot;*&quot;
textblob = &quot;*&quot;
seaborn = &quot;*&quot;
matplotlib = &quot;*&quot;
wordcloud = &quot;*&quot;
stop-words = &quot;*&quot;
vadersentiment = &quot;*&quot;
scikit-learn = &quot;*&quot;
keras = &quot;*&quot;
</code></pre>
",282855.0,,,,,2021-11-02 15:41:33,pipenv - Pipfile.lock is not being generated due to the 'Could not find a version that matches keras-nightly~=2.5.0.dev' error,<tensorflow><keras><pip><tf.keras><pipenv>,6,5,0.0,,,CC BY-SA 4.0
63564017,1,63636446.0,,2020-08-24 15:26:18,,7,1537,"<p>Here is the code I tried:</p>
<pre><code># normalizing the train data
cols_to_norm = [&quot;WORK_EDUCATION&quot;, &quot;SHOP&quot;, &quot;OTHER&quot;,'AM','PM','MIDDAY','NIGHT', 'AVG_VEH_CNT', 'work_traveltime', 'shop_traveltime','work_tripmile','shop_tripmile', 'TRPMILES_sum',
                'TRVL_MIN_sum', 'TRPMILES_mean', 'HBO', 'HBSHOP', 'HBW', 'NHB', 'DWELTIME_mean','TRVL_MIN_mean', 'work_dweltime', 'shop_dweltime', 'firsttrip_time', 'lasttrip_time']
dataframe[cols_to_norm] = dataframe[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max()-x.min()))
# labels    
y = dataframe.R_SEX.values
</code></pre>
<hr />
<pre><code># splitting train and test set
X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.33, random_state=42)

model = Sequential()
model.add(Dense(256, input_shape=(X_train.shape[1],), activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(Dense(256, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam' , metrics=['acc'])
print(model.summary())

model.fit(X_train, y_train , batch_size=128, epochs=30, validation_split=0.2)
</code></pre>
<hr />
<pre><code>Epoch 23/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6623 - acc: 0.5985 - val_loss: 0.6677 - val_acc: 0.5918
Epoch 24/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6618 - acc: 0.5993 - val_loss: 0.6671 - val_acc: 0.5925
Epoch 25/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6618 - acc: 0.5997 - val_loss: 0.6674 - val_acc: 0.5904
Epoch 26/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6614 - acc: 0.6001 - val_loss: 0.6669 - val_acc: 0.5911
Epoch 27/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6608 - acc: 0.6004 - val_loss: 0.6668 - val_acc: 0.5920
Epoch 28/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6605 - acc: 0.6002 - val_loss: 0.6679 - val_acc: 0.5895
Epoch 29/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6602 - acc: 0.6009 - val_loss: 0.6663 - val_acc: 0.5932
Epoch 30/30
1014/1014 [==============================] - 4s 4ms/step - loss: 0.6597 - acc: 0.6027 - val_loss: 0.6674 - val_acc: 0.5910
&lt;tensorflow.python.keras.callbacks.History at 0x7fdd8143a278&gt;
</code></pre>
<p>I have tried modifying the neural network and double-cheking the data.</p>
<p>Is there anything I can do to improve the outcome? Is the model not deep enough? Is there any alternative models suited for my data? Does this mean these features have no predictive value? I'm kind of confused what to do next.</p>
<p>thank you</p>
<p><strong>Update:</strong></p>
<p>I tried adding new column do my dataframe which is the outcome of a KNN model for sex classification. Here is what I did:</p>
<pre><code>#Import knearest neighbors Classifier model
from sklearn.neighbors import KNeighborsClassifier

#Create KNN Classifier
knn = KNeighborsClassifier(n_neighbors=41)

#Train the model using the training sets
knn.fit(X, y)

#predict sex for the train set so that it can be fed to the nueral net
y_pred = knn.predict(X)

#add the outcome of knn to the train set
X = X.assign(KNN_result=y_pred)
</code></pre>
<p>It improved the training and validation accuracy up to 61 percent.</p>
<pre><code>Epoch 26/30
1294/1294 [==============================] - 8s 6ms/step - loss: 0.6525 - acc: 0.6166 - val_loss: 0.6604 - val_acc: 0.6095
Epoch 27/30
1294/1294 [==============================] - 8s 6ms/step - loss: 0.6523 - acc: 0.6173 - val_loss: 0.6596 - val_acc: 0.6111
Epoch 28/30
1294/1294 [==============================] - 8s 6ms/step - loss: 0.6519 - acc: 0.6177 - val_loss: 0.6614 - val_acc: 0.6101
Epoch 29/30
1294/1294 [==============================] - 8s 6ms/step - loss: 0.6512 - acc: 0.6178 - val_loss: 0.6594 - val_acc: 0.6131
Epoch 30/30
1294/1294 [==============================] - 8s 6ms/step - loss: 0.6510 - acc: 0.6183 - val_loss: 0.6603 - val_acc: 0.6103
&lt;tensorflow.python.keras.callbacks.History at 0x7fe981bbe438&gt;
</code></pre>
<p>Thank you</p>
",13505957.0,,13505957.0,,2020-09-15 14:21:26,2020-09-15 14:21:26,keras accuracy doesn't improve more than 59 percent,<python><tensorflow><keras>,4,14,0.0,,,CC BY-SA 4.0
73134521,1,73134765.0,,2022-07-27 08:23:24,,7,229,"<p>I'm playing around with tensorflow to become a bit more familiar with the overall workflow. To do this I thought I should start with creating a simple classifier for the well known Iris dataset.</p>
<p>I load the dataset using:</p>
<pre><code>ds = tfds.load('iris', split='train', shuffle_files=True, as_supervised=True)
</code></pre>
<p>I use the following classifier:</p>
<pre class=""lang-py prettyprint-override""><code>model = keras.Sequential([
    keras.layers.Dense(10,activation=&quot;relu&quot;),
    keras.layers.Dense(10,activation=&quot;relu&quot;),
    keras.layers.Dense(3, activation=&quot;softmax&quot;)
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
)
</code></pre>
<p>I then try to fit the model using:</p>
<pre class=""lang-py prettyprint-override""><code>model.fit(ds,batch_size=50, epochs=100)
</code></pre>
<p>This gives the following error:</p>
<pre><code>Input 0 of layer &quot;dense&quot; is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (4,)

    Call arguments received by layer &quot;sequential&quot; (type Sequential):
      • inputs=tf.Tensor(shape=(4,), dtype=float32)
      • training=True
      • mask=None
</code></pre>
<p>I also tried defining the model using the functional API(as this was my orignal goal to learn)</p>
<pre class=""lang-py prettyprint-override""><code>inputs = keras.Input(shape=(4,), name='features')

first_hidden = keras.layers.Dense(10, activation='relu')(inputs)
second_hidden = keras.layers.Dense(10, activation=&quot;relu&quot;)(first_hidden)

outputs = keras.layers.Dense(3, activation='softmax')(second_hidden)

model = keras.Model(inputs=inputs, outputs=outputs, name=&quot;test_iris_classification&quot;)
</code></pre>
<p>I now get the same error as before but this time with a warning:</p>
<pre><code>WARNING:tensorflow:Model was constructed with shape (None, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='features'), name='features', description=&quot;created by layer 'features'&quot;), but it was called on an input with incompatible shape (4,).
</code></pre>
<p>I suspect this is something quite fundamental that haven't understood but I have not been able to figure it out, despite several hours of googling.</p>
<p>PS:
I also tried to download the whole dataset from the <a href=""https://archive.ics.uci.edu/ml/datasets/iris"" rel=""noreferrer"">UCI Machine Learning Repository</a> as a CSV file.</p>
<p>I read it in like this:</p>
<pre><code>ds = pd.read_csv(&quot;iris.data&quot;, header=None)
labels = []
for name in ds[4]:
    if name == &quot;Iris-setosa&quot;:
        labels.append(0)
    elif name == &quot;Iris-versicolor&quot;:
        labels.append(1)
    elif name == &quot;Iris-virginica&quot;:
        labels.append(2)
    else:
        raise ValueError(f&quot;Name wrong name: {name}&quot;)
labels = np.array(labels)
features = np.array(ds[[0,1,2,3]])
</code></pre>
<p>And fit it like this:</p>
<pre><code>model.fit(features, labels,batch_size=50, epochs=100)
</code></pre>
<p>And I'm able to fit the model to this dataset without any problems for both the sequential and the functional API. Which makes me suspect my misunderstanding has something to do with how the tensorflow_datasets works.</p>
",16244168.0,,16244168.0,,2022-07-27 08:29:20,2022-07-27 08:39:30,How to train on a tensorflow_datasets dataset,<python><tensorflow><machine-learning><keras><tensorflow-datasets>,1,0,,,,CC BY-SA 4.0
63464944,1,63468726.0,,2020-08-18 08:42:29,,7,1500,"<p>I am using keras with a custom loss function like below:</p>
<pre><code>def custom_fn(y_true, y_pred):
   # changing y_true, y_pred values systematically
   return mean_absolute_percentage_error(y_true, y_pred)
   
</code></pre>
<p>Then I am calling <code>model.compile(loss=custom_fn)</code> and <code>model.fit(X, y,..validation_data=(X_val, y_val)..)</code></p>
<p>Keras is then saving <code>loss</code> and <code>val_loss</code> in model history. As a sanity check, when the model finishes training, I am using <code>model.predict(X_val)</code> so I can calculate validation loss manually with my <code>custom_fn</code> using the trained model.</p>
<p>I am saving the model with the best epoch using this callback:</p>
<pre><code>callbacks.append(ModelCheckpoint(path, save_best_only=True, monitor='val_loss', mode='min'))
</code></pre>
<p>so after calculating this, the validation loss should match keras' <code>val_loss</code> value of the best epoch. But this is not happening.</p>
<p>As another attempt to figure this issue out, I am also doing this:</p>
<pre><code>    model.compile(loss=custom_fn, metrics=[custom_fn])
</code></pre>
<p><strong>And to my surprise, <code>val_loss</code> and <code>val_custom_fn</code> do not match (neither <code>loss</code> or <code>loss_custom_fn</code> for that matter).</strong></p>
<p>This is really strange, my <code>custom_fn</code> is essentially keras' built in <code>mape</code> with the <code>y_true</code> and <code>y_pred</code> slightly manipulated. what is going on here?</p>
<p><strong>PS</strong>: the layers I am using are <code>LSTM</code> layers and a final <code>Dense</code> layer. But I think this information is not relevant to the problem. I am also using regularisation as hyperparameter but not dropout.</p>
<h2>Update</h2>
<p>Even removing <code>custom_fn</code> and using keras' built in <code>mape</code> as a loss function and metric like so:</p>
<pre><code>model.compile(loss='mape', metrics=['mape'])
</code></pre>
<p>and for simplicity, removing <code>ModelCheckpoint</code> callback is having the same effect; <strong><code>val_loss</code> and <code>val_mape</code> for each epoch are not equivalent</strong>. This is extremely strange to me. I am either missing something or there is a bug in Keras code..the former might be more realistic.</p>
",7331538.0,,7331538.0,,2020-08-21 21:41:44,2020-08-21 21:41:44,Keras loss and metrics values do not match with same function in each,<python><tensorflow><keras><deep-learning>,1,2,0.0,,,CC BY-SA 4.0
63094847,1,63169463.0,,2020-07-26 00:13:26,,7,1211,"<p>I'm using sklearn pipelines to build a Keras autoencoder model and use gridsearch to find the best hyperparameters. This works fine if I use a Multilayer Perceptron model for classification; however, in the autoencoder I need the output values to be the same as input. In other words, I am using a <code>StandardScalar</code> instance in the pipeline to scale the input values and therefore this leads to my question: how can I make the <code>StandardScalar</code> instance inside the pipeline to work on both the input data as well as target data, so that they end up to be the same?</p>
<p>I'm providing a code snippet as an example.</p>
<pre><code>from sklearn.datasets import make_classification
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV, KFold
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop, Adam
from tensorflow.keras.wrappers.scikit_learn import KerasRegressor

X, y = make_classification (n_features = 50, n_redundant = 0, random_state = 0,
                            scale = 100, n_clusters_per_class = 1)

# Define wrapper
def create_model (learn_rate = 0.01, input_shape, metrics = ['mse']):
  model = Sequential ()
  model.add (Dense (units = 64, activation = 'relu',
                   input_shape = (input_shape, )))
  model.add (Dense (32, activation = 'relu'))
  model.add (Dense (8,  activation = 'relu'))
  model.add (Dense (32, activation = 'relu'))
  model.add (Dense (input_shape, activation = None))
  model.compile (loss = 'mean_squared_error',
                 optimizer = Adam (lr = learn_rate),
                 metrics = metrics)
  return model

# Create scaler
my_scaler = StandardScaler ()
steps = list ()
steps.append (('scaler', my_scaler))
standard_scaler_transformer = Pipeline (steps)

# Create classifier
clf = KerasRegressor (build_fn = create_model, verbose = 2)

# Assemble pipeline
# How to scale input and output??
clf = Pipeline (steps = [('scaler', my_scaler),
                         ('classifier', clf)],
                verbose = True)

# Run grid search
param_grid = {'classifier__input_shape' : [X.shape [1]],
              'classifier__batch_size' : [50],
              'classifier__learn_rate' : [0.001],
              'classifier__epochs' : [5, 10]}
cv = KFold (n_splits = 5, shuffle = False)
grid = GridSearchCV (estimator = clf, param_grid = param_grid,
                     scoring = 'neg_mean_squared_error', verbose = 1, cv = cv)
grid_result = grid.fit (X, X)

print ('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_))

</code></pre>
",10475607.0,,2099607.0,,2020-07-30 08:54:28,2020-07-30 08:58:11,How to scale target values of a Keras autoencoder model using a sklearn pipeline?,<python><tensorflow><machine-learning><keras><scikit-learn>,1,0,0.0,,,CC BY-SA 4.0
66192675,1,66230302.0,,2021-02-14 05:18:27,,7,470,"<p>I'm tried to implement basic GAN in Keras, based on <a href=""https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py"" rel=""noreferrer"">this</a> implementation.</p>
<p>If I sample points on parabola GAN is converges and able to produce samples from this distribution, but if for example I sample points on circle it fails. I wonder why it's hard for GAN? How it can be fixed?</p>
<p>Here is learning process for parabola:
<a href=""https://i.stack.imgur.com/Uwjiv.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Uwjiv.gif"" alt=""enter image description here"" /></a></p>
<p>Here is learning process for circle:
<a href=""https://i.stack.imgur.com/lQJVd.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/lQJVd.gif"" alt=""enter image description here"" /></a></p>
<p>Here is the code to reproduce:</p>
<pre><code>from __future__ import print_function, division

import warnings
warnings.filterwarnings('ignore')

import os
import shutil
from datetime import datetime

from keras.layers import Input, Dense
from keras.layers.advanced_activations import LeakyReLU
from keras.models import Sequential, Model
from keras.optimizers import Adam

from sklearn import datasets
import numpy as np
import tensorflow as tf
from tqdm import tqdm
import matplotlib.pyplot as plt
import cv2

# Derived from original code https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py

def print_env_info():
    print('-' * 60)
    import keras
    print('keras.__version__', keras.__version__)
    print('-' * 60)
    import tensorflow as tf
    print('tf.__version__', tf.__version__)
    print('-' * 60)

class GAN():
    def __init__(self):
        self.latent_dim = 128

        optimizer = Adam(0.0002, 0.5)

        # Build and compile the discriminator
        self.discriminator = self.build_discriminator()
        self.discriminator.compile(loss='binary_crossentropy',
            optimizer=optimizer,
            metrics=['accuracy'])

        # Build the generator
        self.generator = self.build_generator()

        # The generator takes noise as input and generates imgs
        z = Input(shape=(self.latent_dim,))
        img = self.generator(z)

        # For the combined model we will only train the generator
        self.discriminator.trainable = False

        # The discriminator takes generated images as input and determines validity
        validity = self.discriminator(img)

        # The combined model  (stacked generator and discriminator)
        # Trains the generator to fool the discriminator
        self.combined = Model(z, validity)
        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)

        # Tensorboard writer
        log_dir = &quot;logs/&quot; + datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;)
        self.writer = tf.summary.FileWriter(log_dir)

    def build_generator(self):

        model = Sequential()

        model.add(Dense(64, input_dim=self.latent_dim))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dense(128, input_dim=2))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dense(2, activation='tanh'))

        model.summary()

        noise = Input(shape=(self.latent_dim,))
        img = model(noise)

        return Model(noise, img)

    def build_discriminator(self):

        model = Sequential()

        model.add(Dense(64, input_dim=2))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dense(128, input_dim=2))
        model.add(LeakyReLU(alpha=0.2))
        model.add(Dense(1, activation='sigmoid'))
        model.summary()

        img = Input(shape=(2, ))
        validity = model(img)

        return Model(img, validity)

    def generate_dataset(self, n_samples=10000):
        # # V1: y = x^2
        x = np.random.uniform(-1, 1, size=n_samples)
        y = x ** 2
        data = np.stack([x, y], axis=1)

        # V2: x ^ 2 + y ^ 2 = 1
        # angle = np.random.uniform(0, 1, size=n_samples) * (np.pi * 2)
        # x = np.cos(angle)
        # y = np.sin(angle)
        # data = np.stack([x, y], axis=1)

        # V3: swiss roll
        # data, _ = datasets.make_swiss_roll(n_samples=n_samples, noise=0.0, random_state=0)
        # data = np.stack([data[:, 0], data[:, 2]], axis=1)
        # data = data - np.min(data, axis=0)
        # data = data / np.max(data, axis=0)
        # data = 2 * data - 1.0

        # # V4:
        # data, _ = datasets.make_moons(n_samples=n_samples, shuffle=False, noise=None, random_state=0)
        # data = data - np.min(data, axis=0)
        # data = data / np.max(data, axis=0)
        # data = 2 * data - 1.0

        return data

    def summary_image(self, tensor):
        import io
        from PIL import Image

        tensor = tensor.astype(np.uint8)

        height, width, channel = tensor.shape
        image = Image.fromarray(tensor)
        output = io.BytesIO()
        image.save(output, format='PNG')
        image_string = output.getvalue()
        output.close()
        return tf.Summary.Image(height=height,
                                width=width,
                                colorspace=channel,
                                encoded_image_string=image_string)

    def get_visualization(self, epoch):
        def generate_fake_data(n_samples):
            noise = np.random.normal(0, 1, (n_samples, self.latent_dim))
            X_hat = self.generator.predict(noise)
            x = X_hat[:, 0]
            y = X_hat[:, 1]
            return x, y

        def save_figure():
            x_fake, y_fake = generate_fake_data(n_samples=100)
            data = self.generate_dataset(n_samples=1000)
            x_real, y_real = data[:, 0], data[:, 1]

            axes = plt.gca()
            axes.set_xlim([-1, 1])
            axes.set_ylim([-1, 1])
            axes.set_aspect('equal', 'datalim')
            plt.scatter(x_real, y_real, s=1, color='b', alpha=0.2)
            plt.scatter(x_fake, y_fake, s=1, color='r')
            plt.savefig(f'images/{epoch}.png')
            plt.close()

        save_figure()

        image = cv2.imread(f'images/{epoch}.png')
        image = self.summary_image(image)

        return image


    def train(self, epochs, batch_size, sample_interval):
        # Load the dataset
        X_train = self.generate_dataset()

        print('X_train.shape', X_train.shape)

        # Adversarial ground truths
        valid = np.ones((batch_size, 1))
        fake = np.zeros((batch_size, 1))

        for epoch in tqdm(range(epochs), total=epochs):
            # ---------------------
            #  Train Discriminator
            # ---------------------

            # Select a random batch of images
            idx = np.random.randint(0, X_train.shape[0], batch_size)
            imgs = X_train[idx]

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Generate a batch of new images
            gen_imgs = self.generator.predict(noise)

            # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch(imgs, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ---------------------
            #  Train Generator
            # ---------------------

            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

            # Train the generator (to have the discriminator label samples as valid)
            g_loss = self.combined.train_on_batch(noise, valid)

            # Print the progress
            # print (&quot;%d [D loss: %f, acc.: %.2f%%] [G loss: %f]&quot; % (epoch, d_loss[0], 100*d_loss[1], g_loss))

            if epoch % sample_interval == 0:
                image_summary = tf.Summary(value=[tf.Summary.Value(tag='fake', image=self.get_visualization(epoch))])
                self.writer.add_summary(image_summary, epoch)

            if epoch % sample_interval == 0:
                summary = tf.Summary(value=[
                    tf.Summary.Value(tag=&quot;loss/D_loss&quot;, simple_value=d_loss[0]),
                ])
                self.writer.add_summary(summary, epoch)

                summary = tf.Summary(value=[
                    tf.Summary.Value(tag=&quot;D_loss/D_loss_real&quot;, simple_value=d_loss_real[0]),
                ])
                self.writer.add_summary(summary, epoch)

                summary = tf.Summary(value=[
                    tf.Summary.Value(tag=&quot;D_loss/D_loss_fake&quot;, simple_value=d_loss_fake[0]),
                ])
                self.writer.add_summary(summary, epoch)

                summary = tf.Summary(value=[
                    tf.Summary.Value(tag=&quot;loss/Acc&quot;, simple_value=100*d_loss[1]),
                ])
                self.writer.add_summary(summary, epoch)

                summary = tf.Summary(value=[
                    tf.Summary.Value(tag=&quot;D_loss/Acc_real&quot;, simple_value=100*d_loss_real[1]),
                ])
                self.writer.add_summary(summary, epoch)

                summary = tf.Summary(value=[
                    tf.Summary.Value(tag=&quot;D_loss/Acc_fake&quot;, simple_value=100*d_loss_fake[1]),
                ])
                self.writer.add_summary(summary, epoch)

                summary = tf.Summary(value=[
                    tf.Summary.Value(tag=&quot;loss/G_loss&quot;, simple_value=g_loss),
                ])
                self.writer.add_summary(summary, epoch)


if __name__ == '__main__':
    print_env_info()

    if os.path.exists('logs'):
        shutil.rmtree('logs')

    if os.path.exists('images'):
        shutil.rmtree('images')
    os.makedirs('images')

    gan = GAN()
    gan.train(epochs=10000, batch_size=32, sample_interval=200)
</code></pre>
",1179925.0,,,,,2021-02-21 11:39:43,Why GAN is unable to generate samples from some distributions?,<python><keras><deep-learning><generative-adversarial-network>,1,1,0.0,,,CC BY-SA 4.0
66178738,1,66178856.0,,2021-02-12 20:41:08,,7,24129,"<p>I am using Keras to implement a neural network. But when I use <code>model = Sequential()</code>, I get the following error:</p>
<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-31-fa9fd3b0e211&gt; in &lt;module&gt;
      8 
      9 # Create the model
---&gt; 10 model = Sequential()
     11 model.add(Dropout(0.1), input_shape=(128,))
     12 model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/version_utils.py in __new__(cls, *args, **kwargs)
     55     use_v2 = should_use_v2()
     56     cls = swap_class(cls, training.Model, training_v1.Model, use_v2)  # pylint: disable=self-cls-assignment
---&gt; 57     return super(ModelVersionSelector, cls).__new__(cls)
     58 
     59 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/lazy_loader.py in __getattr__(self, item)
     60 
     61   def __getattr__(self, item):
---&gt; 62     module = self._load()
     63     return getattr(module, item)
     64 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/lazy_loader.py in _load(self)
     43     &quot;&quot;&quot;Load the module and insert it into the parent's globals.&quot;&quot;&quot;
     44     # Import the target module and insert it into the parent's namespace
---&gt; 45     module = importlib.import_module(self.__name__)
     46     self._parent_module_globals[self._local_name] = module
     47 

/usr/lib/python3.6/importlib/__init__.py in import_module(name, package)
    124                 break
    125             level += 1
--&gt; 126     return _bootstrap._gcd_import(name[level:], package, level)
    127 
    128 

/usr/lib/python3.6/importlib/_bootstrap.py in _gcd_import(name, package, level)

/usr/lib/python3.6/importlib/_bootstrap.py in _find_and_load(name, import_)

/usr/lib/python3.6/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

/usr/lib/python3.6/importlib/_bootstrap.py in _load_unlocked(spec)

/usr/lib/python3.6/importlib/_bootstrap_external.py in exec_module(self, module)

/usr/lib/python3.6/importlib/_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py in &lt;module&gt;
     48 from tensorflow.python.keras.engine import input_spec
     49 from tensorflow.python.keras.mixed_precision import autocast_variable
---&gt; 50 from tensorflow.python.keras.mixed_precision import loss_scale_optimizer
     51 from tensorflow.python.keras.mixed_precision import policy
     52 from tensorflow.python.keras.saving.saved_model import layer_serialization

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py in &lt;module&gt;
   1152 
   1153 # pylint: disable=protected-access
-&gt; 1154 mixed_precision._register_wrapper_optimizer_cls(optimizer_v2.OptimizerV2,
   1155                                                 LossScaleOptimizerV1)
   1156 

AttributeError: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'
</code></pre>
<p>I am relatively new to deep learning. Any help would be appreciated. Thank you!</p>
",10144339.0,,,,,2022-11-01 04:22:03,AttributeError: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls',<python><python-3.x><keras><deep-learning><tensorflow2.0>,6,0,,,,CC BY-SA 4.0
67908331,1,,,2021-06-09 16:38:57,,7,7216,"<p>In the below code, I am comparing the <strong><code>Predicted Output</code></strong> of the <strong><code>TF Keras Model</code></strong> with the respective value which is <strong><code>calculated Manually</code></strong> (<strong><code>Softmax Activation</code></strong> implemented using <strong><code>Numpy</code></strong>).</p>
<p>Surprisingly, they are not same. Am I missing something?</p>
<p>Also, there is a Warning,</p>
<blockquote>
<p>UserWarning: &quot;<code>sparse_categorical_crossentropy</code> received
<code>from_logits=True</code>, but the <code>output</code> argument was produced by a
sigmoid or softmax activation and thus does not represent logits. Was
this intended?&quot;   '&quot;<code>sparse_categorical_crossentropy</code> received
<code>from_logits=True</code>, but '</p>
</blockquote>
<p>What does that warning mean? And is that warning the reason for the mismatch?</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import numpy as np


inputs = tf.keras.Input(shape=(784,), name=&quot;digits&quot;)
x1 = tf.keras.layers.Dense(64, activation=&quot;relu&quot;)(inputs)
x2 = tf.keras.layers.Dense(64, activation=&quot;relu&quot;)(x1)
outputs = tf.keras.layers.Dense(10, name=&quot;predictions&quot;, activation = 'softmax')(x2)
model = tf.keras.Model(inputs=inputs, outputs=outputs)


# Instantiate an optimizer.
optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)
# Instantiate a loss function.
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

# Prepare the training dataset.
batch_size = 64
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = np.reshape(x_train, (-1, 784))
x_test = np.reshape(x_test, (-1, 784))

# Normalize the values of Pixels of Image. Else, Calculation of Softmax results in NaN
x_train = x_train/255.0
x_test = x_test/255.0

# Reserve 10,000 samples for validation.
x_val = x_train[-10000:]
y_val = y_train[-10000:]
x_train = x_train[:-10000]
y_train = y_train[:-10000]

# Prepare the training dataset.
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)

# Prepare the validation dataset.
val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_dataset = val_dataset.batch(batch_size)

epochs = 2
for epoch in range(epochs):
    print(&quot;\nStart of epoch %d&quot; % (epoch,))

    # Iterate over the batches of the dataset.
    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
        
        x_batch_train = tf.cast(x_batch_train, tf.float32)               
        
        with tf.GradientTape() as tape:
            logits = model(x_batch_train, training=True)  # Logits for this minibatch

            # Compute the loss value for this minibatch.
            loss_value = loss_fn(y_batch_train, logits)
        
        grads = tape.gradient(loss_value, model.trainable_weights)
        
        Initial_Weights_1st_Hidden_Layer = model.trainable_weights[0]
        
        Initial_Weights_2nd_Hidden_Layer = model.trainable_weights[2]
        
        Initial_Weights_Output_Layer = model.trainable_weights[4]
                
        Initial_Bias_1st_Hidden_Layer = model.trainable_weights[1]
        
        Initial_Bias_2nd_Hidden_Layer = model.trainable_weights[3]
        
        Initial_Bias_Output_Layer = model.trainable_weights[5]
        
        # Implementing Relu Activation Function using Numpy
        def Relu_Activation(Input):
            return np.maximum(Input, 0)
        
        #Compute Softmax Activation Function using Numpy
        def Softmax_Activation(Input):
            return np.exp(Input) / np.sum(np.exp(Input), axis=0)
        
        # Calculations
        Input_to_1st_Hidden_Layer = x_batch_train @ Initial_Weights_1st_Hidden_Layer + \
                                                                        Initial_Bias_1st_Hidden_Layer
                     
        Output_Of_1st_Hidden_Layer = Relu_Activation(Input_to_1st_Hidden_Layer)
        
        Input_to_2nd_Hidden_Layer = Output_Of_1st_Hidden_Layer @ Initial_Weights_2nd_Hidden_Layer + \
                                                                        Initial_Bias_2nd_Hidden_Layer
                   
        Output_Of_2nd_Hidden_Layer = Relu_Activation(Input_to_2nd_Hidden_Layer)
      
        Input_to_Final_Layer = Output_Of_2nd_Hidden_Layer @ Initial_Weights_Output_Layer + \
                                                                        Initial_Bias_Output_Layer
        
        # Softmax Activation Function has been used in the Output/Final Layer
        Calculated_Y_Pred = Softmax_Activation(Input_to_Final_Layer)

        # Log every 200 batches.
        if step == 200:
            print('\n Y_Pred = ', logits[0:2])
            print('\n Calculated_Y_Pred = ', Calculated_Y_Pred[0:2])
</code></pre>
<p>The output of the above code is shown below:</p>
<pre class=""lang-py prettyprint-override""><code>Start of epoch 0
/home/mothukuru/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4930: UserWarning: &quot;`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?&quot;
  '&quot;`sparse_categorical_crossentropy` received `from_logits=True`, but '

 Y_Pred =  tf.Tensor(
[[0.07784345 0.13746074 0.09005958 0.08652461 0.07746054 0.12440132
  0.10698392 0.07508533 0.07116801 0.15301245]
 [0.0656803  0.08119027 0.09362638 0.10353054 0.12599334 0.10456354
  0.1271341  0.08623642 0.08971243 0.12233265]], shape=(2, 10), dtype=float32)

 Calculated_Y_Pred =  [[0.01511016 0.02304603 0.01961761 0.01425961 0.01025286 0.02124614
  0.01223315 0.01411171 0.01178642 0.01445299]
 [0.01271159 0.01357185 0.02033444 0.01701196 0.01662761 0.01780546
  0.01449438 0.01615969 0.01481383 0.01152103]]

Start of epoch 1

 Y_Pred =  tf.Tensor(
[[0.12411885 0.08815324 0.05189805 0.07208851 0.11877609 0.06383732
  0.13067529 0.08087374 0.09073243 0.17884655]
 [0.07584718 0.079349   0.06285123 0.1089478  0.09581042 0.09398626
  0.12189291 0.10832074 0.08284932 0.17014521]], shape=(2, 10), dtype=float32)

 Calculated_Y_Pred =  [[0.02525741 0.01648222 0.01210153 0.012623   0.01642019 0.01224833
  0.01583157 0.01587343 0.01606088 0.01728726]
 [0.01414648 0.01359805 0.01343262 0.01748529 0.01214003 0.01652816
  0.01353526 0.01948644 0.01344168 0.01507382]]
</code></pre>
",13503628.0,,4685471.0,,2021-06-09 17:47:31,2021-06-09 17:47:31,Mismatch in the calculated and the actual values of Output of the Softmax Activation Function in the Output Layer,<tensorflow><keras><deep-learning>,0,5,0.0,,,CC BY-SA 4.0
67176547,1,67180315.0,,2021-04-20 09:52:02,,7,4358,"<p>I would like to remove the first <strong>N</strong> layers from the pretrained Keras model. For example, an <code>EfficientNetB0</code>, whose first <strong>3</strong> layers are responsible only for preprocessing:</p>
<pre><code>import tensorflow as tf

efinet = tf.keras.applications.EfficientNetB0(weights=None, include_top=True)

print(efinet.layers[:3])
# [&lt;tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fa9a870e4d0&gt;,
# &lt;tensorflow.python.keras.layers.preprocessing.image_preprocessing.Rescaling at 0x7fa9a61343d0&gt;,
# &lt;tensorflow.python.keras.layers.preprocessing.normalization.Normalization at 0x7fa9a60d21d0&gt;]
</code></pre>
<p>As <a href=""https://stackoverflow.com/users/9215780/m-innat"">M.Innat</a> mentioned, the first layer is an <code>Input Layer</code>, which should be either spared or re-attached. I would like to remove those layers, but simple approach like this throws error:</p>
<pre class=""lang-py prettyprint-override""><code>cut_input_model = return tf.keras.Model(
    inputs=[efinet.layers[3].input], 
    outputs=efinet.outputs
)
</code></pre>
<p>This will result in:</p>
<pre><code>ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(...)
</code></pre>
<p>What would be the recommended way to do this?</p>
",10617503.0,,9215780.0,,2021-04-26 00:06:47,2021-11-26 13:14:18,How to remove first N layers from a Keras Model?,<python><tensorflow><keras><deep-learning><efficientnet>,3,2,0.0,,,CC BY-SA 4.0
64415836,1,,,2020-10-18 16:47:21,,7,682,"<p>I'm trying to load data into a Colab notebook, where the (flat) directory contains a bunch of jpg images, and the label classes are contained in a separate csv file, using tf.keras.preprocessing.image_dataset_from_directory.</p>
<p>According to the documentation:</p>
<p><code>Either &quot;inferred&quot; (labels are generated from the directory structure), or a list/tuple of integer labels of the same size as the number of image files found in the directory. Labels should be sorted according to the alphanumeric order of the image file paths (obtained via os.walk(directory) in Python).</code></p>
<p>I read the csv using pandas and converted it into a list using the following and passed train_labels in as the labels argument:</p>
<pre><code>labels = pd.read_csv(_URL)
train_labels = labels.values[:,1].tolist()
print(&quot;Total labels:&quot;, len(train_labels))
print(train_labels)
&gt;&gt;&gt; Total labels: 1164
&gt;&gt;&gt; [1, 0, 1, 1, 1, 2, 0, ... ]
train_dataset = image_dataset_from_directory(directory=train_dir,
                                         labels=train_labels,
                                         label_mode='int',
                                         shuffle=True,
                                         batch_size=BATCH_SIZE,
                                         image_size=IMG_SIZE)
</code></pre>
<p>However, on running the cell, the output read:</p>
<pre><code>Found 1164 files belonging to 1 classes.
</code></pre>
<p>Is there something wrong with the format of how I'm passing in the list of classes, or are there other settings which I need to make before the label classes can take effect?</p>
",6597774.0,,,,,2020-10-18 16:47:21,Passing in training labels to tf.keras.preprocessing.image_dataset_from_directory doesn't work,<python><machine-learning><keras><image-classification>,0,1,,,,CC BY-SA 4.0
63158424,1,69243656.0,,2020-07-29 16:38:47,,7,1223,"<p>I am using <code>keras</code> with a <code>tensorflow</code> (version 2.2.0) backend to train a classifier to distinguish between two datasets, A and B, which I have mixed into a pandas DataFrame object <code>x_train</code> (with two columns), and with labels in a numpy array <code>y_train</code>. I would like to perform sample weighting in order to account for the fact that A has far more samples than B. In addition, A is comprised of two datasets A1 and A2, with A1 much larger than A2; I would like to account for this fact as well using my sample weights. I have the sample weights in a numpy array called <code>w_train</code>. There are ~10 million training samples.</p>
<p>Here is example code:</p>
<pre><code>model = Sequential()
model.add(Dense(64, input_dim=x_train.shape[1], activation='relu')) 
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(x_train.iloc, y_train, sample_weight=w_train)
</code></pre>
<p><strong>When I use the <code>sample_weight</code> argument in <code>model.fit()</code>, I find that the model fitting initialization (i.e. whatever happens before <code>keras</code> starts to display the training progress) takes forever, too long to wait for</strong>. The problem goes away when I limit the dataset to 1000 samples, but as I increase to 100000 or 1000000 samples I notice that there is a significant difference in initialization and fitting time, so I suspect it has something to do with the way the data is being loaded. Nevertheless, it seems weird that merely adding the <code>sample_weights</code> argument would cause such a large timing difference.</p>
<p>Other information: I am running on CPU using a Jupyter notebook.</p>
<p>What is the problem here? Is there a way for me to modify the training setup or something else in order to speed up the initialization (or training) time?</p>
",9139930.0,,,,,2021-09-19 13:21:05,Why does keras model.fit with sample_weight have long initialization time?,<python><tensorflow><machine-learning><keras>,1,5,0.0,,,CC BY-SA 4.0
67439067,1,67439242.0,,2021-05-07 17:05:54,,7,5617,"<p>I am getting confused with the filter paramater, which is the first parameter in the Conv2D() layer function in keras. As I understand the filters are supposed to do things like edge detection or sharpening the image or blurring the image, but when I am defining the model as</p>
<pre><code>input_shape = (32, 32, 3)
model = Sequential()
model.add( Conv2D(64, kernel_size=(5, 5), activation='relu', input_shape=input_shape, strides=(1,1), padding='same') )
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))
model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', input_shape=input_shape, strides=(1,1), padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))
model.add(Conv2D(128, kernel_size=(5, 5), activation='relu', input_shape=input_shape, strides=(1,1), padding='same'))
model.add(Flatten())
model.add(Dense(3072, activation='relu'))
model.add(Dense(2048, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))
</code></pre>
<p>I am not mentioning the the edge detection or blurring or sharpening anywhere in the Conv2D function. The input images are 32 by 32 RGB images.</p>
<p>So my question is, when I define the Convolution layer as <code>Conv2D(64, ...)</code>, does this 64 means 64 different types of filters, such as vertical edge, horizontal edge, etc, which are chosen by keras at random? if so then is the output of the convolution layer (with 64 filters and 5x5 kernel and 1x1 stride) on a 32x32 1-channel image is 64 images of 28x28 size each. How are these 64 images combined to form a single image for further layers?</p>
",6344234.0,,,,,2022-04-07 21:46:45,What does the filter parameter mean in Conv2d layer?,<python><tensorflow><keras><deep-learning><conv-neural-network>,2,0,0.0,,,CC BY-SA 4.0
63901494,1,,,2020-09-15 12:06:40,,7,1484,"<p>I am applying transfer learning on the ssd_mobilenet_v2_coco_2018_03_29 model. After the training, I am using <code>tf.saved_model.save(model, saved_model_dir)</code> to save the keras model as saved_model.pb.</p>
<p>The original ssd_mobilenet_v2_coco_2018_03_29 model has the following signature defs.</p>
<pre><code>signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['inputs'] tensor_info:
        dtype: DT_UINT8
        shape: (-1, -1, -1, 3)
        name: image_tensor:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['detection_boxes'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 100, 4)
        name: detection_boxes:0
    outputs['detection_classes'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 100)
        name: detection_classes:0
    outputs['detection_scores'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 100)
        name: detection_scores:0
    outputs['num_detections'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1)
        name: num_detections:0
  Method name is: tensorflow/serving/predict
</code></pre>
<p>The saved model has the following signature defs (defaults).</p>
<pre><code>  signature_def['__saved_model_init_op']:
  The given SavedModel SignatureDef contains the following input(s):
  The given SavedModel SignatureDef contains the following output(s):
    outputs['__saved_model_init_op'] tensor_info:
        dtype: DT_INVALID
        shape: unknown_rank
        name: NoOp
  Method name is:

signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['mobilenetv2_1.00_224_input'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 224, 224, 3)
        name: serving_default_mobilenetv2_1.00_224_input:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['dense'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 5)
        name: StatefulPartitionedCall:0
  Method name is: tensorflow/serving/predict
</code></pre>
<p>The original model has 4 output nodes <code>detection_boxes, detection_classes, detection_scores, num_detections</code>. How is it getting <code>StatefulPartitionedCall</code> when I'm exporting it as a saved model? I viewed the saved model using tensorboard and all the 4 output nodes are visible.</p>
<p>[tensorboard image]: [1]: <a href=""https://i.stack.imgur.com/abbqI.png"" rel=""noreferrer"">https://i.stack.imgur.com/abbqI.png</a></p>
<p>When I'm trying to load the (frozen) saved model using batchnorm, I'm getting the following error <code>ValueError: Input 1 of node prefix/StatefulPartitionedCall was passed float from prefix/Conv1/kernel:0 incompatible with expected resource.</code></p>
<p>Any idea what's going on? How can I restore the original output nodes (which is still visible)?</p>
",3433050.0,,,,,2020-09-15 12:06:40,Tensorflow Output nodes replaced with StatefulPartitionedCall which is throwing ValueError on load,<python><tensorflow><keras>,0,4,0.0,,,CC BY-SA 4.0
63435679,1,,,2020-08-16 10:20:55,,7,6579,"<p>I would like to be able to reset the weights of my entire Keras model so that I do not have to compile it again. Compiling the model is currently the main bottleneck of my code. Here is an example of what I mean:</p>
<pre><code>import tensorflow as tf  

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(10)
])

model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])
   
data = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = data.load_data()

model.fit(x=x_train, y=y_train, epochs=10)

# Reset all weights of model here
# model.reset_all_weights() &lt;----- something like that

model.fit(x=x_train, y=y_train, epochs=10)
</code></pre>
",3861775.0,,10908375.0,,2020-08-17 08:49:43,2021-12-22 14:55:39,Reset all weights of Keras model,<python><tensorflow><machine-learning><keras>,2,1,0.0,,,CC BY-SA 4.0
62855617,1,,,2020-07-11 23:29:01,,7,6089,"<p>I'm trying to convert my Keras hdf5 file into a TensorFlow Lite file with the following code:</p>
<pre><code>import tensorflow as tf

# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(&quot;/content/best_model_11class.hdf5&quot;)
tflite_model = converter.convert()

# Save the TF Lite model.
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)
</code></pre>
<p>I'm getting this error on the <code>from_keras_model</code> line:</p>
<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-14-26467c686751&gt; in &lt;module&gt;()
      2 
      3 # Convert the model.
----&gt; 4 converter = tf.lite.TFLiteConverter.from_keras_model(&quot;/content/best_model_11class.hdf5&quot;)
      5 tflite_model = converter.convert()
      6 

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in from_keras_model(cls, model)
    426     # to None.
    427     # Once we have better support for dynamic shapes, we can remove this.
--&gt; 428     if not isinstance(model.call, _def_function.Function):
    429       # Pass `keep_original_batch_size=True` will ensure that we get an input
    430       # signature including the batch dimension specified by the user.

AttributeError: 'str' object has no attribute 'call'
</code></pre>
<p>How do I fix this? By the way, I'm using Google Colab.</p>
",9830958.0,,,,,2022-03-17 12:03:08,Keras Model AttributeError: 'str' object has no attribute 'call',<python-3.x><keras><tensorflow2.0><tf.keras><tensorflow-lite>,3,0,,,,CC BY-SA 4.0
71111005,1,71117585.0,,2022-02-14 11:19:39,,7,10523,"<p>I am trying to run an image-based project on colab. I found the project on github. Everything runs fine till I reached the cell with the following code:</p>
<pre><code>import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.resnet50 import preprocess_input, ResNet50
from keras.models import Model
from keras.layers import Dense, MaxPool2D, Conv2D
</code></pre>
<p>When I run it, the following output is observed:</p>
<pre><code>---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
&lt;ipython-input-24-173cbce466d6&gt; in &lt;module&gt;()
      1 import keras
      2 from keras.preprocessing.image import ImageDataGenerator
----&gt; 3 from keras.applications.resnet50 import preprocess_input, ResNet50
      4 from keras.models import Model
      5 from keras.layers import Dense, MaxPool2D, Conv2D

ModuleNotFoundError: No module named 'keras.applications.resnet50'

---------------------------------------------------------------------------
</code></pre>
<p>It's running 2.7.0 keras, connected to a TPU runtime. I tried !pip installing the said module but no use. I even tried running a demo resnet50 project too but got the same error. Can anyone please help me solve the error?</p>
",14049000.0,,,,,2022-02-15 18:22:23,ModuleNotFoundError: No module named 'keras.applications.resnet50 on google colab,<python><machine-learning><keras><google-colaboratory><resnet>,1,2,0.0,,,CC BY-SA 4.0
64983112,1,65031938.0,,2020-11-24 08:54:27,,7,283,"<p>I have trained two separate models</p>
<ul>
<li>ModelA: Checks if the input text is related to my work (Binary Classifier [related/not-related])</li>
<li>ModelB: Classifier of related texts (Classifier [good/normal/bad]). Only the related texts are relayed to this model from ModelA</li>
</ul>
<p>I want</p>
<ul>
<li>ModelC: Ensemble classifier that outputs [good/normal/bad/not-related]</li>
<li>I'll be training in batches. And there can be mix of <code>not-related</code> and <code>good/normal/bad</code> in one batch. I need them separated.</li>
</ul>
<p>Some pseudo code of what i need</p>
<pre><code># Output of modelA will be a vector I presume `(1, None)` where `None` is batch
def ModelC.predict(input):
    outputA = ModelA(input)
    if outputA == 'not-related':
        return outputA
    return ModelB(outputA)
</code></pre>
<p>I don't know how to include the <code>if</code> logic inside the models inference. How can I achieve this?</p>
",8471995.0,,8471995.0,,2020-11-27 04:19:12,2020-11-27 04:19:12,Keras vertical ensemble model with condition in between,<python><python-3.x><keras><deep-learning><ensemble-learning>,1,0,0.0,,,CC BY-SA 4.0
64309194,1,,,2020-10-11 21:29:00,,7,6398,"<p>After running my model for one epoch it crashed with following error message:</p>
<p><em>InvalidArgumentError:    Specified a list with shape [60,9] from a tensor with shape [56,9]
[[{{node TensorArrayUnstack/TensorListFromTensor}}]]
[[sequential_7/lstm_17/PartitionedCall]] [Op:__inference_train_function_29986]</em></p>
<p>This happened after I changed the LSTM Layer to <code>stateful=True</code> and had to pass
the <code>batch_input_shape</code> Argument instead of the <code>input_shape</code></p>
<p>Below is my code, I'm sure it has something to do with the shape of my data:</p>
<pre><code>test_split = 0.2
history_points = 60
n = int(histories.shape[0] * test_split)

histories_train = histories[:n]
y_train = next_values_normalized[:n]

histories_test = histories[n:]
y_test = next_values_normalized[n:]

next_values_test = next_values[n:]

print(histories_train.shape)
print(y_train.shape)

--&gt;(1421, 60, 9)
--&gt;(1421, 1)

# model architecture

´´´model = Sequential()
model.add(LSTM(units=128, stateful=True,return_sequences=True, batch_input_shape=(60,history_points, 9)))
model.add(LSTM(units=64,stateful=True,return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=32))
model.add(Dropout(0.2))
model.add(Dense(20))
ADAM=keras.optimizers.Adam(0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)
model.compile(loss='mean_squared_error', optimizer=ADAM)

model.fit(x=histories_train, y=y_train, batch_size=batchsize, epochs=50, shuffle=False, validation_split=0.2,verbose=1)
´´´
</code></pre>
",14310625.0,,1968.0,,2020-10-11 21:39:34,2020-11-04 12:52:10,"InvalidArgumentError: Specified a list with shape [60,9] from a tensor with shape [56,9]",<python><tensorflow><keras><lstm><recurrent-neural-network>,1,1,0.0,,,CC BY-SA 4.0
67647843,1,67648035.0,,2021-05-22 09:16:01,,7,6823,"<p>I have trained two keras models with different datasets for same class labels. How could I ensemble the models keras_model.h5 and keras_model2.h5 together and make another keras model say keras_ensemble.h5. I have tried referring various internet sources but not luck. <strong>Can someone help me with the code for ensembling it?</strong>
<a href=""https://github.com/Shooriya-Sridharan/PLANT_DIESEASE_CLASSIFICATION"" rel=""noreferrer"">Here are the models I've trained</a></p>
<p>Please assist me through this.Thank you.</p>
<p>Edit:
This was my code which i was able to get through with the help of the one who responded to my question Frightera</p>
<pre><code> import tensorflow.keras
    import tensorflow as tf
    from PIL import Image, ImageOps
    import numpy as np
    
    # Disable scientific notation for clarity
    np.set_printoptions(suppress=True)
    
    # Load the model
    keras_model = tensorflow.keras.models.load_model('keras_model.h5', compile=False)
    keras_model._name = 'model1'
    keras_model2 = tensorflow.keras.models.load_model('keras_model2.h5', compile=False)
    keras_model2._name = 'model2'
    models = [keras_model, keras_model2]
    #model_input = tf.keras.Input(shape=(125, 125, 3))
    model_input = tf.keras.Input(shape=(224, 224, 3))
    model_outputs = [model(model_input) for model in models]
    ensemble_output = tf.keras.layers.Average()(model_outputs)
    ensemble_model = tf.keras.Model(inputs=model_input, outputs=ensemble_output)
</code></pre>
<p><strong>EDIT</strong>
How do i get the keras ensemble model in h5 format??</p>
",14230118.0,,14230118.0,,2021-05-22 19:28:02,2022-08-30 07:00:58,Is there a way to ensemble two keras (h5) models trained for same classes,<python><machine-learning><keras><ensemble-learning><image-classification>,2,0,0.0,,,CC BY-SA 4.0
70546922,1,70588260.0,,2022-01-01 04:12:57,,6,435,"<p>I've converted a Keras model for use with OpenVino. The original Keras model used sigmoid to return scores ranging from 0 to 1 for binary classification. After converting the model for use with OpenVino, the scores are all near 0.99 for both classes but seem slightly lower for one of the classes.</p>
<p>For example, test1.jpg and test2.jpg (from opposite classes) yield scores of 0.00320357 and 0.9999, respectively.</p>
<p>With OpenVino, the same images yield scores of 0.9998982 and 0.9962392, respectively.</p>
<p>Edit* One suspicion is that the input array is still accepted by the OpenVino model but is somehow changed in shape or &quot;scrambled&quot; and therefore is never a match for class one? In other words, if you fed it random noise, the score would also always be 0.9999. Maybe I'd have to somehow get the OpenVino model to accept the original shape (1,180,180,3) instead of (1,3,180,180) so I don't have to force the input into a different shape than the one the original model accepted? That's weird though because I specified the shape when making the xml and bin for openvino:</p>
<pre><code>python3 /opt/intel/openvino_2021/deployment_tools/model_optimizer/mo_tf.py --saved_model_dir /Users/.../Desktop/.../model13 --output_dir /Users/.../Desktop/... --input_shape=\[1,180,180,3]
</code></pre>
<p>However, I know from error messages that the inference engine is expecting (1,3,180,180) for some unknown reason. Could that be the problem? The other suspicion is something wrong with how the original model was frozen. I'm exploring different ways to freeze the original model (keras model converted to pb) in case the problem is related to that.</p>
<p>I checked to make sure the Sigmoid activation function is being used in the OpenVino implementation (same activation as the Keras model) and it looks like it is. Why, then, are the values not the same? Any help would be much appreciated.</p>
<p>The code for the OpenVino inference is:</p>
<pre><code>import openvino
from openvino.inference_engine import IECore, IENetwork 
from skimage import io
import sys
import numpy as np
import os

def loadNetwork(model_xml, model_bin):

    ie = IECore() 

    network =  ie.read_network(model=model_xml, weights=model_bin)

    input_placeholder_key = list(network.input_info)[0]
    input_placeholder = network.input_info[input_placeholder_key]

    output_placeholder_key = list(network.outputs)[0]
    output_placeholder = network.outputs[output_placeholder_key]

    return network, input_placeholder_key, output_placeholder_key

batch_size = 1
channels = 3
IMG_HEIGHT = 180
IMG_WIDTH = 180

#loadNetwork('saved_model.xml','saved_model.bin')

image_path = 'test.jpg'

def load_source(path_to_image):
    image = io.imread(path_to_image)
    img = np.resize(image,(180,180))
    return img

img_new = load_source('test2.jpg')

#Batch?

def classify(image):
    device = 'CPU'
    network, input_placeholder_key, output_placeholder_key = loadNetwork('saved_model.xml','saved_model.bin')
    ie = IECore() 
    exec_net = ie.load_network(network=network, device_name=device)
    res = exec_net.infer(inputs={input_placeholder_key: image})
    print(res)
    res = res[output_placeholder_key]
    return res

result = classify(img_new)
print(result)
result = result[0]
top_result = np.argmax(result)
print(top_result)
print(result[top_result])
</code></pre>
<p>And the result:</p>
<pre><code>{'StatefulPartitionedCall/model/dense/Sigmoid': array([[0.9962392]], dtype=float32)}
[[0.9962392]]
0
0.9962392
</code></pre>
",14903630.0,,14903630.0,,2022-01-03 07:03:31,2022-01-05 06:06:43,OpenVino converted model not returning same score values as original model (Sigmoid),<tensorflow><machine-learning><keras><computer-vision><openvino>,1,0,0.0,,,CC BY-SA 4.0
68087783,1,,,2021-06-22 16:53:51,,6,257,"<p>Full error:</p>
<blockquote>
<p>Can't pickle &lt;function Layer.add_loss.._tag_callable at 0x7fd4045f55e0&gt;: it's not found as tensorflow.python.keras.engine.base_layer.Layer.add_loss.._tag_callable</p>
</blockquote>
<p>I am trying to train this neural network using code that was written for tensorflow 1 but I cannot pickle the model with my virtual env using tensorflow 2. Does anyone know where I'm going wrong? Thanks!</p>
",12277181.0,,2423278.0,,2021-06-23 13:08:07,2022-06-09 09:17:37,Can't pickle <function Layer.add_loss.<locals>._tag_callable at 0x7fd4045f55e0>:,<tensorflow><keras>,0,0,,,,CC BY-SA 4.0
70477631,1,70488354.0,,2021-12-25 02:23:36,,6,7376,"<p>Here is the batch data set i created before to fit in the model:</p>
<pre><code>train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_path,
    label_mode = 'categorical', #it is used for multiclass classification. It is one hot encoded labels for each class
    validation_split = 0.2,     #percentage of dataset to be considered for validation
    subset = &quot;training&quot;,        #this subset is used for training
    seed = 1337,                # seed is set so that same results are reproduced
    image_size = img_size,      # shape of input images
    batch_size = batch_size,    # This should match with model batch size
)




valid_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_path,
    label_mode ='categorical',
    validation_split = 0.2,
    subset = &quot;validation&quot;,      #this subset is used for validation
    seed = 1337,
    image_size = img_size,
    batch_size = batch_size,
)
</code></pre>
<p>if i run a for loop, i am able to access the img array and labels:</p>
<pre><code>for images, labels in train_ds:
    print(labels)
</code></pre>
<p>But if i try to access them like this:</p>
<p>ATTEMPT 1)</p>
<pre><code>images, labels = train_ds
</code></pre>
<p>I get the following value error: <code>ValueError: too many values to unpack (expected 2)</code></p>
<p>ATTEMPT 2:</p>
<p>If i try to unpack it like this:</p>
<pre><code>images = train_ds[:,0] # get the 0th column of all rows 
labels = train_ds[:,1] # get the 1st column of all rows 
</code></pre>
<p>I get the following error: <code>TypeError: 'BatchDataset' object is not subscriptable</code></p>
<p>Is there a way for me to extract the labels and images without going trough a for loop?</p>
",12722902.0,,9657861.0,,2021-12-28 06:53:54,2021-12-28 06:53:54,BatchDataSet: get img array and labels,<python><tensorflow><keras><deep-learning><tensorflow-datasets>,2,2,0.0,,,CC BY-SA 4.0
67902081,1,68008986.0,,2021-06-09 10:14:16,,6,301,"<p>I am trying to implement the Unrolled GAN model as described <a href=""https://github.com/poolio/unrolled_gan"" rel=""noreferrer"">here</a>, with <a href=""https://github.com/poolio/unrolled_gan/blob/master/Unrolled%20GAN%20demo.ipynb"" rel=""noreferrer"">example code</a>. However, it was implemented using TF1, and I have been doing my best to update it but I am relatively new to python and TF (only been using it for the past ~6 months).</p>
<p>The line(s) that I cannot seem to make work (for the moment, there may be more) is this one:</p>
<pre><code>gen_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, &quot;generator&quot;)
disc_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, &quot;discriminator&quot;)
</code></pre>
<p>These both return empty lists, and I cannot see what I am missing. Even without specifying a scope, the <code>get_collection()</code> returns <code>[]</code>. Earlier, we define both generator and discriminator as scopes like so:</p>
<pre><code>def generator(z, output_dim=2, n_hidden=128, n_layer=2):
    with tf.compat.v1.variable_scope(&quot;generator&quot;):
        h = slim.stack(z, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.tanh)
        x = slim.fully_connected(h, output_dim, activation_fn=None)
    return x

def discriminator(x, n_hidden=128, n_layer=2, reuse=False):
    with tf.compat.v1.variable_scope(&quot;discriminator&quot;, reuse=reuse):
        h = slim.stack(x, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.tanh)
        log_d = slim.fully_connected(h, 1, activation_fn=None)
    return log_d
</code></pre>
<p>Is there a problem with the definition of the scope?</p>
<p>Here is my updated code in full, in case there is maybe something I missed elsewhere:</p>
<pre><code>%pylab inline
from collections import OrderedDict
import tensorflow as tf
import tensorflow_probability as tfp
ds = tfp.distributions
# slim = tf.contrib.slim
import tf_slim as slim

from keras.optimizers import Adam

try:
    from moviepy.video.io.bindings import mplfig_to_npimage
    import moviepy.editor as mpy
    generate_movie = True
except:
    print(&quot;Warning: moviepy not found.&quot;)
    generate_movie = False


def remove_original_op_attributes(graph):
    &quot;&quot;&quot;Remove _original_op attribute from all operations in a graph.&quot;&quot;&quot;
    for op in graph.get_operations():
        op._original_op = None
        
def graph_replace(*args, **kwargs):
    &quot;&quot;&quot;Monkey patch graph_replace so that it works with TF 1.0&quot;&quot;&quot;
    remove_original_op_attributes(tf.get_default_graph())
    return _graph_replace(*args, **kwargs)




def extract_update_dict(update_ops):
    &quot;&quot;&quot;Extract variables and their new values from Assign and AssignAdd ops.
    
    Args:
        update_ops: list of Assign and AssignAdd ops, typically computed using Keras' opt.get_updates()

    Returns:
        dict mapping from variable values to their updated value
    &quot;&quot;&quot;
    name_to_var = {v.name: v for v in tf.compat.v1.global_variables()}
    updates = OrderedDict()
    for update in update_ops:
        var_name = update.op.inputs[0].name
        var = name_to_var[var_name]
        value = update.op.inputs[1]
        if update.op.type == 'Assign':
            updates[var.value()] = value
        elif update.op.type == 'AssignAdd':
            updates[var.value()] = var + value
        else:
            raise ValueError(&quot;Update op type (%s) must be of type Assign or AssignAdd&quot;%update_op.op.type)
    return updates



def sample_mog(batch_size, n_mixture=8, std=0.01, radius=1.0):
    thetas = np.linspace(0, 2 * np.pi, n_mixture)
    xs, ys = radius * np.sin(thetas), radius * np.cos(thetas)
    cat = ds.Categorical(tf.zeros(n_mixture))
    comps = [ds.MultivariateNormalDiag([xi, yi], [std, std]) for xi, yi in zip(xs.ravel(), ys.ravel())]
    data = ds.Mixture(cat, comps)
    return data.sample(batch_size)



def generator(z, output_dim=2, n_hidden=128, n_layer=2):
    with tf.compat.v1.variable_scope(&quot;generator&quot;):
        h = slim.stack(z, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.tanh)
        x = slim.fully_connected(h, output_dim, activation_fn=None)
    return x

def discriminator(x, n_hidden=128, n_layer=2, reuse=False):
    with tf.compat.v1.variable_scope(&quot;discriminator&quot;, reuse=reuse):
        h = slim.stack(x, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.tanh)
        log_d = slim.fully_connected(h, 1, activation_fn=None)
    return log_d



params = dict(
    batch_size=512,
    disc_learning_rate=1e-4,
    gen_learning_rate=1e-3,
    beta1=0.5,
    epsilon=1e-8,
    max_iter=25000,
    viz_every=5000,
    z_dim=256,
    x_dim=2,
    unrolling_steps=5,
)


tf.compat.v1.reset_default_graph()

data = sample_mog(params['batch_size'])

noise = ds.Normal(tf.zeros(params['z_dim']), 
                  tf.ones(params['z_dim'])).sample(params['batch_size'])
# Construct generator and discriminator nets
# with slim.arg_scope([slim.fully_connected], weights_initializer=tf.orthogonal_initializer(gain=1.4)): ## old
with slim.arg_scope([slim.fully_connected], weights_initializer=tf.keras.initializers.Orthogonal(gain=1.4)):
    samples = generator(noise, output_dim=params['x_dim'])
    real_score = discriminator(data)
    fake_score = discriminator(samples, reuse=True)
    
# Saddle objective    
loss = tf.reduce_mean(
    tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.cast(real_score, dtype=tf.float32), labels=tf.cast(tf.ones_like(real_score), dtype=tf.float32)) +
    tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.cast(fake_score, dtype=tf.float32), labels=tf.cast(tf.zeros_like(fake_score), dtype=tf.float32)))

gen_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, &quot;generator&quot;)
disc_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, &quot;discriminator&quot;)

# Vanilla discriminator update
d_opt = Adam(lr=params['disc_learning_rate'], beta_1=params['beta1'], epsilon=params['epsilon'])
# updates = d_opt.get_updates(disc_vars, [], loss) ## old
updates = d_opt.get_updates(loss, [])
d_train_op = tf.group(*updates, name=&quot;d_train_op&quot;)

### I HAVE NOT UPDATED BEYOND THIS POINT ###

# Unroll optimization of the discrimiantor
if params['unrolling_steps'] &gt; 0:
    # Get dictionary mapping from variables to their update value after one optimization step
    update_dict = extract_update_dict(updates)
    cur_update_dict = update_dict
    for i in xrange(params['unrolling_steps'] - 1):
        # Compute variable updates given the previous iteration's updated variable
        cur_update_dict = graph_replace(update_dict, cur_update_dict)
    # Final unrolled loss uses the parameters at the last time step
    unrolled_loss = graph_replace(loss, cur_update_dict)
else:
    unrolled_loss = loss

# Optimize the generator on the unrolled loss
g_train_opt = tf.train.AdamOptimizer(params['gen_learning_rate'], beta1=params['beta1'], epsilon=params['epsilon'])
g_train_op = g_train_opt.minimize(-unrolled_loss, var_list=gen_vars)


sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())

</code></pre>
",3575623.0,,9215780.0,,2021-06-14 10:05:11,2021-07-04 14:50:53,Updating Unrolled GAN to TF2,<python><tensorflow><keras><generative-adversarial-network>,1,0,0.0,,,CC BY-SA 4.0
69591717,1,69594400.0,,2021-10-16 00:05:23,,6,2706,"<p>My input is a array of 64 integers.</p>
<pre><code>model = Sequential()
model.add( Input(shape=(68,), name=&quot;input&quot;))
model.add(Conv1D(64, 2, activation=&quot;relu&quot;, padding=&quot;same&quot;, name=&quot;convLayer&quot;))
</code></pre>
<p>I have 10,000 of these arrays in my training set.  And I supposed to be specifying this in order for conv1D to work?</p>
<p>I am getting the dreaded</p>
<pre><code>ValueError: Input 0 of layer convLayer is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: [None, 68]
</code></pre>
<p>error and I really don't understand what I need to do.</p>
",449693.0,,9657861.0,,2022-04-19 13:41:18,2022-04-19 13:41:18,How is the Keras Conv1D input specified? I seem to be lacking a dimension,<python><tensorflow><machine-learning><keras><conv1d>,2,0,0.0,,,CC BY-SA 4.0
63484172,1,63543566.0,,2020-08-19 09:41:11,,6,8452,"<p>I want to load FaceNet in Keras but I am getting errors.
the modal facenet_keras.h5 is ready but I can't load it.</p>
<p>you can get facenet_keras.h5 from this link:</p>
<p><a href=""https://drive.google.com/drive/folders/1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn"" rel=""noreferrer"">https://drive.google.com/drive/folders/1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn</a></p>
<p>My tensorflow version is:</p>
<pre><code>tensorflow.__version__
</code></pre>
<p>'2.2.0'</p>
<p>and when i want to load data:</p>
<pre><code>from tensorflow.keras.models import load_model
load_model('facenet_keras.h5')
</code></pre>
<p>get this error:</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-6-2a20f38e8217&gt; in &lt;module&gt;
----&gt; 1 load_model('facenet_keras.h5')

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    182     if (h5py is not None and (
    183         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--&gt; 184       return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
    185 
    186     if sys.version_info &gt;= (3, 4) and isinstance(filepath, pathlib.Path):

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    175       raise ValueError('No model found in config file.')
    176     model_config = json.loads(model_config.decode('utf-8'))
--&gt; 177     model = model_config_lib.model_from_config(model_config,
    178                                                custom_objects=custom_objects)
    179 

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)
     53                     '`Sequential.from_config(config)`?')
     54   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
---&gt; 55   return deserialize(config, custom_objects=custom_objects)
     56 
     57 

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    103     config['class_name'] = _DESERIALIZATION_TABLE[layer_class_name]
    104 
--&gt; 105   return deserialize_keras_object(
    106       config,
    107       module_objects=globs,

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    367 
    368       if 'custom_objects' in arg_spec.args:
--&gt; 369         return cls.from_config(
    370             cls_config,
    371             custom_objects=dict(

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py in from_config(cls, config, custom_objects)
    984         ValueError: In case of improperly formatted config dict.
    985     &quot;&quot;&quot;
--&gt; 986     input_tensors, output_tensors, created_layers = reconstruct_from_config(
    987         config, custom_objects)
    988     model = cls(inputs=input_tensors, outputs=output_tensors,

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py in reconstruct_from_config(config, custom_objects, created_layers)
   2017   # First, we create all layers and enqueue nodes to be processed
   2018   for layer_data in config['layers']:
-&gt; 2019     process_layer(layer_data)
   2020   # Then we process nodes in order of layer depth.
   2021   # Nodes that cannot yet be processed (if the inbound node

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py in process_layer(layer_data)
   1999       from tensorflow.python.keras.layers import deserialize as deserialize_layer  # pylint: disable=g-import-not-at-top
   2000 
-&gt; 2001       layer = deserialize_layer(layer_data, custom_objects=custom_objects)
   2002       created_layers[layer_name] = layer
   2003 

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    103     config['class_name'] = _DESERIALIZATION_TABLE[layer_class_name]
    104 
--&gt; 105   return deserialize_keras_object(
    106       config,
    107       module_objects=globs,

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    367 
    368       if 'custom_objects' in arg_spec.args:
--&gt; 369         return cls.from_config(
    370             cls_config,
    371             custom_objects=dict(

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py in from_config(cls, config, custom_objects)
    988   def from_config(cls, config, custom_objects=None):
    989     config = config.copy()
--&gt; 990     function = cls._parse_function_from_config(
    991         config, custom_objects, 'function', 'module', 'function_type')
    992 

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py in _parse_function_from_config(cls, config, custom_objects, func_attr_name, module_attr_name, func_type_attr_name)
   1040     elif function_type == 'lambda':
   1041       # Unsafe deserialization from bytecode
-&gt; 1042       function = generic_utils.func_load(
   1043           config[func_attr_name], globs=globs)
   1044     elif function_type == 'raw':

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in func_load(code, defaults, closure, globs)
    469   except (UnicodeEncodeError, binascii.Error):
    470     raw_code = code.encode('raw_unicode_escape')
--&gt; 471   code = marshal.loads(raw_code)
    472   if globs is None:
    473     globs = globals()

ValueError: bad marshal data (unknown type code)
</code></pre>
<p>thank you.</p>
",10180891.0,,14029512.0,,2020-08-19 09:51:34,2022-04-20 11:18:58,tensorflow load data: bad marshal data,<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0
70535121,1,,,2021-12-30 17:57:07,,6,315,"<p>I'm trying to use KerasTuner to automatically tune the neural network architecture, i.e., the number of hidden layers and the number of nodes in each hidden layer. Currently, the neural network architecture is defined using one parameter <code>NN_LAYER_SIZES</code>. For example,</p>
<pre><code>NN_LAYER_SIZES = [128, 128, 128, 128]
</code></pre>
<p>indicates the NN has 4 hidden layers and each hidden layer has 128 nodes.</p>
<p>KerasTuner has the following hyperparameter types (<a href=""https://keras.io/api/keras_tuner/hyperparameters/"" rel=""noreferrer"">https://keras.io/api/keras_tuner/hyperparameters/</a>):</p>
<ul>
<li>Int</li>
<li>Float</li>
<li>Boolean</li>
<li>Choice</li>
</ul>
<p>It seems none of these hyperparameter types fits my use case. So I wrote the following code to scan the number of hidden layers and the number of nodes. However, it's not been recognized as a hyperparameter.</p>
<pre><code>number_of_hidden_layer = hp.Int(&quot;layer_number&quot;, min_value=2, max_value=5, step=1)
number_of_nodes = hp.Int(&quot;node_number&quot;, min_value=4, max_value=8, step=1)
NN_LAYER_SIZES = [2**number_of_nodes for _ in range(number of hidden_layer)]
</code></pre>
<p>Any suggestions on how to make it right?</p>
",3673947.0,,9657861.0,,2022-10-02 16:31:59,2023-02-04 18:04:01,How can I tune neural network architecture using KerasTuner?,<python><tensorflow><keras><neural-network><keras-tuner>,2,0,,,,CC BY-SA 4.0
63927188,1,64049260.0,,2020-09-16 20:00:35,,6,783,"<p>I am writing a custom loss function that requires calculating ratios of predicted values per group. As a <strong>simplified</strong> example, here is what my Data and model code looks like:</p>
<pre><code>def main():
    df = pd.DataFrame(columns=[&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;condition_1&quot;, &quot;condition_2&quot;, &quot;label&quot;],
                      data=[[5, 10, &quot;a&quot;, &quot;1&quot;, 0],
                            [30, 20, &quot;a&quot;, &quot;1&quot;, 1],
                            [50, 40, &quot;a&quot;, &quot;1&quot;, 0],
                            [15, 20, &quot;a&quot;, &quot;2&quot;, 0],
                            [25, 30, &quot;b&quot;, &quot;2&quot;, 1],
                            [35, 40, &quot;b&quot;, &quot;1&quot;, 0],
                            [10, 80, &quot;b&quot;, &quot;1&quot;, 1]])
    features = [&quot;feature_1&quot;, &quot;feature_2&quot;]
    conds_and_label = [&quot;condition_1&quot;, &quot;condition_2&quot;, &quot;label&quot;]
    X = df[features]
    Y = df[conds_and_label]
    model = my_model(input_shape=len(features))
    model.fit(X, Y, epochs=10, batch_size=128)
    model.evaluate(X, Y)


def custom_loss(conditions, y_pred):  # this is what I need help with
    conds = [&quot;condition_1&quot;, &quot;condition_2&quot;]
    conditions[&quot;label_pred&quot;] = y_pred
    g = conditions.groupby(by=conds,
                           as_index=False).apply(lambda x: x[&quot;label_pred&quot;].sum() /
                                                           len(x)).reset_index(name=&quot;pred_ratio&quot;)
    # true_ratios will be a constant, external DataFrame. Simplified example here:
    true_ratios = pd.DataFrame(columns=[&quot;condition_1&quot;, &quot;condition_2&quot;, &quot;true_ratio&quot;],
                               data=[[&quot;a&quot;, &quot;1&quot;, 0.1],
                                     [&quot;a&quot;, &quot;2&quot;, 0.2],
                                     [&quot;b&quot;, &quot;1&quot;, 0.8],
                                     [&quot;b&quot;, &quot;2&quot;, 0.9]])
    merged = pd.merge(g, true_ratios, on=conds)
    merged[&quot;diff&quot;] = merged[&quot;pred_ratio&quot;] - merged[&quot;true_ratio&quot;]
    return K.mean(K.abs(merged[&quot;diff&quot;]))


def joint_loss(conds_and_label, y_pred):
    y_true = conds_and_label[:, 2]
    conditions = tf.gather(conds_and_label, [0, 1], axis=1)
    loss_1 = standard_loss(y_true=y_true, y_pred=y_pred)  # not shown
    loss_2 = custom_loss(conditions=conditions, y_pred=y_pred)
    return 0.5 * loss_1 + 0.5 * loss_2


def my_model(input_shape=None):
    model = Sequential()
    model.add(Dense(units=2, activation=&quot;relu&quot;), input_shape=(input_shape,))
    model.add(Dense(units=1, activation='sigmoid'))
    model.add(Flatten())
    model.compile(loss=joint_loss, optimizer=&quot;Adam&quot;,
                  metrics=[joint_loss, custom_loss, &quot;accuracy&quot;])
    return model
</code></pre>
<p>What I need help with is the <code>custom_loss</code> function. As you can see, it is currently written as if the inputs are Pandas DataFrames. However, the inputs will be Keras Tensors (with tensorflow backend), so I am trying to figure out <strong>how to convert the current code in <code>custom_loss</code> to use Keras/TF backend functions</strong>. For example, I searched online and couldn't find out a way to do a groupby in Keras/TF to get the ratios I need...</p>
<p>Some context/explanation that might be helpful to you:</p>
<ol>
<li>My main loss function is <code>joint_loss</code>, which consists of <code>standard_loss</code> (not shown) and <code>custom_loss</code>. But I only need help converting <code>custom_loss</code>.</li>
<li>What <code>custom_loss</code> does is:
<ol>
<li>Groupby on two condition columns (these two columns represent the groups of the data).</li>
<li>Get the ratio of predicted 1s to total number of batch samples per each group.</li>
<li>Compare the &quot;pred_ratio&quot; to a set of &quot;true_ratio&quot; and get the difference.</li>
<li>Calculate mean absolute error from the differences.</li>
</ol>
</li>
</ol>
",8020900.0,,,,,2020-09-25 17:50:59,Keras custom loss function per tensor group,<python><tensorflow><keras><pandas-groupby><loss-function>,1,4,0.0,,,CC BY-SA 4.0
65395179,1,,,2020-12-21 15:07:50,,6,2869,"<p>Sensors (<strong>of the same type</strong>) scattered on my site are manually reporting on irregular intervals to my backend. Between reports the sensors aggregate events and report them as a batch.</p>
<p>The following dataset is a collection of sequence events data, batch collected. For example sensor 1 reported 2 times. On the first batch 2 events and on the second batch 3 events, while sensor 2 reported 1 time with 3 events.</p>
<p>I would like  to use this data as my train data <strong>X</strong></p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>sensor_id</th>
<th>batch_id</th>
<th>timestamp</th>
<th>feature_1</th>
<th>feature_n</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>2020-12-21T00:00:00+00:00</td>
<td>0.54</td>
<td>0.33</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>2020-12-21T01:00:00+00:00</td>
<td>0.23</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>2020-12-21T03:00:00+00:00</td>
<td>0.51</td>
<td>0.13</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>2020-12-21T04:00:00+00:00</td>
<td>0.23</td>
<td>0.24</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>2020-12-21T05:00:00+00:00</td>
<td>0.33</td>
<td>0.44</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>2020-12-21T00:00:00+00:00</td>
<td>0.54</td>
<td>0.33</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>2020-12-21T01:00:00+00:00</td>
<td>0.23</td>
<td>0.14</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>2020-12-21T03:00:00+00:00</td>
<td>0.51</td>
<td>0.13</td>
</tr>
</tbody>
</table>
</div>
<p>My target <strong>y</strong>, is a score calculated from all the events collected by a sensor:<br />
I.E <code>socre_sensor_1 = f([[batch1...],[batch2...]])</code></p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>sensor_id</th>
<th>final_score</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.8</td>
</tr>
<tr>
<td>2</td>
<td>0.6</td>
</tr>
</tbody>
</table>
</div>
<p>I would like to predict <strong>y</strong> each time a batch is collected, I.E 2 predictions for a sensor with 2 reports.</p>
<hr />
<p><strong>LSTM model:</strong><br />
I've started with an LSTM model, since I'm trying to predict on a time-series of events.
My first thought was to select a fixed size input and to zero pad the input when the number of events collected is smaller than the input size.Then mask the padded value:</p>
<pre><code>model.add(Masking(mask_value=0., input_shape=(num_samples, num_features)))
</code></pre>
<p>For example:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>sensor_id</th>
<th>batch_id</th>
<th>timestamp</th>
<th>feature_1</th>
<th>feature_n</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>2020-12-21T00:00:00+00:00</td>
<td>0.54</td>
<td>0.33</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>2020-12-21T01:00:00+00:00</td>
<td>0.23</td>
<td>0.14</td>
</tr>
</tbody>
</table>
</div>
<p>Would produce the following input if selected length is 5:</p>
<pre><code>[
 [0.54, 0.33],
 [0.23, 0.14],
 [0,0],
 [0,0],
 [0,0]
]
</code></pre>
<p>However, the variance of number of events per sensor report in my train data is large, one report could collect 1000 events while the other one can collect 10. So if I'm selecting the average size (let's say 200), some inputs would be with a lot of padding, while other would be truncated and data will be lost.</p>
<p>I've heard about <a href=""https://www.tensorflow.org/guide/ragged_tensor"" rel=""nofollow noreferrer"">ragged tensors</a>, but I'm not sure it fit my use case. How would one approach such a problem?</p>
",1115237.0,,1968.0,,2020-12-23 16:26:55,2020-12-27 08:16:30,Train and predict on variable length sequences,<python><tensorflow><keras><lstm>,4,5,0.0,,,CC BY-SA 4.0
68131274,1,68158394.0,,2021-06-25 12:50:08,,6,1657,"<p>I'm trying to do transfer learning on MobileNetV3-Small using Tensorflow 2.5.0 to predict dog breeds (133 classes) and since it got reasonable accuracy on the ImageNet dataset (1000 classes) I thought it should have no problem adapting to my problem.</p>
<p>I've tried a multitude of training variations and recently had a breakthrough but now my training stagnates at about 60% validation accuracy with minor fluctuations in validation loss (accuracy and loss curves for training and validation below).</p>
<p><a href=""https://i.stack.imgur.com/ovjSx.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ovjSx.png"" alt=""Accuracy and loss curves for training and validation data"" /></a></p>
<p>I tried using <code>ReduceLROnPlateau</code> in the 3rd graph below, but it didn't help to improve matters. Can anyone suggest how I could improve the training?</p>
<pre><code>from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.layers import GlobalMaxPooling2D, Dense, Dropout, BatchNormalization
from tensorflow.keras.applications import MobileNetV3Large, MobileNetV3Small
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True # needed for working with this dataset


# define generators
train_datagen = ImageDataGenerator(vertical_flip=True, horizontal_flip=True,
                                   rescale=1.0/255, brightness_range=[0.5, 1.5],
                                   zoom_range=[0.5, 1.5], rotation_range=90)
test_datagen = ImageDataGenerator(rescale=1.0/255)

train_gen = train_datagen.flow_from_directory(train_dir, target_size=(224,224),
                                              batch_size=32, class_mode=&quot;categorical&quot;)
val_gen = test_datagen.flow_from_directory(val_dir, target_size=(224,224),
                                              batch_size=32, class_mode=&quot;categorical&quot;)
test_gen = test_datagen.flow_from_directory(test_dir, target_size=(224,224),
                                              batch_size=32, class_mode=&quot;categorical&quot;)

pretrained_model = MobileNetV3Small(input_shape=(224,224,3), classes=133,
                             weights=&quot;imagenet&quot;, pooling=None, include_top=False)
# set all layers trainable because when I froze most of the layers the model didn't learn so well
for layer in pretrained_model.layers:
    layer.trainable = True
last_output = pretrained_model.layers[-1].output
x = GlobalMaxPooling2D()(last_output)
x = BatchNormalization()(x)
x = Dense(512, activation='relu')(x)
x = Dense(133, activation='softmax')(x)
model = Model(pretrained_model.input, x)

model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

# val_acc with min_delta 0.003; val_loss with min_delta 0.01
plateau = ReduceLROnPlateau(monitor=&quot;val_loss&quot;, mode=&quot;min&quot;, patience=5,
                            min_lr=1e-8, factor=0.3, min_delta=0.01,
                            verbose=1)
checkpointer = ModelCheckpoint(filepath=savepath, verbose=1, save_best_only=True,
                               monitor=&quot;val_accuracy&quot;, mode=&quot;max&quot;,
                               save_weights_only=True)
</code></pre>
",7547932.0,,7547932.0,,2021-06-25 14:31:27,2021-06-28 06:36:59,Transfer learning on MobileNetV3 reaches plateau and I can't move past it,<python><tensorflow><keras><tensorflow2.0><mobilenet>,1,3,,,,CC BY-SA 4.0
68444781,1,,,2021-07-19 17:35:58,,6,408,"<p>I created a Seq2Seq model for text summarization. I have two models, one with attention and one without. The one without attention was able to generate predictions but I can't do it for the one with attention even though it fits successfully.</p>
<p>This is my model:</p>
<pre><code>latent_dim = 300
embedding_dim = 200

clear_session()

# Encoder
encoder_inputs = Input(shape=(max_text_len, ))

# Embedding layer
enc_emb = Embedding(x_voc, embedding_dim,
                    trainable=True)(encoder_inputs)

# Encoder LSTM 1
encoder_lstm1 = Bidirectional(LSTM(latent_dim, return_sequences=True,
                     return_state=True, dropout=0.4,
                     recurrent_dropout=0.4))
(encoder_output1, forward_h1, forward_c1, backward_h1, backward_c1) = encoder_lstm1(enc_emb)

# Encoder LSTM 2
encoder_lstm2 = Bidirectional(LSTM(latent_dim, return_sequences=True,
                     return_state=True, dropout=0.4,
                     recurrent_dropout=0.4))
(encoder_output2, forward_h2, forward_c2, backward_h2, backward_c2) = encoder_lstm2(encoder_output1)

# Encoder LSTM 3
encoder_lstm3 = Bidirectional(LSTM(latent_dim, return_state=True,
                     return_sequences=True, dropout=0.4,
                     recurrent_dropout=0.4))
(encoder_outputs, forward_h, forward_c, backward_h, backward_c) = encoder_lstm3(encoder_output2)

state_h = Concatenate()([forward_h, backward_h])
state_c = Concatenate()([forward_c, backward_c])

# Set up the decoder, using encoder_states as the initial state
decoder_inputs = Input(shape=(None, ))

# Embedding layer
dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)
dec_emb = dec_emb_layer(decoder_inputs)


# Decoder LSTM
decoder_lstm = LSTM(latent_dim*2, return_sequences=True,
                    return_state=True, dropout=0.4,
                    recurrent_dropout=0.2)
(decoder_outputs, decoder_fwd_state, decoder_back_state) = \
    decoder_lstm(dec_emb, initial_state=[state_h, state_c])

#start Attention part
attention = dot([decoder_outputs, encoder_outputs], axes=[2, 2])
attention = Activation('softmax')(attention)
context = dot([attention, encoder_outputs], axes=[2,1])
decoder_outputs = Concatenate()([context, decoder_outputs])
#end Attention

# Dense layer
decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))(decoder_outputs)

# Define the model
model = Model([encoder_inputs, decoder_inputs], decoder_dense)
</code></pre>
<p>This is how construct the encoder and decoder for generating predictions:</p>
<pre><code>model = load_model(&quot;model_intro.h5&quot;)

encoder_inputs = model.input[0]  # input_1

encoder_outputs, forward_h, forward_c, backward_h, backward_c = model.layers[5].output #Bi-lstm2

state_h_enc = Concatenate()([forward_h, backward_h])
state_c_enc = Concatenate()([forward_c, backward_c])

encoder_states = [state_h_enc, state_c_enc]
encoder_model = Model(encoder_inputs, encoder_states)

decoder_inputs = model.input[1]  # input_2
decoder_state_input_h = Input(shape=(latent_dim*2,), name=&quot;input_3&quot;)
decoder_state_input_c = Input(shape=(latent_dim*2,), name=&quot;input_4&quot;)
decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]
decoder_emdedding = model.layers[6](decoder_inputs)
decoder_lstm = model.layers[9]
decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_emdedding, initial_state=decoder_states_inputs)
decoder_states = [state_h_dec, state_c_dec]

#start Attention
attention = dot([decoder_outputs, encoder_outputs], axes=[2, 2])
attention2 = Activation('softmax')(attention)
context = dot([attention2, encoder_outputs], axes=[2,1])
decoder_outputs = Concatenate(axis=-1)([context, decoder_outputs])
#end Attention

decoder_dense = model.layers[-1]
decoder_outputs = decoder_dense(decoder_outputs)
decoder_model = Model(
    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states
)
</code></pre>
<p>In the code if I remove the attention part, it works fine. In the code I have added the comment for the start and the end of attention. The model with attention also fits successfully, however, while constructing the encoder and decoder for generating predictions, I get:</p>
<pre><code>ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='input_1'), name='input_1', description=&quot;created by layer 'input_1'&quot;) at layer &quot;embedding&quot;. The following previous layers were accessed without issue: []
</code></pre>
<p>This is how my model looks like:
<a href=""https://i.stack.imgur.com/0PB9P.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/0PB9P.png"" alt=""model"" /></a></p>
",9417884.0,,,,,2023-06-30 05:10:37,"Keras, model trains successfully but generating predictions gives ValueError: Graph disconnected: cannot obtain value for tensor KerasTensor",<python><tensorflow><keras><attention-model><seq2seq>,1,4,0.0,,,CC BY-SA 4.0
71412499,1,71564427.0,,2022-03-09 16:11:26,,6,862,"<p>I'm using Tensorflow/Keras 2.4.1 and I have a (unsupervised) custom metric that takes several of my model inputs as parameters such as:</p>
<pre class=""lang-py prettyprint-override""><code>model = build_model() # returns a tf.keras.Model object
my_metric = custom_metric(model.output, model.input[0], model.input[1])
model.add_metric(my_metric)
[...]
model.fit([...]) # training with fit
</code></pre>
<p>However, it happens that <code>custom_metric</code> is very expensive so I would like it to be computed during validation only. I found this <a href=""https://stackoverflow.com/a/60829012/6315123"">answer</a> but I hardly understand how I can adapt the solution to my metric that uses several model inputs as parameter since the <code>update_state</code> method doesn't seem flexible.</p>
<p>In my context, is there a way to avoid computing my metric during training, aside from writing my own training loop ?
Also, I am very surprised we cannot natively specify to Tensorflow that some metrics should only be computed at validation time, is there a reason for that ?</p>
<p>In addition, since the model is trained to optimize the loss, and that the training dataset should not be used to evaluate a model, I don't even understand why, by default, Tensorflow computes metrics during training.</p>
",6315123.0,,10375049.0,,2022-03-23 08:04:45,2022-07-19 15:13:59,How to prevent Keras from computing metrics during training,<python><tensorflow><machine-learning><keras><deep-learning>,3,0,,,,CC BY-SA 4.0
71492778,1,,,2022-03-16 06:46:59,,6,8714,"<p>I want to save a Tensorflow model and then later use it for deployment purposes. I dont want to use <code>model.save()</code> to save it because my purpose is to somehow 'pickle' it and use it in a different system where tensorflow is not installed, like:</p>
<pre><code>model = pickle.load(open(path, 'rb'))
model.predict(prediction_array)
</code></pre>
<p>Earlier with sklearn, when i was pickling a KNN model, it was successful and i was able to run inference without installing sklearn.</p>
<p>But when I tried to pickle my Tensorflow model, I got this error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;e:/VA_nlu_addition_branch_lite/nlu_stable2/train.py&quot;, line 21, in &lt;module&gt;
pickle.dump(model, open('saved/model.p', 'wb'))
TypeError: can't pickle _thread.RLock objects
</code></pre>
<p>My model looks like this:</p>
<pre><code>model = keras.Sequential([
            keras.Input(shape=(len(x[0]))),
            keras.layers.Dense(units=16, activation='elu'),
            keras.layers.Dense(units=8, activation='elu'),
            keras.layers.Dense(units=len(y[0]), activation='softmax'),
        ])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(x, y, epochs=200, batch_size=8)
pickle.dump(model, open('saved/model.p', 'wb'))

</code></pre>
<p><strong>Model summary</strong></p>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense (Dense)                (None, 16)                1680
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 136
_________________________________________________________________
dense_2 (Dense)              (None, 20)                180
=================================================================
Total params: 1,996
Trainable params: 1,996
Non-trainable params: 0
</code></pre>
<p>Here is a <a href=""https://stackoverflow.com/questions/39514440/serve-tensorflow-model-without-installing-tensorflow"">StackOverflow question</a> regarding this problem, but the link in the answer was expired.</p>
<p>Also here is <a href=""https://stackoverflow.com/questions/56260192/load-tensorflow-model-without-importing-tensorflow"">another similar question</a>, but i didn't quite get it.</p>
<p>I have a very simple model, no checkpoints, nothing much complicated, so is there some way to save the Tensorflow model object to a binary file? Or even if its multiple binary files, i dont mind, but it just doesn't need to use tensoflow, if the <a href=""https://stackoverflow.com/questions/56260192/load-tensorflow-model-without-importing-tensorflow"">numpy solution</a> would help, i would use that, but i dont know how to implement it here. Any help would be appreciated, Thanks!</p>
",13903152.0,,,,,2023-05-15 12:20:38,how to save tensorflow model to pickle file,<python><tensorflow><keras><pickle>,2,1,,,,CC BY-SA 4.0
67171002,1,67185664.0,,2021-04-20 00:43:32,,6,565,"<p>I want to create a Tensorflow neural network model using the Functional API, but I'm not sure how to separate the input into two. I wanted to do something like: given an input, its first half goes to the first part of the neural network, its second half goes to the second part, and each input is passed through the layers until they concatenate, go through another layer and finally reach the output. I thought of something like the snippet of code below, along with a quick sketch.</p>
<pre><code>from tensorflow.keras.layers import Dense

def define_model(self):
    input1 = tf.keras.Input(shape=(4,)) #input is a 1D vector containing 7 elements, split as 4 and 3
    input2 = tf.keras.Input(shape=(3,))

    layer1_1 = Dense(4, activation=tf.nn.leaky_relu)(input1)
    layer2_1 = Dense(4, activation=tf.nn.leaky_relu)(layer1_1)

    layer1_2 = Dense(4, activation=tf.nn.leaky_relu)(input2)
    layer2_2 = Dense(3, activation=tf.nn.leaky_relu)(layer1_2)

    concat_layer = tf.keras.concatenate([layer2_1,layer2_2], axis = 0)
    layer3 = Dense(6, activation=tf.nn.leaky_relu)(concat_layer)

    output = Dense(4)(layer3) #no activation

    self.model = tf.keras.Model(inputs = [input1,input2],outputs = output)
    self.model.compile(loss = 'mean_squared_error', optimizer = 'rmsprop')
    return self.model
</code></pre>
<p><a href=""https://i.stack.imgur.com/QNBeD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QNBeD.png"" alt=""enter image description here"" /></a></p>
<p>First of all, should I add any Dropout or BatchNormalization layers in this model?</p>
<p>Also, the first 4 elements of the input array are binary (like [1,0,0,1] or [0,1,1,1]), while the other 3 can be any real number. Should I treat the 1st &quot;column&quot; of the neural network differently than the 2nd one, given that the first operates with inputs in the 0&lt;x&lt;1 range, while the 2nd one doesn't?</p>
<p>It sounds right, but I can't really test if it should work or not, as I would have to rework A LOT of the code to generate enough data to train it. Am I going in the right direction or should I be doing something different? Would this code work at all?</p>
<p>EDIT: I'm having issues during training. Suppose that I want to train the model like this (the values don't matter all that much, what's important is the data type):</p>
<pre><code>#this snippet generates training data - nothing real, just test examples. Also, I changed the output layer from 4 elements to just 1 to test it.
A1=[np.array([[1.,0,0,1]]),np.array([[0,1.,0]])]
B1=np.array([7])

c=np.array([[5,-4,1,-1],[2,3,-1]], dtype = object)
A2 = [[np.random.randint(2, size= [1,4]),np.random.randint(2, size= [1,3])] for i in range(1000)]
B2 = np.array([np.sum(A[i][0]*c[0])+np.sum(A[i][1]*c[1]) for i in range(1000)]) 

model.fit(A1,B1, epochs = 50, verbose=False) #this works!
model.fit(A2,B2, epochs = 50, verbose=False) #but this doesn't.


</code></pre>
<p>FINAL EDIT: here are the predict() and predict_on_batch() functions.</p>
<pre><code>def predict(a,b):
    pred = m.predict([a,b])
    return pred

def predict_b(c,d):
    preds = m.predict_on_batch([c,d])
    return preds

#a, b, c and d must look like this:
a = [np.array([0,1,0,1])]
b = [np.array([0,0,1])]

c =        [np.array([1, 0, 0, 1]), 
            np.array([0, 1, 1, 1]), 
            np.array([0, 1, 0, 0]), 
            np.array([1, 0, 0, 0]), 
            np.array([0, 0, 1, 0])] 

d =        [np.array([1, 0, 1]),
            np.array([0, 0, 1]),
            np.array([0, 1, 1]),
            np.array([1, 1, 1]),
            np.array([0, 0, 0])]
#notice that all of those should follow the same pattern, which is a list of arrays.
</code></pre>
<p>The rest of the code is under M. Innat's answer.</p>
",14559548.0,,14559548.0,,2021-04-21 01:20:36,2021-04-21 01:20:36,How to build a Tensorflow model with more than one input?,<python><tensorflow><keras><deep-learning>,1,6,0.0,,,CC BY-SA 4.0
63827339,1,69093914.0,,2020-09-10 10:04:39,,6,4621,"<p>I am working on Image Binarization using UNet and have a dataset of 150 images and their binarized versions too. My idea is to augment the images randomly to make them look like they are differentso I have made a function which inserts any of the 4-5 types of Noises, skewness, shearing and so on to an image. I could have easily used</p>
<p><code>ImageDataGenerator(preprocess_function=my_aug_function)</code> to augment the images but the problem is that my <strong>y target</strong> is also an image. Also, I could have used something like:</p>
<pre><code>train_dataset = (
    train_dataset.map(
        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE
    )
    .batch(batch_size)
    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
)
</code></pre>
<p>But it has 2 problems:</p>
<ol>
<li>With larger dataset, it'll blow up the memory as data needs to be already in the memory</li>
<li>This is the crucial part that I need to augment the images on the go to make it look like I have a huge dataset.</li>
</ol>
<p>Another Solution could be saving augmented images to a directory and making them 30-40K and then loading them. It would be silly thing to do.</p>
<p>Now the idea part is that I can use <code>Sequence</code> as the parent class but How can I keep on augmenting and generating new images on the fly with respective Y binarized images?</p>
<p>I have an idea as the below code. Can somebody help me with the augmentation and generation of y images. I have my <code>X_DIR, Y_DIR</code> where image names for binarised and original are same but stored in different directories.</p>
<pre><code>class DataGenerator(tensorflow.keras.utils.Sequence):
    def __init__(self, files_path, labels_path, batch_size=32, shuffle=True, random_state=42):
        'Initialization'
        self.files = files_path
        self.labels = labels_path
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.random_state = random_state
        self.on_epoch_end()


    def on_epoch_end(self):
        'Updates indexes after each epoch'
        # Shuffle the data here


    def __len__(self):
        return int(np.floor(len(self.files) / self.batch_size))

    def __getitem__(self, index):
        # What do I do here? 


    def __data_generation(self, files):
        # I think this is responsible for Augmentation but no idea how should I implement it and how does it works.

</code></pre>
",11725056.0,,,,,2022-12-26 15:12:49,How to build a Custom Data Generator for Keras/tf.Keras where X images are being augmented and corresponding Y labels are also images,<python><tensorflow><keras><deep-learning><tensorflow2.0>,3,0,0.0,,,CC BY-SA 4.0
67049352,1,67161157.0,,2021-04-11 19:30:03,,6,10113,"<p>The following error appears when I import the keras library</p>
<pre class=""lang-py prettyprint-override""><code>from keras.models import Sequential
from keras.layers import Dense, LSTM
</code></pre>
<blockquote>
<pre><code>AttributeError: module 'keras.utils.generic_utils' has no attribute
'populate_dict_with_module_objects
</code></pre>
</blockquote>
<p>I am working on windows 10 my keras version is: 2.4.3 and tensorflow version is 2.5.0rc0
I also installed cuda to solve the problem but it was not effective</p>
",15606452.0,,7023590.0,,2021-04-11 20:51:13,2021-04-19 11:29:32,AttributeError: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects',<python><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0
63779927,1,63780288.0,,2020-09-07 14:50:29,,6,5020,"<p><strong>Import libraries and models,</strong></p>
<pre><code>from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
import keras.backend as k

batch_size = 128
num_classes = 10
epochs = 12
</code></pre>
<p><strong>Below the written code,</strong></p>
<pre><code>#Loss and Optimizer
optimizer = keras.optimizers.Adam()
loss = keras.losses.categorical_crossentropy()
</code></pre>
<p><strong>Below the type error, which I badly faced and i can't make the solution,</strong></p>
<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-8-f3fea941b382&gt; in &lt;module&gt;()
      1 #Loss and Optimizer
      2 optimizer = keras.optimizers.Adam()
----&gt; 3 loss = keras.losses.categorical_crossentropy()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     &quot;&quot;&quot;Call target, and fall back on dispatchers if there is a TypeError.&quot;&quot;&quot;
    200     try:
--&gt; 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

TypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'
</code></pre>
<p><em><strong>Need help to solve this problem, please help me. Advanced thanks.</strong></em></p>
",14065992.0,,,,,2020-09-07 15:18:28,TypeError: categorical_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred',<python><keras><conv-neural-network>,1,0,,,,CC BY-SA 4.0
66961808,1,66961991.0,,2021-04-06 01:58:07,,6,4944,"<h1>Question</h1>
<p><code>float16</code> can be used in numpy but not in Tensorflow 2.4.1 causing the error.</p>
<p>Is float16 available only when running on an instance with GPU with 16 bit support?</p>
<p><a href=""https://www.tensorflow.org/guide/mixed_precision"" rel=""noreferrer"">Mixed precision</a></p>
<blockquote>
<p>Today, most models use the float32 dtype, which takes 32 bits of
memory. However, there are two lower-precision dtypes, float16 and
bfloat16, each which take 16 bits of memory instead. Modern
accelerators can run operations faster in the 16-bit dtypes, as they
have specialized hardware to run 16-bit computations and 16-bit dtypes
can be read from memory faster.</p>
<p>NVIDIA GPUs can run operations in float16 faster than in float32, and
TPUs can run operations in bfloat16 faster than float32. Therefore,
these lower-precision dtypes should be used whenever possible on those
devices. However, variables and a few computations should still be in
float32 for numeric reasons so that the model trains to the same
quality. The Keras mixed precision API allows you to use a mix of
either float16 or bfloat16 with float32, to get the performance
benefits from float16/bfloat16 and the numeric stability benefits from
float32.</p>
</blockquote>
<p>Then when testing on CPU, do I need to change the type manually to float32 to make it run? According to <a href=""https://github.com/tensorflow/tensorflow/issues/26033"" rel=""noreferrer"">[TF2.0] Change default types globally</a>, currently there is no option to change the default float precision.</p>
<h2>numpy</h2>
<pre><code>import numpy as np
np.arange(12, dtype=np.float16).reshape(3,4)
---
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.]], dtype=float16)
</code></pre>
<h2>Tensorflow</h2>
<pre><code>import tensorflow as tf
tf.reshape(tf.range(12, dtype=tf.float16), (3,4))
---
NotFoundError                             Traceback (most recent call last)
&lt;ipython-input-14-dbaa1413ee5c&gt; in &lt;module&gt;
      1 import tensorflow as tf
----&gt; 2 tf.reshape(tf.range(12, dtype=tf.float16), (3,4))

~/conda/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     &quot;&quot;&quot;Call target, and fall back on dispatchers if there is a TypeError.&quot;&quot;&quot;
    200     try:
--&gt; 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/conda/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py in range(start, limit, delta, dtype, name)
   1875     delta = cast(delta, inferred_dtype)
   1876 
-&gt; 1877     return gen_math_ops._range(start, limit, delta, name=name)
   1878 
   1879 

~/conda/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py in _range(start, limit, delta, name)
   7190       return _result
   7191     except _core._NotOkStatusException as e:
-&gt; 7192       _ops.raise_from_not_ok_status(e, name)
   7193     except _core._FallbackException:
   7194       pass

~/conda/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6860   message = e.message + (&quot; name: &quot; + name if name is not None else &quot;&quot;)
   6861   # pylint: disable=protected-access
-&gt; 6862   six.raise_from(core._status_to_exception(e.code, message), None)
   6863   # pylint: enable=protected-access
   6864 

~/.local/lib/python3.8/site-packages/six.py in raise_from(value, from_value)

NotFoundError: Could not find device for node: {{node Range}} = Range[Tidx=DT_HALF]
All kernels registered for op Range:
  device='CPU'; Tidx in [DT_INT64]
  device='CPU'; Tidx in [DT_INT32]
  device='CPU'; Tidx in [DT_DOUBLE]
  device='CPU'; Tidx in [DT_FLOAT]
 [Op:Range]
</code></pre>
<h1>Update</h1>
<p>When first create with float32 then cast to float16 works. Please advise why the error is caused.</p>
<pre><code>import tensorflow as tf
a = tf.reshape(tf.range(12, dtype=tf.float32), (3,4))
print(f&quot;a.dtype is {a.dtype}&quot;)

tf.cast(a, tf.float16)
---
a.dtype is &lt;dtype: 'float32'&gt;

&lt;tf.Tensor: shape=(3, 4), dtype=float16, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.]], dtype=float16)&gt;
</code></pre>
",4281353.0,,10908375.0,,2021-04-06 02:28:48,2021-04-06 02:28:48,tensorflow - how to use 16 bit precision float,<python><tensorflow><keras><precision>,1,0,0.0,,,CC BY-SA 4.0
63658086,1,63661721.0,,2020-08-30 13:46:16,,6,20097,"<p>I have a VAE architecture script as follows:</p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np

import tensorflow as tf

from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Lambda, Reshape, Layer
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K

INPUT_DIM = (64,64,3)

CONV_FILTERS = [32,64,64, 128]
CONV_KERNEL_SIZES = [4,4,4,4]
CONV_STRIDES = [2,2,2,2]
CONV_ACTIVATIONS = ['relu','relu','relu','relu']

DENSE_SIZE = 1024

CONV_T_FILTERS = [64,64,32,3]
CONV_T_KERNEL_SIZES = [5,5,6,6]
CONV_T_STRIDES = [2,2,2,2]
CONV_T_ACTIVATIONS = ['relu','relu','relu','sigmoid']

Z_DIM = 32

BATCH_SIZE = 100
LEARNING_RATE = 0.0001
KL_TOLERANCE = 0.5




class Sampling(Layer):
    def call(self, inputs):
        mu, log_var = inputs
        epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)
        return mu + K.exp(log_var / 2) * epsilon


class VAEModel(Model):


    def __init__(self, encoder, decoder, r_loss_factor, **kwargs):
        super(VAEModel, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.r_loss_factor = r_loss_factor

    def train_step(self, data):
        if isinstance(data, tuple):
            data = data[0]
        def compute_kernel(x, y):
            x_size = tf.shape(x)[0]
            y_size = tf.shape(y)[0]
            dim = tf.shape(x)[1]
            tiled_x = tf.tile(tf.reshape(x, tf.stack([x_size, 1, dim])), tf.stack([1, y_size, 1]))
            tiled_y = tf.tile(tf.reshape(y, tf.stack([1, y_size, dim])), tf.stack([x_size, 1, 1]))
            return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))

        def compute_mmd(x, y):
            x_kernel = compute_kernel(x, x)
            y_kernel = compute_kernel(y, y)
            xy_kernel = compute_kernel(x, y)
            return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)

        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(data)
            reconstruction = self.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.square(data - reconstruction), axis = [1,2,3]
            )
            reconstruction_loss *= self.r_loss_factor
            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
            kl_loss = tf.reduce_sum(kl_loss, axis = 1)
            kl_loss *= -0.5

            true_samples = tf.random.normal(tf.stack([BATCH_SIZE, Z_DIM]))
            loss_mmd = compute_mmd(true_samples, z)
            

            total_loss = reconstruction_loss + loss_mmd
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        return {
            &quot;loss&quot;: total_loss,
            &quot;reconstruction_loss&quot;: reconstruction_loss,
            &quot;kl_loss&quot;: kl_loss,
            &quot;mmd_loss&quot;: loss_mmd
        }
    
    def call(self,inputs):
        latent = self.encoder(inputs)
        return self.decoder(latent)



class VAE():
    def __init__(self):
        self.models = self._build()
        self.full_model = self.models[0]
        self.encoder = self.models[1]
        self.decoder = self.models[2]

        self.input_dim = INPUT_DIM
        self.z_dim = Z_DIM
        self.learning_rate = LEARNING_RATE
        self.kl_tolerance = KL_TOLERANCE

    def _build(self):
        vae_x = Input(shape=INPUT_DIM, name='observation_input')
        vae_c1 = Conv2D(filters = CONV_FILTERS[0], kernel_size = CONV_KERNEL_SIZES[0], strides = CONV_STRIDES[0], activation=CONV_ACTIVATIONS[0], name='conv_layer_1')(vae_x)
        vae_c2 = Conv2D(filters = CONV_FILTERS[1], kernel_size = CONV_KERNEL_SIZES[1], strides = CONV_STRIDES[1], activation=CONV_ACTIVATIONS[0], name='conv_layer_2')(vae_c1)
        vae_c3= Conv2D(filters = CONV_FILTERS[2], kernel_size = CONV_KERNEL_SIZES[2], strides = CONV_STRIDES[2], activation=CONV_ACTIVATIONS[0], name='conv_layer_3')(vae_c2)
        vae_c4= Conv2D(filters = CONV_FILTERS[3], kernel_size = CONV_KERNEL_SIZES[3], strides = CONV_STRIDES[3], activation=CONV_ACTIVATIONS[0], name='conv_layer_4')(vae_c3)

        vae_z_in = Flatten()(vae_c4)

        vae_z_mean = Dense(Z_DIM, name='mu')(vae_z_in)
        vae_z_log_var = Dense(Z_DIM, name='log_var')(vae_z_in)

        vae_z = Sampling(name='z')([vae_z_mean, vae_z_log_var])
        

        #### DECODER: 
        vae_z_input = Input(shape=(Z_DIM,), name='z_input')

        vae_dense = Dense(1024, name='dense_layer')(vae_z_input)
        vae_unflatten = Reshape((1,1,DENSE_SIZE), name='unflatten')(vae_dense)
        vae_d1 = Conv2DTranspose(filters = CONV_T_FILTERS[0], kernel_size = CONV_T_KERNEL_SIZES[0] , strides = CONV_T_STRIDES[0], activation=CONV_T_ACTIVATIONS[0], name='deconv_layer_1')(vae_unflatten)
        vae_d2 = Conv2DTranspose(filters = CONV_T_FILTERS[1], kernel_size = CONV_T_KERNEL_SIZES[1] , strides = CONV_T_STRIDES[1], activation=CONV_T_ACTIVATIONS[1], name='deconv_layer_2')(vae_d1)
        vae_d3 = Conv2DTranspose(filters = CONV_T_FILTERS[2], kernel_size = CONV_T_KERNEL_SIZES[2] , strides = CONV_T_STRIDES[2], activation=CONV_T_ACTIVATIONS[2], name='deconv_layer_3')(vae_d2)
        vae_d4 = Conv2DTranspose(filters = CONV_T_FILTERS[3], kernel_size = CONV_T_KERNEL_SIZES[3] , strides = CONV_T_STRIDES[3], activation=CONV_T_ACTIVATIONS[3], name='deconv_layer_4')(vae_d3)
        

        #### MODELS

    
        vae_encoder = Model(vae_x, [vae_z_mean, vae_z_log_var, vae_z], name = 'encoder')
        vae_decoder = Model(vae_z_input, vae_d4, name = 'decoder')

        vae_full = VAEModel(vae_encoder, vae_decoder, 10000)

        opti = Adam(lr=LEARNING_RATE)
        vae_full.compile(optimizer=opti)
        
        return (vae_full,vae_encoder, vae_decoder)

    def set_weights(self, filepath):
        self.full_model.load_weights(filepath)

    def train(self, data):

        self.full_model.fit(data, data,
                shuffle=True,
                epochs=1,
                batch_size=BATCH_SIZE)
        
    def save_weights(self, filepath):
        self.full_model.save_weights(filepath)
</code></pre>
<p>Problem:</p>
<pre class=""lang-py prettyprint-override""><code>vae = VAE()
vae.set_weights(filepath)
</code></pre>
<p>throws:</p>
<blockquote>
<pre class=""lang-py prettyprint-override""><code>File
&quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py&quot;,
line 2200, in load_weights
    'Unable to load weights saved in HDF5 format into a subclassed ' ValueError: Unable to load weights saved in HDF5 format into a
subclassed Model which has not created its variables yet. Call the
Model first, then load the weights.
</code></pre>
</blockquote>
<p>I am not sure what this means since I am not that proficient in OOP. The surprising bit is that the above code was working until it stopped working. The model is training from scratch and it saves the weights in <code>filepath</code>. But when I am loading the same weights now it is throwing the above error!</p>
",5112168.0,,588437.0,,2020-08-30 17:52:21,2023-03-27 05:38:28,Tensorflow 2.0 ValueError while Loading weights from .h5 file,<python><keras><tensorflow2.0>,6,0,0.0,,,CC BY-SA 4.0
66814443,1,66814712.0,,2021-03-26 09:46:00,,6,1490,"<p>I would like to integrate the <a href=""https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits"" rel=""noreferrer"">weighted_cross_entropy_with_logits</a> to deal with data imbalance. I am not sure how to do it. Class 0 has 10K images, while class 1 has 500 images. Here is my code.</p>
<pre><code>model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(dim, dim, 3), activation='relu'),
    ....
    tf.keras.layers.Dense(2, activation='softmax')
])

model.compile(optimizer=&quot;nadam&quot;,
              loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=['accuracy'])


class_weight = {0: 1.,
                1: 20.}

model.fit(
    train_ds,
    val_ds,
    epochs=epc,
    verbose=1,
    class_weight=class_weight)
</code></pre>
",10868301.0,,,,,2021-03-26 10:00:53,How to define a weighted loss function for TF2.0+ keras CNN for image classification?,<python><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0
63754311,1,63754719.0,,2020-09-05 13:14:56,,6,27188,"<p>Hello I am training a model with TensorFlow and Keras, and the dataset was downloaded from <a href=""https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765"" rel=""noreferrer"">https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765</a></p>
<p>This is a zip folder that I split in the following directories:</p>
<pre><code>.
├── test
│   ├── Cat
│   └── Dog
└── train
    ├── Cat
    └── Dog
</code></pre>
<p>Test.cat and test.dog have each folder 1000 jpg photos, and train.cat and traing.dog have each folder 11500 jpg photos.</p>
<p>The load is doing with this code:</p>
<pre><code>batch_size = 16

# Data augmentation and preprocess
train_datagen = ImageDataGenerator(rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.20) # set validation split

# Train dataset
train_generator = train_datagen.flow_from_directory(
    'PetImages/train',
    target_size=(244, 244),
    batch_size=batch_size,
    class_mode='binary',
    subset='training') # set as training data

# Validation dataset
validation_generator = train_datagen.flow_from_directory(
    'PetImages/train',
    target_size=(244, 244),
    batch_size=batch_size,
    class_mode='binary',
    subset='validation') # set as validation data

test_datagen = ImageDataGenerator(rescale=1./255)
# Test dataset
test_datagen = test_datagen.flow_from_directory(
    'PetImages/test')
</code></pre>
<p>THe model is training with the following code:</p>
<pre><code>history = model.fit(train_generator,
                    validation_data=validation_generator,
                    epochs=5)
</code></pre>
<p>And i get the following input:</p>
<pre><code>Epoch 1/5
1150/1150 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9906
</code></pre>
<p>But when the epoch is in this point I get the following error:</p>
<blockquote>
<p>UnidentifiedImageError: cannot identify image file &lt;_io.BytesIO object
at 0x7f9e185347d0&gt;</p>
</blockquote>
<p>How can I solve this, in order to finish the training?</p>
<p>Thanks</p>
",3672883.0,,,,,2023-02-06 13:24:35,UnidentifiedImageError: cannot identify image file,<python><tensorflow><keras>,5,4,0.0,,,CC BY-SA 4.0
63687314,1,63843517.0,,2020-09-01 12:05:21,,6,3911,"<p>I have, thanks to <a href=""https://stackoverflow.com/questions/54402866/why-does-tensorflow-take-more-gpu-ram-than-the-model-file"">this</a> question mostly been able to solve the problem of tensorflow allocating memory which I didn't want allocated. However, I have recently found that despite my using set_session with allow_growth=True, using model.fit will still mean that all the memory is allocated and I can no longer use it for the rest of my program, even when the function is exited and the model should no longer have any allocated memory due to the fact that the model is a local variable.
Here is some example code demonstrating this:</p>
<pre><code>from numpy import array
from keras import Input, Model
from keras.layers import Conv2D, Dense, Flatten
from keras.optimizers import SGD

# stops keras/tensorflow from allocating all the GPU's memory immediately
from tensorflow.compat.v1.keras.backend import set_session
from tensorflow.compat.v1 import Session, ConfigProto, GPUOptions
tf_config = ConfigProto(gpu_options=GPUOptions(allow_growth=True))
session = Session(config=tf_config)
set_session(session)


# makes the neural network
def make_net():
    input = Input((2, 3, 3))
    conv = Conv2D(256, (1, 1))(input)
    flattened_input = Flatten()(conv)
    output = Dense(1)(flattened_input)
    model = Model(inputs=input, outputs=output)
    sgd = SGD(0.2, 0.9)
    model.compile(sgd, 'mean_squared_error')
    model.summary()
    return model


def make_data(input_data, target_output):
    input_data.append([[[0 for i in range(3)] for j in range(3)] for k in range(2)])
    target_output.append(0)


def main():
    data_amount = 4096
    input_data = []
    target_output = []
    model = make_model()
    for i in range(data_amount):
        make_data(input_data, target_output)
    model.fit(array(input_data), array(target_output),  batch_size=len(input_data))
    return


while True:
    main()
</code></pre>
<p>When I run this code with the Pycharm debugger, I find that the GPU RAM used stays at around 0.1GB until I run model.fit for the first time, at which point the memory usage shoots up to 3.2GB of my 4GB of GPU RAM. I have also noted that the memory usage doesn't increase after the first time that model.fit is run and that if I remove the convolutional layer from my network, the memory increase doesn't happen at all.
Could someone please shine some light on my problem?</p>
<p>UPDATE: Setting per_process_gpu_memory_fraction in GPUOptions to 0.1 helps limit the effect in the code included, but not in my actual program. A better solution would still be helpful.</p>
",10788239.0,,10788239.0,,2020-09-02 16:59:30,2021-07-14 07:38:26,Why does keras model.fit use so much memory despite using allow_growth=True?,<python><tensorflow><memory><keras>,2,2,,,,CC BY-SA 4.0
66514664,1,,,2021-03-07 08:44:44,,6,1842,"<p>My OC is big sur for apple M1, therefore my tensorflow version is 2.4 which has been installed from official apple github repo(<a href=""https://github.com/apple/tensorflow_macos"" rel=""nofollow noreferrer"">https://github.com/apple/tensorflow_macos</a>). When i use code bellow, i get tensor(&lt;tf.Tensor 'StatefulPartitionedCall:0' shape=(1, 2880, 4320, 3) dtype=float32&gt;)</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import tensorflow_hub as hub
from PIL import Image
import numpy as np

from tensorflow.python.compiler.mlcompute import mlcompute
from tensorflow.python.framework.ops import disable_eager_execution
disable_eager_execution()
mlcompute.set_mlc_device(device_name='gpu') # Available options are 'cpu', 'gpu', and 'any'.
tf.config.run_functions_eagerly(False)
print(tf.executing_eagerly())

image = np.asarray(Image.open('/Users/alex26/Downloads/face.jpg'))
image = tf.cast(image, tf.float32)
image = tf.expand_dims(image, 0)

model = hub.load(&quot;https://tfhub.dev/captain-pool/esrgan-tf2/1&quot;)
sr = model(image) #&lt;tf.Tensor 'StatefulPartitionedCall:0' shape=(1, 2880, 4320, 3)dtype=float32&gt;
</code></pre>
<p><strong>How to get image from sr Tensor?</strong></p>
",14426701.0,,14426701.0,,2021-03-09 17:45:22,2021-03-12 20:54:24,Convert tf.Tensor to numpy array and than save it as image in without eager_execution,<python><tensorflow><keras>,3,0,,,,CC BY-SA 4.0
66508872,1,,,2021-03-06 17:54:46,,6,6415,"<p>I am working on a project on Python that detects disease on leaves and sprays fertilizer on the leaf.</p>
<p>After many hours of troubleshooting other errors, I came down to the following final error that always happens and I can't seem to fix.</p>
<p>Following are the versions I have used for the dependencies so far:</p>
<ul>
<li>keras = 2.4.3</li>
<li>cv2 = 4.5.1</li>
<li>numpy = 1.20.1</li>
<li>tensorflow = 2.4.0</li>
<li>h5py = 3.2.1</li>
<li>pandas = 1.2.3</li>
</ul>
<p>Error that I am facing:</p>
<pre><code>Traceback (most recent call last):
  File &quot;leaf_cnn.py&quot;, line 12, in &lt;module&gt;
    model = load_model('Leaf_CNN.h5')
  File &quot;/home/pi/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py&quot;, line 207, in load_model
    compile)
  File &quot;/home/pi/.local/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py&quot;, line 182, in load_model_from_hdf5
    model_config = json_utils.decode(model_config.decode('utf-8'))
AttributeError: 'str' object has no attribute 'decode'
</code></pre>
<p>Code file leaf_cnn.py</p>
<pre><code># importing files/dependencies

from tensorflow.keras.models import load_model
import cv2
import numpy as np
#import Categories
import time
import RPi.GPIO as GPIO

#loading model/ML algorithm 

model = load_model('Leaf_CNN.h5')
cap = cv2.VideoCapture(0) # capture frame
ret, img = cap.read()

channel = 21 
GPIO.setmode(GPIO.BCM)
GPIO.setup(channel,GPIO.OUT)
#cv2.imshow('aaa',img)  'display image with title'

img = cv2.resize(img,(224,224)) 
img = np.reshape(img,[1,224,224,3])
classes = model.predict(img)
y_pred = np.argmax(classes, axis=1)
y_pred = Categories.categories[int(y_pred)]

if &quot;healthy&quot; not in y_pred:
    GPIO.output(21, GPIO.HIGH) #turn-on relay
    time.sleep(1)
else:
    GPIO.output(21, GPIO.LOW) #turn-off relay
    time.sleep(1)
#cv2.waitKey(0)
#cv2.destroyAllWindows()
</code></pre>
",15343775.0,,15343775.0,,2021-03-06 18:12:53,2021-03-26 19:56:13,model_config = json_utils.decode(model_config.decode('utf-8')) AttributeError: 'str' object has no attribute 'decode',<python><numpy><tensorflow><keras><raspberry-pi>,1,2,,,,CC BY-SA 4.0
63703280,1,,,2020-09-02 10:07:34,,6,6287,"<p>I have trained the CNN to classify images on 3 class.
while training the model i have used ImageDataGenerator class from keras to apply preprocessing function on image and rescale it.
Now my network is trained with a good accuracy on test set, but i don't know how to apply preprocessing function on single image prediction. If i use ImageDataGenerator it looks for directory.
Suggest me some alternatives to do preprocessing function and rescaling on single image.
see my code below</p>
<p>TRAINING SET:</p>
<pre><code>train_datagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input,
                                   rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)
training_set = train_datagen.flow_from_directory('./training_set',
                                                 target_size = (224, 224),
                                                 batch_size = 10,
                                                 class_mode = 'categorical')
</code></pre>
<p>TESTING SET:</p>
<pre><code>test_datagen =ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,                                                            
                                                         rescale = 1./255)
test_set = test_datagen.flow_from_directory('./test_set',
                                            target_size = (224, 224),
                                            batch_size = 10,
                                            shuffle=False,
                                            class_mode = 'categorical') 
</code></pre>
<p>Now,im unable to apply preprocessing function and rescaling on single image before prediction.
SINGLE PREDICTION:</p>
<pre><code>single_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input,
                                   rescale = 1./255)
single_test = single_datagen.flow_from_directory('./single_prediction/cc.jpg',
                                            target_size = (224, 224),
                                            batch_size = 1,
                                            class_mode = 'categorical') 
</code></pre>
<p>ERROR:
NotADirectoryError: [Errno 20] Not a directory: './single_prediction/cc.jpg'</p>
",13780005.0,,13780005.0,,2020-09-02 10:13:44,2021-03-12 09:02:50,How to predict a single image with Keras ImageDataGenerator?,<python><image><tensorflow><keras><conv-neural-network>,2,1,0.0,,,CC BY-SA 4.0
68737130,1,68737211.0,,2021-08-11 06:39:32,,6,23312,"<p>I want to <code>import keras</code> after I did <code>pip install keras</code>, but it shows message as shown below. I even can't call any function from keras library. Can anyone know about this?</p>
<pre><code>import keras
</code></pre>
<p>Error:</p>
<pre><code>AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'register_clear_session_function'
</code></pre>
",14761117.0,,2423278.0,,2021-08-11 06:43:25,2023-06-27 17:40:13,Error while import keras: AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'register_clear_session_function',<python><keras>,5,0,,,,CC BY-SA 4.0
68835665,1,,,2021-08-18 15:57:19,,6,3229,"<p>I am trying to use a BERT pretrained model to do a multiclass classification (of 3 classes). Here's my function to use the model and also added some extra functionalities:</p>
<pre><code>def create_model(max_seq_len, bert_ckpt_file):

  with tf.io.gfile.GFile(bert_config_file, &quot;r&quot;) as reader:
      bc = StockBertConfig.from_json_string(reader.read())
      bert_params = map_stock_config_to_params(bc)
      bert_params.adapter_size = None
      bert = BertModelLayer.from_params(bert_params, name=&quot;bert&quot;)
        
  input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=&quot;input_ids&quot;)
  bert_output = bert(input_ids)

  print(&quot;bert shape&quot;, bert_output.shape)

  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)
  cls_out = keras.layers.Dropout(0.5)(cls_out)
  logits = keras.layers.Dense(units=768, activation=&quot;tanh&quot;)(cls_out)
  logits = keras.layers.Dropout(0.5)(logits)
  logits = keras.layers.Dense(units=len(classes), activation=&quot;softmax&quot;)(logits)

  model = keras.Model(inputs=input_ids, outputs=logits)
  model.build(input_shape=(None, max_seq_len))

  load_stock_weights(bert, bert_ckpt_file)
        
  return model
</code></pre>
<p>Now when I am trying to call the function, I am getting error. The parameter values have max_seq_len = 128, bert_ckpt_file = bert checkpoint file.</p>
<pre><code>model = create_model(data.max_seq_len, bert_ckpt_file)
</code></pre>
<p>I am getting the following error:</p>
<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-41-9609c396a3ce&gt; in &lt;module&gt;()
----&gt; 1 model = create_model(data.max_seq_len, bert_ckpt_file)

5 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    693       except Exception as e:  # pylint:disable=broad-except
    694         if hasattr(e, 'ag_error_metadata'):
--&gt; 695           raise e.ag_error_metadata.to_exception(e)
    696         else:
    697           raise

TypeError: in user code:

    /usr/local/lib/python3.7/dist-packages/bert/model.py:80 call  *
        output           = self.encoders_layer(embedding_output, mask=mask, training=training)
    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1030 __call__  **
        self._maybe_build(inputs)
    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:2659 _maybe_build
        self.build(input_shapes)  # pylint:disable=not-callable
    /usr/local/lib/python3.7/dist-packages/bert/transformer.py:209 build
        self.input_spec = keras.layers.InputSpec(shape=input_shape)
    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:2777 __setattr__
        super(tf.__internal__.tracking.AutoTrackable, self).__setattr__(name, value)  # pylint: disable=bad-super-call
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:530 _method_wrapper
        result = method(self, *args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1297 input_spec
        'Got: {}'.format(v))

    TypeError: Layer input_spec must be an instance of InputSpec. Got: InputSpec(shape=(None, 128, 768), ndim=3)
</code></pre>
",16558440.0,,,,,2022-08-24 21:23:44,"TypeError: Layer input_spec must be an instance of InputSpec. Got: InputSpec(shape=(None, 128, 768), ndim=3)",<python><tensorflow><keras><deep-learning><bert-language-model>,3,5,0.0,,,CC BY-SA 4.0
62917349,1,63042165.0,,2020-07-15 14:33:03,,6,2831,"<p>Consider the following code that works with a Keras Sequential model on the CIFAR-10 data set. Background is given at the end of the post:</p>
<pre><code>import tensorflow as tf
from sklearn.datasets import fetch_openml
from sklearn.utils import shuffle

data, targets = shuffle(*fetch_openml('CIFAR_10', version=1, return_X_y=True))
train_sz = 50000
X_train, X_test, y_train, y_test = data[:train_sz, :], data[train_sz:, :], np.asarray(targets[:train_sz], dtype=np.int), np.asarray(targets[train_sz:], dtype=np.int)

model = tf.keras.Sequential()
model.add(tf.keras.Input(shape=(X_train.shape[1],)))
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(10))
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam')

s = 0
for _ in range(500):
    for i in range(100):
        layers = []
        for layer in model.get_weights():
            layers.append(np.random.normal(0, 1, layer.shape))
        model.set_weights(layers)
        eval = model.evaluate(X_train, y_train)
        s += eval
        print(f'Done {i}')
print(s)
</code></pre>
<p>After about 1 (sometimes a little before that, sometimes a little after) iteration of the outer for loop, Python crashes with exit code <code>137</code>, which usually means out of memory AFAIK. I have 16 GB of memory on my system, of which about 20% is used before running this. After running it, it steadily increases up to
about 80%-90% memory usage, then drops to 60%-70% (GC kicking in?), then increases again and so on for 2-3 times until it finally crashes.</p>
<p>I'm on a headless Ubuntu 18.04 Server machine, with Python 3.7 in Anaconda, on Tensorflow 2.2 with a Titan X GTX GPU that is not being used for anything else (so about 11GB of memory free there).</p>
<p>My calculations (very pessimistic, to be sure):</p>
<ol>
<li>I have about 12 GB free when I run this.</li>
<li>Storing the data uses <code>60000*32*32*3</code> floating point numbers, which is about <code>1500 MB</code> for float64s. Let's put down <strong>6 GB</strong> here because of all the copies I'm making. Regardless, it looks like this is what uses the most memory.</li>
<li>The layer sizes are negligible at this point: <code>X_train.shape[1]</code> is 3072 (<code>32*32*3</code>), and 64 hidden units is nothing.</li>
<li><code>model.evaluate</code> has a default batch size of 32, so inside it, it should use about <code>32*32*32*3*64</code> float64s for the output of the middle layer. That's 50 MB, let's put in <strong>1 GB</strong> here just to be sure again.</li>
<li><code>model.evaluate</code> probably also needs to store the predictions, so that's <code>50000*10</code> float64s, which is another 4 MB. Let's put in another <strong>1 GB</strong> here for good measure.</li>
</ol>
<p>Total: <strong>6 + 1 + 1 = 8 GB</strong>. My memory usage should absolutely not exceed 80%, and I have overestimated the calculations by a lot.</p>
<p>Why is so much memory being used and can I optimize anything in how I manage the data?</p>
<p>I've tried forcing the X's to <code>np.int</code> using <code>np.asarray</code>, there's no point for float64s there, but that just makes it crash much faster - it's like it keeps both the float64s and the ints in memory or something.</p>
<p><strong>Background</strong></p>
<p>I'm working on a genetic algorithm that trains artificial neural networks. I've traced the crash to the computation of the fitnesses, which involves applying the trained weights stored in each individual to the neural network and evaluating the network (inner <code>i</code> loop, I have 100 individuals in my population). This is repeated for each generation (outermost for loop). A bit more memory is used there, but still very little.</p>
<p>That is why there is no fitting going on here, the weights are determined by my genetic algorithm and applied to the network.</p>
<p>This reduced code reproduces the issue.</p>
",270287.0,,270287.0,,2020-07-15 20:11:10,2020-08-18 04:12:19,Python Keras code out of memory for no apparent reason,<python><python-3.x><numpy><tensorflow><keras>,3,5,0.0,,,CC BY-SA 4.0
62771845,1,,,2020-07-07 09:12:50,,6,7899,"<p>I want to use the BERT Word Vector Embeddings in the Embeddings layer of LSTM instead of the usual default embedding layer. Is there any way I can do it?</p>
",10097229.0,,,,,2022-03-12 04:32:56,Using BERT Embeddings in Keras Embedding layer,<python-3.x><keras><nlp><embedding><bert-language-model>,1,7,0.0,,,CC BY-SA 4.0
63399368,1,,,2020-08-13 16:25:41,,6,1388,"<p>I'm using <code>StaticHashTable</code> as in one Lambda layer after the output layer of my tf.keras model. It's quite simple actually: I've a text classification models and I'm adding a simple lambda layer that takes the <code>model.output</code> and convert the model_id to more general labels. I can save this version of model with model.save(... as H5 format..) without any issue, and can load it back and use it without any problem.</p>
<p>Issue is, when I try to export my TF2.2.0 model for TF-Serving, I can't find how I can export it. Here is what I can do with TF1.X or with <code>TF2.X + tf.compat.v1.disable_eager_execution()</code></p>
<pre class=""lang-py prettyprint-override""><code>tf.compat.v1.disable_eager_execution()
version = 1
name = 'tmp_model'
export_path = f'/opt/tf_serving/{name}/{version}'
builder = saved_model_builder.SavedModelBuilder(export_path)

model_signature = tf.compat.v1.saved_model.predict_signature_def(
    inputs={
        'input': model.input
    }, 
    outputs={
        'output': model.output
    }
)

with tf.compat.v1.keras.backend.get_session() as sess:
    builder.add_meta_graph_and_variables(
        sess=sess,
        tags=[tf.compat.v1.saved_model.tag_constants.SERVING],
        signature_def_map={
            'predict': model_signature
        },
        # For initializing Hashtables
        main_op=tf.compat.v1.tables_initializer()
    )
    builder.save()
</code></pre>
<p>This will save my models with TF1.X format for serving and I can use it without any issue. Things is, I'm using LSTM layer and I want to use my model on GPU. By the documentation, if I disable the eager mode, I can't use the GPU-version of LSTM with TF2.2. And without going through above mentioned code, I can't save my model for serving wrt TF2.2 standard and StaticHashTables.</p>
<p>Here is how I'm trying to export my TF2.2 model which is using StaticHashTables in final layer; and which is giving error as below:</p>
<pre class=""lang-py prettyprint-override""><code>class MyModule(tf.Module):

    def __init__(self, model):
        super(MyModule, self).__init__()
        self.model = model
    
    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 16), dtype=tf.int32, name='input')])
    def predict(self, input):
        result = self.model(input)
        return {&quot;output&quot;: result}

version = 1
name = 'tmp_model'
export_path = f'/opt/tf_serving/{name}/{version}'

module = MyModule(model)
tf.saved_model.save(module, export_path, signatures={&quot;predict&quot;: module.predict.get_concrete_function()})
</code></pre>
<p><strong>Error:</strong></p>
<pre class=""lang-sh prettyprint-override""><code>AssertionError: Tried to export a function which references untracked object Tensor(&quot;2907:0&quot;, shape=(), dtype=resource).
TensorFlow objects (e.g. tf.Variable) captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.
</code></pre>
<p>Any suggestion or am I missing anything on exporting TF2.2 model which is using the <code>StaticHashTables</code> in final Lambda layer for TensorFlow Serving?</p>
<p>More info here: <a href=""https://github.com/tensorflow/serving/issues/1719"" rel=""noreferrer"">https://github.com/tensorflow/serving/issues/1719</a></p>
<p>Thanks!</p>
",4496896.0,,4496896.0,,2021-12-04 18:18:19,2021-12-04 18:18:19,Error with exporting TF2.2.0 model with tf.lookup.StaticHashTable for Serving,<tensorflow><keras><tensorflow2.0><tf.keras><tensorflow-serving>,1,0,,,,CC BY-SA 4.0
65963752,1,66000444.0,,2021-01-30 01:21:02,,6,906,"<p>I have built a model that takes 3 images of a time series along with 5 numerical information as input and produces the next three images of the time series.
I accomplished this by:</p>
<ol>
<li>Build a ConvLSTM2D model for processing the images (pretty similar to the example listed on Keras documentation <a href=""https://keras.io/examples/vision/conv_lstm/"" rel=""noreferrer"">here</a>). Input size=(3x128x128x3)</li>
<li>Build a simple model for tabular data with a few Dense layers. Input size=(1,5)</li>
<li>Concatenate these two models</li>
<li>Have a Conv3D model that produces the next 3 images</li>
</ol>
<p>The LSTM models produces output of size 393216 (3x128x128x8). Now I had to set the output of tabular model to 49,152 so that I can have the input size of 442368 (3x128x128x9) in the next layer. So this unnecessary inflation of tabular model's Dense layer makes the otherwise efficient LSTM model perform awfully.</p>
<p>Is there a better way to concatenate the two models? Is there a way I can just have an output of 10 in the tabular model's Dense layer?</p>
<p>The model:</p>
<pre><code>x_input = Input(shape=(None, 128, 128, 3))
x = ConvLSTM2D(32, 3, strides = 1, padding='same', dilation_rate = 2,return_sequences=True)(x_input)
x = BatchNormalization()(x)
x = ConvLSTM2D(16, 3, strides = 1, padding='same', dilation_rate = 2,return_sequences=True)(x)
x = BatchNormalization()(x)
x = ConvLSTM2D(8, 3, strides = 1, padding='same', dilation_rate = 2,return_sequences=True)(x)
x = BatchNormalization()(x)
x = Flatten()(x)
# x = MaxPooling3D()(x)

x_tab_input = Input(shape=(5))
x_tab = Dense(100, activation=&quot;relu&quot;)(x_tab_input)
x_tab = Dense(49152, activation=&quot;relu&quot;)(x_tab)
x_tab = Flatten()(x_tab)

concat = Concatenate()([x, x_tab])

output = Reshape((3,128,128,9))(concat)
output = Conv3D(filters=3, kernel_size=(3, 3, 3), activation='relu', padding=&quot;same&quot;)(output)
model = Model([x_input, x_tab_input], output)
model.compile(loss='mae', optimizer='rmsprop')
</code></pre>
<p>Model Summary:</p>
<pre><code>Model: &quot;functional_3&quot;
______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to                                      
======================================================================================================================================================
input_4 (InputLayer)                             [(None, None, 128, 128, 3)]      0                                                                   
______________________________________________________________________________________________________________________________________________________
conv_lst_m2d_9 (ConvLSTM2D)                      (None, None, 128, 128, 32)       40448             input_4[0][0]                                     
______________________________________________________________________________________________________________________________________________________
batch_normalization_9 (BatchNormalization)       (None, None, 128, 128, 32)       128               conv_lst_m2d_9[0][0]                              
______________________________________________________________________________________________________________________________________________________
conv_lst_m2d_10 (ConvLSTM2D)                     (None, None, 128, 128, 16)       27712             batch_normalization_9[0][0]                       
______________________________________________________________________________________________________________________________________________________
batch_normalization_10 (BatchNormalization)      (None, None, 128, 128, 16)       64                conv_lst_m2d_10[0][0]                             
______________________________________________________________________________________________________________________________________________________
input_5 (InputLayer)                             [(None, 5)]                      0                                                                   
______________________________________________________________________________________________________________________________________________________
conv_lst_m2d_11 (ConvLSTM2D)                     (None, None, 128, 128, 8)        6944              batch_normalization_10[0][0]                      
______________________________________________________________________________________________________________________________________________________
dense (Dense)                                    (None, 100)                      600               input_5[0][0]                                     
______________________________________________________________________________________________________________________________________________________
batch_normalization_11 (BatchNormalization)      (None, None, 128, 128, 8)        32                conv_lst_m2d_11[0][0]                             
______________________________________________________________________________________________________________________________________________________
dense_1 (Dense)                                  (None, 49152)                    4964352           dense[0][0]                                       
______________________________________________________________________________________________________________________________________________________
flatten_3 (Flatten)                              (None, None)                     0                 batch_normalization_11[0][0]                      
______________________________________________________________________________________________________________________________________________________
flatten_4 (Flatten)                              (None, 49152)                    0                 dense_1[0][0]                                     
______________________________________________________________________________________________________________________________________________________
concatenate (Concatenate)                        (None, None)                     0                 flatten_3[0][0]                                   
                                                                                                    flatten_4[0][0]                                   
______________________________________________________________________________________________________________________________________________________
reshape_2 (Reshape)                              (None, 3, 128, 128, 9)           0                 concatenate[0][0]                                 
______________________________________________________________________________________________________________________________________________________
conv3d_2 (Conv3D)                                (None, 3, 128, 128, 3)           732               reshape_2[0][0]                                   
======================================================================================================================================================
Total params: 5,041,012
Trainable params: 5,040,900
Non-trainable params: 112
______________________________________________________________________________________________________________________________________________________
</code></pre>
",499996.0,,,,,2021-02-02 08:21:19,Better way to concatenate ConvLSTM2D model and Tabular model,<tensorflow><machine-learning><keras><lstm>,1,1,0.0,,,CC BY-SA 4.0
63321892,1,63442865.0,,2020-08-09 02:17:17,,6,9691,"<p>I am wondering if I can be able to use OpenAI GPT-3 for transfer learning in a text classification problem?
If so, how can I get start on it using Tensorflow, Keras.</p>
",3593041.0,,1243762.0,,2020-11-29 11:46:41,2020-11-29 11:46:41,How can I use GPT 3 for my text classification?,<keras><text-classification><transfer-learning><openai-api><gpt-3>,1,7,0.0,,,CC BY-SA 4.0
63286750,1,63287068.0,,2020-08-06 15:21:31,,6,3130,"<p>Consider the following custom layer code from a TensorFlow tutorial:</p>
<pre><code>class MyDenseLayer(tf.keras.layers.Layer):
  def __init__(self, num_outputs):
    super(MyDenseLayer, self).__init__()
    self.num_outputs = num_outputs

  def build(self, input_shape):
    self.kernel = self.add_weight(&quot;kernel&quot;,
                                  shape=[int(input_shape[-1]),
                                         self.num_outputs])

  def call(self, input):
    return tf.matmul(input, self.kernel)
</code></pre>
<p>How do I apply any pre-defined regularization (say <code>tf.keras.regularizers.L1</code>) or custom regularization on the parameters of the custom layer?</p>
",7144225.0,,2099607.0,,2020-08-06 15:40:14,2020-08-06 15:40:14,How to apply kernel regularization in a custom layer in Keras/TensorFlow?,<python><tensorflow><machine-learning><keras><regularized>,1,0,0.0,,,CC BY-SA 4.0
65993065,1,,,2021-02-01 12:53:34,,6,2673,"<p>We can pass the <code>training = False</code> argument while calling the pre-trained model when using Keras Functional API as shown in <a href=""https://keras.io/guides/transfer_learning/#transfer-learning-amp-finetuning"" rel=""noreferrer"">this</a> tutorial.</p>
<p>How to implement the same in Keras Sequential API?</p>
<p>Here's the code which I am trying to replicate using Sequential API:</p>
<pre><code>inputs = tf.keras.Input( shape = ( TARGET_SIZE[0], TARGET_SIZE[1], 3 ) )
base_model = Xception( include_top = False, pooling = 'avg' )
base_model.trainable = False
x = base_model( inputs, training = False ) 
x = Dense( 512, activation = 'relu' )( x )
x = Dense( 256, activation = 'relu' )( x )
x = Dense( 128, activation = 'relu' )( x )
outputs = Dense( 6, activation = 'softmax' )( x )
</code></pre>
<p>Below is the code implementing this whole model <em>without</em> <code>training = False</code> using Sequential API like below:</p>
<pre><code>model = Sequential()
model.add( Xception( include_top = False, pooling = 'avg', input_shape = ( TARGET_SIZE[0], TARGET_SIZE[1], 3 ) ) )
model.add( Dense( units = 512, activation = 'relu' ) )
model.add( Dense( units = 256, activation = 'relu' ) )
model.add( Dense( units = 128, activation = 'relu' ) )
model.add( Dense( 6, activation = 'softmax' ) )
</code></pre>
<p>But, I am unable to squeeze in the <code>training = False</code> argument with it.</p>
",10797659.0,,4685471.0,,2021-02-01 20:06:48,2023-02-20 07:33:56,training = False in Keras Sequential API,<tensorflow><machine-learning><keras><neural-network>,2,7,,,,CC BY-SA 4.0
68976745,1,68980531.0,,2021-08-29 20:42:26,,6,3474,"<p>I'm currently building a GAN with Tensorflow 2 and Keras and noticed a lot of the existing Neural Networks for the generator and discriminator use Conv2D and Conv2DTranspose in Keras.</p>
<p>I'm struggling to find something that functionally explains the difference between the two. Can anyone explain what these two different options for making a NN in Keras mean?</p>
",14528328.0,,,,,2022-09-12 08:35:56,In Keras what is the difference between Conv2DTranspose and Conv2D,<tensorflow><keras><conv-neural-network><convolution><deconvolution>,1,0,0.0,,,CC BY-SA 4.0
62743531,1,62747179.0,,2020-07-05 16:39:07,,6,3691,"<p>I have trained fasttext model with Gensim over the corpus of very short sentences (up to 10 words). I know that my test set includes words that are not in my train corpus, i.e some of the words in my corpus are like &quot;Oxytocin&quot; &quot;Lexitocin&quot;, &quot;Ematrophin&quot;,'Betaxitocin&quot;</p>
<p>given a new word in the test set, fasttext knows pretty well to generate a vector with high cosine-similarity to the other similar words in the train set by using the characters level n-gram</p>
<p>How do i incorporate the fasttext model inside a LSTM keras network without losing the fasttext model to just a list of vectors in the vocab? because then I won't handle any OOV even when fasttext do it well.</p>
<p>Any idea?</p>
",2509698.0,,10375049.0,,2021-01-16 17:16:53,2021-01-16 17:16:53,Using Gensim Fasttext model with LSTM nn in keras,<tensorflow><keras><nlp><gensim><word-embedding>,1,0,0.0,,,CC BY-SA 4.0
63216731,1,,,2020-08-02 13:45:00,,6,3743,"<p>I am having trouble understanding the way 2 or more convolutional layers (each followed by a pooling layer) work in a CNN.</p>
<p>Consider the input to be a 3 channel 300x300 image. If the first convolution layer has 32 convolutions and the second layers have 64 convolutional layers, then the first layer creates 32 feature maps. But how many feature maps does the second layer create? Does every convolution out of 64 act on the previously generated 32 feature maps, thus creating 32*64 = 2048 feature maps in total? Or does something else take place?</p>
<p>A simple code relating the question is:</p>
<pre><code>model = keras.models.Sequential([
keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)),
keras.layers.MaxPooling2D(2, 2),

keras.layers.Conv2D(64, (3, 3), activation='relu'),
keras.layers.MaxPooling2D(2, 2)])
</code></pre>
",14037329.0,,8890604.0,,2020-08-02 14:12:18,2020-08-02 14:12:18,How do stacked convolutional layers work in a CNN?,<python><tensorflow><keras><deep-learning><conv-neural-network>,2,0,0.0,,,CC BY-SA 4.0
63157402,1,63222778.0,,2020-07-29 15:45:55,,6,616,"<p>I'm having some difficulty with chaining together two models in an unusual way.</p>
<p>I am trying to replicate the following flowchart:</p>
<p><img src=""https://i.imgur.com/c4sONiF.png"" alt=""Cascaded RNN 2-D"" /></p>
<p>For clarity, at each timestep of <code>Model[0]</code> I am attempting to generate an entire time series from <code>IR[i]</code> (Intermediate Representation) as a repeated input using <code>Model[1]</code>.  The purpose of this scheme is it allows the generation of a ragged 2-D time series from a 1-D input (while both allowing the second model to be omitted when the output for that timestep is not needed, and not requiring <code>Model[0]</code> to constantly &quot;switch modes&quot; between accepting input, and generating output).</p>
<p>I assume a custom training loop will be required, and I already have a custom training loop for handling statefulness in the first model (the previous version only had a single output at each timestep).  As depicted, the second model should have reasonably short outputs (able to be constrained to fewer than 10 timesteps).</p>
<p>But at the end of the day, while I can wrap my head around what I want to do, I'm not nearly adroit enough with Keras and/or Tensorflow to actually implement it.  (In fact, this is my first non-toy project with the library.)</p>
<p>I have unsuccessfully searched literature for similar schemes to parrot, or example code to fiddle with.  And I don't even know if this idea is possible from within TF/Keras.</p>
<p>I already have the two models working in isolation. (As in I've worked out the dimensionality, and done some training with dummy data to get garbage outputs for the second model, and the first model is based off of a previous iteration of this problem and has been fully trained.) If I have <code>Model[0]</code> and <code>Model[1]</code> as python variables (let's call them <code>model_a</code> and <code>model_b</code>), then how would I chain them together to do this?</p>
<p>Edit to add:</p>
<p>If this is all unclear, perhaps having the dimensions of each input and output will help:</p>
<p>The dimensions of each input and output are:</p>
<p>Input: <code>(batch_size, model_a_timesteps, input_size)</code><br>
IR: <code>(batch_size, model_a_timesteps, ir_size)</code></p>
<p>IR[i] (after duplication): <code>(batch_size, model_b_timesteps, ir_size)</code><br>
Out[i]: <code>(batch_size, model_b_timesteps, output_size)</code><br>
Out: <code>(batch_size, model_a_timesteps, model_b_timesteps, output_size)</code></p>
",483486.0,,10133797.0,,2021-12-03 21:34:54,2021-12-03 21:34:54,Cascade multiple RNN models for N-dimensional output,<python><tensorflow><keras><recurrent-neural-network><tf.keras>,1,8,0.0,,,CC BY-SA 4.0
64434655,1,64438413.0,,2020-10-19 20:23:27,,6,2629,"<p>I've been using <code>tensorflow</code> without issue, until I added the following lines of code:</p>
<pre><code>log_dir = os.path.join(&quot;logs&quot;,
                       &quot;fit&quot;,
                       datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;))

tensorboard_callback = TensorBoard(log_dir)
</code></pre>
<p>After running this I get an large amount of information printed to the console. I've tried looking at the  <code>tf.keras.callbacks.TensorBoard</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard"" rel=""noreferrer"">documentation</a> to see if I can reduce verbosity but I don't see an option.</p>
<p>From various <a href=""https://stackoverflow.com/questions/40426502/is-there-a-way-to-suppress-the-messages-tensorflow-prints"">stackoverflow answers</a> I've also tried setting the verbosity of <code>tf</code> down but to no avail:</p>
<pre><code>tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
tf.get_logger().setLevel('ERROR')
tf.autograph.set_verbosity(3)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
</code></pre>
<p>I have the following specifications:</p>
<pre><code>Python = 3.8
Tensorflow = 2.3.1
Cuda Toolkit = 10.1 
cuDNN = 7.6.4
GPU=Nvidia RTX2060
</code></pre>
<p>The information being printed to the console are all <code>I</code> messages, I've pasted these below if they add any important detail.</p>
<pre><code>2020-10-19 20:59:45.205887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-19 20:59:47.463539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-10-19 20:59:48.540417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-10-19 20:59:48.542360: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-19 20:59:48.562444: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-19 20:59:48.569770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-19 20:59:48.572530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-19 20:59:48.581126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-19 20:59:48.586315: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-19 20:59:48.604682: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-19 20:59:48.605112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-19 21:00:02.120333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-19 21:00:02.128143: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x255e4b0b0a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-19 21:00:02.128792: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-19 21:00:03.014080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-10-19 21:00:03.014776: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-19 21:00:03.015127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-19 21:00:03.015477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-19 21:00:03.015822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-19 21:00:03.016172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-19 21:00:03.016565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-19 21:00:03.016911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-19 21:00:03.017288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-19 21:00:03.722569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-19 21:00:03.722942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-10-19 21:00:03.723166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-10-19 21:00:03.723522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4594 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-10-19 21:00:03.726833: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x255883632b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-19 21:00:03.727297: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060, Compute Capability 7.5
2020-10-19 21:00:08.908192: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2020-10-19 21:00:08.908485: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs
2020-10-19 21:00:08.910553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cupti64_101.dll
2020-10-19 21:00:09.007043: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed
2020-10-19 21:06:09.402869: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2020-10-19 21:06:09.403307: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1513] CUPTI activity buffer flushed
</code></pre>
<p>Can anyone please help me to stop these messages printing to the console its making analysing other info on the console very difficult!</p>
<p>Thanks!</p>
",13187876.0,,,,,2021-04-30 04:10:28,Stop Tensorflow from printing to the console,<python><tensorflow><machine-learning><keras><callback>,1,0,,,,CC BY-SA 4.0
69136518,1,,,2021-09-10 18:22:13,,6,4840,"<p>I'm working on a project where I have trained a series of binary classifiers with <strong>Keras</strong>, with <strong>Tensorflow</strong> as the backend engine. The input data I have is a series of images, where each binary classifier must make the prediction on the images, later I save the predictions on a CSV file.</p>
<p>The problem I have is when I get the predictions from the first series of binary classifiers there isn't any warning, but when the 5th or 6th binary classifier calls the method <strong>predict</strong> on the input data I get the following warning:</p>
<blockquote>
<p>WARNING:tensorflow:5 out of the last 5 calls to &lt;function
Model.make_predict_function..predict_function at
0x2b280ff5c158&gt; triggered tf.function retracing. Tracing is expensive
and the excessive number of tracings could be due to (1) creating
@tf.function repeatedly in a loop, (2) passing tensors with different
shapes, (3) passing Python objects instead of tensors. For (1), please
define your @tf.function outside of the loop. For (2), @tf.function
has experimental_relax_shapes=True option that relaxes argument shapes
that can avoid unnecessary retracing. For (3), please refer to
<a href=""https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args</a>
and <a href=""https://www.tensorflow.org/api_docs/python/tf/function"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/function</a> for  more
details.</p>
</blockquote>
<p>To answer each point in the parenthesis, here are my answers:</p>
<ol>
<li>The <strong>predict</strong> method is called inside a for loop.</li>
<li>I don't pass tensors but a list of <strong>NumPy arrays</strong> of gray scale images, all of them with the same size in width and height. The only thing that can change is the batch size because the list can have only 1 image or more than one.</li>
<li>As I wrote in point 2, I pass a list of NumPy arrays.</li>
</ol>
<p>I have debugged my program and found that this warning always happens when the method predict is called. To summarize the code I have written is the following:</p>
<pre><code>import cv2 as cv
import tensorflow as tf
from tensorflow.keras.models import load_model
# Load the models
binary_classifiers = [load_model(path) for path in path2models]
# Get the images
images = [#Load the images with OpenCV]
# Apply the resizing and reshapes on the images.
my_list = list()
for image in images:
    image_reworked = # Apply the resizing and reshaping on images
    my_list.append(image_reworked)

# Get the prediction from each model
# This is where I get the warning
predictions = [model.predict(x=my_list,verbose=0) for model in binary_classifiers]
</code></pre>
<h3>What I have tried</h3>
<p>I have defined a function as tf.function and putted the code of the predictions inside the tf.function like this</p>
<pre><code>@tf.function
def testing(models, faces):
    return [model.predict(x=faces,verbose=0) for model in models]
</code></pre>
<p>But I ended up getting the following error:</p>
<blockquote>
<p>RuntimeError: Detected a call to <code>Model.predict</code> inside a
<code>tf.function</code>. Model.predict is a high-level endpoint that manages
its own <code>tf.function</code>. Please move the call to <code>Model.predict</code> outside
of all enclosing <code>tf.function</code>s. Note that you can call a <code>Model</code>
directly on Tensors inside a <code>tf.function</code> like: <code>model(x)</code>.</p>
</blockquote>
<p>So calling the method <code>predict</code> is basically already a tf.function. So it's useless to define a tf.function when the warning I get it's from that method.</p>
<p>I have also checked those other two questions:</p>
<ol>
<li><a href=""https://stackoverflow.com/questions/61647404/tensorflow-2-getting-warningtensorflow9-out-of-the-last-9-calls-to-function"">Tensorflow 2: Getting &quot;WARNING:tensorflow:9 out of the last 9 calls to  triggered tf.function retracing. Tracing is expensive&quot;</a></li>
<li><a href=""https://stackoverflow.com/questions/65563185/loading-multiple-saved-tensorflow-keras-models-for-prediction"">Loading multiple saved tensorflow/keras models for prediction</a></li>
</ol>
<p>But neither of the two questions answers my question about how to avoid this warning. Plus I have also checked the links in the warning message but I couldn't solve my problem.</p>
<h3>What I want</h3>
<p>I simply want to avoid this warning. While I'm still getting the predictions from the models I noticed that the python program takes way too much time on doing predictions for a list of images.</p>
<h3>What I'm using</h3>
<ul>
<li>Python 3.6.13</li>
<li>Tensorflow 2.3.0</li>
</ul>
<h3>Solution</h3>
<p>After some tries to suppress the warning from the <code>predict</code> method, I have checked the documentation of Tensorflow and in one of the first tutorials on how to use Tensorflow it is explained that, by default, Tensorflow is executed in eager mode, which is useful for testing and debugging the network models. Since I have already tested my models many times, it was only required to disable the eager mode by writing this single python line of code:</p>
<p><code>tf.compat.v1.disable_eager_execution()</code></p>
<p>Now the warning doesn't show up anymore.</p>
",10933292.0,,10933292.0,,2021-09-12 20:55:44,2021-09-22 13:45:19,"Tensorflow 2 getting ""WARNING:tensorflow:x out of the last x calls to <function> triggered tf.function retracing.""",<python><tensorflow><machine-learning><keras><deep-learning>,1,2,,,,CC BY-SA 4.0
62910334,1,,,2020-07-15 08:09:13,,6,2201,"<p>I'm training a U-Net CNN in Keras/Tensorflow and find that loss massively decreases between the last batch of the first epoch, and the first batch of the second epoch:</p>
<pre><code>Epoch 00001: loss improved from inf to 0.07185 - categorical_accuracy: 0.8636
Epoch 2/400: 1/250 [.....................] - loss: 0.0040 - categorical_accuracy: 0.8878
</code></pre>
<p>Weirdly categorical accuracy does not drop with loss, but increases slightly. After the drop in loss, it doesn't decrease further, but settles around the lower value. I know this is very little information on the problem, but this behaviour might indicate a common problem I can investigate more?</p>
<p>Some extra info:
Optimizer = Adam(lr=1e-4)(Lowering lr didn't seem to help)</p>
<p>Loss: 'class weighted categorical cross entropy', calculated as follows</p>
<pre><code>def class_weighted_categorical_crossentropy(class_weights):
        
        def loss_function(y_true, y_pred):

        # scale preds so that the class probas of each sample sum to 1
        y_pred /= tf.reduce_sum(y_pred, -1, True)
        # manual computation of crossentropy
        epsilon = tf.convert_to_tensor(K.epsilon(), y_pred.dtype.base_dtype)
        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)

        # Multiply each class by its weight:
        classes_list = tf.unstack(y_true * tf.math.log(y_pred), axis=-1)
        for i in range(len(classes_list)):
            classes_list[i] = tf.scalar_mul(class_weights[i], classes_list[i])

        # Return weighted sum:
        return - tf.reduce_sum(tf.stack(classes_list, axis=-1), -1)

    return loss_function
</code></pre>
<p>Any ideas/sanity checks are much appreciated!</p>
<p>EDIT:<a href=""https://i.stack.imgur.com/TRpAZ.png"" rel=""noreferrer"">This</a> is the loss plot for training, I didn't have time to neaten it up, its loss plotted per step, not epoch, and you can see the shift to epoch 2 after 250 steps, up until that point the loss curve seems very good, but the shift two epoch two seems strange.</p>
",12966703.0,,5772882.0,,2020-07-23 10:12:11,2020-07-23 10:12:11,Why does Keras loss drop dramatically after the first epoch?,<python><keras><loss>,1,3,,,,CC BY-SA 4.0
63518432,1,,,2020-08-21 07:31:11,,6,1775,"<p>I have a memory leak with TensorFlow 1.14. I referred to various GitHub issues and <a href=""https://stackoverflow.com/questions/44327803/memory-leak-with-tensorflow"">Memory leak with TensorFlow</a> to address my issue, and I followed the advice of the answer, that seemed to have solved the problem. However it does not work here. I even ported the code to Tensorflow 2.1 and 2.3 but still could not solve the problem.</p>
<p>Whenever I load the model then memory leak is there. I tried to clear the session after the model is loaded and used garbage collect API also but leak still persists.</p>
<p>In order to recreate the memory leak, I have created a simple example. I have used below function to check the memory used of the python process.</p>
<pre><code>def memory_usage_func():
    import os
    import psutil
    process = psutil.Process(os.getpid())
    mem_used = process.memory_info()[0] &gt;&gt; 20
    print(&quot;Memory used:&quot;, mem_used)
    return mem_used
</code></pre>
<p>Below is the function to load the model and check memory usage:</p>
<pre><code>for i in range(100):
    model = load_model('./model_example.h5', compile=False)
    del model
    memory_usage_func()
</code></pre>
<p>In above code, memory leak issue persists. Further, I tried to do prediction. For that, I created a session, load the model and run predict(). There also I face same memory leak issues. I used <code>tf.keras.backend.clear_session()</code> and <code>gc.collect()</code> after model is loaded. But, it is unable to clear the session and free the memory.</p>
",14141340.0,,,,,2021-11-29 17:44:24,Memory leak issue in tensorflow,<python><tensorflow><keras><memory-leaks>,1,1,0.0,,,CC BY-SA 4.0
62869217,1,63256834.0,,2020-07-13 04:22:02,,6,855,"<p>I used Taylor expansion in image classification task. Basically, firstly, pixel vector is generated from RGB image, and each pixel values from pixel vector is going to approximated with  Taylor series expansion of <code>sin(x)</code>. In tensorflow implementation, I tried possible of coding up this with tensorflow, and I still have some problem when I tried to create feature maps by stacking tensor with expansion terms. Can anyone provide possible perspective how can I make my current attempt more efficient? Any possible thoughts?</p>
<p>Here is the expansion terms of Taylor series of <code>sin(x)</code>:</p>
<p><a href=""https://i.stack.imgur.com/ERGpY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ERGpY.png"" alt=""Taylor expansion of sin(x)"" /></a></p>
<p>here is my current attempt:</p>
<pre><code>term = 2
c = tf.constant([1, -1/6])
power = tf.constant([1, 3])

x = tf.keras.Input(shape=(32, 32, 3))
res =[]
for x in range(term):
    expansion = c * tf.math.pow(tf.tile(x[..., None], [1, 1, 1, 1, term]),power)
    m_ij = tf.math.cumsum(expansion, axis=-1)
    res.append(m_i)
</code></pre>
<p>but this is not quite working because I want to create input features maps from each expansion neurons, <code>delta_1</code>, <code>delta_2</code> needs to be stacked, which I didn't make correctly in my above attempt, and my code is not well generalized also. How can I refine my above coding attempts in correct way of implementation? Can any one give me possible ideas or canonical answer to improve my current attempts?</p>
",6598723.0,,6598723.0,,2021-02-28 23:35:53,2021-02-28 23:35:53,make input features map from expansion tensor in keras,<python><tensorflow><keras><computer-vision><conv-neural-network>,1,7,,,,CC BY-SA 4.0
63513390,1,,,2020-08-20 21:31:23,,6,2174,"<p>Let's suppose we have some model including custom losses &amp; metrics that are important during training. Is it possible to save the complete model, so weights + graphdef / pb-file, without the custom objects?</p>
<p>During inference the custom losses &amp; metrics are <strong>not needed</strong>, thus...</p>
<pre><code>tf.keras.models.load_model(&quot;some_model&quot;, custom_objects={...})
</code></pre>
<p>...would just render the inference code more complicated since custom object code needs to be included for inferencing (although it is not used).</p>
<p>However, <code>tf.keras.callbacks.ModelCheckpoint</code> (even with <code>include_optimizer=False</code>) as well as calling <code>model.save()</code> always save the model definition <em>including</em> the custom objects.</p>
<p>Hence, simply loading the model with...</p>
<pre><code>tf.keras.models.load_model(&quot;some_model&quot;)
</code></pre>
<p>...will always fail and complain about the missing custom objects.</p>
<p>Is it possible to somehow save the whole model without custom losses/metrics? To get an &quot;inference&quot; version of the network that is easy to load?</p>
<p>Or is the only solution to this to freeze everything to a TFLite model?</p>
<p>Of course, one could simply use <code>model.save_weights()</code>, but then the actual code needs to be included for inference later, which is not desired.</p>
",3314143.0,,,,,2022-08-22 20:13:31,Save complete tf.keras model without custom objects?,<python><tensorflow><keras><save><restore>,1,0,,,,CC BY-SA 4.0
71962592,1,72013870.0,,2022-04-22 01:44:49,,6,599,"<p>I have trained a Siamese neural network that uses triplet loss. It was a pain, but I think I managed to do it. However, I am struggling to understand how to make evaluations with this model.</p>
<p>The SNN:</p>
<pre><code>def triplet_loss(y_true, y_pred):
    margin = K.constant(1)
    return K.mean(K.maximum(K.constant(0), K.square(y_pred[:,0]) - 0.5*(K.square(y_pred[:,1])+K.square(y_pred[:,2])) + margin))

def euclidean_distance(vects):
    x, y = vects
    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))
</code></pre>
<pre><code>anchor_input = Input((max_len, ), name='anchor_input')
positive_input = Input((max_len, ), name='positive_input')
negative_input = Input((max_len, ), name='negative_input')

Shared_DNN = create_base_network(embedding_dim = EMBEDDING_DIM, max_len=MAX_LEN, embed_matrix=embed_matrix)

encoded_anchor = Shared_DNN(anchor_input)
encoded_positive = Shared_DNN(positive_input)
encoded_negative = Shared_DNN(negative_input)

positive_dist = Lambda(euclidean_distance, name='pos_dist')([encoded_anchor, encoded_positive])
negative_dist = Lambda(euclidean_distance, name='neg_dist')([encoded_anchor, encoded_negative])
tertiary_dist = Lambda(euclidean_distance, name='ter_dist')([encoded_positive, encoded_negative])

stacked_dists = Lambda(lambda vects: K.stack(vects, axis=1), name='stacked_dists')([positive_dist, negative_dist, tertiary_dist])

model = Model([anchor_input, positive_input, negative_input], stacked_dists, name='triple_siamese')

model.compile(loss=triplet_loss, optimizer=adam_optim, metrics=[accuracy])
</code></pre>
<pre><code>history = model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=128, epochs=25)
</code></pre>
<p>I understand that once a model is trained with triplets, the evaluation shouldn't actually require that triplets be used. However, how do I finagle this reshaping?</p>
<p>Because this is a SNN, I would want to feed two inputs into <code>model.evaluate</code>, along with a categorical variable denoting if the two inputs are similar or not <code>(1 = similar, 0 = not similar)</code>.</p>
<p>So basically, I want <code>model.evaluate(input1, input2, y_label)</code>. But I am not sure how to get this with the model that I trained. As shown above, I trained with three inputs: <code>model.fit([Anchor,Positive,Negative],y=Y_dummy ... ) </code>.</p>
<p>I know I should save the weights of my trained model, but I just don't know what model to load the weights onto.</p>
<p>Your help is greatly appreciated!</p>
<p><strong>EDIT</strong>:
I am aware of the below approach for prediction, but I am not looking for prediction, I am looking to use <code>model.evaluate</code> as I want to get some final measure of loss/accuracy for the model. Also this approach only feeds the anchor into the model (wheras I'm interested in text similarity, so would want to feed in 2 inputs)</p>
<pre><code>eval_model = Model(inputs=anchor_input, outputs=encoded_anchor)
eval_model.load_weights('weights.hdf5')

</code></pre>
",17894682.0,,10375049.0,,2022-07-07 12:03:24,2022-07-07 12:03:24,Evaluating (model.evaluate) with a triplet loss Siamese neural network model - tensorflow,<tensorflow><keras><deep-learning><siamese-network><triplet>,1,0,0.0,,,CC BY-SA 4.0
65809906,1,,,2021-01-20 12:50:19,,6,3073,"<p>When I attempt to use tf.map_fn in the definition of a keras Functional model, I get the error:</p>
<pre><code>TypeError: Could not build a TypeSpec for &lt;KerasTensor: ...
</code></pre>
<p>e.g. this simple model will trigger that error in tf-nightly 2.5.0 :</p>
<pre><code>import tensorflow as tf

from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model

x = Input(shape=(10,))

y = tf.map_fn(lambda x : x * 2, x, fn_output_signature=tf.float32)

model = Model(inputs=x, outputs=y)
</code></pre>
<p>Whereas replacing the call to tf.map_fn to calls to other tensorflow operations works fine.</p>
",7381780.0,,,,,2021-01-20 13:19:50,TypeError: Could not build a TypeSpec for <KerasTensor when using tf.map_fn and keras functional model,<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0
72831076,1,72869570.0,,2022-07-01 14:53:16,,6,908,"<p>I am trying to build a machine learning model which predicts a single number from a series of numbers. I am using a Sequential model from the keras API of Tensorflow.</p>
<p>You can imagine my dataset to look something like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Index</th>
<th>x data</th>
<th>y data</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td><code>np.ndarray(shape (1209278,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>1</td>
<td><code>np.ndarray(shape (1211140,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>2</td>
<td><code>np.ndarray(shape (1418411,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>3</td>
<td><code>np.ndarray(shape (1077132,) )</code></td>
<td><code>numpy.float32</code></td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<p><strong>This was my first attempt:</strong></p>
<p>I tried using a numpy ndarray which contains numpy ndarrays which finally contain floats as my xdata, so something like this:</p>
<pre class=""lang-py prettyprint-override""><code>array([
    array([3.59280851, 3.60459062, 3.60459062, ..., 4.02911493])
    array([3.54752101, 3.56740332, 3.56740332, ..., 4.02837855])
    array([3.61048168, 3.62152741, 3.62152741, ..., 4.02764217])
])
</code></pre>
<p>My y data is a numpy ndarray containing floats, which looks something like this</p>
<pre class=""lang-py prettyprint-override""><code>array([2.9864411, 3.0562437, ... , 2.7750807, 2.8712902], dtype=float32)
</code></pre>
<p>But when I tried to train the model using <code>model.fit()</code> it yields this error:</p>
<pre><code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).
</code></pre>
<p>I was able to solve this error by asking a question related to this:
<a href=""https://stackoverflow.com/questions/72815591/how-can-i-have-a-series-of-numpy-ndarrays-as-the-input-data-to-train-a-tensorflo"">How can I have a series of numpy ndarrays as the input data to train a tensorflow machine learning model?</a></p>
<p><strong>My latest attempt:</strong>
Because Tensorflow does not seem to be able to convert a ndarray of ndarrays to a tensor, I tried to convert my x data to a list of ndarrays like this:</p>
<pre class=""lang-py prettyprint-override""><code>[
    array([3.59280851, 3.60459062, 3.60459062, ..., 4.02911493])
    array([3.54752101, 3.56740332, 3.56740332, ..., 4.02837855])
    array([3.61048168, 3.62152741, 3.62152741, ..., 4.02764217])
]
</code></pre>
<p>I left my y data untouched, so as a ndarray of floats.
Sadly my attempt of using a list of ndarrays instead of a ndarray of ndarrays yielded this error:</p>
<pre class=""lang-py prettyprint-override""><code>ValueError: Data cardinality is ambiguous:
  x sizes: 1304593, 1209278, 1407624, ...
  y sizes: 46
Make sure all arrays contain the same number of samples.
</code></pre>
<p>As you can see, my x data consists of arrays which all have a different shape.
But I don't think that this should be a problem.</p>
<p><strong>Question:</strong></p>
<p>My guess is that Tensorflow tries to use my list of arrays as <em>multiple</em> inputs.
<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"" rel=""nofollow noreferrer"">Tensorflow fit() documentation</a></p>
<p>But I don't want to use my x data as multiple inputs.
Easily said I just want my model to predict a number from a sequence of numbers.
For example like this:</p>
<ul>
<li>array([3.59280851, 3.60459062, 3.60459062, ...]) =&gt; 2.8989773</li>
<li>array([3.54752101, 3.56740332, 3.56740332, ...]) =&gt; 3.0893357</li>
<li>...</li>
</ul>
<p><strong>How can I use a sequence of numbers to predict a single number in Tensorflow?</strong></p>
<p><strong>EDIT</strong>
Maybe I should have added that I want to use a RNN, especially a LSTM.
I have had a look at the Keras documentation, and in their simplest example they are using a <code>Embedding</code> layer. But I don't really know what to do.</p>
<p>All in all I think that my question ist pretty general and should be easy to answer if you know how to tackle this problem, unlike me.
Thanks in advance!</p>
",13990977.0,,13990977.0,,2022-07-04 16:04:33,2022-07-05 13:21:44,How can I use a sequence of numbers to predict a single number in Tensorflow?,<python><arrays><numpy><tensorflow><keras>,1,2,,,,CC BY-SA 4.0
63655484,1,,,2020-08-30 08:28:16,,6,695,"<p>I am training a keras model whose last layer is a single <code>sigmoid</code> unit:</p>
<pre><code>output = Dense(units=1, activation='sigmoid')
</code></pre>
<p>I am training this model with some training data in which the expected output is always a number between 0.0 and 1.0.
I am compiling the model with mean-squared-error:</p>
<pre><code>model.compile(optimizer='adam', loss='mse')
</code></pre>
<p>Since both the expected output and the real output are single floats between 0 and 1, I was expecting a loss between 0 and 1 as well, but when I start the training I get a loss of <code>3.3932</code>, larger than 1.</p>
<p>Am I missing something?</p>
<p><strong>Edit:</strong>
I am adding an example to show the problem:
<a href=""https://drive.google.com/file/d/1fBBrgW-HlBYhG-BUARjTXn3SpWqrHHPK/view?usp=sharing"" rel=""nofollow noreferrer"">https://drive.google.com/file/d/1fBBrgW-HlBYhG-BUARjTXn3SpWqrHHPK/view?usp=sharing</a>
(I cannot just paste the code because I need to attach the training data)</p>
<p>After running <code>python stackoverflow.py</code>, the summary of the model will be shown, as well as the training process.
I also print the minimum and maximum values of y_true each step to verify that they are within the [0, 1] range.
There is no need to wait for the training to finish, you will see that the loss during the first few epochs is much larger than 1.</p>
",14190580.0,,14190580.0,,2020-08-31 19:23:25,2021-05-11 09:36:44,Training MSE loss larger than theoretical maximum?,<python><keras><loss><sigmoid><mse>,2,5,,,,CC BY-SA 4.0
71104727,1,,,2022-02-13 20:50:28,,6,16029,"<p>I'm trying to build a Deep Q Learning code for CartPole-v1 game. However I encounter an AssertionError:</p>
<pre class=""lang-python prettyprint-override""><code>AssertionError: Duplicate registrations for type 'experimentalOptimizer'
</code></pre>
<p>Some of the stacktrace is shown below:</p>
<p><img src=""https://i.stack.imgur.com/mRRRX.png"" alt=""the error"" /></p>
<p>I upgraded TensorFlow but it didn't work. What should I do to fix it?</p>
<h3>System Details</h3>
<ul>
<li>Windows OS</li>
<li>Spyder IDE</li>
<li>Anaconda 3 (<strong>base</strong> environment)</li>
</ul>
",12005744.0,,570918.0,,2022-02-14 16:09:01,2022-06-03 13:07:31,keras AssertionError: Duplicate registrations for type 'experimentalOptimizer',<python><tensorflow><keras>,3,1,,,,CC BY-SA 4.0
66408995,1,,,2021-02-28 12:17:04,,6,3017,"<p>I have created and trained a TensorFlow model using the HammingLoss metric from <a href=""https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/HammingLoss"" rel=""noreferrer"">TensorFlow addons</a>. Thus, it's not a custom metric that I have created on my own. I use a callbacks function with the methords <code>ModelCheckpoint()</code> and <code>EarlyStopping</code> to save the best weights of the best model and stop model training at a given threshold repsectively. When I save the model checkpoint I serialize the whole model structure (similar to <code>model.save()</code>), istead of <code>model.save_weights()</code>, which would have saved only the model weights (more about ModelCheckpoint <a href=""https://keras.io/api/callbacks/model_checkpoint/"" rel=""noreferrer"">here</a>).</p>
<p><strong>TL;DR:</strong> <a href=""https://colab.research.google.com/drive/1A1hIXYLEhO8smRb1w7I57jLVgGRC0WOK?usp=sharing"" rel=""noreferrer"">Here</a> is a colab notebook with the code I post below in case you want to skip this.</p>
<p>The model I have trained is saved in GoogleDrive in the link <a href=""https://drive.google.com/drive/folders/10I1ZJt4oR-zzG5VcJrf50su-pAbJfui1?usp=sharing"" rel=""noreferrer"">here</a>. To load the specific model I use the following code:</p>
<pre class=""lang-py prettyprint-override""><code>neural_network_parameters = {}

#======================================================================
#           PARAMETERS THAT DEFINE THE NEURAL NETWORK STRUCTURE       =
#======================================================================

neural_network_parameters['model_loss'] = tf.keras.losses.BinaryCrossentropy(from_logits=False, name='binary_crossentropy')

neural_network_parameters['model_metric'] = [tfa.metrics.HammingLoss(mode=&quot;multilabel&quot;, name=&quot;hamming_loss&quot;),
                                             tfa.metrics.F1Score(17, average=&quot;micro&quot;, name=&quot;f1_score_micro&quot;),
                                             tfa.metrics.F1Score(17, average=None, name=&quot;f1_score_none&quot;),
                                             tfa.metrics.F1Score(17, average=&quot;macro&quot;, name=&quot;f1_score_macro&quot;),
                                             tfa.metrics.F1Score(17, average=&quot;weighted&quot;, name=&quot;f1_score_weighted&quot;)]

&quot;&quot;&quot;Initialize the hyper parameters tuning the model using Tensorflow's hyperparameters module&quot;&quot;&quot;
HP_HIDDEN_UNITS = hp.HParam('batch_size', hp.Discrete([32]))
HP_EMBEDDING_DIM = hp.HParam('embedding_dim', hp.Discrete([50]))
HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([0.001])) # Adam default: 0.001, SGD default: 0.01, RMSprop default: 0.001....0.1 to be removed
HP_DECAY_STEPS_MULTIPLIER = hp.HParam('decay_steps_multiplier', hp.Discrete([10]))

METRIC_ACCURACY = &quot;hamming_loss&quot;

dependencies = {
    'hamming_loss': tfa.metrics.HammingLoss(mode=&quot;multilabel&quot;, name=&quot;hamming_loss&quot;),
    'attention': attention(return_sequences=True)
}

def import_trained_keras_model(model_index, method, decay_steps_mode, optimizer_name, hparams):
    &quot;&quot;&quot;Load the model&quot;&quot;&quot;
    
    training_date=&quot;2021-02-27&quot;
    model_path_structure=f&quot;{folder_path_model_saved}/{initialize_notebbok_variables.saved_model_name}_{hparams[HP_EMBEDDING_DIM]}dim_{hparams[HP_HIDDEN_UNITS]}batchsize_{hparams[HP_LEARNING_RATE]}lr_{hparams[HP_DECAY_STEPS_MULTIPLIER]}decaymultiplier_{training_date}&quot;
    model_imported=load_model(f&quot;{model_path_structure}&quot;, custom_objects=dependencies)

    if optimizer_name==&quot;adam&quot;:
        optimizer = optimizer_adam_v2(hparams)
    
    elif optimizer_name==&quot;sgd&quot;:
        optimizer = optimizer_sgd_v1(hparams, &quot;step decay&quot;)

    else:
        optimizer = optimizer_rmsprop_v1(hparams)

    model_imported.compile(optimizer=optimizer,
                            loss=neural_network_parameters['model_loss'],
                            metrics=neural_network_parameters['model_metric'])

    print(f&quot;Model {model_index} is loaded successfully\n&quot;)
    
    return model_imported
</code></pre>
<p>Calling the function <code>import trained keras model</code></p>
<pre class=""lang-py prettyprint-override""><code>&quot;&quot;&quot;Now that the functions have been created it's time to import each trained classifier from the selected dictionary of hyper parameters, calculate the evaluation metric per model and finally serialize the scores dataframe for later use.&quot;&quot;&quot;
list_models=[] #a list to store imported models
model_optimizer=&quot;adam&quot;

for batch_size in HP_HIDDEN_UNITS.domain.values:
  for embedding_dim in HP_EMBEDDING_DIM.domain.values:
      for learning_rate in HP_LEARNING_RATE.domain.values:
          for decay_steps_multiplier in HP_DECAY_STEPS_MULTIPLIER.domain.values:
              hparams = {
                  HP_HIDDEN_UNITS: batch_size,
                  HP_EMBEDDING_DIM: embedding_dim,
                  HP_LEARNING_RATE: learning_rate,
                  HP_DECAY_STEPS_MULTIPLIER: decay_steps_multiplier
                }
              print(f&quot;\n{len(list_models)+1}/{(len(HP_HIDDEN_UNITS.domain.values)*len(HP_EMBEDDING_DIM.domain.values)*len(HP_LEARNING_RATE.domain.values)*len(HP_DECAY_STEPS_MULTIPLIER.domain.values))}&quot;)
              print({h.name: hparams[h] for h in hparams},'\n')
              
              model_object=import_trained_keras_model(len(list_models)+1, &quot;import custom trained model&quot;, &quot;on&quot;, model_optimizer, hparams)
              list_models.append(model_object)
</code></pre>
<p>When I call the function I get the following error</p>
<blockquote>
<p>ValueError: Unable to restore custom object of type _tf_keras_metric currently. Please make sure that the layer implements <code>get_config</code>and <code>from_config</code> when saving. In addition, please use the <code>custom_objects</code> arg when calling <code>load_model()</code>.</p>
</blockquote>
<p>It's strange that I get this error since the model metric to compile the NN is from a built in method of TensorFlow and <strong>NOT</strong> some sort of a custom metric that I developed myself.</p>
<p>I have searched also this <a href=""https://github.com/jakeret/unet/issues/8"" rel=""noreferrer"">thread</a> in GitHub which closed without explaining the root of the problem.</p>
<p><strong>[UPDATE]--Found a temporary solution</strong></p>
<p>I managed to successfully import the model by turning the <code>compile</code> argument to False in order to re-compile the model imported inside the function.</p>
<p>So I did smth like <code>model_imported=load_model(f&quot;{model_path_structure}&quot;, custom_objects=dependencies, compile=False)</code>.</p>
<p>This action produced the following result:</p>
<blockquote>
<p>WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements <code>get_config</code> and <code>from_config</code> when saving. In addition, please use the <code>custom_objects</code> arg when calling <code>load_model()</code>.</p>
</blockquote>
<blockquote>
<p>Model 1 is loaded successfully.</p>
</blockquote>
<p>So TensorFlow still cannot understand that HammingLoss is not a custom metric but rather a metric imported from Tensorflow Addons. However, despite the warning the model loaded successfully.</p>
",10623444.0,,10623444.0,,2021-02-28 15:29:23,2022-07-22 20:10:13,Unable to restore custom object of type _tf_keras_metric currently using the HammingLoss metric from TensorFlow Addons module,<python><tensorflow><keras><deep-learning>,0,0,0.0,,,CC BY-SA 4.0
64425861,1,,,2020-10-19 10:52:22,,6,403,"<pre><code>import tensorflow as tf

class MyModel(tf.keras.Model):

    def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)

    @tf.function
    def call(self, enc_input, dec_input, training, mask1, mask2, mask3):
        x = self.dense1(enc_input)
        return self.dense2(x)

x = tf.random.normal((10,20))

model = MyModel()

y = model(x, x, False, None, None, None)

tf.keras.models.save_model(model, '/saved')
</code></pre>
<p>when I try to save the model, throws an error even though i'm passing all the arguments.</p>
<p><code>tf__call() missing 4 required positional arguments: 'training', 'mask1', 'mask2', and 'mask3'</code></p>
<p>How to save the entire model and not just saving weights ?</p>
",6393479.0,,,,,2020-10-28 07:43:45,How to save a keras subclassed model with positional parameters in Call() method?,<tensorflow><keras><tensorflow2.0><tf.keras>,1,1,0.0,,,CC BY-SA 4.0
64301624,1,,,2020-10-11 07:30:12,,6,1686,"<p>I am working on a machine language translation problem. The Model I am using is:</p>
<pre><code>    Model = Sequential([
          Embedding(english_vocab_size, 256, input_length=english_max_len, mask_zero=True),
          LSTM(256, activation='relu'),
          RepeatVector(german_max_len),
          LSTM(256, activation='relu', return_sequences=True),
          Dense(german_vocab_size, activation='softmax')
    ])
</code></pre>
<p>Here,<code>english_vocab_size</code> and <code>english_max_len</code> are the total number of english words in the english vocabulory and number of words in each english sentence respectively. And the same is with <code>german_vocab_size</code> and <code>german_max_len</code>.</p>
<p>Now, how can I add <code>tf.keras.layers.AdditiveAttention</code> layer in this Model?</p>
<p>Edit - I tried a lot to find good tutorials of implementing <code>tf.keras.layers.AdditiveAttention</code> layer on an nlp task, but couldn't find any. So, I think if someone can explain how can I  put the <code>tf.keras.layers.AdditiveAttention</code> layer in this model, the person would be the first person to give a very clear explanation on how to use <code>tf.keras.layers.AdditiveAttention</code> as it would be then very clear implementation  on how to use the <code>tf.keras.layers.AdditiveAttention</code> layer !</p>
",,user14349917,,user14349917,2020-10-11 11:29:34,2022-08-08 10:01:13,How can I add tf.keras.layers.AdditiveAttention in my model?,<python><machine-learning><keras><deep-learning><attention-model>,2,3,0.0,,,CC BY-SA 4.0
65262832,1,,,2020-12-12 08:05:54,,6,2809,"<p>So I have few words without labels but I need to classify them into 4-5 categories.
I can visibly say that this test set can be classified. Although I do not have training data so I need to use a pre-trained model to classify these words. Which model is good for this paradigm and on which dataset has it already been trained?</p>
<p>Thanks</p>
",14812110.0,,,,,2021-02-07 12:00:29,Pre-Trained models for text Classification,<python><machine-learning><keras><text-classification><pre-trained-model>,1,3,,,,CC BY-SA 4.0
64401570,1,64514507.0,,2020-10-17 10:44:49,,6,1957,"<p>In the code below, I import a saved  sparse numpy matrix, created with python, densify it, add a masking, batchnorm and dense ouptput layer to a many to one SimpleRNN.  The keras sequential model works fine, however, I am unable to use shap.  This is run in Jupyter lab from Winpython 3830 on a Windows 10 desktop.  The X matrix has a shape of (4754, 500, 64): 4754 examples with 500 timesteps and 64 variables.  I've created a function to simulate the data so the code can be tested.  The simulated data returns the same error.</p>
<pre><code>from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
import tensorflow.keras.backend as Kb
from tensorflow.keras import layers
from tensorflow.keras.layers import BatchNormalization
from tensorflow import keras as K
import numpy as np
import shap
import random

def create_x():
    dims = [10,500,64]
    data = []
    y = []
    for i in range(dims[0]):
        data.append([])

        for j in range(dims[1]):
            data[i].append([])
            for k in range(dims[2]):
                isnp = random.random()
                if isnp &gt; .2:
                    data[i][j].append(np.nan)
                else:
                    data[i][j].append(random.random())
        if isnp &gt; .5:
            y.append(0)
        else:
            y.append(1)
    return np.asarray(data), np.asarray(y)

def first_valid(arr, axis, invalid_val=0):
    #return the 2nd index of 3 for  the first non np.nan on the 3rd axis
    mask = np.invert(np.isnan(arr))
    return np.where(mask.any(axis=axis), mask.argmax(axis=axis), invalid_val)

def densify_np(X):
    X_copy = np.empty_like (X)
    X_copy[:] = X
    #loop over the first index
    for i in range(len(X_copy)):

        old_row = []
        #get the 2nd index of the first valid value for each 3rd index
        indices = first_valid(X_copy[i,:,:],axis=0, invalid_val=0)
        for j in range(len(indices)):
            if np.isnan(X_copy[i,indices[j],j]):
                old_row.append(0)
            else:
                old_row.append(X_copy[i,indices[j],j])
        X_copy[i,0,:]= old_row
        for k in range(1,len(X_copy[i,:])):
            for l in range(len(X_copy[i,k,:])):
                if np.isnan(X_copy[i,k,l]):
                    X_copy[i,k,l] = X_copy[i,k-1,l]
           
    return(X_copy)
#this is what I do in the actual code
#X = np.load('C:/WinPython/WPy64-3830/data/X.npy')
#Y = np.load('C:/WinPython/WPy64-3830/scripts/Y.npy')

#simulated junk data
X, Y = create_x()

#create a dense matrix from the sparse one.
X = densify_np(X)

seed = 7
np.random.seed(seed)
array_size = 64
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)
batch = 64
model = Sequential()


model.add(layers.Input(shape=(500,array_size)))
model.add(layers.Masking(mask_value=0.,input_shape=(500, array_size)))
model.add(BatchNormalization())
model.add(layers.SimpleRNN(1, activation=None, dropout = 0, recurrent_dropout=.2))
model.add(layers.Dense(1, activation = 'sigmoid'))
opt = K.optimizers.Adam(learning_rate=.001)

model.compile(loss='binary_crossentropy', optimizer=opt)
model.fit(X_train, y_train.astype(int), validation_data=(X_test,y_test.astype(int)), epochs=25, batch_size=batch)

explainer = shap.DeepExplainer(model, X_test)
shap_values = explainer.shap_values(X_train)
</code></pre>
<p>Running the last line to create the shap_values yields the error below.</p>
<pre><code>StagingError                              Traceback (most recent call last)
&lt;ipython-input-6-f789203da9c8&gt; in &lt;module&gt;
      1 import shap
      2 explainer = shap.DeepExplainer(model, X_test)
----&gt; 3 shap_values = explainer.shap_values(X_train)
      4 print('done')

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\__init__.py in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)
    117         were chosen as &quot;top&quot;.
    118         &quot;&quot;&quot;
--&gt; 119         return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py in shap_values(self, X, ranked_outputs, output_rank_order, check_additivity)
    302                 # run attribution computation graph
    303                 feature_ind = model_output_ranks[j,i]
--&gt; 304                 sample_phis = self.run(self.phi_symbolic(feature_ind), self.model_inputs, joint_input)
    305 
    306                 # assign the attributions to the right part of the output arrays

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py in run(self, out, model_inputs, X)
    359 
    360                 return final_out
--&gt; 361             return self.execute_with_overridden_gradients(anon)
    362 
    363     def custom_grad(self, op, *grads):

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py in execute_with_overridden_gradients(self, f)
    395         # define the computation graph for the attribution values using a custom gradient-like computation
    396         try:
--&gt; 397             out = f()
    398         finally:
    399             # reinstate the backpropagatable check

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py in anon()
    355                     v = tf.constant(data, dtype=self.model_inputs[i].dtype)
    356                     inputs.append(v)
--&gt; 357                 final_out = out(inputs)
    358                 tf_execute.record_gradient = tf_backprop._record_gradient
    359 

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = &quot;nonXla&quot;
--&gt; 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    821       # This is the first call of __call__, so we have to initialize.
    822       initializers = []
--&gt; 823       self._initialize(args, kwds, add_initializers_to=initializers)
    824     finally:
    825       # At this point we know that the initialization is complete (or less

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
    694     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    695     self._concrete_stateful_fn = (
--&gt; 696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    697             *args, **kwds))
    698 

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-&gt; 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-&gt; 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3063     arg_names = base_arg_names + missing_arg_names
   3064     graph_function = ConcreteFunction(
-&gt; 3065         func_graph_module.func_graph_from_py_func(
   3066             self._name,
   3067             self._python_function,

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, &quot;ag_error_metadata&quot;):
--&gt; 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

StagingError: in user code:

    C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\shap\explainers\deep\deep_tf.py:244 grad_graph  *
        x_grad = tape.gradient(out, shap_rAnD)
    C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:1067 gradient  **
        flat_grad = imperative_grad.imperative_grad(
    C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\imperative_grad.py:71 imperative_grad
        return pywrap_tfe.TFE_Py_TapeGradient(
    C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\eager\backprop.py:151 _gradient_function
        grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access
    C:\WinPython\WPy64-3830\python-3.8.3.amd64\lib\site-packages\tensorflow\python\framework\registry.py:96 lookup
        raise LookupError(

    LookupError: gradient registry has no entry for: shap_TensorListStack
</code></pre>
",11672482.0,,11672482.0,,2020-10-19 19:53:12,2020-10-24 14:43:13,Error using shap with SimpleRNN sequential model,<python><tensorflow><keras><recurrent-neural-network><shap>,1,4,,,,CC BY-SA 4.0
68152972,1,,,2021-06-27 16:01:18,,6,276,"<p>Where the values are</p>
<pre><code>rnn_size: 512
batch_size: 128


rnn_inputs: Tensor(&quot;embedding_lookup/Identity_1:0&quot;, shape=(?, ?, 128), dtype=float32)
sequence_length: Tensor(&quot;inputs_length:0&quot;, shape=(?,), dtype=int32)
cell_fw: &lt;tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.DropoutWrapper object at 0x7f4f534eb6d0&gt;
cell_bw: &lt;tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.DropoutWrapper object at 0x7f4f534eb910&gt;
</code></pre>
<p>Getting the enc_state value by</p>
<pre><code>enc_output, enc_state = tf.compat.v1.nn.bidirectional_dynamic_rnn(cell_fw, 
                                                                        cell_bw, 
                                                                        rnn_inputs,
                                                                        sequence_length,
                                                                        dtype=tf.float32)
</code></pre>
<p>Where the enc_state value is</p>
<pre><code>enc_state: LSTMStateTuple(c=&lt;tf.Tensor 'RNN_Encoder_Cell_2D/encoder_1/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 512) dtype=float32&gt;, h=&lt;tf.Tensor 'RNN_Encoder_Cell_2D/encoder_1/bidirectional_rnn/fw/fw/while/Exit_4:0' shape=(?, 512) dtype=float32&gt;)
</code></pre>
<p>TF1 code:</p>
<pre><code>initial_state = tf.contrib.seq2seq.DynamicAttentionWrapperState(enc_state,
                                                                _zero_state_tensors(rnn_size, 
                                                                                    batch_size, 
                                                                                    tf.float32))
</code></pre>
<p>converting into TF2 by</p>
<pre><code>initial_state = tfa.seq2seq.AttentionWrapper(enc_state,_zero_state_tensors(rnn_size, batch_size, tf.float32))
</code></pre>
<p>Getting error:</p>
<hr />
<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-54-d87646b9df5d&gt; in &lt;module&gt;()
      8                                                     threshold) 
      9             model = build_graph(keep_probability, rnn_size, num_layers, batch_size, 
---&gt; 10                                 learning_rate, embedding_size, direction)
     11             train(model, epochs, log_string)

6 frames
/usr/local/lib/python3.7/dist-packages/typeguard/__init__.py in check_type(argname, value, expected_type, memo)
    596                 raise TypeError(
    597                     'type of {} must be {}; got {} instead'.
--&gt; 598                     format(argname, qualified_name(expected_type), qualified_name(value)))
    599     elif isinstance(expected_type, TypeVar):
    600         # Only happens on &lt; 3.6

TypeError: type of argument &quot;cell&quot; must be tensorflow.python.keras.engine.base_layer.Layer; got tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.LSTMStateTuple instead
</code></pre>
<p>Also can you explain the last line of the error i.e</p>
<pre><code>    TypeError: type of argument &quot;cell&quot; must be tensorflow.python.keras.engine.base_layer.Layer; got tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.LSTMStateTuple instead
</code></pre>
",16328377.0,,16328377.0,,2021-06-27 16:33:59,2021-06-27 16:33:59,Getting error while converting a code in tf1 to tf2,<python><tensorflow><keras><tensorflow2.0><attention-model>,0,1,0.0,,,CC BY-SA 4.0
63422301,1,,,2020-08-15 03:30:22,,6,3994,"<p>So I recently tried running tensorflow-gpu on a pc with the following specs:</p>
<p>AMD Ryzen 5 2600X 6 core, NVIDIA GeForce RTX 2060 with 16 GB ram</p>
<p>I ran the built in dataset with Fashion mnist in the tutorial on <a href=""https://colab.research.google.com/github/lmoroney/mlday-tokyo/blob/master/Lab2-Computer-Vision.ipynb"" rel=""noreferrer"">colab</a>. I ran the following code and noticed that colab did not run on a gpu:</p>
<p><code>print(&quot;GPU is&quot;, &quot;available&quot; if tf.config.list_physical_devices('GPU') else &quot;NOT AVAILABLE&quot;)</code></p>
<p>So I went through the tutorial and essentially ran their code:</p>
<pre><code>import tensorflow as tf
import time

print(&quot;GPU is&quot;, &quot;available&quot; if tf.config.list_physical_devices('GPU') else &quot;NOT AVAILABLE&quot;)

mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images  = training_images / 255.0
test_images = test_images / 255.0

model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), 
                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), 
                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])



start_time = time.time()
model.compile(optimizer = tf.keras.optimizers.Adam(),
              loss = 'sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=5)

print(&quot;My program took {} seconds to run&quot;.format(time.time() - start_time))
</code></pre>
<p>I noticed that on colab it took ~17 seconds to compile and fit the data. When I ran it on my computer which did detect the GPU, it took ~13 seconds to do the same process. I was under the impression that the GPU I had would be light years faster so I was wondering what the problem is with my setup or if I was using my GPU incorrectly.</p>
<p>Also I am running python 3.7.7, tensorflow version 2.1.0, and keras version 2.2.4-tf.</p>
",12946401.0,,12946401.0,,2020-08-15 03:55:25,2020-08-17 01:50:45,Tensorflow with GPU slower than expected,<python><tensorflow><keras><tensorflow2.0>,2,1,,,,CC BY-SA 4.0
70739244,1,,,2022-01-17 09:40:25,,6,6591,"<p>I am trying to save the trained model below.</p>
<pre><code>resnet = ResNet50V2(input_shape=(im_size,im_size,3), weights='imagenet', include_top=False)
headModel = AvgPool2D(pool_size=(3,3))(resnet.output)
headModel = Flatten(name=&quot;flatten&quot;)(headModel)
headModel = Dense(256, activation=&quot;relu&quot;)(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(1, activation=&quot;sigmoid&quot;)(headModel)
resnet50v2 = Model(inputs=resnet.input, outputs=headModel)


resnet50v2.compile(loss='binary_crossentropy', optimizer=opt, metrics=METRICS)

history = resnet50v2.fit(
        datagen.flow(X_train, y_train, batch_size=32, subset='training'),
        batch_size=batch_size,
        epochs=150,
        steps_per_epoch=steps_per_epoch,    
        validation_data=datagen.flow(X_train, y_train, batch_size=8, subset='validation'))
</code></pre>
<p>However, whenever I try to save it with the following command:</p>
<p><code>resnet50v2.save('Saved_Models/resnet50.h5', save_format='h5')</code></p>
<p>I get the error</p>
<pre><code>
ValueError                                Traceback (most recent call last)
/tmp/ipykernel_3252071/2034094124.py in &lt;module&gt;
----&gt; 1 resnet50v2.save('Saved_Models/resnet50.h5', save_format='h5')

~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---&gt; 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb

~/.local/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds)
    147                     group = self.require_group(parent_path)
    148 
--&gt; 149             dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)
    150             dset = dataset.Dataset(dsid)
    151             return dset

~/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter)
    140 
    141 
--&gt; 142     dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)
    143 
    144     if (data is not None) and (not isinstance(data, Empty)):

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/h5d.pyx in h5py.h5d.create()

ValueError: Unable to create dataset (name already exists)
</code></pre>
<p>How can I save my models?</p>
",4943535.0,,9657861.0,,2022-01-31 15:49:12,2023-02-22 13:02:15,ValueError: Unable to create dataset (name already exists) while saving tensorflow model,<python><tensorflow><keras><save><resnet>,1,0,,,,CC BY-SA 4.0
71099818,1,71158506.0,,2022-02-13 10:32:46,,6,294,"<p>I am implementing a simple chatbot using keras and WebSockets. I now have a model that can make a prediction about the user input and send the according answer.</p>
<p>When I do it through command line it works fine, however when I try to send the answer through my WebSocket, the WebSocket doesn't even start anymore.</p>
<p>Here is my working WebSocket code:</p>
<pre><code>@sock.route('/api')
def echo(sock):
    while True:
        # get user input from browser
        user_input = sock.receive()
        # print user input on console
        print(user_input)
        # read answer from console
        response = input()
        # send response to browser
        sock.send(response)
</code></pre>
<p>Here is my code to communicate with the keras model on command line:</p>
<pre><code>while True:
    question = input(&quot;&quot;)
    ints = predict(question)
    answer = response(ints, json_data)
    print(answer)
</code></pre>
<p>Used methods are those:</p>
<pre><code>def predict(sentence):
    bag_of_words = convert_sentence_in_bag_of_words(sentence)
    # pass bag as list and get index 0
    prediction = model.predict(np.array([bag_of_words]))[0]
    ERROR_THRESHOLD = 0.25
    accepted_results = [[tag, probability] for tag, probability in enumerate(prediction) if probability &gt; ERROR_THRESHOLD]

    accepted_results.sort(key=lambda x: x[1], reverse=True)

    output = []
    for accepted_result in accepted_results:
        output.append({'intent': classes[accepted_result[0]], 'probability': str(accepted_result[1])})
        print(output)
    return output


def response(intents, json):
    tag = intents[0]['intent']
    intents_as_list = json['intents']
    for i in intents_as_list:
        if i['tag'] == tag:
            res = random.choice(i['responses'])
            break
    return res
</code></pre>
<p>So when I start the WebSocket with the working code I get this output:</p>
<pre><code> * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
 * Restarting with stat
 * Serving Flask app 'server' (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on
</code></pre>
<p>But as soon as I have anything of my model in the <code>server.py</code> class I get this output:</p>
<pre><code>2022-02-13 11:31:38.887640: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-02-13 11:31:38.887734: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)
Metal device set to: Apple M1

systemMemory: 16.00 GB
maxCacheSize: 5.33 GB
</code></pre>
<p>It is enough when I just have an import at the top like this: <code>from chatty import response, predict</code> - even though they are unused.</p>
",17588551.0,,,,,2022-02-17 12:52:40,WebSocket not working when trying to send generated answer by keras,<python><tensorflow><machine-learning><keras><websocket>,2,0,,,,CC BY-SA 4.0
64881855,1,64883343.0,,2020-11-17 19:15:51,,6,1511,"<p>I'm trying to draw in my mind the structure of the LSTMs and I don't understand what are the Kernel and Recurrent Kernel. According to this <a href=""https://mc.ai/a-practical-guide-to-rnn-and-lstm-in-keras/"" rel=""nofollow noreferrer"">post</a> in LSTMs section, the Kernel it's the four matrices that are multiplied by the inputs and Recurrent Kernel it's the four matrices that are multiplied by the hidden state, but, what are those 4 matrices in this diagram?</p>
<p><a href=""https://i.stack.imgur.com/hMXqp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hMXqp.png"" alt=""enter image description here"" /></a></p>
<p>Are the gates?</p>
<p>I was testing with this <a href=""https://netron.app/"" rel=""nofollow noreferrer"">app</a> how the <code>unit</code> variable of the code below affect the kernel, recurrent kernel and bias:</p>
<pre><code>model = Sequential()
model.add(LSTM(unit = 1, input_shape=(1, look_back)))
</code></pre>
<p>with <code>look_back = 1</code> it returns me that:</p>
<p><a href=""https://i.stack.imgur.com/c4SFH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/c4SFH.png"" alt=""enter image description here"" /></a></p>
<p>with <code>unit = 2</code> it returns me this</p>
<p><a href=""https://i.stack.imgur.com/ZGJXO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZGJXO.png"" alt=""enter image description here"" /></a></p>
<p>With <code>unit = 3</code> this</p>
<p><a href=""https://i.stack.imgur.com/l8X2G.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/l8X2G.png"" alt=""enter image description here"" /></a></p>
<p>Testing with this values I could deducted this expressions</p>
<p><a href=""https://i.stack.imgur.com/oRcHX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oRcHX.png"" alt=""enter image description here"" /></a></p>
<p>but I don't know how this works by inside. What does mean <code>&lt;1x(4u)&gt;</code> or <code>&lt;ux(4u)&gt;</code>? <code>u = units</code></p>
",11781705.0,,3653343.0,,2020-11-18 01:41:10,2020-11-18 01:48:59,Kernel and Recurrent Kernel in Keras LSTMs,<python><machine-learning><keras><lstm>,1,0,0.0,,,CC BY-SA 4.0
64155323,1,,,2020-10-01 12:22:38,,6,830,"<p>I'm trying to use <a href=""https://arxiv.org/abs/1702.03275"" rel=""noreferrer"">Batch Renormalization</a> in my model which is implemented in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"" rel=""noreferrer""><code>tf.keras.layers.BatchNormalization</code></a> via the <code>renorm_clipping</code> parameter:</p>
<blockquote>
<p>A dictionary that may map keys 'rmax', 'rmin', 'dmax' to scalar Tensors used to clip the renorm correction. The correction (r,d) is used as corrected_value = normalized_value * r + d, with r clipped to [rmin, rmax], and d to [-dmax, dmax]. Missing rmax, rmin, dmax are set to inf, 0, inf, respectively.</p>
</blockquote>
<p>However, this minimal code example fails with Tensorflow 2.3.1:</p>
<pre class=""lang-py prettyprint-override""><code># The actual input we care about
inputs = tf.keras.Input([1])

# The current global step
step = tf.keras.Input([1])

# Compute renorm parameters from global step
rmax = 1 + step / 1000
rmin = 1 / rmax
dmax = step / 1000

# Instantiate batch norm layer
layer = tf.keras.layers.BatchNormalization(renorm=True, renorm_clipping={
    &quot;rmax&quot;: rmax,
    &quot;rmin&quot;: rmin,
    &quot;dmax&quot;: dmax,
})(inputs)

# Build Model
model = tf.keras.Model(inputs=[inputs, step], outputs=layer)

# Use model in tf.function
@tf.function
def predict(x):
    return model(x, training=True)

predict([tf.constant([[1.0], [1.0]]), tf.constant([[1.0], [2.0]])])
</code></pre>
<p>It fails in the <code>predict()</code> with:</p>
<blockquote>
<p><code>_SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [&lt;tf.Tensor 'RealDiv_7:0' shape=(None, 1) dtype=float32&gt;, &lt;tf.Tensor 'AddV2_2:0' shape=(None, 1) dtype=float32&gt;, &lt;tf.Tensor 'RealDiv_8:0' shape=(None, 1) dtype=float32&gt;]</code></p>
</blockquote>
<p>If I set <code>step</code> to a constant value, everything works as expected, so clearly the problem is that I pass the <code>Input</code> tensor as a parameter to the <code>BatchNormalization</code> constructor. But the batch norm parameters need to updated dynamically and adding the <code>step</code> as an additional input seemed like the most elegant solution.</p>
<p>How would I get this example to work?</p>
",783758.0,,,,,2020-10-01 12:22:38,Batch Renormalization with Tensorflow 2+ and tf.function,<tensorflow><keras><deep-learning>,0,0,,,,CC BY-SA 4.0
64223840,1,64290276.0,,2020-10-06 10:21:15,,6,2862,"<p>I know how to write a custom loss function in Keras with additional input, not the standard <code>y_true</code>, <code>y_pred</code> pair, see below. My issue is inputting the loss function with a <em>trainable</em> variable (a few of them) which is part of the loss gradient and should therefore be updated.</p>
<p>My workaround is:</p>
<ul>
<li>Enter the network a dummy input of <code>N</code>X<code>V</code> size where <code>N</code> is the number of observations and <code>V</code> number of additional variables</li>
<li>Add a <code>Dense()</code> layer <code>dummy_output</code> so that Keras will track my <code>V</code> &quot;weights&quot;</li>
<li>Use this layer's <code>V</code> weights in my custom loss function for my true output layer</li>
<li>Use a dummy loss function (simply returns 0.0 and/or has weight 0.0) for this <code>dummy_output</code> layer so my <code>V</code> &quot;weights&quot; are only updated via my custom loss function</li>
</ul>
<p><strong>My question is:</strong> Is there a more natural Keras/TF-like way of doing this? Because it feels so contrived not to mention prone to bugs.</p>
<p>Example of my workaround:</p>
<p><strong>(Yes I know this is a very silly custom loss function, in reality things are much more complex)</strong></p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.keras.layers import Input
from tensorflow.keras import Model

n_col = 10
n_row = 1000
X = np.random.normal(size=(n_row, n_col))
beta = np.arange(10)
y = X @ beta

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# my custom loss function accepting my dummy layer with 2 variables
def custom_loss_builder(dummy_layer):
    def custom_loss(y_true, y_pred):
        var1 = dummy_layer.trainable_weights[0][0]
        var2 = dummy_layer.trainable_weights[0][1]
        return var1 * K.mean(K.square(y_true-y_pred)) + var2 ** 2 # so var2 should get to zero, var1 should get to minus infinity?
    return custom_loss

# my dummy loss function
def dummy_loss(y_true, y_pred):
    return 0.0

# my dummy input, N X V, where V is 2 for 2 vars
dummy_x_train = np.random.normal(size=(X_train.shape[0], 2)) 

# model
inputs = Input(shape=(X_train.shape[1],))
dummy_input = Input(shape=(dummy_x_train.shape[1],))
hidden1 = Dense(10)(inputs) # here only 1 hidden layer in the &quot;real&quot; network, assume whatever network is built here
output = Dense(1)(hidden1)
dummy_output = Dense(1, use_bias=False)(dummy_input)
model = Model(inputs=[inputs, dummy_input], outputs=[output, dummy_output])

# compilation, notice zero loss for the dummy_output layer
model.compile(
  loss=[custom_loss_builder(model.layers[-1]), dummy_loss],
  loss_weights=[1.0, 0.0], optimizer= 'adam')

# run, notice y_train repeating for dummy_output layer, it will not be used, could have created dummy_y_train as well
history = model.fit([X_train, dummy_x_train], [y_train, y_train],
                    batch_size=32, epochs=100, validation_split=0.1, verbose=0,
                   callbacks=[EarlyStopping(monitor='val_loss', patience=5)])
</code></pre>
<p>Seems to work as indeed whatever the start values for <code>var1</code> and <code>var2</code> (the initialization of the <code>dummy_output</code> layer) they aspire for minus <code>inf</code> and <code>0</code> respectively:</p>
<p>(this plot comes from running the model iteratively and saving those two weights like below)</p>
<pre class=""lang-py prettyprint-override""><code>var1_list = []
var2_list = []
for i in range(100):
    if i % 10 == 0:
        print('step %d' % i)
    model.fit([X_train, dummy_x_train], [y_train, y_train],
              batch_size=32, epochs=1, validation_split=0.1, verbose=0)
    var1, var2 = model.layers[-1].get_weights()[0]
    var1_list.append(var1.item())
    var2_list.append(var2.item())

plt.plot(var1_list, label='var1')
plt.plot(var2_list, 'r', label='var2')
plt.legend()
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/ZFLjp.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ZFLjp.png"" alt=""enter image description here"" /></a></p>
",4095235.0,,4095235.0,,2020-10-06 10:27:34,2020-10-10 05:26:22,Use additional *trainable* variables in Keras/Tensorflow custom loss function,<python><tensorflow><keras><loss-function>,1,3,0.0,,,CC BY-SA 4.0
65131391,1,65132672.0,,2020-12-03 17:51:10,,6,4249,"<p>I am porting a keras model over to <code>torch</code> and I'm having trouble replicating the exact behavior of keras/tensorflow's <code>'categorical_crossentropy'</code> after a softmax layer.  I have some workarounds for this problem, so I'm only interested in understanding what <em>exactly</em> tensorflow calculates when calculating categorical cross entropy.</p>
<p>As a toy problem, I set up labels and predicted vectors</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; from tensorflow.keras import backend as K
&gt;&gt;&gt; import numpy as np


&gt;&gt;&gt; true = np.array([[0.0, 1.0], [1.0, 0.0]])
&gt;&gt;&gt; pred = np.array([[0.0, 1.0], [0.0, 1.0]])
</code></pre>
<p>And calculate the Categorical Cross Entropy with:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; loss = tf.keras.losses.CategoricalCrossentropy()
&gt;&gt;&gt; print(loss(pred, true).eval(session=K.get_session()))
8.05904769897461
</code></pre>
<p>This differs from the analytical result</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; loss_analytical = -1*K.sum(true*K.log(pred))/pred.shape[0]
&gt;&gt;&gt; print(loss_analytical.eval(session=K.get_session()))
nan
</code></pre>
<p>I dug into the source code for keras/tf's cross entropy (see <a href=""https://stackoverflow.com/questions/61558769/softmax-cross-entropy-implementation-in-tensorflow-github-source-code"">Softmax Cross Entropy implementation in Tensorflow Github Source Code</a>) and found the c function at <a href=""https://github.com/tensorflow/tensorflow/blob/c903b4607821a03c36c17b0befa2535c7dd0e066/tensorflow/compiler/tf2xla/kernels/softmax_op.cc"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/c903b4607821a03c36c17b0befa2535c7dd0e066/tensorflow/compiler/tf2xla/kernels/softmax_op.cc</a> line 116.  In that function, there is a comment:</p>
<pre class=""lang-c prettyprint-override""><code>// sum(-labels *
// ((logits - max_logits) - log(sum(exp(logits - max_logits)))))
// along classes
// (The subtraction broadcasts along the batch dimension.)
</code></pre>
<p>And implementing that, I tried:</p>
<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; max_logits = K.max(pred, axis=0)
&gt;&gt;&gt; max_logits = max_logits
&gt;&gt;&gt; xent = K.sum(-true * ((pred - max_logits) - K.log(K.sum(K.exp(pred - max_logits)))))/pred.shape[0]

&gt;&gt;&gt; print(xent.eval(session=K.get_session()))
1.3862943611198906
</code></pre>
<p>I also tried to print the trace for <code>xent.eval(session=K.get_session())</code>, but the trace is ~95000  lines long.  So it begs the question: what exactly is keras/tf doing when calculating <code>'categorical_crossentropy'</code>? It makes sense that it doesn't return <code>nan</code>, that would cause training issues, but where does 8 come from?</p>
",3760011.0,,,,,2020-12-03 20:43:53,What exactly is Keras's CategoricalCrossEntropy doing?,<python><tensorflow><machine-learning><keras>,2,0,0.0,,,CC BY-SA 4.0
64534477,1,,,2020-10-26 09:29:43,,6,1649,"<p>I am trying to save my CNN to a file every at every checkpoint. However which extension should I use as my file directory? Also would I need to call <code>model.save(filepath)</code> at the end of the code or would my model be saved automatically by <code>ModelCheckpoint()</code>?</p>
<p>I have my model saved as a .h5 file but I don't know whether I should change it.</p>
<pre><code>from keras import Sequential
from keras_preprocessing.image import ImageDataGenerator
from keras.layers import *
from keras.callbacks import ModelCheckpoint
import numpy as np
import os

img_size = 500 # number of pixels for width and height

#Random Seed
np.random.seed(12321)


training_path = os.getcwd() + &quot;/cats and dogs images/train&quot;
testing_path = os.getcwd() + &quot;/cats and dogs images/test&quot;

#Defines the Model
model = Sequential([
        Conv2D(filters=64, kernel_size=(3,3), activation=&quot;relu&quot;, padding=&quot;same&quot;, input_shape=(img_size,img_size,3)),
        MaxPool2D(pool_size=(2,2), strides=2),
        Conv2D(filters=64, kernel_size=(3,3), activation=&quot;relu&quot;, padding=&quot;same&quot;),
        MaxPool2D(pool_size=(2,2), strides=2),
        Flatten(),
        Dense(32, activation=&quot;relu&quot;),
        Dense(1, activation=&quot;sigmoid&quot;)
])


#Scales the pixel values to between 0 to 1
datagen = ImageDataGenerator(rescale=1.0/255.0)

#Prepares Training Data
training_dataset = datagen.flow_from_directory(directory = training_path, target_size=(img_size,img_size), classes = [&quot;cat&quot;,&quot;dog&quot;], batch_size = 19)

#Prepares Testing Data
testing_dataset = datagen.flow_from_directory(directory = testing_path, target_size=(img_size,img_size), classes = [&quot;cat&quot;,&quot;dog&quot;], batch_size = 19)


#Compiles the model
model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;adam&quot;, metrics=['accuracy'])


#Checkpoint
checkpoint = ModelCheckpoint(&quot;trained_model.h5&quot;, monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)

#Fitting the model to the dataset (Training the Model)
model.fit(x = training_dataset, steps_per_epoch = 658, validation_data=testing_dataset, validation_steps=658, epochs = 10, callbacks=[checkpoint], verbose = 1)


# evaluate model on training dataset
acc = model.evaluate_generator(training_dataset, steps=len(training_dataset), verbose=0)
print(&quot;Accuracy on training dataset:&quot;)
print('&gt; %.3f' % (acc * 100.0))


#evaluate model on testing dataset
acc = model.evaluate_generator(testing_dataset, steps=len(testing_dataset), verbose=0)
print(&quot;Accuracy on testing dataset:&quot;)
print('&gt; %.3f' % (acc * 100.0))

##Saving the Model:
#model.save(&quot;trained model.h5&quot;)
#print(&quot;Saved model to disk&quot;)
</code></pre>
",13310711.0,,,,,2021-09-30 08:03:18,What is the difference between the file extensions .h5 .hdf5 and .ckpt and which one should I use?,<keras><neural-network><conv-neural-network>,1,0,0.0,,,CC BY-SA 4.0
65305864,1,65381320.0,,2020-12-15 12:28:29,,6,1408,"<p>I'm using Keras to try to predict a vector of scores (0-1) using a sequence of events.</p>
<p>For example, <strong>X</strong> is a sequence of 3 vectors comprised of 6 features each, while <strong>y</strong> is a vector of 3 scores:</p>
<pre><code>X
[
  [1,2,3,4,5,6], &lt;--- dummy data
  [1,2,3,4,5,6],
  [1,2,3,4,5,6]
]

y
[0.34 ,0.12 ,0.46] &lt;--- dummy data
</code></pre>
<p>I want to adress the problem as ordinal classification, so if the actual values are <code>[0.5,0.5,0.5]</code> the prediction <code>[0.49,0.49,0.49]</code> is better then <code>[0.3,0.3,0.3]</code>. My Original solution, was to use <code>sigmoid</code> activation on my last layer and <code>mse</code> as the loss function, so the output is ranged between 0-1 for each of the output neurons:</p>
<pre><code>def get_model(num_samples, num_features, output_size):
    opt = Adam()
    model = Sequential()
    
    model.add(LSTM(config['lstm_neurons'], activation=config['lstm_activation'], input_shape=(num_samples, num_features)))
    model.add(Dropout(config['dropout_rate']))

    for layer in config['dense_layers']:
      model.add(Dense(layer['neurons'], activation=layer['activation']))

    model.add(Dense(output_size, activation='sigmoid'))
    model.compile(loss='mse', optimizer=opt, metrics=['mae', 'mse'])

    return model
</code></pre>
<p>My Goal is to understand the usage of <strong>WeightedKappaLoss</strong> and to implement it on my actual data. I've created <strong><a href=""https://colab.research.google.com/drive/1dJLzdqWLBJDvnExTAv1Ty1kk9ccReluR?usp=sharing"" rel=""noreferrer"">this Colab</a></strong> to fiddle around with the idea.  In the Colab, my data is a sequence shaped <code>(5000,3,3)</code> and my targets shape is <code>(5000, 4)</code> representing 1 of 4 possible classes.</p>
<p>I want the model to understand that it needs to trim the floating point of the X in order to predict the right y class:</p>
<pre><code>[[3.49877793, 3.65873511, 3.20218196],
 [3.20258153, 3.7578669 , 3.83365481],
 [3.9579924 , 3.41765455, 3.89652426]], ----&gt; y is 3 [0,0,1,0]

[[1.74290875, 1.41573056, 1.31195701],
 [1.89952004, 1.95459796, 1.93148095],
 [1.18668981, 1.98982041, 1.89025326]], ----&gt; y is 1 [1,0,0,0]
</code></pre>
<p>New model code:</p>
<pre><code>def get_model(num_samples, num_features, output_size):
    opt = Adam(learning_rate=config['learning_rate'])
    model = Sequential()
    
    model.add(LSTM(config['lstm_neurons'], activation=config['lstm_activation'], input_shape=(num_samples, num_features)))
    model.add(Dropout(config['dropout_rate']))

    for layer in config['dense_layers']:
      model.add(Dense(layer['neurons'], activation=layer['activation']))

    model.add(Dense(output_size, activation='softmax'))
    model.compile(loss=tfa.losses.WeightedKappaLoss(num_classes=4), optimizer=opt, metrics=[tfa.metrics.CohenKappa(num_classes=4)])

    return model
</code></pre>
<p>When fitting the model I can see the following metrics on TensorBoard:
<a href=""https://i.stack.imgur.com/2LslK.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/2LslK.png"" alt=""enter image description here"" /></a><a href=""https://i.stack.imgur.com/zUCMN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/zUCMN.png"" alt=""enter image description here"" /></a></p>
<p>I'm not sure about the following points and would appreciate clarification:</p>
<ul>
<li>Am I using it right?</li>
<li>In my original problem, I'm predicting 3 scores, as opposed of the Colab example, where I'm predicting only 1. If I'm using WeightedKappaLoss, does it mean I'll need to convert each of the scores to a vector of 100 one-hot encoding?</li>
<li>Is there a way to use the WeightedKappaLoss on the original floating point scores without converting to a classification problem?</li>
</ul>
",1115237.0,,1115237.0,,2020-12-16 09:07:56,2020-12-21 01:05:00,Understanding WeightedKappaLoss using Keras,<python><tensorflow><keras><cohen-kappa><ordinal-classification>,1,4,0.0,,,CC BY-SA 4.0
74667876,1,,,2022-12-03 15:01:43,,6,9920,"<p>I am getting the above error when running tensorflow.keras.models.load_model('')</p>
<p>I was working on tensorflow in the Spyder environment and I had no issues.
Since I kept getting prompts (whenever launched Spyder) that the new version 5 of Spyder is available, I uninstalled the existing Spyder version and installed the latest version. In fact I uninstalled Anaconda itself and reinstalled it all over again (since the above problem persisted).
However when running the same programs with included the code for loading an existing saved LSTM model, I got the below error.</p>
<p>prediction_model = tensorflow.keras.models.load_model('')
The model is saved as a .h5 file.</p>
<p>the complete error string when running the load_model command is as follows:</p>
<pre><code>File &quot;C:\Users\ayapp\anaconda3\lib\site-packages\keras\utils\traceback_utils.py&quot;, line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None

  File &quot;C:\Users\ayapp\anaconda3\lib\site-packages\keras\optimizers\optimizer_experimental\optimizer.py&quot;, line 94, in _process_kwargs
    raise TypeError(f&quot;{k} is not a valid argument, kwargs should be empty &quot;

TypeError: weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`.
</code></pre>
<p>This issue was never faced when I was working in my earlier version of Spyder.</p>
<p>Can anybody suggest a solution?</p>
",19577587.0,,,,,2023-02-06 04:23:25,"TypeError: weight_decay is not a valid argument, kwargs should be empty for `optimizer_experimental.Optimizer`",<tensorflow><keras><typeerror><spyder>,3,1,,,,CC BY-SA 4.0
63456418,1,63465999.0,,2020-08-17 18:12:04,,6,12977,"<p>I have been using the famous dogs-vs-cats kaggle dataset and trying to come up with my own CNN Model. I'm new to using the <code>image_dataset_from_directory</code> method to import the dataset after configuring it into two folders that contain the cat and dog images separately.</p>
<p>Here is the code for the model.</p>
<pre><code>from keras.models import Sequential
from keras.layers import Conv2D,MaxPooling2D,\
     Dropout,Flatten,Dense,Activation,\
     BatchNormalization
model=Sequential()
model.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Conv2D(128,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(2,activation='sigmoid'))
model.compile(loss = 'binary_crossentropy',
  optimizer='adam',metrics=['accuracy'])
</code></pre>
<p>And here's the code for the dataset:</p>
<pre><code>Dataset = tf.keras.preprocessing.image_dataset_from_directory(
    TRAIN_DIR,
    labels=&quot;inferred&quot;,
    label_mode=&quot;binary&quot;,
    class_names=None,
    color_mode=&quot;rgb&quot;,
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation=&quot;bilinear&quot;,
    follow_links=False,
)
</code></pre>
<p>After running the fit function to train my CNN. I was shown this error:</p>
<pre><code>ValueError: in user code:

    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\engine\training.py:806 train_function  *
        return step_function(self, iterator)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\engine\training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\engine\training.py:789 run_step  **
        outputs = model.train_step(data)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\engine\training.py:748 train_step
        loss = self.compiled_loss(
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\engine\compile_utils.py:204 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\losses.py:149 __call__
        losses = ag_call(y_true, y_pred)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\losses.py:253 call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\dispatch.py:201 wrapper
        return target(*args, **kwargs)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\losses.py:1605 binary_crossentropy
        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\dispatch.py:201 wrapper
        return target(*args, **kwargs)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\keras\backend.py:4823 binary_crossentropy
        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\dispatch.py:201 wrapper
        return target(*args, **kwargs)
    C:\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\nn_impl.py:173 sigmoid_cross_entropy_with_logits
        raise ValueError(&quot;logits and labels must have the same shape (%s vs %s)&quot; %

    ValueError: logits and labels must have the same shape ((None, 2) vs (None, 1))
</code></pre>
<p>How can I fix this?</p>
",14067807.0,,14067807.0,,2020-08-17 18:27:22,2020-08-18 09:44:44,"Keras: ValueError: logits and labels must have the same shape ((None, 2) vs (None, 1))",<python><tensorflow><keras>,1,8,0.0,,,CC BY-SA 4.0
72336254,1,72336872.0,,2022-05-22 09:20:59,,5,955,"<p>I am trying to predict price values from datasets using keras. I am following this tutorial: <a href=""https://keras.io/examples/structured_data/structured_data_classification_from_scratch/"" rel=""nofollow noreferrer"">https://keras.io/examples/structured_data/structured_data_classification_from_scratch/</a>, but when I get to the part of fitting the model, I am getting a huge negative loss and very small accuracy</p>
<pre><code>Epoch 1/50
1607/1607 [==============================] - ETA: 0s - loss: -117944.7500 - accuracy: 3.8897e-05
2022-05-22 11:14:28.922065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
1607/1607 [==============================] - 15s 10ms/step - loss: -117944.7500 - accuracy: 3.8897e-05 - val_loss: -123246.0547 - val_accuracy: 7.7791e-05
Epoch 2/50
1607/1607 [==============================] - 15s 9ms/step - loss: -117944.7734 - accuracy: 3.8897e-05 - val_loss: -123246.0547 - val_accuracy: 7.7791e-05
Epoch 3/50
1607/1607 [==============================] - 15s 10ms/step - loss: -117939.4844 - accuracy: 3.8897e-05 - val_loss: -123245.9922 - val_accuracy: 7.7791e-05
Epoch 4/50
1607/1607 [==============================] - 16s 10ms/step - loss: -117944.0859 - accuracy: 3.8897e-05 - val_loss: -123245.9844 - val_accuracy: 7.7791e-05
Epoch 5/50
1607/1607 [==============================] - 15s 10ms/step - loss: -117944.7422 - accuracy: 3.8897e-05 - val_loss: -123246.0547 - val_accuracy: 7.7791e-05
Epoch 6/50
1607/1607 [==============================] - 15s 10ms/step - loss: -117944.8203 - accuracy: 3.8897e-05 - val_loss: -123245.9766 - val_accuracy: 7.7791e-05
Epoch 7/50
1607/1607 [==============================] - 15s 10ms/step - loss: -117944.8047 - accuracy: 3.8897e-05 - val_loss: -123246.0234 - val_accuracy: 7.7791e-05
Epoch 8/50
1607/1607 [==============================] - 15s 10ms/step - loss: -117944.7578 - accuracy: 3.8897e-05 - val_loss: -123245.9766 - val_accuracy: 7.7791e-05
Epoch 9/50
</code></pre>
<p><a href=""https://i.stack.imgur.com/RLTVC.png"" rel=""nofollow noreferrer"">This is my graph</a>, as far as the code, it looks like the one from the example but adapted:</p>
<pre><code># Categorical feature encoded as string
desc = keras.Input(shape=(1,), name=&quot;desc&quot;, dtype=&quot;string&quot;)

# Numerical features
date = keras.Input(shape=(1,), name=&quot;date&quot;)
quant = keras.Input(shape=(1,), name=&quot;quant&quot;)

all_inputs = [
    desc,
    quant,
    date,
]

# String categorical features
desc_encoded = encode_categorical_feature(desc, &quot;desc&quot;, train_ds)

# Numerical features
quant_encoded = encode_numerical_feature(quant, &quot;quant&quot;, train_ds)
date_encoded = encode_numerical_feature(date, &quot;date&quot;, train_ds)

all_features = layers.concatenate(
    [
        desc_encoded,
        quant_encoded,
        date_encoded,
    ]
)
x = layers.Dense(32, activation=&quot;sigmoid&quot;)(all_features)
x = layers.Dropout(0.5)(x)
output = layers.Dense(1, activation=&quot;relu&quot;)(x)
model = keras.Model(all_inputs, output)
model.compile(&quot;adam&quot;, &quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;])
</code></pre>
<p>And the dataset looks like this:</p>
<pre><code>date    desc    quant   price
0   20140101.0  CARBONATO DE DIMETILO   999.00  1428.57
1   20140101.0  HIDROQUINONA    137.00  1314.82
2   20140101.0  1,5 PENTANODIOL TECN.   495.00  2811.60
3   20140101.0  SOSA CAUSTICA LIQUIDA 50%   567160.61   113109.14
4   20140101.0  BOROHIDRURO SODICO  6.24    299.27
</code></pre>
<p>Also I am converting the date from being YYYY-MM-DD to being numbers using:</p>
<pre><code>dataset['date'] = pd.to_datetime(dataset[&quot;date&quot;]).dt.strftime(&quot;%Y%m%d&quot;).astype('float64')
</code></pre>
<p>What am I doing wrong? :(</p>
<p>EDIT: I though the encoder function from the tutorial was normalizing data, but it wasnt. Is there any other tutorial that you know guys which can guide me better? The loss problem has been fixed ! (was due to normalization)</p>
",17397969.0,,17397969.0,,2022-05-22 11:37:58,2022-05-22 11:37:58,Negative huge loss in tensorflow,<python><tensorflow><machine-learning><keras><deep-learning>,1,3,,,,CC BY-SA 4.0
71300786,1,,,2022-02-28 20:35:25,,5,954,"<p>I have a simple model that currently outputs a single numerical value which I've adapted to instead output a distribution using TFP (mean + std deviation) so I can instead understand the model's confidence around the prediction.</p>
<pre><code>  model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, input_shape=[len(df.columns),], activation='relu'), # Should only be one input, so [1,]
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(2 * len(target.columns)), # there are 2 outputs, so we want a mean + standard deviation for EACH of the outputs
    tfp.layers.DistributionLambda(
      lambda t: tfd.Normal(loc=t[..., :1],
                           scale=1e-3 + tf.math.softplus(0.05 * t[...,1:]))
    )
  ])
</code></pre>
<p>The current 2 Dense outputs point to the mean + standard deviation of the output distribution.</p>
<p>In my real dataset, I have two numerical values I attempt to predict based on input data. How do I make a model output two distributions? I think the final Dense layer would need to be 4 nodes (2 means and 2 standard deviations), but I'm not sure how to make this properly work with the Distribution Lambda. I'm hoping to have a single model that predicts this rather than having to train one model per target output.</p>
<p><strong>EDIT</strong>: I created this collab for people to see what I'm getting at a little more easily. I simplified the example a little bit more and hopefully, it's more self-explanatory what I'm trying to accomplish:</p>
<p><a href=""https://colab.research.google.com/drive/1Wlucked4V0z-Bm_ql8XJnOJL0Gm4EwnE?usp=sharing"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/1Wlucked4V0z-Bm_ql8XJnOJL0Gm4EwnE?usp=sharing</a></p>
",4352047.0,,9215780.0,,2022-03-10 06:26:35,2022-03-10 17:22:43,TensorFlow Probability - want NN to output multiple distributions,<python><tensorflow><keras><tensorflow-probability>,2,0,,,,CC BY-SA 4.0
64405461,1,64405520.0,,2020-10-17 17:41:49,,5,10212,"<p>Trying to add Densenet121 functional block to the model.
I need Keras model to be written in this format, not using</p>
<pre><code>model=Sequential() 
model.add()
</code></pre>
<p>method
What's wrong the function, build_img_encod</p>
<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-62-69dd207148e0&gt; in &lt;module&gt;()
----&gt; 1 x = build_img_encod()

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py in assert_input_compatibility(input_spec, inputs, layer_name)
    164         spec.min_ndim is not None or
    165         spec.max_ndim is not None):
--&gt; 166       if x.shape.ndims is None:
    167         raise ValueError('Input ' + str(input_index) + ' of layer ' +
    168                          layer_name + ' is incompatible with the layer: '

AttributeError: 'Functional' object has no attribute 'shape'
</code></pre>
<pre><code>def build_img_encod( ):
    base_model = DenseNet121(input_shape=(150,150,3),
                                 include_top=False,
                                 weights='imagenet')
    for layer in base_model.layers:
            layer.trainable = False
    flatten = Flatten(name=&quot;flatten&quot;)(base_model)
    img_dense_encoder = Dense(1024, activation='relu',name=&quot;img_dense_encoder&quot;, kernel_regularizer=regularizers.l2(0.0001))(flatten)
    model = keras.models.Model(inputs=base_model, outputs = img_dense_encoder)
    return model
</code></pre>
",14309081.0,,6117017.0,,2020-10-17 17:53:03,2020-10-17 17:53:45,Keras AttributeError: 'Functional' object has no attribute 'shape',<tensorflow><keras><deep-learning><transfer-learning>,2,0,,,,CC BY-SA 4.0
68712545,1,,,2021-08-09 13:03:38,,5,1373,"<p>I'm training a model for image segmentation using tf.keras using a custom data generator to read and augment images. While training the model works fine (i.e. without memory problems), when trying to predict on my test set my GPU (8GB, see nvidia-smi later) runs out of memory. This is the case both when predicting directly after training and after restarting the kernel, loading the model using <code>model.load_weights()</code> and using <code>model.predict()</code> afterwards and with the same batch size used in training (4, using ~6GB of memory during training) or a batch size of 1 with both batch sizes trying to allocate more than 8GB.</p>
<p>During training, the memory usage is stable around 6GB but when using <code>model.predict()</code> it starts out at around 6GB but jumps to 8GB after approximately 10 seconds before throwing the <code>ResourceExhaustedError</code>(see later for stacktrace). This seems very counter-intuitive to me and the tips I've found through google (e.g. restarting python, loading the model from weights, then predict to free memory used beforehand) haven't worked, so any help would be great.</p>
<p>The output of <code>!nvidia-smi</code>, my code for the data generator and training/prediction including error messages are as follows:</p>
<h1>nvidia-smi</h1>
<pre><code>Mon Aug  9 14:27:29 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 471.11       Driver Version: 471.11       CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ... WDDM  | 00000000:0D:00.0  On |                  N/A |
| 56%   50C    P8    24W / 220W |   8057MiB /  8192MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1576    C+G   Insufficient Permissions        N/A      |
|    0   N/A  N/A      2292    C+G   ...kyb3d8bbwe\Calculator.exe    N/A      |
|    0   N/A  N/A      8316    C+G   C:\Windows\explorer.exe         N/A      |
|    0   N/A  N/A      8736    C+G   ...lPanel\SystemSettings.exe    N/A      |
|    0   N/A  N/A     11220    C+G   ...bbwe\Microsoft.Photos.exe    N/A      |
|    0   N/A  N/A     11740    C+G   ...5n1h2txyewy\SearchApp.exe    N/A      |
|    0   N/A  N/A     12280    C+G   ...ekyb3d8bbwe\YourPhone.exe    N/A      |
|    0   N/A  N/A     12820    C+G   ...8wekyb3d8bbwe\GameBar.exe    N/A      |
|    0   N/A  N/A     13820    C+G   ...perience\NVIDIA Share.exe    N/A      |
|    0   N/A  N/A     14552    C+G   ...nputApp\TextInputHost.exe    N/A      |
|    0   N/A  N/A     14848    C+G   ...y\ShellExperienceHost.exe    N/A      |
|    0   N/A  N/A     14976    C+G   ...zilla Firefox\firefox.exe    N/A      |
|    0   N/A  N/A     15688    C+G   ...udibleRT.WindowsPhone.exe    N/A      |
|    0   N/A  N/A     16628      C   ...Data\Anaconda3\python.exe    N/A      |
|    0   N/A  N/A     23648    C+G   ...aming\Spotify\Spotify.exe    N/A      |
+-----------------------------------------------------------------------------+
</code></pre>
<h1>Data Generator</h1>
<pre class=""lang-py prettyprint-override""><code>class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, batch_size, mode=&quot;train&quot;, shuffle=True, augment=False, p_augment=0,
                 union=False, greyscale=False, normalize=True, dims=(256, 1600)):
        &quot;&quot;&quot;DataGenerator usable for train/val/test splits&quot;&quot;&quot;
        self.df = df
        self.length = len(df)
        self.BATCH_SIZE = batch_size
        self.mode = mode
        self.shuffle = shuffle
        self.augment = augment
        self.p_augment = p_augment
        self.union = union
        self.greyscale = greyscale
        self.normalize = normalize
        self.dims = dims
        self.num_channels = 1 if greyscale else 3
        self.num_classes = 1 if union else 4
        self.indices = df.index.values.tolist() # will be reset anyways
        self.on_epoch_end()
        
        assert mode in [&quot;train&quot;, &quot;predict&quot;], &quot;DataGenerator mode is unsupported. Set it to \&quot;train\&quot; or \&quot;predict\&quot;.&quot;
        if augment:
            assert p_augment &gt; 0 and p_augment &lt;= 1, &quot;Augmentation is turned on, but probability is zero or larger than one.&quot;
        
        
    def __len__(self):
        &quot;&quot;&quot;number of batches in each epoch&quot;&quot;&quot;
        return int(np.floor(self.length / self.BATCH_SIZE))
    
    
    def on_epoch_end(self):
        &quot;&quot;&quot;shuffle list of indices&quot;&quot;&quot;
        # called on the end of every epoch
        self.indices = self.df.index.values.tolist()
        if self.shuffle:
            np.random.shuffle(self.indices)
            
    
    def _load_img(self, img_path):
        &quot;&quot;&quot;loads image in RGB/greyscale and normalizes it&quot;&quot;&quot;
        if self.greyscale:
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        else:
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
        if self.normalize:
            img = img.astype(np.float32) / 255.
        else:
            img = img.astype(np.float32)
            
        return img
    
    
    def _gen_x(self, idx_list):
        &quot;&quot;&quot;generates input values from list of indices&quot;&quot;&quot;
        res = np.empty(shape=(self.BATCH_SIZE, *self.dims, self.num_channels))
        
        for i, df_idx in enumerate(idx_list):
            img_path = self.df.loc[df_idx][&quot;img_id&quot;]
            img = self._load_img(img_path)
            if self.greyscale:
                res[i, ] = np.expand_dims(img, axis=-1)
            else:
                res[i, ] = img
            
        return res
    
    
    def _gen_tgt(self, idx_list):
        &quot;&quot;&quot;generates target values from list of indices&quot;&quot;&quot;
        res = np.empty(shape=(self.BATCH_SIZE, *self.dims, self.num_classes))
        
        for i, df_idx in enumerate(idx_list):
            rles = self.df.loc[df_idx][&quot;c1&quot;:&quot;c_all&quot;]
            if self.union:
                # return mask of all defect pixels (no diff between defect class)
                masks = build_masks(rles, union_only=True)
            else:
                masks = build_masks(rles)
            res[i, ] = masks
            
        return res
    
    
    def __getitem__(self, idx):
        &quot;&quot;&quot;creates one batch of data&quot;&quot;&quot;
        # get indices of batch (self.indices is shuffled list of df indices)
        idxs = self.indices[idx*self.BATCH_SIZE:(idx+1)*self.BATCH_SIZE]
        
        x = self._gen_x(idxs)
        
        if self.mode == &quot;predict&quot;:
            return x
        
        # mode is train -&gt; get target data and possible augment
        tgt = self._gen_tgt(idxs)
        if self.augment:
            x, tgt = self._augment_batch(x, tgt)
        
        return x, tgt
    
    
    def _augment_batch(self, _x, _tgt):
        # flips img and masks vertically and/or horizontally with p_augment respectively
        for i in range(self.BATCH_SIZE):
            # flip up-down
            if random.random() &gt; self.p_augment:
                if self.greyscale:
                    _x[i] = np.expand_dims(cv2.flip(_x[i], flipCode=0), axis=-1)
                else:
                    _x[i] = cv2.flip(_x[i], flipCode=0)
                _tgt[i] = cv2.flip(_tgt[i], flipCode=0)
            
            # flip left-right
            if random.random() &gt; self.p_augment:
                if self.greyscale:
                    _x[i] = np.expand_dims(cv2.flip(_x[i], flipCode=1), axis=-1)
                else:
                    _x[i] = cv2.flip(_x[i], flipCode=1)
                _tgt[i] = cv2.flip(_tgt[i], flipCode=1)
                
        return _x, _tgt
</code></pre>
<h1>Training</h1>
<pre class=""lang-py prettyprint-override""><code>from copy import deepcopy

# configs for train/val datagens
train_config = {&quot;mode&quot;: &quot;train&quot;,
               &quot;batch_size&quot;: 4,
               &quot;shuffle&quot;:True,
               &quot;augment&quot;:True,
               &quot;p_augment&quot;: 0.5,
               &quot;union&quot;: False,
               &quot;greyscale&quot;: False,
               &quot;normalize&quot;: True,
               &quot;dims&quot;: (256,1600)}

val_config = deepcopy(train_config)
val_config[&quot;shuffle&quot;] = False
val_config[&quot;augment&quot;] = False

train_datagen = DataGenerator(df_train, **train_config)
val_datagen = DataGenerator(df_val, **val_config)

# returns model with correct image dims and number of classes
model = get_model_from_generator(train_datagen)
model.compile(optimizer=Adam(learning_rate=1e-4), loss=bce_dice_loss,
                   metrics=[&quot;binary_crossentropy&quot;, dice_coef])

cb_es = tf.keras.callbacks.EarlyStopping(monitor=&quot;val_loss&quot;, patience=10)
cb_best = tf.keras.callbacks.ModelCheckpoint(&quot;models/fcn_rgb/cp_{epoch:02d}_{val_loss:.3f}.ckpt&quot;, monitor=&quot;val_loss&quot;,
                                             save_weights_only=True, save_best_only=True)
history = model.fit(x=train_datagen, callbacks=[cb_es, cb_best], epochs=100,
                           validation_data=val_datagen)
</code></pre>
<p>which trains fine (see output of first epochs)</p>
<pre><code>Epoch 1/100
2513/2513 [==============================] - 541s 207ms/step - loss: 0.2413 - binary_crossentropy: 0.5235 - dice_coef: 0.0205 - val_loss: -0.0034 - val_binary_crossentropy: 0.1481 - val_dice_coef: 0.0775
Epoch 2/100
2513/2513 [==============================] - 518s 206ms/step - loss: -0.1231 - binary_crossentropy: 0.0864 - dice_coef: 0.1663 - val_loss: -0.2862 - val_binary_crossentropy: 0.0627 - val_dice_coef: 0.3175
</code></pre>
<h1>Prediction</h1>
<p>Throws the same error with or without restarting the kernel after training the model.</p>
<pre class=""lang-py prettyprint-override""><code>test_config = {&quot;mode&quot;: &quot;predict&quot;,
               &quot;batch_size&quot;: 1,
               &quot;shuffle&quot;:False,
               &quot;augment&quot;:False,
               &quot;p_augment&quot;: 0,
               &quot;union&quot;: False,
               &quot;greyscale&quot;: False,
               &quot;normalize&quot;: True,
               &quot;dims&quot;: (256,1600)}

test_datagen = DataGenerator(df_test, **test_config)
model = get_model_from_generator(train_datagen)
model.load_weights(&quot;models/fcn_rgb/cp_38_-0.497.ckpt&quot;)
preds = model.predict(test_datagen)
</code></pre>
<p>error message:</p>
<pre><code>---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
&lt;ipython-input-16-d0a77a4d2cd0&gt; in &lt;module&gt;
----&gt; 1 preds = model.predict(test_datagen)

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\engine\training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1627           for step in data_handler.steps():
   1628             callbacks.on_predict_batch_begin(step)
-&gt; 1629             tmp_batch_outputs = self.predict_function(iterator)
   1630             if data_handler.should_sync:
   1631               context.async_wait()

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--&gt; 828       result = self._call(*args, **kwds)
    829       compiler = &quot;xla&quot; if self._experimental_compile else &quot;nonXla&quot;
    830       new_tracing_count = self.experimental_get_tracing_count()

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    860       # In this case we have not created variables on the first call. So we can
    861       # run the first trace but we should fail if variables are created.
--&gt; 862       results = self._stateful_fn(*args, **kwds)
    863       if self._created_variables:
    864         raise ValueError(&quot;Creating variables on a non-first call to a function&quot;

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
   2940       (graph_function,
   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)
-&gt; 2942     return graph_function._call_flat(
   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   2944 

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1916         and executing_eagerly):
   1917       # No tape is watching; skip to running the function.
-&gt; 1918       return self._build_call_outputs(self._inference_function.call(
   1919           ctx, args, cancellation_manager=cancellation_manager))
   1920     forward_backward = self._select_forward_and_backward_functions(

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    553       with _InterpolateFunctionError(self):
    554         if cancellation_manager is None:
--&gt; 555           outputs = execute.execute(
    556               str(self.signature.name),
    557               num_outputs=self._num_outputs,

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---&gt; 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:

ResourceExhaustedError:  OOM when allocating tensor with shape[1,96,128,800] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
     [[node model_1/batch_normalization_57/FusedBatchNormV3 (defined at &lt;ipython-input-16-d0a77a4d2cd0&gt;:1) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_predict_function_8858]

Function call stack:
predict_function
</code></pre>
<p>I'm using tensorflow version 2.4.1.</p>
<p>edit:
I forgot to mention I've also tried activation tfs dynamic memory allocation before both training and predicting with the following code, but the error still appears.</p>
<pre><code># dynamic memory allocation
gpus = tf.config.list_physical_devices(&quot;GPU&quot;)
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        logical_gpus = tf.config.experimental.list_logical_devices(&quot;GPU&quot;)
        print(len(gpus), &quot;Physical GPUs,&quot;, len(logical_gpus), &quot;Logical GPUs&quot;)
    except RuntimeError as e:
        # must be set before GPUs have been initialized
        print(e)
</code></pre>
",5130444.0,,,,,2021-08-09 13:03:38,Tensorflow Keras model OOM when using model.predict() although training using model.fit() runs without problems,<python><tensorflow><machine-learning><keras><out-of-memory>,0,6,0.0,,,CC BY-SA 4.0
71241340,1,,,2022-02-23 17:15:01,,5,213,"<p>I would like to implement a metric in TensorFlow based on the combined results of two outputs.</p>
<p>My model takes in a 100-character string and returns two outputs (called flavour and form) based on this string. These outputs are both softmax probabilities that are compared with a one-hot encoded vectors (standard classification). The code for the model is:</p>
<pre><code>inputs = Input(shape=(None,))
input_embeddings = Embedding(vocab_size, embedding_size, mask_zero=True)(inputs)

shared_lstm = Bidirectional(LSTM(units, return_sequences=True, dropout=0.2))(input_embeddings)

fl_lstm = Bidirectional(LSTM(units, dropout=0.2))(shared_lstm)
fl_dense = Dense(flavour_size, activation='softmax', name='flavour')(fl_lstm)

fo_lstm = Bidirectional(LSTM(units, dropout=0.2))(shared_lstm)
fo_dense = Dense(form_size, activation='softmax', name='form')(fo_lstm)

split_shared_model = Model(inputs=inputs, outputs=[fl_dense, fo_dense])
</code></pre>
<p>Here is a flow diagram of the model's architecture:</p>
<p><a href=""https://i.stack.imgur.com/75vQh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/75vQh.png"" alt=""enter image description here"" /></a></p>
<p>Currently, I am compiling and fitting as follows:</p>
<pre><code>split_shared_model.compile(optimizer='adam', loss=CategoricalCrossentropy(), 
                  metrics=['accuracy'])

split_shared_model.fit(X_train, [fl_train, fo_train],
                       batch_size=32,
                       epochs=10)
</code></pre>
<p>Each of the individual outputs (flavour and form) reach score around 96% accuracy on the test set. However, I would like to create a metric that combines these two predictions and assess them together. Something that might look a little bit like:</p>
<pre><code>def combined_accuracy(fl_true, fo_true, fl_pred, fo_pred):
    correct_fl = K.equal(fl_true, K.round(fl_pred))
    correct_fo = K.equal(fo_true, K.round(fo_pred))
    combined = tf.logical_and(correct_fl, correct_fo)
    return K.mean(combined)
</code></pre>
<p>I've looked at the Keras documentation (<a href=""https://keras.io/api/metrics/#creating-custom-metrics"" rel=""nofollow noreferrer"">https://keras.io/api/metrics/#creating-custom-metrics</a>), but it seems as if the custom metric is applied to each output individually.</p>
<p>What can I try next?</p>
",13498838.0,,13498838.0,,2022-03-13 07:19:47,2022-03-13 07:19:47,How can I combine two outputs to form a custom metric in TensorFlow?,<python><tensorflow><keras><metrics>,0,0,,,,CC BY-SA 4.0
64401472,1,64402227.0,,2020-10-17 10:33:21,,5,613,"<p>The following code gives me error <code>ValueError: Shapes (None, 3, 2) and (None, 2) are incompatible</code>. What I want to do is to construct a multi-task network. How should I resolve it? I am using Tensorflow 2.3.0.</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras import Model


base_model = tf.keras.applications.EfficientNetB7(input_shape=(32,32, 3), weights='imagenet',
                                                  include_top=False)  # or weights='noisy-student'

for layer in base_model.layers[:]:
    layer.trainable = False

x = GlobalAveragePooling2D()(base_model.output)
dropout_rate = 0.3


x = Dense(256, activation='relu')(x)
x = Dropout(dropout_rate)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(dropout_rate)(x)


all_target = []
loss_list = []
test_metrics = {}
for name, node in  [(&quot;task1&quot;, 2), (&quot;task2&quot;, 2), (&quot;task3&quot;, 2)]:
    y1 = Dense(128, activation='relu')(x)
    y1 = Dropout(dropout_rate)(y1)
    y1 = Dense(64, activation='relu')(y1)
    y1 = Dropout(dropout_rate)(y1)
    # y1 = Dense(64, activation='relu')(y1)
    # y1 = Dropout(dropout_rate)(y1)
    y1 = Dense(node, activation='softmax', name=name)(y1)
    all_target.append(y1)
    loss_list.append('categorical_crossentropy')
    test_metrics[name] = &quot;accuracy&quot;

#    model = Model(inputs=model_input, outputs=[y1, y2, y3])
model = Model(inputs=base_model.input, outputs=all_target)

model.compile(loss=loss_list, optimizer='adam', metrics=test_metrics)

res=np.random.randint(2, size=3072).reshape(32, 32, 3)
res=np.expand_dims(res, 0)

lab=np.array([[[0,1], [0,1], [0,1]]])

history = model.fit(res, y=lab, epochs=1, verbose=1)
</code></pre>
",1497720.0,,1164465.0,,2020-10-17 12:10:32,2020-10-17 17:29:56,"How to fix Keras ValueError: Shapes (None, 3, 2) and (None, 2) are incompatible?",<python><tensorflow><keras><tensorflow2.0>,1,0,,,,CC BY-SA 4.0
62951662,1,62951778.0,,2020-07-17 10:00:53,,5,7489,"<p>I'm trying to create a keras model with multiple input branches, but keras doesn't like that the inputs have different sizes.</p>
<p>Here is a minimal example:</p>
<pre><code>import numpy as np

from tensorflow import keras
from tensorflow.keras import layers


inputA = layers.Input(shape=(2,))
xA = layers.Dense(8, activation='relu')(inputA)

inputB = layers.Input(shape=(3,))
xB = layers.Dense(8, activation='relu')(inputB)

merged = layers.Concatenate()([xA, xB])

output = layers.Dense(8, activation='linear')(merged)    

model = keras.Model(inputs=[inputA, inputB], outputs=output)


a = np.array([1, 2])
b = np.array([3, 4, 5])    

model.predict([a, b])
</code></pre>
<p>Which results in the error:</p>
<pre><code>ValueError: Data cardinality is ambiguous:
  x sizes: 2, 3
Please provide data which shares the same first dimension.
</code></pre>
<p>Is there a better way to do this in keras? I've read the other questions referencing the same error, but I'm not really understanding what I need to change.</p>
",58866.0,,10375049.0,,2022-01-03 08:37:30,2022-01-03 08:37:30,ValueError: Data cardinality is ambiguous. Please provide data which shares the same first dimension,<python><tensorflow><machine-learning><keras>,1,0,0.0,,,CC BY-SA 4.0
64407457,1,,,2020-10-17 21:20:56,,5,1538,"<p>This is tf 2.3.0. During training, reported values for SparseCategoricalCrossentropy loss and sparse_categorical_accuracy seemed way off. I looked through my code but couldn't spot any errors yet. Here's the code to reproduce:</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

x = np.random.randint(0, 255, size=(64, 224, 224, 3)).astype('float32')
y = np.random.randint(0, 3, (64, 1)).astype('int32')

ds = tf.data.Dataset.from_tensor_slices((x, y)).batch(32)

def create_model():
  input_layer = tf.keras.layers.Input(shape=(224, 224, 3), name='img_input')
  x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, name='rescale_1_over_255')(input_layer)

  base_model = tf.keras.applications.ResNet50(input_tensor=x, weights='imagenet', include_top=False)

  x = tf.keras.layers.GlobalAveragePooling2D(name='global_avg_pool_2d')(base_model.output)

  output = Dense(3, activation='softmax', name='predictions')(x)

  return tf.keras.models.Model(inputs=input_layer, outputs=output)

model = create_model()

model.compile(
  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
  loss=tf.keras.losses.SparseCategoricalCrossentropy(), 
  metrics=['sparse_categorical_accuracy']
)

model.fit(ds, steps_per_epoch=2, epochs=5)
</code></pre>
<p>This is what printed:</p>
<pre><code>Epoch 1/5
2/2 [==============================] - 0s 91ms/step - loss: 1.5160 - sparse_categorical_accuracy: 0.2969
Epoch 2/5
2/2 [==============================] - 0s 85ms/step - loss: 0.0892 - sparse_categorical_accuracy: 1.0000
Epoch 3/5
2/2 [==============================] - 0s 84ms/step - loss: 0.0230 - sparse_categorical_accuracy: 1.0000
Epoch 4/5
2/2 [==============================] - 0s 82ms/step - loss: 0.0109 - sparse_categorical_accuracy: 1.0000
Epoch 5/5
2/2 [==============================] - 0s 82ms/step - loss: 0.0065 - sparse_categorical_accuracy: 1.0000
</code></pre>
<p>But if I double check with model.evaluate, and &quot;manually&quot; checking the accuracy:</p>
<pre><code>model.evaluate(ds)

2/2 [==============================] - 0s 25ms/step - loss: 1.2681 - sparse_categorical_accuracy: 0.2188
[1.268101453781128, 0.21875]

y_pred = model.predict(ds)
y_pred = np.argmax(y_pred, axis=-1)
y_pred = y_pred.reshape(-1, 1)
np.sum(y == y_pred)/len(y)

0.21875
</code></pre>
<p>Result from model.evaluate(...) agrees on the metrics with &quot;manual&quot; checking. But if you stare at the loss/metrics from training, they look way off. It is rather hard to see whats wrong since no error or exception is ever thrown.</p>
<p>Additionally, i created a very simple case to try to reproduce this, but it actually is not reproducible here. Note that batch_size == length of data so this isnt mini-batch GD, but full batch GD (to eliminate confusion with mini-batch loss/metrics:</p>
<pre><code>x = np.random.randn(1024, 1).astype('float32')
y = np.random.randint(0, 3, (1024, 1)).astype('int32')
ds = tf.data.Dataset.from_tensor_slices((x, y)).batch(1024)
model = Sequential()
model.add(Dense(3, activation='softmax'))
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(), 
    metrics=['sparse_categorical_accuracy']
)
model.fit(ds, epochs=5)
model.evaluate(ds)
</code></pre>
<p>As mentioned in my comment, one suspect is batch norm layer, which I dont have for the case that can't reproduce.</p>
",1762295.0,,1762295.0,,2020-10-18 00:18:05,2020-10-19 00:18:33,tf keras SparseCategoricalCrossentropy and sparse_categorical_accuracy reporting wrong values during training,<tensorflow><keras><cross-entropy>,2,5,0.0,,,CC BY-SA 4.0
66268795,1,,,2021-02-18 22:02:04,,5,1967,"<p><strong>TLDR;</strong> Made a custom tf.keras.utils.Sequence [<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"" rel=""noreferrer"">1</a>] to load batched data into <code>keras.model.fit(...)</code>. Generator had considerably worse performance than when model is called on data loaded from memory, even though hyperparameters/model/data structure is the same. Model was overfitting so was wondering if the index argument from the <code>model.fit(...)</code> [<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""noreferrer"">2</a>] method to the <code>__getitem__(..., index)</code> method in the generator causes the same images to be fed to the model multiple times? <strong>How is the index argument selected? is it ordered? is the max index controlled by the <code>__len(...)__</code>?</strong></p>
<p><strong>References</strong></p>
<ol>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"" rel=""noreferrer"">tf.keras.utils.Sequence</a></li>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/Model"" rel=""noreferrer"">keras.model.fit</a></li>
</ol>
<p>I am using a subclass of tf.keras.utils.Sequence [<a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"" rel=""noreferrer"">1</a>] to feed batches of data to the model.fit(...) method, shown below.</p>
<pre><code>class Generator(Sequence):
    
    def __init__(self, df, x, y, file_type, req_dim, directory, batch_size):
        # data info
        self.df = df
        self.x = self.df[x]  # path list to images being loaded
        self.y = self.df[y]  # corresponding target values
        self.index = self.df.index.to_list()
        self.directory = directory  # directory where features images are stored 
        self.file_type = file_type  # dictate which type of image to load 
        # for batches
        self.batch_size = batch_size

    def __len__(self):
        &quot;&quot;&quot;
        :returns number of batches per epoch
        &quot;&quot;&quot;
        return int(np.floor(len(self.df) / self.batch_size))

    def __getitem__(self, index):
        &quot;&quot;&quot;
        receives call from keras (index) and grabs corresponding data batch
        :param index:
        :return:
        &quot;&quot;&quot;
        # instantiate output array
        x = np.empty((self.batch_size, *self.req_dim))

        # batches
        batch_x = self.x[index*self.batch_size:(index+1)*self.batch_size].to_numpy()
        batch_y = self.y[index*self.batch_size:(index+1)*self.batch_size].to_numpy(dtype=float)

        for i in batch_x:

            # logic to load images + perform operations on them
            im = load(...)
            im = operations(im)
            
            x[i, ] = im  # makes batches of ims

        return tuple((x, batch_y.reshape(-1, 1)))

</code></pre>
<p>Traditionally i have loaded the data directly into memory but have needed to use the above Sequence subclass (similar to a generator, will refer to as generator moving forward) to deal with larger file sizes. To test if the generator worked i used data that could be loaded both directly into memory <em>and</em> with the generator. The results from data loaded into memory are consistent with previous experiments while using the generator causes the model to over-fit on the training data.</p>
<p>Since the model was overfitting i was wondering if the index argument input in the<code>__getitem__(self, index)</code>, which is sent by keras to retrieve a given batch number, was ordered or if it can cause a single image to be read in multiple times?</p>
<p>The generator is used in the below pseudo code:</p>
<pre><code># load data
data = load_data(...)

# split data according to batch size used later so that each split has an equal number of samples when 
# divided into batches
train, test, val = train_test_split(data) 

scaler = Scaler()
train['target'] = scaler.fit_transform(train['target'])
test['target'] = scaler.transform(test['target'])
val['target'] = scaler.transform(val['target'])

# instantiate generator
train_gen = DataGenerator(train, x='feature_name', y='target', file_type, dims, directory, batch_size=5)

# load validation images and targets directly to memory
val_x = load(...)
val_y = val['target'].to_numpy(dtype=float)


model = model_1(*dims)  # Convolutional neural network that takes in height, width, depth args

model.compile(optimizer=Adam(lr=1e-5, decay=1e-5/400), loss=LogCosh())

history = model.fit(train_gen, validation_data=(val_x, val_y)

pred = model.pred(test)

</code></pre>
",13891768.0,,13891768.0,,2021-02-19 15:00:10,2022-02-25 07:47:55,What is the index argument from the __getitem__(...) method in tf.keras.utils.Sequence?,<python><tensorflow><keras><conv-neural-network>,2,3,,,,CC BY-SA 4.0
64775882,1,64857775.0,,2020-11-10 19:55:45,,5,340,"<p>I'm working on testing a model before I let it rip on a full dataset. My data is RGB images in an array, so, my training dataset currently has the dimensions</p>
<pre><code>&gt; dim(ff_train)
[1]  10 500 500   3
</code></pre>
<p>So, 10 images, each 500x500 with 3 color layers (RGB).</p>
<p>My test data is the same</p>
<pre><code>&gt; dim(ff_test)
[1]  10 500 500   3
</code></pre>
<p>I've setup my model like so:</p>
<pre><code>

model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;, 
              input_shape = c(10)) %&gt;%
  layer_dense(units = 16, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

model %&gt;% compile(
  optimizer = &quot;rmsprop&quot;,
  loss = &quot;binary_crossentropy&quot;,
  metrics = c(&quot;accuracy&quot;)
)

history &lt;- model %&gt;% fit(
  x = ff_train,
  y = ff_train_labels$fraction_yes,
  epochs = 20,
  validation_data = list(ff_test, ff_test_labels$fraction_yes))
</code></pre>
<p>where input shape is 10 as I have 10 images. I also have 10 labels for each which are numbers in a numeric vector between 0 and 1 (fraction of an event occurring in a sample) - both are of length 10.</p>
<p>However, when I run the model, I get the error</p>
<pre><code> Error in py_call_impl(callable, dots$args, dots$keywords) : 
  ValueError: in user code:
</code></pre>
<p>which, after following googling around led me to <a href=""https://github.com/rstudio/keras/issues/1063"" rel=""noreferrer"">https://github.com/rstudio/keras/issues/1063</a> stating that the problem is a mismatch in my dimensions or structure between train and test which.... seems incorrect?</p>
<p>What am I missing here? Where is the dimensional mismatch?</p>
",190352.0,,,,,2020-11-16 12:10:19,Trying to solve data dimension mismatch in keras,<r><keras>,1,3,0.0,,,CC BY-SA 4.0
64771870,1,,,2020-11-10 15:30:43,,5,2161,"<p>I am using a colab pro TPU instance for the purpose of patch image classification.
i'm using tensorflow version 2.3.0.</p>
<p>When calling model.fit I get the following error:  <code>InvalidArgumentError: Unable to find the relevant tensor remote_handle: Op ID: 14738, Output num: 0</code> with the following trace:</p>
<pre><code>--------
InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-20-5fd2ec1ce2f9&gt; in &lt;module&gt;()
     15         steps_per_epoch=STEPS_PER_EPOCH,
     16         validation_data=dev_ds,
---&gt; 17         validation_steps=VALIDATION_STEPS
     18     )

6 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    106   def _method_wrapper(self, *args, **kwargs):
    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
--&gt; 108       return method(self, *args, **kwargs)
    109 
    110     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1084       data_handler._initial_epoch = (  # pylint: disable=protected-access
   1085           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))
-&gt; 1086       for epoch, iterator in data_handler.enumerate_epochs():
   1087         self.reset_metrics()
   1088         callbacks.on_epoch_begin(epoch)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in enumerate_epochs(self)
   1140         if self._insufficient_data:  # Set by `catch_stop_iteration`.
   1141           break
-&gt; 1142         if self._adapter.should_recreate_iterator():
   1143           data_iterator = iter(self._dataset)
   1144         yield epoch, data_iterator

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in should_recreate_iterator(self)
    725     # each epoch.
    726     return (self._user_steps is None or
--&gt; 727             cardinality.cardinality(self._dataset).numpy() == self._user_steps)
    728 
    729   def _validate_args(self, y, sample_weights, steps):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in numpy(self)
   1061     &quot;&quot;&quot;
   1062     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
-&gt; 1063     maybe_arr = self._numpy()  # pylint: disable=protected-access
   1064     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
   1065 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)
   1029       return self._numpy_internal()
   1030     except core._NotOkStatusException as e:  # pylint: disable=protected-access
-&gt; 1031       six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access
   1032 
   1033   @property

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Unable to find the relevant tensor remote_handle: Op ID: 14738, Output num: 0

</code></pre>
<p>H have two dataset zip files containing 300,000&gt; and 100,000&lt; training and validation examples which I download from my Google Drive using !gdown and unzip it on Colab VM. For data pipeline I use tf.data.Dataset API and feed the API with list of filepaths and then use .map method to perform image fetching from memory, <strong>please keep in mind that my training dataset can't be fit into memory</strong></p>
<p>Here is the code for creating Dataset:</p>
<pre><code>train_dir = '/content/content/Data/train'
dev_dir = '/content/content/Data/dev'

def create_dataset(dir, label_dic, is_training=True):
    filepaths = list(tf.data.Dataset.list_files(dir + '/*.jpg'))

    labels = []

    for f in filepaths:
        ind = f.numpy().decode().split('/')[-1].split('.')[0]
        labels.append(label_dic[ind])

    ds = tf.data.Dataset.from_tensor_slices((filepaths, labels))
    ds = ds.map(load_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    ds = ds.cache() 

    if is_training:
        ds = ds.shuffle(len(filepaths), reshuffle_each_iteration=True)
        ds = ds.repeat(EPOCHS) 
    ds = ds.batch(BATCH_SIZE) 
    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)

    return ds


train_ds = create_dataset(train_dir, train_label)
dev_ds = create_dataset(dev_dir, dev_label, False)
</code></pre>
<p>And here is the code for creating and compiling my model and fitting the datasets, I use a keras custom model with VGG16 backend:</p>
<pre><code>def create_model(input_shape, batch_size):
    VGG16 = keras.applications.VGG16(include_top=False,input_shape=input_shape, weights='imagenet')

    for layer in VGG16.layers:
        layer.trainable = False

    input_layer = keras.Input(shape=input_shape, batch_size=batch_size)

    VGG_out = VGG16(input_layer)

    x = Flatten(name='flatten', input_shape=(512,8,8))(VGG_out)
    x = Dense(256, activation='relu', name='fc1')(x)
    x = Dropout(0.5)(x)
    x = Dense(1, activation='sigmoid', name='fc2')(x)

    model = Model(input_layer, x)
    model.summary()
    return model

with strategy.scope():

    model = create_model(INPUT_SHAPE, BATCH_SIZE)
    model.compile(optimizer='adam',
            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
            metrics=['accuracy'])
    
model.fit(train_ds,
        epochs=5,
        steps_per_epoch=STEPS_PER_EPOCH,
        validation_data=dev_ds,
        validation_steps=VALIDATION_STEPS
    )
</code></pre>
<p><strong>For TPU initialization and strategy</strong>I use a <code>strategy = tf.distribute.TPUStrategy(resolver)</code>
Initialization code shown below:</p>
<pre><code>resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)

tf.tpu.experimental.initialize_tpu_system(resolver)
print(&quot;All devices: &quot;, tf.config.list_logical_devices('TPU'))


</code></pre>
<p>a copy of the whole notebook with outputs can be reached at: <a href=""https://github.com/Pooya448/Tumor_Segmentation/blob/main/Patch_Classification.ipynb"" rel=""noreferrer"">Colab Ipython Notebook</a></p>
",8777119.0,,,,,2022-09-02 04:17:20,"Unable to find the relevant tensor remote_handle: Op ID: 14738, Output num: 0",<keras><google-colaboratory><tensorflow-datasets><tpu><data-pipeline>,2,2,,,,CC BY-SA 4.0
63359321,1,,,2020-08-11 13:34:55,,5,14836,"<p>defining the samples per epoch = 233 and nb_val_samples = 62 and epochs =4 then in am getting the error</p>
<blockquote>
<p>Type-error: fit_generator() got an unexpected keyword argument 'samples_per_epoch'</p>
</blockquote>
<p>What caused this error and how to solve it?</p>
<pre><code>history_object = model.fit_generator(train_generator, 
     samples_per_epoch=samples_per_epoch,
     validation_data=validation_generator,
     nb_val_samples=nb_val_samples, 
     nb_epoch=nb_epoch, verbose=1,
     callbacks=callbacks_list)

```

 
</code></pre>
",14078744.0,,4420967.0,,2020-08-11 14:44:01,2020-08-29 15:58:11,Type-error: fit_generator() got an unexpected keyword argument 'samples_per_epoch',<python><machine-learning><keras>,2,1,0.0,,,CC BY-SA 4.0
64181260,1,64181631.0,,2020-10-03 06:09:11,,5,3124,"<p>I have defined custom metric for tensorflow.keras to compute macro-f1-score after every epoch as follows:</p>
<pre><code>from tensorflow import argmax as tf_argmax
from sklearn.metric import f1_score

def macro_f1(y_true, y_pred):
    # labels are one-hot encoded. so, need to convert
    # [1,0,0] to 0 and
    # [0,1,0] to 1 and
    # [0,0,1] to 2. Then pass these arrays to sklearn f1_score.
    y_true = tf_argmax(y_true, axis=1)
    y_pred = tf_argmax(y_pred, axis=1)
    return f1_score(y_true, y_pred, average='macro')
</code></pre>
<p>and using it during model compilation</p>
<pre><code>model_4.compile(loss = 'categorical_crossentropy',
                optimizer = Adam(lr=init_lr, decay=init_lr / num_epochs),
                metrics = [Recall(name='recall') #, weighted_f1
                           macro_f1])
</code></pre>
<p>and when i try to fit like this:</p>
<pre><code>history_model_4 = model_4.fit(train_image_generator.flow(x=train_imgs, y=train_targets, batch_size=batch_size),
                            validation_data = (val_imgs, val_targets),
                            epochs=num_epochs,
                            class_weight=mask_weights_train,
                            callbacks=[model_save_cb, early_stop_cb, epoch_times_cb],
                            verbose=2)
</code></pre>
<p>this is the error:</p>
<pre><code>OperatorNotAllowedInGraphError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    &lt;ipython-input-57-a890ea61878e&gt;:6 macro_f1  *
        return f1_score(y_true, y_pred, average='macro')
    /usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1095 f1_score  *
        return fbeta_score(y_true, y_pred, 1, labels=labels,
    /usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1217 fbeta_score  *
        _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,
    /usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1478 precision_recall_fscore_support  *
        labels = _check_set_wise_labels(y_true, y_pred, average, labels,
    /usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1301 _check_set_wise_labels  *
        y_type, y_true, y_pred = _check_targets(y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:80 _check_targets  *
        check_consistent_length(y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:209 check_consistent_length  *
        uniques = np.unique(lengths)
    &lt;__array_function__ internals&gt;:6 unique  **
        
    /usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:263 unique
        ret = _unique1d(ar, return_index, return_inverse, return_counts)
    /usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:311 _unique1d
        ar.sort()
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:877 __bool__
        self._disallow_bool_casting()
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:487 _disallow_bool_casting
        &quot;using a `tf.Tensor` as a Python `bool`&quot;)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:474 _disallow_when_autograph_enabled
        &quot; indicate you are trying to use an unsupported feature.&quot;.format(task))

    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.
</code></pre>
<p>What caused such errors and how do I fix it and use it as one of my evaluation metrics at the end of ever y epoch?</p>
<p>EDIT 1:<br />
note: all of this has been done in a jupyter notebook, i have added &quot;&gt;&gt;&gt;&quot;s to seperate lines</p>
<pre><code># getting a batch to pass to model
&gt;&gt;&gt; a_batch = train_image_generator.flow(x=train_imgs, y=train_targets, batch_size=batch_size).next()
# checking its' type to ensure that it's what i though it is
&gt;&gt;&gt; type(a_batch)
# passing the batch to the model
&gt;&gt;&gt; logits = model_4(a_batch)
# checking the type of output
&gt;&gt;&gt; type(logits)
tensorflow.python.framework.ops.EagerTensor
# extracting only the passed targets to calculate f1-score
&gt;&gt;&gt; _, dummy_targets = a_batch
# checking it's type
&gt;&gt;&gt; type(dummy_targets)
numpy.ndarray
&gt;&gt;&gt; macro_f1(y_true=dummy_targets, y_pred=logits)
0.0811965811965812
</code></pre>
",11814996.0,,11814996.0,,2020-10-03 07:02:08,2020-10-03 07:08:01,using sklearn macro f1-score as a metric in tensorflow.keras,<python><tensorflow><keras>,1,3,,,,CC BY-SA 4.0
65085780,1,65086047.0,,2020-12-01 06:38:30,,5,517,"<p>I want to limit CPU cores and threads.
So I found three ways to limit these.</p>
<p><strong>1) &quot;Keras backend + Tensorflow&quot;</strong></p>
<pre><code>from keras import backend as K
import tensorflow as tf

config = tf.ConfigProto(intra_op_parallelism_threads=2, \ 
                        inter_op_parallelism_threads=4, \
                        allow_soft_placement=True, \
                        device_count = {'CPU': 1})
session = tf.Session(config=config)
K.set_session(session)
</code></pre>
<p><strong>2) &quot;Keras from Tensorflow&quot;</strong></p>
<pre><code>import tensorflow as tf
from tensorflow import keras

tf.config.threading.set_intra_op_parallelism_threads(2)  
tf.config.threading.set_inter_op_parallelism_threads(4) 
</code></pre>
<p><strong>3) &quot;keras from Tensorflow&quot;</strong></p>
<pre><code>import os

os.environ['TF_NUM_INTRAOP_THREADS'] = '2'
os.environ['TF_NUM_INTEROP_THREADS'] = '4'
</code></pre>
<p>These three ways are same affects?</p>
<p>Lastly I understood for the parameters like I wrote below</p>
<ul>
<li>intra_op_parallelism_threads(&quot;number of CPU cores&quot;)</li>
<li>inter_op_parallelism_threads(&quot;number of threads&quot;)</li>
</ul>
<p>is this right?
If I miss-understanding please let me know.</p>
<p>Thank you.</p>
",13359038.0,,13359038.0,,2020-12-01 06:56:05,2023-03-01 12:36:06,"What is difference between ""Keras backend + Tensorflow"" and ""Keras from Tensorflow"" using CPU(in Tensorflow 2.x)",<python><keras><tensorflow2>,2,0,,,,CC BY-SA 4.0
63122680,1,63178745.0,,2020-07-27 20:01:29,,5,1279,"<p>I'm trying to improve the stability of my GAN model by adding a standard deviation variable to my layer's feature map. I'm following the example set in the <a href=""https://github.com/GANs-in-Action/gans-in-action/blob/master/chapter-6/Chapter_6_PGGAN.ipynb"" rel=""noreferrer"">GANs-in-Action</a> git. The math itself makes sense to me. The mechanics of my model and the reasons why this addresses mode collapse makes sense to me. However, a shortcoming from the example is that they never actually show how this code is executed.</p>
<pre><code>def minibatch_std_layer(layer, group_size=4):
    group_size = keras.backend.minimum(group_size, tf.shape(layer)[0])

    shape = list(keras.backend.int_shape(input))
    shape[0] = tf.shape(input)[0]

    minibatch = keras.backend.reshape(layer,(group_size, -1, shape[1], shape[2], shape[3]))
    minibatch -= tf.reduce_mean(minibatch, axis=0, keepdims=True)
    minibatch = tf.reduce_mean(keras.backend.square(minibatch), axis = 0)
    minibatch = keras.backend.square(minibatch + 1e8)
    minibatch = tf.reduce_mean(minibatch, axis=[1,2,4], keepdims=True)
    minibatch = keras.backend.tile(minibatch,[group_size, 1, shape[2], shape[3]])
    return keras.backend.concatenate([layer, minibatch], axis=1)

def build_discriminator():

    const = ClipConstraint(0.01)

    discriminator_input = Input(shape=(4000,3), batch_size=BATCH_SIZE, name='discriminator_input')
    
    x = discriminator_input

    x = Conv1D(64, 3, strides=1, padding=&quot;same&quot;, kernel_constraint=const)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.3)(x)
    x = Dropout(0.25)(x)

    x = Conv1D(128, 3, strides=2, padding=&quot;same&quot;, kernel_constraint=const)(x)
    x = LeakyReLU(0.3)(x)
    x = Dropout(0.25)(x)

    x = Conv1D(256, 3, strides=3, padding=&quot;same&quot;, kernel_constraint=const)(x)
    x = LeakyReLU(0.3)(x)
    x = Dropout(0.25)(x)

    # Trying to add it to the feature map here 
    x = minibatch_std_layer(Conv1D(256, 3, strides=3, padding=&quot;same&quot;, kernel_constraint=const)(x))

    x = Flatten()(x)

    x = Dense(1000)(x)

    discriminator_output = Dense(1, activation='sigmoid')(x)

    return Model(discriminator_input, discriminator_output, name='discriminator_model')

d = build_discriminator()
</code></pre>
<p>No matter how I structure it, I can't get the discriminator to build. It continues to return different types of <code>AttributeError</code>s but I've been unable to understand what it wants. Searching the issue, there were lots of Medium posts showing a high level overview of what this does in a progressive GAN, but nothing I could find showing its application.</p>
<p>Does anyone have any suggestions about how the above code is added to a layer?</p>
",10147489.0,,,,,2022-09-06 15:39:08,Correct way to apply Minibatch Standard Deviation to Keras GAN layer,<python><tensorflow><keras>,2,4,0.0,,,CC BY-SA 4.0
65078707,1,65131007.0,,2020-11-30 17:57:38,,5,1415,"<p>I'm making my first steps learning Deep Learning. I am trying to do Activity Recognition from images sequences (frames) of videos. As a result i am facing a problem with the training procedure.</p>
<p>Firstly i need to determine the architecture of my images folders:</p>
<pre><code>Making Food -&gt; p1 -&gt; rgb_frame1.png,rgb_frame2.png ... rgb_frame200.png
Making Food -&gt; p2 -&gt; rgb_frame1.png,rgb_frame2.png ... rgb_frame280.png
                      ...
                      ...
                      ...
Taking  Medicine -&gt; p1 -&gt; rgb_frame1.png,rgb_frame2.png...rgbframe500.png

                      etc..
      
</code></pre>
<p>So the problem is that each folder can have a <strong>different number of frames</strong> so I get confused both with the input shape of the model and the timesteps which I should use.
I am creating a model (as you see bellow) with time distirbuted CNN(pre trained VGG16) and LSTM that takes an input all the frames of all classes with the coresponding labels (in the above example  making food would be the coresponding label to p1_rgb_frame1 etc.) and the final shape of <code>x_train</code> is <code>(9000,200,200,3)</code> where <code>9000</code> coresponds to all frames from all classes, <code>200</code> is height &amp; width and <code>3</code> the channel of images. I am reshaping this data to <code>(9000,1,200,200,3)</code> in order to be used as input to the model.
I am wondering and worried that I do not pass a proper timestep, as a result a wrong training , i have val_acc ~ 98% but when testing with different dataset is much lower. Can you suggest another way to do it more efficient?</p>
<pre><code>  x = base_model.output
  x = Flatten()(x)
  features = Dense(64, activation='relu')(x)
  conv_model = Model(inputs=base_model.input, outputs=features)    
  for layer in base_model.layers:
      layer.trainable = False
       
  model = Sequential()
  model.add(TimeDistributed(conv_model, input_shape=(None,200,200,3)))
  model.add(LSTM(32, return_sequences=True))
  model.add(LSTM(16))
</code></pre>
",14688283.0,,5745505.0,,2020-11-30 18:09:06,2020-12-03 17:25:47,Image sequence training with CNN and RNN,<python><tensorflow><machine-learning><keras><deep-learning>,1,0,0.0,,,CC BY-SA 4.0
62877879,1,62879210.0,,2020-07-13 14:20:00,,5,3084,"<p>I am working on a multimodal classifier with images and text. I have developed and succesfully two models, one is a CNN for images and the other is a BERT-based model for text. The last layer of both models is a Dense with <em>n</em> units and <em>softmax</em> activation (where n is the number of classes). Keras provides different merging layers for combining the output vectors of these models (<a href=""https://keras.io/api/layers/merging_layers/"" rel=""nofollow noreferrer"">https://keras.io/api/layers/merging_layers/</a>) and then it is possible to create a new network, but my question is: is there a better way to combine the decisions of the single models? Maybe to weight the values inside the vectors based on some criterion?
Currently I have developed my model with a simple concatenation layer like this:</p>
<pre><code>image_side = images_model(image_input)
text_side = text_model(text_input)
# Concatenation
merged = layers.Concatenate(name='Concatenation')([image_side, text_side])
merged = layers.Dense(128, activation = 'relu', name='Dense_128')(merged)
merged = layers.Dropout(0.2)(merged)
output = layers.Dense(nClasses, activation='softmax', name = &quot;class&quot;)(merged)
</code></pre>
<p>Thank you in advance!</p>
",13038652.0,,10375049.0,,2020-11-16 08:12:33,2020-11-16 08:12:33,Implementing late fusion in Keras,<python><tensorflow><machine-learning><keras><deep-learning>,1,0,0.0,,,CC BY-SA 4.0
70164002,1,,,2021-11-30 03:42:18,,5,3054,"<p>I am trying to use Keras for an attention mechanism in a machine translation using an LSTM network.</p>
<p>However, I get a TypeError exception when in my code.</p>
<pre><code>TypeError: Exception encountered when calling layer &quot;tf.keras.backend.rnn_1&quot; (type TFOpLambda).

You are passing KerasTensor(type_spec=TensorSpec(shape=(None, 35), dtype=tf.float32, name=None), name='tf.compat.v1.nn.softmax_3/Softmax:0', description=&quot;created by layer 'tf.compat.v1.nn.softmax_3'&quot;), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.
</code></pre>
<p>It seems <code>You can work around this limitation by putting the operation in a custom Keras layer call and calling that layer on this symbolic input/output.</code> Does anyone know what this means?</p>
<p>The main code is here and it fails at <code>attention_result, attention_weights = attention_layer([encoder_outputs1, decoder_outputs])</code></p>
<pre><code># Encoder 

encoder_inputs = Input(shape=(max_length_english,)) 
enc_emb = Embedding(vocab_size_source, 1024,trainable=True)(encoder_inputs) 

# Bidirectional lstm layer
enc_lstm1 = Bidirectional(LSTM(256,return_sequences=True,return_state=True))
encoder_outputs1, forw_state_h, forw_state_c, back_state_h, back_state_c = enc_lstm1(enc_emb)

final_enc_h = Concatenate()([forw_state_h,back_state_h])
final_enc_c = Concatenate()([forw_state_c,back_state_c])

encoder_states =[final_enc_h, final_enc_c]

# Set up the decoder. 
decoder_inputs = Input(shape=(None,)) 
dec_emb_layer = Embedding(vocab_size_target, 1024,trainable=True) 
dec_emb = dec_emb_layer(decoder_inputs)

#LSTM using encoder_states as initial state
decoder_lstm = LSTM(512, return_sequences=True, return_state=True) 
decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)

#Attention Layer
attention_layer = AttentionLayer()
attention_result, attention_weights = attention_layer([encoder_outputs1, decoder_outputs])

# Concat attention output and decoder LSTM output 
decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_result])

#Dense layer
decoder_dense = Dense(vocab_size_target, activation='softmax')
decoder_outputs = decoder_dense(decoder_concat_input)


# Define the model
model = Model([encoder_inputs, decoder_inputs], decoder_outputs) 

</code></pre>
<p>The relevant code for attention.py is</p>
<pre><code>def call(self, inputs, verbose=False):
        &quot;&quot;&quot;
        inputs: [encoder_output_sequence, decoder_output_sequence]
        &quot;&quot;&quot;
        assert type(inputs) == list
        encoder_out_seq, decoder_out_seq = inputs
        if verbose:
            print('encoder_out_seq&gt;', encoder_out_seq.shape)
            print('decoder_out_seq&gt;', decoder_out_seq.shape)

        def energy_step(inputs, states):
            &quot;&quot;&quot; Step function for computing energy for a single decoder state &quot;&quot;&quot;

            assert_msg = &quot;States must be a list. However states {} is of type {}&quot;.format(states, type(states))
            assert isinstance(states, list) or isinstance(states, tuple), assert_msg

            &quot;&quot;&quot; Some parameters required for shaping tensors&quot;&quot;&quot;
            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]
            de_hidden = inputs.shape[-1]

            &quot;&quot;&quot; Computing S.Wa where S=[s0, s1, ..., si]&quot;&quot;&quot;
            # &lt;= batch_size*en_seq_len, latent_dim
            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))
            # &lt;= batch_size*en_seq_len, latent_dim
            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))
            if verbose:
                print('wa.s&gt;',W_a_dot_s.shape)

            &quot;&quot;&quot; Computing hj.Ua &quot;&quot;&quot;
            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # &lt;= batch_size, 1, latent_dim
            if verbose:
                print('Ua.h&gt;',U_a_dot_h.shape)

            &quot;&quot;&quot; tanh(S.Wa + hj.Ua) &quot;&quot;&quot;
            # &lt;= batch_size*en_seq_len, latent_dim
            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))
            if verbose:
                print('Ws+Uh&gt;', reshaped_Ws_plus_Uh.shape)

            &quot;&quot;&quot; softmax(va.tanh(S.Wa + hj.Ua)) &quot;&quot;&quot;
            # &lt;= batch_size, en_seq_len
            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))
            # &lt;= batch_size, en_seq_len
            e_i = K.softmax(e_i)

            if verbose:
                print('ei&gt;', e_i.shape)

            return e_i, [e_i]

        def context_step(inputs, states):
            &quot;&quot;&quot; Step function for computing ci using ei &quot;&quot;&quot;
            # &lt;= batch_size, hidden_size
            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)
            if verbose:
                print('ci&gt;', c_i.shape)
            return c_i, [c_i]

        def create_inital_state(inputs, hidden_size):
            # We are not using initial states, but need to pass something to K.rnn funciton
            fake_state = K.zeros_like(inputs)  # &lt;= (batch_size, enc_seq_len, latent_dim
            fake_state = K.sum(fake_state, axis=[1, 2])  # &lt;= (batch_size)
            fake_state = K.expand_dims(fake_state)  # &lt;= (batch_size, 1)
            fake_state = K.tile(fake_state, [1, hidden_size])  # &lt;= (batch_size, latent_dim
            return fake_state

        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])
        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # &lt;= (batch_size, enc_seq_len, latent_dim

        &quot;&quot;&quot; Computing energy outputs &quot;&quot;&quot;
        # e_outputs =&gt; (batch_size, de_seq_len, en_seq_len)
        last_out, e_outputs, _ = K.rnn(
            energy_step, decoder_out_seq, [fake_state_e],
        )

        &quot;&quot;&quot; Computing context vectors &quot;&quot;&quot;
        last_out, c_outputs, _ = K.rnn(
            context_step, e_outputs, [fake_state_c],
        )

        return c_outputs, e_outputs
</code></pre>
<p>and it fails at</p>
<pre><code>&quot;&quot;&quot; Computing energy outputs &quot;&quot;&quot;
        # e_outputs =&gt; (batch_size, de_seq_len, en_seq_len)
        last_out, e_outputs, _ = K.rnn(
            energy_step, decoder_out_seq, [fake_state_e],
        )
</code></pre>
<p>If anyone knows how to fix this and work around this limitation, please advise. Thank you so much.</p>
",5086421.0,,,,,2022-07-11 15:01:55,"Work around Keras TypeError limitation when calling layer ""tf.keras.backend.rnn_1""",<python><tensorflow><keras><deep-learning><lstm>,2,2,0.0,,,CC BY-SA 4.0
68903269,1,,,2021-08-24 07:17:26,,5,1565,"<p>I am training a keras model and using a custom learning rate scheduler for the optimizer (of type tf.keras.optimizers.schedules.LearningRateSchedule), and i want to log the learning rate change via the weights&amp;biases framework.
i couldn't find how to pass it to the WandbCallback object or log it in any way</p>
",10620420.0,,4685471.0,,2021-08-24 09:55:30,2022-08-21 12:50:30,logging learning rate schedule in keras via weights and biases,<python><tensorflow><keras><deep-learning><wandb>,3,1,0.0,,,CC BY-SA 4.0
62861773,1,62862033.0,,2020-07-12 13:37:51,,5,879,"<p>Can we use mulitple loss function in this architecture:
I have two different type of loss functions and want to use it on last layer [Output]
loss functions :</p>
<ul>
<li>binary_crossentropy</li>
<li>custom loss function</li>
</ul>
<p>Can we do that?
<a href=""https://i.stack.imgur.com/UwIvv.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/UwIvv.png"" alt=""enter image description here"" /></a></p>
",12924273.0,,,,,2020-07-12 14:10:36,Can we use multiple loss functions in same layer?,<tensorflow><machine-learning><keras><deep-learning><loss-function>,2,0,0.0,,,CC BY-SA 4.0
75671125,1,,,2023-03-08 09:06:14,,5,366,"<p>Given a binary dataset (derived from yes/no questionnaire responses) aimed to use for subsequent unsupervised cluster analysis, with significant multicolinearity and a total of 31 features by ~50,000 observations (subjects), it appeared sensible to reduce the dimensionality of the input data before performing cluster analysis. I attempted using an autoencoder for this, but surprisingly, the clusters (derived through k-medoids, chosen due to the nominal nature of the underlying data and a greater stability in relation to outliers/noise compared to e.g., k-means) were actually more distinct and clearly distinguished when using MCA, with a clear maximum Silhouette coefficient at k = 5.</p>
<p>Given that MCA with the first 5 PCs (explaining just ~75% of the variance, chosen through a scree plot) was used before I attempted the autoencoder way, it surprises me that an autoencoder did a worse job at extracting meaningful features at the same bottleneck dimension. <strong>The problem with the current autoencoder, appears to be that the data in the bottleneck layer, which is used in the clustering, is distorted...</strong></p>
<p>Below is the code I used to construct the autoencoder. Can it be so that the hyper-parameters are off, or some details of the overall architecture? Random search of specific numbers of the number of layers, learning rate, batch size, dimensions in the layers etc. have not yielded anything substantial. Loss is similar between train and validation dataset, and levels out at around 0.15 after ~40 epochs.</p>
<p>I've also tried to identify studies where such data has been used, but not found anything useful.</p>
<pre><code>import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt


input_dim = 31
layer_1_dim = 18
layer_2_dim = 10
bottleneck_dim = 5
learning_rate = 0.001
epochs = 100
batch_size = 300


# split data into training and validation
training_n = int(data.shape[0] * 0.8)
train_data = data[:training_n, :]
val_data = data[training_n:, :]

# define autoencoder initializer
initializer = tf.keras.initializers.GlorotUniform()

# autoencoder layers
input_layer = Input(shape=(input_dim,))
layer = Dense(layer_1_dim, activation='relu')(input_layer)
layer = Dense(layer_2_dim, activation='relu', kernel_initializer=initializer)(layer)
layer = Dense(bottleneck_dim, activation='relu', kernel_initializer=initializer, name=&quot;bottleneck-output&quot;)(layer)
layer = Dense(layer_2_dim, activation='relu', kernel_initializer=initializer)(layer) 
layer = Dense(layer_1_dim, activation='relu', kernel_initializer=initializer)(layer)
output_layer = Dense(input_dim, activation='sigmoid', kernel_initializer=initializer)(layer)

# define and compile autoencoder model
autoencoder = Model(inputs=input_layer, outputs=output_layer)
optimizer = Adam(learning_rate=learning_rate)
autoencoder.compile(optimizer=optimizer, loss='binary_crossentropy')

# train the autoencoder model
history = autoencoder.fit(train_data, train_data, epochs=epochs, batch_size=batch_size, validation_data=(val_data, val_data))

# get bottleneck output
bottleneck_autoencoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('bottleneck-output').output)
bottleneck_output = bottleneck_autoencoder.predict(data)

# plot loss in traning and validation set
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Autoencoder loss (binary cross-entropy)')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.savefig('output/embedding.png')
</code></pre>
",2926271.0,,2926271.0,,2023-03-10 09:13:09,2023-03-17 10:53:06,Autoencoder for dimensionality reduction of binary dataset for clustering,<python><tensorflow><keras><artificial-intelligence><cluster-analysis>,2,4,,,,CC BY-SA 4.0
62859668,1,,,2020-07-12 10:02:29,,5,2453,"<p>I am trying to implement 2-D convolution in python.
I have an input image set of dimensions (m, 64, 64, 3), where m is the number of images.
I want to use a filter size f=8 and stride=8 for both height and width, and SAME padding so that input width and height (64, 64) are preserved.</p>
<p>Using the formula <strong>[n' = floor((n-f+2*pad)/stride + 1)]</strong> and putting n'=64, n=64, stride=8, f=8, I get <strong>pad=224</strong>, which is unreasonably large.</p>
<p>For example, when I took m, the number of images, as 1080, it presumably resulted in a memory error and my system crashed.</p>
<p>But when I used the Keras library and the following code, it worked fine.</p>
<pre><code>X = keras.layers.Conv2D(filters=32, kernel_size=(8, 8), strides=(8, 8), padding='same')(X)
</code></pre>
<p>Here is my implementation of the Conv2D in python:</p>
<pre><code>import numpy as np

# A.shape = (1080, 64, 64, 3)
# W.shape = (8, 8, 3, 32)
# b.shape = (32,)

def conv_fwd(A, W, b, pad=0, stride=1):
    pad_A = np.pad(A, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode='constant')
    (m, w, h, nc) = A.shape
    (fw, fh, ncc, ncn) = W.shape

    if nc != ncc:
        raise Exception('Number of channels in kernel and input do not match')

    wn = int((w-fw+2*pad)/stride + 1)
    hn = int((h-fh+2*pad)/stride + 1)
    A_n = np.zeros((m, wn, hn, ncn))
    W = W.reshape(fw*fh*ncc, ncn)

    for i in range(wn):
        for j in range(hn):
            A_n[:, i, j] = pad_A[:, i*stride:i*stride+fw, j*stride:j*stride+fh].reshape(m, fw*fh*nc).dot(W) + b
    return A_n
</code></pre>
<p>So I'm assuming there is a different process for calculating the padding in keras. I tried looking for the source code, but couldn't find it. How does it work?</p>
",13915889.0,,13915889.0,,2020-07-12 10:29:10,2020-07-15 12:27:07,"How does SAME padding work in convolution neural networks, when stride is greater than 1?",<python><tensorflow><keras><conv-neural-network><zero-padding>,1,0,,,,CC BY-SA 4.0
69432710,1,70250391.0,,2021-10-04 08:02:30,,5,2743,"<p>When I try to load my trained <code>tf.keras</code> model, I get the error: <code>JSONDecodeError: Expecting value</code>.
The issue is not reproducible, i.e., I get the error when I try to load a model that I have trained on a cluster and downloaded to my computer. When I tried to just compile, save, and load the same model, the error doesn't appear.</p>
<p>Any ideas what the issue could be?</p>
<p>The following code <strong>works</strong> (as opposed to loading the trained model):</p>
<pre><code>import tensorflow as tf
from tensorflow import keras as ks
import numpy as np
import os
def UNet(n_classes, input_shape = (256, 256, 3), dropout = 0.05,
         ops = {&quot;activation&quot; : &quot;relu&quot;,
                &quot;padding&quot; : &quot;same&quot;,
                &quot;kernel_initializer&quot; : &quot;he_normal&quot;
        }):
    # input layer
    inputz = ks.layers.Input(shape = input_shape)
    
    # encoder part
    ## 1st convolution
    c1 = ks.layers.Conv2D(64, (3, 3), **ops)(inputz)
    c1 = ks.layers.Conv2D(64, (3, 3), **ops)(c1)
    ## 1st max pooling
    p1 = ks.layers.MaxPooling2D(pool_size = (2, 2))(c1)
    
    ## 2nd convolution
    c2 = ks.layers.Conv2D(128, (3, 3), **ops)(p1)
    c2 = ks.layers.Conv2D(128, (3, 3), **ops)(c2)
    ## 2nd max pooling
    p2 = ks.layers.MaxPooling2D(pool_size = (2, 2))(c2)
    
    ## 3rd convolution
    c3 = ks.layers.Conv2D(256, (3, 3), **ops)(p2)
    c3 = ks.layers.Conv2D(256, (3, 3), **ops)(c3)
    ## 3rd max pooling
    p3 = ks.layers.MaxPooling2D(pool_size = (2, 2))(c3)
    
    ## 4th convolution
    c4 = ks.layers.Conv2D(512, (3, 3), **ops)(p3)
    c4 = ks.layers.Conv2D(512, (3, 3), **ops)(c4)
    ## Drop
    d4 = ks.layers.Dropout(dropout)(c4)
    ## 4th max pooling
    p4 = ks.layers.MaxPooling2D(pool_size = (2, 2))(d4)
    
    ## 5th convolution
    c5 = ks.layers.Conv2D(1024, (3, 3), **ops)(p4)
    c5 = ks.layers.Conv2D(1024, (3, 3), **ops)(c5)
    ## Drop
    d5 = ks.layers.Dropout(dropout)(c5)
    
    # decoder part
    ## 1st up convolution
    us6 = ks.layers.UpSampling2D(size = (2, 2))(d5)
    up6 = ks.layers.Conv2D(512, (2, 2), **ops)(us6)
    ## merge
    ct6 = ks.layers.concatenate([d4, up6], axis = 3)
    uc6 = ks.layers.Conv2D(512, (3, 3), **ops)(ct6)
    uc6 = ks.layers.Conv2D(512, (3, 3), **ops)(uc6)
    
    ## 2nd up convolution
    us7 = ks.layers.UpSampling2D(size = (2, 2))(uc6)
    up7 = ks.layers.Conv2D(256, (2, 2), **ops)(us7)
    ## merge
    ct7 = ks.layers.concatenate([c3, up7], axis = 3)
    uc7 = ks.layers.Conv2D(256, (3, 3), **ops)(ct7)
    uc7 = ks.layers.Conv2D(256, (2, 2), **ops)(uc7)
     
    ## 3rd up convolution
    us8 = ks.layers.UpSampling2D(size = (2, 2))(uc7)
    up8 = ks.layers.Conv2D(128, (2, 2), **ops)(us8)
    ## merge
    ct8 = ks.layers.concatenate([c2, up8], axis = 3)
    uc8 = ks.layers.Conv2D(128, (3, 3), **ops)(ct8)
    uc8 = ks.layers.Conv2D(128, (3, 3), **ops)(uc8)
     
    ## 4th up convolution
    us9 = ks.layers.UpSampling2D(size = (2, 2))(uc8)
    up9 = ks.layers.Conv2D(64, (2, 2), **ops)(us9)
    ## merge
    ct9 = ks.layers.concatenate([c1, up9], axis = 3)
    uc9 = ks.layers.Conv2D(64, (3, 3), **ops)(ct9)
    uc9 = ks.layers.Conv2D(64, (3, 3), **ops)(uc9)
    uc9 = ks.layers.Conv2D(2, (3, 3), **ops)(uc9)
    
    # output layer
    if n_classes &gt; 2:
        activ = &quot;softmax&quot;
    else:
        activ = &quot;sigmoid&quot;
    outputz = ks.layers.Conv2D(n_classes, 1, activation = activ)(uc9)
    
    model = ks.Model(inputs = [inputz], outputs = [outputz])
    print(model.summary())
    print(f'Total number of layers: {len(model.layers)}')
    return model

# get model
model = UNet(n_classes = 5)

class UpdatedMeanIoU(tf.keras.metrics.MeanIoU):
  def __init__(self,
               y_true = None,
               y_pred = None,
               num_classes = None,
               name = None,
               dtype = None):
    super(UpdatedMeanIoU, self).__init__(num_classes = num_classes,
                                         name = name, dtype = dtype)

  def update_state(self, y_true, y_pred, sample_weight = None):
    y_pred = tf.math.argmax(y_pred, axis = -1)
    return super().update_state(y_true, y_pred, sample_weight)
mIoU = UpdatedMeanIoU(num_classes = 5)



lr_sched = ks.optimizers.schedules.ExponentialDecay(
    initial_learning_rate = 1e-3,
    decay_steps = np.floor(50),
    decay_rate = 0.995)

optimizer = ks.optimizers.RMSprop(learning_rate = lr_sched, clipnorm = 1)

lozz = ks.losses.SparseCategoricalCrossentropy()

model.compile(optimizer = optimizer, loss = lozz,
              metrics = [mIoU])

model.save(&quot;G:\\mot&quot;, save_format = &quot;tf&quot;)
os.chdir(&quot;G:\\mot&quot;)
trained_model = ks.models.load_model(&quot;G:\\mot&quot;, custom_objects = {&quot;UpdatedMeanIoU&quot;: mIoU})
</code></pre>
<p>The part code that does not work just includes a <code>model.fit</code> between <code>model.compile</code> and <code>model.save</code>.</p>
<p>The corrupt model can be found <a href=""https://www.dropbox.com/sh/o9c7umyw3b4862y/AAB-sdyOpOrXe_7Z1bZ5H0Tpa?dl=0"" rel=""noreferrer"">here</a>.</p>
<p>This is the full error message:</p>
<pre><code>trained_model = ks.models.load_model(moddir,\
                                     custom_objects = {&quot;UpdatedMeanIoU&quot;: mIoU})
Traceback (most recent call last):

  File &quot;&lt;ipython-input-140-4d44f44a3739&gt;&quot;, line 1, in &lt;module&gt;
    trained_model = ks.models.load_model(moddir,\

  File &quot;c:\users\manuel\python\lib\site-packages\tensorflow\python\keras\saving\save.py&quot;, line 206, in load_model
    return saved_model_load.load(filepath, compile, options)

  File &quot;c:\users\manuel\python\lib\site-packages\tensorflow\python\keras\saving\saved_model\load.py&quot;, line 155, in load
    keras_loader.finalize_objects()

  File &quot;c:\users\manuel\python\lib\site-packages\tensorflow\python\keras\saving\saved_model\load.py&quot;, line 626, in finalize_objects
    self._reconstruct_all_models()

  File &quot;c:\users\manuel\python\lib\site-packages\tensorflow\python\keras\saving\saved_model\load.py&quot;, line 645, in _reconstruct_all_models
    self._reconstruct_model(model_id, model, layers)

  File &quot;c:\users\manuel\python\lib\site-packages\tensorflow\python\keras\saving\saved_model\load.py&quot;, line 661, in _reconstruct_model
    config = json_utils.decode(

  File &quot;c:\users\manuel\python\lib\site-packages\tensorflow\python\keras\saving\saved_model\json_utils.py&quot;, line 62, in decode
    return json.loads(json_string, object_hook=_decode_helper)

  File &quot;c:\users\manuel\python\lib\json\__init__.py&quot;, line 359, in loads
    return cls(**kw).decode(s)

  File &quot;c:\users\manuel\python\lib\json\decoder.py&quot;, line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())

  File &quot;c:\users\manuel\python\lib\json\decoder.py&quot;, line 355, in raw_decode
    raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None

JSONDecodeError: Expecting value
</code></pre>
<p><strong>Edit:</strong></p>
<p>I can load the model on the server where I trained it (in a separate Python session). However, I cannot do the same on my computer after downloading the files. Are there some hidden files the model depends on? Or can there be problems with different OS or different module versions?</p>
",11611246.0,,11611246.0,,2021-10-05 23:48:47,2022-04-06 16:04:46,JSONDecodeError: Expecting value when loading tf.Keras model,<json><python-3.x><tensorflow><keras>,1,1,,,,CC BY-SA 4.0
63600431,1,,,2020-08-26 15:01:40,,5,11548,"<p>Hello I was trying to run model fit based on the following codes but somehow it keep saying</p>
<p>TypeError: 'NoneType' object is not callable. Not sure which part I have done wrong. THis is</p>
<p>part of my optimization training process. I am lost here... Is there minimum requirement to run such model.fit?</p>
<p>Please help me with this!</p>
<pre><code>    import tensorflow as tf
    from tensorflow.keras import layers
    
    from tensorflow.keras import datasets
    
    (train_x, train_y), (test_x, test_y) = datasets.mnist.load_data()
    
    inputs = layers.Input((28, 28, 1))
    net = layers.Conv2D(32, (3, 3), padding ='SAME')(inputs)
    net = layers.Activation('relu')(net)
    net = layers.Conv2D(32, (3, 3), padding ='SAME')(net)
    net = layers.Activation('relu')(net)
    net = layers.MaxPooling2D(pool_size=(2, 2))(net)
    net = layers.Dropout(0.25)(net)
    
    net = layers.Conv2D(64, (3, 3), padding ='SAME')(net)
    net = layers.Activation('relu')(net)
    net = layers.Conv2D(64, (3, 3), padding ='SAME')(net)
    net = layers.Activation('relu')(net)
    net = layers.MaxPooling2D(pool_size=(2, 2))(net)
    net = layers.Dropout(0.25)(net)
    
    net = layers.Flatten()(net)
    net = layers.Dense(512)(net)
    net = layers.Activation('relu')(net)
    net = layers.Dropout(0.5)(net)
    net = layers.Dense(10)(net)
    net = layers.Activation('softmax')(net)
    
    model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')
    
    loss_fun = tf.keras.losses.sparse_categorical_crossentropy 
    
    metrics = tf.keras.metrics.Accuracy() 
    
    optm = tf.keras.optimizers.Adam()
    
    model.compile(optimizer=tf.keras.optimizers.Adam(), 
                  loss='sparse_categorical_crossentropy', 
                  metrics=[tf.keras.metrics.Accuracy()])
    
    train_x.shape, train_y.shape
    
    test_x.shape, test_y.shape
    
    import numpy as np
    
    np.expand_dims(train_x, -1).shape
    
    tf.expand_dims(train_x, -1).shape
    
    train_x = train_x[..., tf.newaxis]
    test_x = test_x[..., tf.newaxis]
    train_x.shape
    
    np.min(train_x), np.max(train_x)
    
    train_x = train_x / 255.
    test_x = test_x / 255.
    
    np.min(train_x), np.max(train_x)
    
    num_epochs = 1
    batch_size = 32
    
    model.fit(train_x, train_y,
              batch_size=batch_size,
              shuffle=True,
              epochs=num_epochs)



    ---------------------------------------------------------------------------
    TypeError                                 Traceback (most recent call last)
    &lt;ipython-input-20-870033ef5c40&gt; in &lt;module&gt;
          2           batch_size=batch_size,
          3           shuffle=True,
    ----&gt; 4           epochs=num_epochs)
    
    ~/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
        106   def _method_wrapper(self, *args, **kwargs):
        107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
    --&gt; 108       return method(self, *args, **kwargs)
        109 
        110     # Running inside `run_distribute_coordinator` already.
    
    ~/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
       1096                 batch_size=batch_size):
       1097               callbacks.on_train_batch_begin(step)
    -&gt; 1098               tmp_logs = train_function(iterator)
       1099               if data_handler.should_sync:
       1100                 context.async_wait()
    
    ~/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
        778       else:
        779         compiler = &quot;nonXla&quot;
    --&gt; 780         result = self._call(*args, **kwds)
        781 
        782       new_tracing_count = self._get_tracing_count()
    
    ~/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
        805       # In this case we have created variables on the first call, so we run the
        806       # defunned version which is guaranteed to never create variables.
    --&gt; 807       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
        808     elif self._stateful_fn is not None:
        809       # Release the lock early so that multiple threads can perform the call
    
    TypeError: 'NoneType' object is not callable
</code></pre>
",14166658.0,,,user13959036,2020-08-27 02:58:44,2022-10-06 07:56:11,model fit/ TypeError: 'NoneType' object is not callable,<python><tensorflow><keras>,2,3,,,,CC BY-SA 4.0
63231811,1,63253351.0,,2020-08-03 14:55:34,,5,14656,"<p>I am following <a href=""https://www.tensorflow.org/lite/tutorials/model_maker_image_classification"" rel=""noreferrer"">this</a> tutorial on creating a custom Model using TensorFlow lite Model Maker on Collab.</p>
<pre><code>import pathlib
path = pathlib.Path('/content/employee_pics') 
count = len(list(path.glob('*/*.jpg')))
count

data = ImageClassifierDataLoader.from_folder(path)
train_data, test_data = data.split(0.5)
</code></pre>
<p>I have an issue with step 2:</p>
<pre><code>model = image_classifier.create(train_data)
</code></pre>
<p>I get an error:
ValueError: <strong>Expect x to be a non-empty array or dataset.</strong></p>
<p><a href=""https://i.stack.imgur.com/hHHRL.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/hHHRL.png"" alt=""enter image description here"" /></a></p>
<p>Am I doing something wrong? The data set provided in the example works fine though. Why?</p>
",8086424.0,,8086424.0,,2020-08-04 12:31:11,2021-11-07 17:01:07,ValueError: Expect x to be a non-empty array or dataset (Tensor Flow lite model maker on Collab),<tensorflow><keras><tf.keras><tensorflow-lite><google-mlkit>,3,3,0.0,,,CC BY-SA 4.0
71164259,1,71469695.0,,2022-02-17 19:25:22,,5,1194,"<p>I am currently using a model from tf.keras.applications for training. And a data augmentation layer along with it. Wierdly, after I import the model from applications, the augmentation layer does not work. The augmentation layer does work before I import it. What is going on?</p>
<p>Also, this has only started happening recently after the new version of TF 2.8.0 was released. Before it was working all fine.</p>
<p>The code for the augmentation layer is</p>
<pre><code>data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip(&quot;horizontal_and_vertical&quot;),
  tf.keras.layers.RandomRotation(0.5),
])
</code></pre>
<p>And I am importing the model using</p>
<pre><code>base_model = tf.keras.applications.MobileNetV3Small(
                 input_shape=(75, 50, 3), alpha=1.0, 
                 weights='imagenet', pooling='avg', include_top=False,
                 dropout_rate=0.1, include_preprocessing=False)
</code></pre>
<p>Please help me understand what is going on. You can reproduce the code here on this notebook <a href=""https://colab.research.google.com/drive/13Jd3l2CxbvIWQv3Y7CtryOdrv2IdKNxD?usp=sharing"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/13Jd3l2CxbvIWQv3Y7CtryOdrv2IdKNxD?usp=sharing</a></p>
",15316721.0,,15316721.0,,2022-02-18 11:23:47,2022-09-06 16:44:20,Tensorflow augmentation layers not working after importing from tf.keras.applications,<python><tensorflow><keras>,3,1,,,,CC BY-SA 4.0
68913379,1,68914231.0,,2021-08-24 19:52:11,,5,705,"<p>I recently read a paper entitled &quot;REGULARIZING NEURAL NETWORKS BY PENALIZING CONFIDENT OUTPUT DISTRIBUTIONS <a href=""https://arxiv.org/abs/1701.06548%22"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1701.06548&quot;</a>. The authors discuss regularizing neural networks by penalizing low entropy
output distributions through adding a negative entropy term to the negative log-likelihood and creating a custom loss function for model training.</p>
<p><a href=""https://i.stack.imgur.com/JsAvA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JsAvA.jpg"" alt=""enter image description here"" /></a></p>
<p>The value β controls the strength of confidence penalty. I have written a custom function for categorical cross-entropy as shown below but the negative entropy term need to be added to the loss function.</p>
<pre><code>import tensorflow as tf
def custom_loss(y_true, y_pred):
    cce = tf.keras.losses.CategoricalCrossentropy()
    cce_loss = cce(y_true, y_pred)    
    return cce_loss
</code></pre>
",7575552.0,,7575552.0,,2021-08-24 20:48:15,2021-08-24 21:28:39,How to create the custom loss function by adding negative entropy to the cross-entropy?,<python><numpy><tensorflow><keras><deep-learning>,2,2,,,,CC BY-SA 4.0
64770484,1,64772183.0,,2020-11-10 14:08:21,,5,607,"<p>I built a multi-input model with the Keras functional API. The idea is to classify a text and its metadata. The model works fine with NumPy format inputs but fails with a tf.data.Dataset.</p>
<pre><code>UnimplementedError:  Cast string to int32 is not supported
     [[node functional_5/Cast (defined at &lt;ipython-input-3-8e2b230c1da3&gt;:17) ]] [Op:__inference_train_function_24120]

Function call stack:
train_function
</code></pre>
<p>I'm not sure how to interpret it as both inputs should be equivalent. Thanks in advance for any guidance. I attached below a dummy equivalent of my project.</p>
<p><strong>Model:</strong></p>
<pre><code>import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras import Input, Model, layers
from transformers import DistilBertTokenizer, TFDistilBertModel


MAX_LEN = 20

STRING_CATEGORICAL_COLUMNS = [
    &quot;Organization&quot;,
    &quot;Sector&quot;,
    &quot;Content_type&quot;,
    &quot;Geography&quot;,
    &quot;Themes&quot;,
]

VOCAB = {
    &quot;Organization&quot;: [&quot;BNS&quot;, &quot;FED&quot;, &quot;ECB&quot;],
    &quot;Sector&quot;: [&quot;BANK&quot;, &quot;ASS&quot;, &quot;MARKET&quot;],
    &quot;Content_type&quot;: [&quot;LAW&quot;, &quot;NOTES&quot;, &quot;PAPER&quot;],
    &quot;Geography&quot;: [&quot;UK&quot;, &quot;FR&quot;, &quot;DE&quot;, &quot;CH&quot;, &quot;US&quot;, &quot;ES&quot;, &quot;NA&quot;],
    &quot;Themes&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;],
}

DIM = {
    &quot;Organization&quot;: 7,
    &quot;Sector&quot;: 2,
    &quot;Content_type&quot;: 3,
    &quot;Geography&quot;: 4,
    &quot;Themes&quot;: 5,
}


# BERT branch
tf_model = TFDistilBertModel.from_pretrained(&quot;distilbert-base-uncased&quot;, name=&quot;tfbert&quot;)

input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=&quot;input_ids&quot;)
attention_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name=&quot;attention_mask&quot;)


embedding = tf_model(input_ids, attention_mask=attention_mask)[0][:, 0]

bert_input = {&quot;input_ids&quot;: input_ids, &quot;attention_mask&quot;: attention_mask}
model_bert = Model(inputs=[bert_input], outputs=[embedding])


# meta branch
meta_inputs = {}
meta_prepocs = []

for key in VOCAB:
    inputs = Input(shape=(None,), dtype=tf.string, name=key)
    meta_inputs[key] = inputs

    vocab_list = VOCAB[key]
    vocab_size = len(vocab_list)
    embed_dim = DIM[key]

    x = layers.experimental.preprocessing.StringLookup(
        vocabulary=vocab_list, num_oov_indices=1, mask_token=&quot;PAD&quot;, name=&quot;lookup_&quot; + key
    )(inputs)

    x = layers.Embedding(
        input_dim=vocab_size + 2,  # 2 = PAD + NA
        output_dim=embed_dim,
        mask_zero=True,
        name=&quot;embedding_&quot; + key,
    )(x)

    x = layers.GlobalAveragePooling1D(
        data_format=&quot;channels_last&quot;, name=&quot;poolembedding_&quot; + key
    )(x)

    meta_prepocs.append(x)

meta_output = layers.concatenate(meta_prepocs, name=&quot;concatenate_meta&quot;)
model_meta = Model(meta_inputs, meta_output)


# combining branches
combined = layers.concatenate(
    [model_bert.output, model_meta.output], name=&quot;concatenate_all&quot;
)
ouput = layers.Dense(128, activation=&quot;relu&quot;, name=&quot;dense&quot;)(combined)
ouput = layers.Dense(4, name=&quot;class_output&quot;)(ouput)
model = Model(inputs=[model_bert.input, model_meta.input], outputs=ouput)

model.compile(
    optimizer=keras.optimizers.RMSprop(1e-3),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
)
</code></pre>
<p><strong>Dataset</strong>
A dummy dataset of 5 texts and respective metadata</p>
<pre><code># input meta
dict_meta = {
    &quot;Organization&quot;: [
        [&quot;BNS&quot;, &quot;NA&quot;],
        [&quot;ECB&quot;, &quot;PAD&quot;],
        [&quot;NA&quot;, &quot;PAD&quot;],
        [&quot;NA&quot;, &quot;PAD&quot;],
        [&quot;NA&quot;, &quot;PAD&quot;],
    ],
    &quot;Sector&quot;: [
        [&quot;BANK&quot;, &quot;PAD&quot;, &quot;PAD&quot;],
        [&quot;ASS&quot;, &quot;PAD&quot;, &quot;NA&quot;],
        [&quot;MARKET&quot;, &quot;NA&quot;, &quot;NA&quot;],
        [&quot;NA&quot;, &quot;PAD&quot;, &quot;NA&quot;],
        [&quot;NA&quot;, &quot;PAD&quot;, &quot;NA&quot;],
    ],
    &quot;Content_type&quot;: [
        [&quot;NOTES&quot;, &quot;PAD&quot;],
        [&quot;PAPER&quot;, &quot;UNK&quot;],
        [&quot;LAW&quot;, &quot;PAD&quot;],
        [&quot;LAW&quot;, &quot;PAD&quot;],
        [&quot;LAW&quot;, &quot;NOTES&quot;],
    ],
    &quot;Geography&quot;: [
        [&quot;UK&quot;, &quot;FR&quot;],
        [&quot;DE&quot;, &quot;CH&quot;],
        [&quot;US&quot;, &quot;ES&quot;],
        [&quot;ES&quot;, &quot;PAD&quot;],
        [&quot;NA&quot;, &quot;PAD&quot;],
    ],
    &quot;Themes&quot;: [[&quot;A&quot;, &quot;B&quot;], [&quot;B&quot;, &quot;C&quot;], [&quot;C&quot;, &quot;PAD&quot;], [&quot;C&quot;, &quot;PAD&quot;], [&quot;G&quot;, &quot;PAD&quot;]],
}

# input text
list_text = [
    &quot;Trump in denial over election defeat as Biden gears up to fight Covid&quot;,
    &quot;Feds seize $1 billion in bitcoins they say were stolen from Silk Road&quot;,
    &quot;Kevin de Bruyne misses penalty as Manchester City and Liverpool draw&quot;,
    &quot;United States nears 10 million coronavirus cases&quot;,
    &quot;Fiji resort offers the ultimate in social distancing&quot;,
]

tokenizer = DistilBertTokenizer.from_pretrained(&quot;distilbert-base-uncased&quot;)
params = {
    &quot;max_length&quot;: MAX_LEN,
    &quot;padding&quot;: &quot;max_length&quot;,
    &quot;truncation&quot;: True,
}
tokenized = tokenizer(list_text, **params)
dict_text = tokenized.data

#input label
label = [[1], [0], [1], [0], [1]]
</code></pre>
<p><strong>Training with NumPy format</strong></p>
<pre><code>ds_meta = tf.data.Dataset.from_tensor_slices((dict_meta))
ds_meta = ds_meta.batch(5)
example_meta = next(iter(ds_meta))

ds_text = tf.data.Dataset.from_tensor_slices((dict_text))
ds_text = ds_text.batch(5)
example_text = next(iter(ds_text))

ds_label = tf.data.Dataset.from_tensor_slices((label))
ds_label = ds_label.batch(5)
example_label = next(iter(ds_label))

model.fit([example_text, example_meta], example_label)
</code></pre>
<pre><code>1/1 [==============================] - 0s 1ms/step - loss: 2.4866
</code></pre>
<p><strong>Training with tf.data.Dataset</strong></p>
<pre><code>ds = tf.data.Dataset.from_tensor_slices(
    (
        {
            &quot;attention_mask&quot;: dict_text[&quot;attention_mask&quot;],
            &quot;input_ids&quot;: dict_text[&quot;input_ids&quot;],
            &quot;Content_type&quot;: dict_meta[&quot;Organization&quot;],
            &quot;Geography&quot;: dict_meta[&quot;Geography&quot;],
            &quot;Organization&quot;: dict_meta[&quot;Organization&quot;],
            &quot;Sector&quot;: dict_meta[&quot;Sector&quot;],
            &quot;Themes&quot;: dict_meta[&quot;Themes&quot;],
        },
        {&quot;class_output&quot;: label},
    )
)


ds = ds.batch(5)
model.fit(ds, epochs=1)
</code></pre>
<pre><code>2020-11-10 14:52:47.502445: W tensorflow/core/framework/op_kernel.cc:1744] OP_REQUIRES failed at cast_op.cc:124 : Unimplemented: Cast string to int32 is not supported
Traceback (most recent call last):

  File &quot;&lt;ipython-input-10-a894466398cd&gt;&quot;, line 1, in &lt;module&gt;
    model.fit(ds, epochs=1)

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py&quot;, line 108, in _method_wrapper
    return method(self, *args, **kwargs)

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py&quot;, line 1098, in fit
    tmp_logs = train_function(iterator)

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 780, in __call__
    result = self._call(*args, **kwds)

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 807, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 550, in call
    ctx=ctx)

  File &quot;/opt/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py&quot;, line 60, in quick_execute
    inputs, attrs, num_outputs)

UnimplementedError:  Cast string to int32 is not supported
     [[node functional_5/Cast (defined at &lt;ipython-input-3-8e2b230c1da3&gt;:17) ]] [Op:__inference_train_function_24120]

Function call stack:
train_function
</code></pre>
",10074708.0,,,,,2020-11-10 15:49:59,Issue tf.data.Dataset for Keras multi-input model,<python><python-3.x><tensorflow><keras><tensorflow2.0>,1,0,,,,CC BY-SA 4.0
68428331,1,68428592.0,,2021-07-18 10:50:31,,5,2864,"<p>I'm a self-taught Python user.
In Python codes,</p>
<pre><code>model.fit(x_train, y_train, verbose=1, validation_split=0.2, shuffle=True, epochs=20000)
</code></pre>
<p>Then, 80% of the data is used for training and 20% is used for validation, and the epoch is repeated 20,000 times for training.</p>
<p>And,</p>
<pre><code>shuffle=True
</code></pre>
<p>So, I think this code is a cross-validation, or more specifically, a k-divisional cross-validation with k=5.
I was wondering if this is correct, because when I looked up the Keras code for k-fold cross-validation, I found some code that uses Scikit-learn's Kfold.</p>
<p>I apologize for the rudimentary nature of this question, but I would appreciate it if you could help me.</p>
",14067192.0,,14067192.0,,2021-07-19 03:14:25,2021-07-19 03:14:25,Is validation_split=0.2 in Keras a cross-validation?,<python><validation><keras><scikit-learn><deep-learning>,1,0,,,,CC BY-SA 4.0
67848962,1,67851641.0,,2021-06-05 11:14:20,,5,3576,"<p>I'm trying to do transfer learning, using a pretrained <strong>Xception</strong> model with a newly added classifier.</p>
<p>This is the model:</p>
<pre><code>base_model = keras.applications.Xception(
    weights=&quot;imagenet&quot;,
    input_shape=(224,224,3),
    include_top=False
)
</code></pre>
<p>The dataset I'm using is <code>oxford_flowers102</code> taken directly from tensorflow datasets.
<a href=""https://www.tensorflow.org/datasets/catalog/oxford_flowers102"" rel=""noreferrer"">This</a> is a dataset page.</p>
<p><strong>I have a problem with selecting some parameters</strong> - either training accuracy shows suspiciously low values, or there's an error.</p>
<p>I need help with specifying this parameter, for this (oxford_flowers102) dataset:</p>
<ol>
<li>Newly added dense layer for the classifier. I was trying with:
<code>outputs = keras.layers.Dense(102, activation='softmax')(x)</code> and I'm not sure whether I should select the activation function here or not.</li>
<li>loss function for model.</li>
<li>metrics.</li>
</ol>
<p>I tried:</p>
<pre><code>model.compile(
    optimizer=keras.optimizers.Adam(),
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[keras.metrics.Accuracy()],
)
</code></pre>
<p>I'm not sure whether it should be <code>SparseCategoricalCrossentropy</code> or <code>CategoricalCrossentropy</code>, and what about <code>from_logits</code> parameter?</p>
<p>I'm also not sure whether should I choose for metrics<code>keras.metrics.Accuracy()</code> or <code>keras.metrics.CategoricalAccuracy()</code></p>
<p>I am definitely lacking some theoretical knowledge, but right now I just need this to work. Looking forward to your answers!</p>
",11480186.0,,9215780.0,,2021-06-05 16:28:31,2021-06-05 16:28:31,Selecting loss and metrics for Tensorflow model,<tensorflow><machine-learning><keras><deep-learning><tensorflow2.0>,1,0,0.0,,,CC BY-SA 4.0
68283519,1,68404933.0,,2021-07-07 09:35:51,,5,1489,"<p>When using multiple GPUs to perform inference on a model (e.g. the call method: model(inputs)) and calculate its gradients, the machine only uses one GPU, leaving the rest idle.</p>
<p>For example in this code snippet below:</p>
<pre><code>import tensorflow as tf
import numpy as np
import os

os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;0,1&quot;

# Make the tf-data
path_filename_records = 'your_path_to_records'
bs = 128

dataset = tf.data.TFRecordDataset(path_filename_records)
dataset = (dataset
           .map(parse_record, num_parallel_calls=tf.data.experimental.AUTOTUNE)
           .batch(bs)
           .prefetch(tf.data.experimental.AUTOTUNE)
          )

# Load model trained using MirroredStrategy
path_to_resnet = 'your_path_to_resnet'
mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():
    resnet50 = tf.keras.models.load_model(path_to_resnet)

for pre_images, true_label in dataset:
    with tf.GradientTape() as tape:
       tape.watch(pre_images)
       outputs = resnet50(pre_images)
       grads = tape.gradient(outputs, pre_images)
</code></pre>
<p>Only one GPU is used. You can profile the behavior of the GPUs with nvidia-smi. I don't know if it is supposed to be like this, both the <code>model(inputs)</code> and <code>tape.gradient</code> to not have multi-GPU support. But if it is, then it's a big problem because if you have a large dataset and need to calculate the gradients with respect to the inputs (e.g. interpretability porpuses) it might take days with one GPU.
Another thing I tried was using <code>model.predict()</code> but this isn't possible with <code>tf.GradientTape</code>.</p>
<p><strong>What I've tried so far and didn't work</strong></p>
<ol>
<li>Put all the code inside mirrored strategy scope.</li>
<li>Used different GPUs: I've tried A100, A6000 and RTX5000. Also changed the number of graphic cards and varied the batch size.</li>
<li>Specified a list of GPUs, for instance, <code>strategy = tf.distribute.MirroredStrategy(['/gpu:0', '/gpu:1'])</code>.</li>
<li>Added this <code>strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())</code> as @Kaveh suggested.</li>
</ol>
<p><strong>How do I know that only one GPU is working?</strong></p>
<p>I used the command <code>watch -n 1 nvidia-smi</code> in the terminal and observed that only one GPU is at 100%, the rest are at 0%.</p>
<p><strong>Working Example</strong></p>
<p>You can find a working example with a CNN trained on the dogs_vs_cats datasets below. You won't need to manually download the dataset as I used the tfds version, nor train a model.</p>
<p><strong>Notebook</strong>: <a href=""https://drive.google.com/file/d/1CoYVckmEQXp2Wf_PRlGtnrlGnF8smxvt/view?usp=sharing"" rel=""nofollow noreferrer"">Working Example.ipynb</a></p>
<p><strong>Saved Model</strong>:</p>
<ul>
<li><a href=""https://drive.google.com/file/d/1Y0-fQytVsnHPs8JL6kKJr3tEL0mKNtjJ/view?usp=sharing"" rel=""nofollow noreferrer"">HDF5</a></li>
<li><a href=""https://drive.google.com/file/d/19oSIaUTtEy1q6rlDj8GzuWIvwAq_7XMi/view?usp=sharing"" rel=""nofollow noreferrer"">Saved Format</a></li>
</ul>
",8527630.0,,8527630.0,,2021-07-15 20:07:14,2021-07-16 07:14:47,Tensorflow - Multi-GPU doesn’t work for model(inputs) nor when computing the gradients,<tensorflow><keras><multi-gpu>,1,20,0.0,,,CC BY-SA 4.0
66642948,1,66673845.0,,2021-03-15 17:44:05,,5,1039,"<p>What I want to do is input a list of numbers to my LSTM model, and have my LSTM model output its own list of numbers. My project is a program that takes an online MIDI file, converts it into a list of numbers, gets a new list of numbers from the LSTM, change those new numbers into MIDI, and then listen to the file. The place where I am running into an issue is where I get a new list of numbers from the LSTM model.</p>
<p>Here is the main code that I currently have:</p>
<pre><code>from midi_to_text import data_parse
from split_sequence import split_sequence
import py_midicsv as pm
import math
from numpy import asarray
from tensorflow.keras import Sequential
from tensorflow.keras.layers import *
import tensorflow as tf


raw_midi = pm.midi_to_csv('OnlineMidi.mid')
data = data_parse(raw_midi)

n_steps = 1
X, y = split_sequence(data, n_steps)
X = X.reshape((X.shape[0], X.shape[1], 1))
X = tf.cast(X, dtype='float32')

model = Sequential()
model.add(LSTM(256, activation='sigmoid', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(128, activation='sigmoid', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(128))
model.add(Dropout(0.2))
model.add(Dense(1, activation='linear'))
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

model.fit(X, y, epochs=100, batch_size=32, verbose=2)

notes = [64]
song_length = 10

for i in range(song_length):
    prediction = model.predict(asarray(notes).reshape((-1, 1, 1)))
    prediction[0][0] = (prediction[0][0] * 384) - (prediction[0][0] * 13) + 13
    # Turns float from 0 to 1 back into integer
    notes.append(prediction[0][0])

print(notes)
</code></pre>
<p>Here is my function for creating the training set and labels:</p>
<pre><code>from numpy import asarray


def split_sequence(data, n_steps):
    new_data, expected_values = list(), list()
    for i in range(len(data)):
        if n_steps + i &lt;= len(data) - 1:
            new_data.append(data[i:n_steps + i])
            expected_values.append(data[n_steps + i])
        else:
            break

    for i in new_data:
        i[0] = (i[0] - 13) / (384 - 13)

    for i in range(len(expected_values)):
        expected_values[i] = (expected_values[i] - 13) / (384 - 13)
    # Turns values into float between 0 and 1
    return asarray(new_data), asarray(expected_values)
</code></pre>
<p>This is the x training data when n_steps = 1:</p>
<pre><code>[[64], [76], [64], [75], [64], [76], [64], [75], [64], [76], [64], [71], [64], [74], [64], [72], [69], [64], [45], [64], [52], [64], [57], [64], [60], [64]]
</code></pre>
<p>This is the labels when n_steps = 1:</p>
<pre><code>[76, 64, 75, 64, 76, 64, 75, 64, 76, 64, 71, 64, 74, 64, 72, 69, 64, 45, 64, 52, 64, 57, 64, 60, 64, 64, 64, 69, 71, 64, 40, 64, 52, 64, 56, 64, 64, 64,]
</code></pre>
<p>This is my data:</p>
<pre><code>[64, 76, 64, 75, 64, 76, 64, 75, 64, 76, 64, 71, 64, 74, 64, 72, 69, 64, 45, 64, 52, 64, 57, 64, 60, 64, 64, 64]
</code></pre>
<p>This is what my model is currently outputting, a list of 9 predictions starting with the seed 64:</p>
<pre><code>[64, 62.63686, 62.636864, 62.636864, 62.636864, 62.636864, 62.636864, 62.636864, 62.636864, 62.636864, 62.636864]
</code></pre>
<p>What I do not understand is why these predictions are all basically the same. When I print the prediction in the last for loop in my main code, I get an output of a list with x lists inside where x is the number of input data. Here is an example of one of these predictions:</p>
<pre><code>[[62.500393]
 [62.500393]
 [62.500393]
 [62.500393]
 [62.500393]
 [62.500393]
 [62.500393]
 [62.500393]
 [62.500393]
 [62.500393]]
</code></pre>
<p>This is why in that for loop I just take the first list's value in the list as the prediction.
To recap, I have a program that takes a list of numbers, and I want to have an LSTM model output a list of prediction numbers starting with the seed 64. The issue I am running into is that my model is, for some reason, outputting basically the same prediction every time, so I need help on this prediction process.</p>
<p>**UPDATE:
**
I tried putting the model.fit() and model.predict() in a for loop and just loop over that 10 times to see what happened. Good news: each prediction was different than the last and that is good. Bad news: It is very slow and I am not sure if this is the best way to go about this. Any advice for getting these values closer to expected values or if this method is even good? It seems highly ineffecient because I am retraining the model 10 times just for 10 output notes (its actually 5, the other 5 values are the duration for each note).</p>
<p>Here is my new output using this for loop:</p>
<pre><code>[64, 56.53626, 58.395187, 61.333992, 59.08212, 58.66997, 55.86058, 59.819744, 54.183216, 55.231224, 53.8824]
</code></pre>
<p>Here is my new code, it is the same things just with a big for loop:</p>
<pre><code>from midi_to_text import data_parse
from split_sequence import split_sequence
import py_midicsv as pm
import math
from numpy import asarray
from tensorflow.keras import Sequential
from tensorflow.keras.layers import *
import tensorflow as tf


raw_midi = pm.midi_to_csv('OnlineMidi.mid')
data = data_parse(raw_midi)

n_steps = 1
X, y = split_sequence(data, n_steps)
print(X)
print(y)
X = X.reshape((X.shape[0], X.shape[1], 1))
X = tf.cast(X, dtype='float32')

notes = [64]

model = Sequential()
model.add(LSTM(256, activation='linear', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(128, activation='linear', return_sequences=True))
model.add(LSTM(128))
model.add(Dropout(0.2))
model.add(Dense(1, activation='linear'))
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

for i in range(10):
    model.fit(X, y, epochs=5, batch_size=2, verbose=2)

    prediction = model.predict(asarray(notes).reshape((-1, 1, 1)))
    prediction[0][0] = (prediction[0][0] * 384) - (prediction[0][0] * 13) + 13
    notes.append(prediction[0][0])

print(notes)
</code></pre>
<p>Custom midi_to_text data parser:</p>
<pre><code>def data_parse(raw_midi):
    temp = []
    final = []
    to_remove = []
    shift_unit = 20

    for i in range(len(raw_midi)):
        temp.append(raw_midi[i].split(', '))

    for i in range(len(temp)):
        if temp[i][2] != 'Note_on_c':
            to_remove.append(temp[i])
    
    for i in to_remove:
        temp.remove(i)
    
    for i in temp:
        i.remove(i[0])
        i.remove(i[1])
        i.remove(i[1])
        i.remove(i[2])

    for i in range(len(temp)):
        if i == len(temp) - 1:
            temp[i][0] = '64'
        else:
            temp[i][0] = str(int(temp[i + 1][0]) - int(temp[i][0]))
            
    to_remove.clear()
    
    for i in range(len(temp)):
        if i == len(temp) - 1:
            break
        if temp[i + 1][0] == '0':
            temp[i].append(temp[i + 1][1])
            to_remove.append(temp[i + 1])
    
    for i in to_remove:
        temp.remove(i)

    for i in temp:
        for _ in i:
            final.append(int(_))

    return final
</code></pre>
<p>THANKS!!</p>
",15290446.0,,15290446.0,,2021-03-16 15:27:27,2021-03-17 13:14:37,TensorFlow LSTM predicting same value,<python><tensorflow><machine-learning><keras><lstm>,1,7,0.0,,,CC BY-SA 4.0
63533821,1,63699653.0,,2020-08-22 07:49:49,,5,1481,"<p>I'm looking at creating a pipeline for a time-series LSTM model. I have two feeds of inputs, lets call them <code>series1</code> and <code>series2</code>.</p>
<p>I initialize the <code>tf.data</code> object by calling <code>from.tensor.slices</code>:</p>
<pre><code>ds = tf.data.Dataset.from_tensor_slices((series1, series2))
</code></pre>
<p>I batch them further into windows of a set windows size and shift 1 between windows:</p>
<pre><code>ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
</code></pre>
<p>At this point I want to play around with how they are batched together. I want to produce a certain input like the following as an example:</p>
<pre><code>series1 = [1, 2, 3, 4, 5]
series2 = [100, 200, 300, 400, 500]

batch 1: [1, 2, 100, 200]
batch 2: [2, 3, 200, 300]
batch 3: [3, 4, 300, 400]
</code></pre>
<p>So each batch will return two elements of series1 and then two elements of series2. This code snippet does <strong>not</strong> work to batch them separately:</p>
<pre><code>ds = ds.map(lambda s1, s2: (s1.batch(window_size + 1), s2.batch(window_size + 1))
</code></pre>
<p>Because it returns two mapping of dataset objects. Since they are objects they are not subscriptible, so this does not work either:</p>
<pre><code>ds = ds.map(lambda s1, s2: (s1[:2], s2[:2]))
</code></pre>
<p>I'm sure the solution is some utilization of <code>.apply</code> with a custom lambda function. Any help is much appreciated.</p>
<h2>Edit</h2>
<p>I am also looking at producing a label that represents the next element of the series. So for example, the batches will produce the following:</p>
<pre><code>batch 1: (tf.tensor([1, 2, 100, 200]), tf.tensor([3]))
batch 2: (tf.tensor([2, 3, 200, 300]), tf.tensor([4]))
batch 3: (tf.tensor([3, 4, 300, 400]), tf.tensor([5]))
</code></pre>
<p>Where <code>[3]</code>, <code>[4]</code> and <code>[5]</code> represent the next elements of <code>series1</code> to be predicted.</p>
",11065415.0,,10908375.0,,2020-09-03 19:59:31,2020-09-08 23:24:20,Batching in tf.data.dataset in time-series analysis,<python><tensorflow><keras><tensorflow2.0><tensorflow-datasets>,3,0,0.0,,,CC BY-SA 4.0
66813950,1,,,2021-03-26 09:10:57,,5,349,"<p>As far as I know and research, the sequences in a data set can be of different lengths; we do not need to pad or truncate them provided that each batch in the training process contains the sequences with the same length.</p>
<p>To realize and apply it, I decided to set the batch size to 1 and trained my RNN model over the IMDB movie classification dataset. I added the code that I had written below.</p>
<pre><code>import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import SimpleRNN
from tensorflow.keras.layers import Embedding

max_features = 10000
batch_size = 1

(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)

model = Sequential()
model.add(Embedding(input_dim=10000, output_dim=32))
model.add(SimpleRNN(units=32, input_shape=(None, 32)))
model.add(Dense(1, activation=&quot;sigmoid&quot;))
model.compile(optimizer=&quot;rmsprop&quot;, 
                  loss=&quot;binary_crossentropy&quot;, metrics=[&quot;acc&quot;])

history = model.fit(x_train, y_train, 
                     batch_size=batch_size, epochs=10, 
                     validation_split=0.2)
</code></pre>
<pre><code>acc = history.history[&quot;acc&quot;]
loss = history.history[&quot;loss&quot;]
val_acc = history.history[&quot;val_acc&quot;]
val_loss = history.history[&quot;val_loss&quot;]

epochs = range(len(acc) + 1)
plt.plot(epochs, acc, &quot;bo&quot;, label=&quot;Training Acc&quot;)
plt.plot(epochs, val_acc, &quot;b&quot;, label=&quot;Validation Acc&quot;)
plt.title(&quot;Training and Validation Accuracy&quot;)
plt.legend()
plt.figure()
plt.plot(epochs, loss, &quot;bo&quot;, label=&quot;Training Loss&quot;)
plt.plot(epochs, val_loss, &quot;b&quot;, label=&quot;Validation Loss&quot;)
plt.title(&quot;Training and Validation Loss&quot;)
plt.legend()
plt.show()
</code></pre>
<p>What error I have been encountered is to fail to convert the input to tensor format because of the list components in the input numpy array. However, when I change them, I continue to get similar kinds of errors.</p>
<p>The error message:</p>
<pre><code>ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list).
</code></pre>
<p>I could not handle the problem. Could anyone help me on this point?</p>
",8393861.0,,9215780.0,,2021-06-24 16:56:09,2021-06-24 16:56:09,Movie Review Classification with Recurrent Networks,<python><tensorflow><keras><deep-learning><recurrent-neural-network>,2,0,0.0,,,CC BY-SA 4.0
66545781,1,66546115.0,,2021-03-09 11:09:58,,5,9362,"<p>I am attempting to implement a CNN-LSTM that classifies mel-spectrogram images representing the speech of people with Parkinson's Disease/Healthy Controls. I am trying to implement a pre-existing model (DenseNet-169) with an LSTM model, however I am running into the following error: <code>ValueError: Input 0 of layer zero_padding2d is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 216, 1].</code> Can anyone advise where I'm going wrong?</p>
<pre><code>import librosa
import os
import glob
import IPython.display as ipd
from pathlib import Path
import timeit
import time, sys

%matplotlib inline
import matplotlib.pyplot as plt
import librosa.display

import pandas as pd
from sklearn import datasets, linear_model
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
import numpy as np
import cv2
import seaborn as sns

%tensorflow_version 1.x #version 1 works without problems
import tensorflow

from tensorflow.keras import models
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import TimeDistributed

import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization, Activation, GaussianNoise, LSTM
from sklearn.metrics import accuracy_score

DATA_DIR = Path('/content/drive/MyDrive/PhD_Project_Experiments/Spontaneous_Dialogue_PD_Dataset') 
diagnosis = [x.name for x in DATA_DIR.glob('*') if x.is_dir()]
diagnosis

def create_paths_ds(paths: Path, label: str) -&gt; list:
    EXTENSION_TYPE = '.wav'
    return [(x, label) for x in paths.glob('*' + EXTENSION_TYPE)]

from collections import Counter

categories_to_use = [
    'Parkinsons_Disease',
    'Healthy_Control',
]

NUM_CLASSES = len(categories_to_use)

print(f'Number of classes: {NUM_CLASSES}')

paths_all_labels = []
for cat in categories_to_use:
    paths_all_labels += create_paths_ds(DATA_DIR / cat, cat)
 
X_train, X_test = train_test_split(paths_all_labels,test_size=0.1, stratify = [paths_all_labels[y][1] for y in range(len(paths_all_labels))] ) #fix stratified sampling for test data
X_train, X_val = train_test_split(X_train, test_size=0.2, stratify = [X_train[y][1] for y in range(len(X_train))] ) 

for i in categories_to_use:
  print('Number of train samples for '+i+': '+ str([X_train[y][1] for y in range(len(X_train))].count(i))) #checks whether train samples are equally divided
  print('Number of test samples for '+i+': '+ str([X_test[y][1] for y in range(len(X_test))].count(i))) #checks whether test samples are equally divided
  print('Number of validation samples for '+i+': '+ str([X_val[y][1] for y in range(len(X_val))].count(i))) #checks whether val samples are equally divided

print(f'Train length: {len(X_train)}')
print(f'Validation length: {len(X_val)}')
print(f'Test length: {len(X_test)}')

def load_and_preprocess_lstm(dataset, SAMPLE_SIZE = 30):
    IMG_SIZE = (216,128) 
    progress=0

    data = []
    labels = []
    for (path, label) in dataset:
        audio, sr = librosa.load(path)
        dur = librosa.get_duration(audio, sr = sr)
        sampleNum = int(dur / SAMPLE_SIZE)
        offset = (dur % SAMPLE_SIZE) / 2
        for i in range(sampleNum):
            audio, sr = librosa.load(path, offset= offset+i, duration=SAMPLE_SIZE)
            sample = librosa.feature.melspectrogram(audio, sr=sr)
            # print(sample.shape)
            sample = cv2.resize(sample, dsize=IMG_SIZE)
            sample = np.expand_dims(sample,-1)
            print(sample.shape)
            data += [(sample, label)]
            labels += [label]
        progress +=1
        print('\r Progress: '+str(round(100*progress/len(dataset))) + '%', end='')
    return data, labels

def retrieve_samples(sample_size, model_type):

    if model_type == 'cnn':
  
        print(&quot;\nLoading train samples&quot;)
        X_train_samples, train_labels = load_and_preprocess_cnn(X_train,sample_size)
        print(&quot;\nLoading test samples&quot;)
        X_test_samples, test_labels = load_and_preprocess_cnn(X_test,sample_size)
        print(&quot;\nLoading val samples&quot;)
        X_val_samples, val_labels = load_and_preprocess_cnn(X_val,sample_size)
        print('\n')

    elif model_type == 'lstm':

        print(&quot;\nLoading train samples&quot;)
        X_train_samples, train_labels = load_and_preprocess_lstm(X_train,sample_size)
        print(&quot;\nLoading test samples&quot;)
        X_test_samples, test_labels = load_and_preprocess_lstm(X_test,sample_size)
        print(&quot;\nLoading val samples&quot;)
        X_val_samples, val_labels = load_and_preprocess_lstm(X_val,sample_size)      
        print('\n')

    elif model_type == &quot;cnnlstm&quot;:

        print(&quot;\nLoading train samples&quot;)
        X_train_samples, train_labels = load_and_preprocess_lstm(X_train,sample_size)
        print(&quot;\nLoading test samples&quot;)
        X_test_samples, test_labels = load_and_preprocess_lstm(X_test,sample_size)
        print(&quot;\nLoading val samples&quot;)
        X_val_samples, val_labels = load_and_preprocess_lstm(X_val,sample_size)      
        print('\n')

    print(&quot;shape: &quot; + str(X_train_samples[0][0].shape))
    print(&quot;number of training samples: &quot;+ str(len(X_train_samples)))
    print(&quot;number of validation samples: &quot;+ str(len(X_val_samples)))
    print(&quot;number of test samples: &quot;+ str(len(X_test_samples)))


    return X_train_samples, X_test_samples, X_val_samples

def create_cnn_lstm_model(input_shape):

    model = Sequential()
    cnn = tensorflow.keras.applications.DenseNet169(include_top=True, weights=None, input_tensor=None, input_shape=input_shape, pooling=None, classes=2)
    # define LSTM model
    model.add(tensorflow.keras.layers.TimeDistributed(cnn, input_shape=input_shape))
    model.add(LSTM(units = 512, dropout=0.5, recurrent_dropout=0.3, return_sequences = True, input_shape = input_shape))
    model.add(LSTM(units = 512, dropout=0.5, recurrent_dropout=0.3, return_sequences = False))
    model.add(Dense(units=NUM_CLASSES, activation='sigmoid'))#Compile

    model.compile(loss=tensorflow.keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])
    print(model.summary())

    return model

def create_model_data_and_labels(X_train_samples, X_val_samples, X_test_samples):
    #Prepare samples to work for training the model
    labelizer = LabelEncoder()

    #prepare training data and labels
    x_train = np.array([x[0] for x in X_train_samples])
    y_train = np.array([x[1] for x in X_train_samples])
    y_train = labelizer.fit_transform(y_train) 
    y_train = to_categorical(y_train)

    #prepare validation data and labels
    x_val = np.array([x[0] for x in X_val_samples])
    y_val = np.array([x[1] for x in X_val_samples])
    y_val = labelizer.transform(y_val)
    y_val = to_categorical(y_val)

    #prepare test data and labels
    x_test = np.array([x[0] for x in X_test_samples])
    y_test = np.array([x[1] for x in X_test_samples])
    y_test = labelizer.transform(y_test)
    y_test = to_categorical(y_test)

    return x_train, y_train, x_val, y_val, x_test, y_test, labelizer


#Main loop for testing multiple sample sizes

#choose model type: 'cnn' or 'lstm'
model_type = 'cnnlstm'

n_epochs = 20
patience= 20
es = EarlyStopping(patience=20)
fragment_sizes = [5,10]
start = timeit.default_timer()

ModelData = pd.DataFrame(columns = ['Model Type','Fragment size (s)', 'Time to Compute (s)',  'Early Stopping epoch', 'Training accuracy', 'Validation accuracy', 'Test Accuracy']) #create a DataFrame for storing the results 

conf_matrix_data = []

for i in fragment_sizes:

    start_per_size = timeit.default_timer()

    print(f'\n---------- Model trained on fragments of size: {i} seconds ----------------')
    X_train_samples, X_test_samples, X_val_samples = retrieve_samples(i,model_type)
    x_train, y_train, x_val, y_val, x_test, y_test, labelizer = create_model_data_and_labels(X_train_samples, X_val_samples, X_test_samples)

    if model_type == 'cnn':
        model = create_cnn_model(X_train_samples[0][0].shape)
    elif model_type == 'lstm':
        model = create_lstm_model(X_train_samples[0][0].shape)
    elif model_type == 'cnnlstm':
        model = create_cnn_lstm_model(X_train_samples[0][0].shape)


    history = model.fit(x_train, y_train, 
              batch_size = 8, 
              epochs=n_epochs,
              verbose=1, 
              callbacks=[es],
              validation_data=(x_val, y_val))
    print('Finished training')


    early_stopping_epoch = len(history.history['accuracy'])
    training_accuracy = history.history['accuracy'][early_stopping_epoch-1-patience]
    validation_accuracy = history.history['val_accuracy'][early_stopping_epoch-1-patience]

    plot_data(history, i)

    predictions = model.predict(x_test)
    score = accuracy_score(labelizer.inverse_transform(y_test.argmax(axis=1)), labelizer.inverse_transform(predictions.argmax(axis=1)))

    print('Fragment size = ' + str(i) + ' seconds')
    print('Accuracy on test samples: ' + str(score))
    
    conf_matrix_data += [(predictions, y_test, i)]

    stop_per_size = timeit.default_timer()
    time_to_compute = round(stop_per_size - start_per_size)

    print ('Time to compute: '+str(time_to_compute))

    ModelData.loc[len(ModelData)] = [model_type, i, time_to_compute, early_stopping_epoch, training_accuracy, validation_accuracy, score] #store particular settings configuration, early stoppping epoch and accuracies in dataframe

stop = timeit.default_timer()
print ('\ntime to compute: '+str(stop-start))
</code></pre>
",11698228.0,,4755954.0,,2023-01-11 23:15:03,2023-01-11 23:15:03,How to implement a CNN-LSTM using Keras,<python><tensorflow><keras><conv-neural-network><lstm>,1,9,,,,CC BY-SA 4.0
72467711,1,72533328.0,,2022-06-01 20:30:24,,5,1906,"<p>The tensorflow versions that I can still recreate this behavior are: <code>2.7.0</code>, <code>2.7.3</code>, <code>2.8.0</code>, <code>2.9.0</code>. Actually, these are all the versions I've tried; I wasn't able to resolve the issue in any version.</p>
<ul>
<li>OS: Ubuntu 20</li>
<li>GPU: RTX 2060</li>
<li>RAM: 16GB</li>
</ul>
<p>I am trying to feed my data to a model using a generator:</p>
<pre class=""lang-py prettyprint-override""><code>class DataGen(tf.keras.utils.Sequence):
    def __init__(self, indices, batch_size):
        self.X = X
        self.y = y
        self.indices = indices
        self.batch_size = batch_size
    
    def __getitem__(self, index):
        X_batch = self.X[self.indices][
            index * self.batch_size : (index + 1) * self.batch_size
        ]
        y_batch = self.y[self.indices][
            index * self.batch_size : (index + 1) * self.batch_size
        ]
        return X_batch, y_batch
    
    def __len__(self):
        return len(self.y[self.indices]) // self.batch_size

train_gen = DataGen(train_indices, 32)
val_gen = DataGen(val_indices, 32)
test_gen = DataGen(test_indices, 32)
</code></pre>
<p>where <code>X</code>, <code>y</code> is my dataset loaded from a <code>.h5</code> file using <code>h5py</code>, and <code>train_indices</code>, <code>val_indices</code>, <code>test_indices</code> are the indices for each set that will be used on <code>X</code> and <code>y</code>.</p>
<p>I am creating the model and feeding the data using:</p>
<pre class=""lang-py prettyprint-override""><code># setup model
base_model = tf.keras.applications.MobileNetV2(input_shape=(128, 128, 3),
                                                include_top=False)
base_model.trainable = False

mobilenet1 = Sequential([
    base_model,
    Flatten(),
    Dense(27, activation='softmax')
])

mobilenet1.compile(optimizer=tf.keras.optimizers.Adam(),
                   loss=tf.keras.losses.CategoricalCrossentropy(),
                   metrics=['accuracy'])
# model training
hist_mobilenet = mobilenet1.fit(train_gen, validation_data=val_gen, epochs=1)
</code></pre>
<p>The memory right before training is 8%, but the moment training starts it begins getting values from 30% up to 60%. Since I am using a generator and loading the data in small parts of 32 observations at a time, it seems odd to me that the memory climbs this high. Also, even when training stops, memory stays above 30%. I checked all global variables but none of them has such a large size. If I start another training session memory starts having even higher usage values and eventually jupyter notebook kernel dies.</p>
<p>Is something wrong with my implementation or this is normal?</p>
<h4>Edit 1: some additional info.</h4>
<ul>
<li>Whenever the training stops, memory usage drops a little, but I can decrease it even more by calling garbage collector. However, I cannot bring it back down to 8%, even when I delete the history created by fit</li>
<li>the x and y batches' size sum up to 48 bytes; this outrages me! how come loading 48 of data at a time is causing the memory usage to increase that much? Supposedly I am using HDF5 dataset to be able to handle the data without overloading RAM. The next thing that comes to my mind is that <code>fit</code> creates some variables, but it doesn't make sense that it needs so many GBs of memory to store them</li>
</ul>
",9758352.0,,9215780.0,,2022-06-06 05:15:26,2022-06-07 14:50:26,Is memory supposed to be this high during model.fit using a generator?,<python><tensorflow><keras>,3,6,,,,CC BY-SA 4.0
69403584,1,,,2021-10-01 09:28:17,,5,590,"<p>I'm trying to run a hand analysis program using mediapipe's hand recognition library as well as tensorflow models to recognize if hands are in a particular position. I tried to use the two together, but ran into an issue.</p>
<p>Whenever I try to use both the tensorflow model and the mediapipe library, I cannot. The program freezes and does not run to completion. However, as soon as I remove the model loading, the program runs just fine. So I'm wondering if there's some sort of memory issue that's holding things up, which would be odd, as the model I'm trying to load is only 25kb.</p>
<p>Here's the code:</p>
<pre><code>import cv2
from tensorflow.keras.models import load_model
import h5py
import mediapipe as mp

model = load_model('/path_to_model/model.h5')

print('Marker 1')

mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_hands = mp.solutions.hands

print('Marker 2')

cap = cv2.VideoCapture(0)
cap.set(3, 1280) # set the Horizontal resolution
cap.set(4, 720) # Set the Vertical resolution

print('Marker 3')

num_frames = 0

print('Marker 4')

with mp_hands.Hands(
    min_detection_confidence=.5,
    min_tracking_confidence=.1) as hands:
    print('Marker 5')
    while cap.isOpened():
        print('Marker 6')
        success, image = cap.read()
        print('Marker 7')
        if not success:
            print(&quot;Ignoring empty camera frame.&quot;)
            continue
        print('Marker 8')

        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        print('Marker 9')

        gray_roi =cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)
        
        print('Marker 10')
        
        image.flags.writeable = False
        results = hands.process(image)
        print('Marker 11')

        image.flags.writeable = True
        print('Marker 12')
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        print('Marker 13')
        if results.multi_hand_landmarks:
            print('Marker 14')
            for hand_landmarks in results.multi_hand_landmarks:
                print('Marker 15')
                mp_drawing.draw_landmarks(
                image,
                hand_landmarks,
                mp_hands.HAND_CONNECTIONS,
                mp_drawing_styles.get_default_hand_landmarks_style(),
                mp_drawing_styles.get_default_hand_connections_style())
                print('Marker 16')
        print('Marker 17')
        if results.multi_handedness is None:
                print('Marker 17')
                string = 'Handedness: N/A'
        else:
            print('Marker 18')
            string = 'Handedness:' + str(len(results.multi_handedness))
      
            print('Marker 19')
            if num_frames % 5 == 0:
                    print('Marker 20')
                    position = function_that_uses_model_to_determine_hand_position(gray_roi)  
                    print('Marker 21')
                
        print('Marker 22')    
        cv2.putText(image, string, (10, 70), cv2.FONT_HERSHEY_PLAIN, 3,
        (255, 0, 255), 3)
        cv2.putText(image, position, (70, 70), cv2.FONT_HERSHEY_PLAIN, 3,
        (255, 0, 255), 3)
        print('Marker 23')
        cv2.imshow('MediaPipe Hands', image)
        print('Marker 24')
        if cv2.waitKey(5) &amp; 0xFF == 27:
            break
        print('Marker 25')
        num_frames+=1
        print('Marker 26')
cap.release()
</code></pre>
<p>If I comment the load_model parts out (and the associated code lines), it runs just fine. However, whenever I try to include loading the model, I only make it to <code>Marker 10</code>. Heck, I don't even need to try loading the model. I still only make it to <code>Marker 10</code> if all I include is the <code>from tensorflow.keras.models import load_model</code> line and nothing else to do with tensorflow. So obviously importing or using that is causing some issues that prevent the rest of the program from running.</p>
<p>My tensorflow version is 1.14.0, keras version is 2.3.1, and python version is 3.7.6.</p>
<p>Let me know if you smart people know how this can be remedied!</p>
<p>Thanks,
Sam</p>
",12370143.0,,12370143.0,,2021-10-03 23:58:55,2021-10-04 19:34:26,Importing Tensorflow Causes Program to Freeze,<python><tensorflow><keras><memory-leaks><mediapipe>,1,2,0.0,,,CC BY-SA 4.0
63458668,1,63459031.0,,2020-08-17 21:08:03,,5,7906,"<p>I am trying to learn image auto encoding but I can't use input and output images to train the model</p>
<p>ex:
input images folder: &quot;.../Pictures/Input&quot;<br/>
output images folder: &quot;.../Pictures/Output&quot;</p>
<pre><code>#get input images from data_dir_input
ds_input = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir_input,
    seed=123,
    image_size=(img_height, img_width),
    label_mode=None,
    batch_size=batch_size)

#get output images from data_dir_output
ds_output = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir_output,
    seed=123,
    image_size=(img_height, img_width),
    label_mode=None,
    batch_size=batch_size)

# --------- model init etc --------------
# ...


model.fit(x=ds_input, y=ds_output, batch_size=32, epochs=50)

</code></pre>
<p>But I get error saying this:</p>
<p><code> `y` argument is not supported when using dataset as input</code></p>
<p>How can i use my own input images and output images when training model?</p>
",10304864.0,,10304864.0,,2020-08-18 01:05:50,2023-06-01 15:04:00,Tensorflow image_dataset_from_directory for input dataset and output dataset,<python><tensorflow><image-processing><keras><autoencoder>,1,0,0.0,,,CC BY-SA 4.0
66542889,1,66562628.0,,2021-03-09 07:57:15,,5,540,"<p>I have a burning issue on applying same dropout mask for all of the timesteps within a time series sample so that LSTM layer sees same inputs in one forward pass. I read multiple articles but did not find a solution to this. Does the following <a href=""https://raphaellederman.github.io/articles/videoclassification_2/#building-an-appropriate-classification-model"" rel=""nofollow noreferrer"">implementation</a> support this? Or this randomly drops different feature maps in each timestep?</p>
<pre><code>dim = (420,48,48,1) # grayscale images of size 48x48
inputShape = (dim)
Input_words = Input(shape=inputShape, name='input_vid')
x = TimeDistributed(Conv2D(filters=50, kernel_size=(8,8), padding='same', activation='relu'))(Input_words)
x = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x)
x = TimeDistributed(SpatialDropout2D(0.2))(x)
x = TimeDistributed(BatchNormalization())(x)
x = TimeDistributed(Flatten())(x)
x = LSTM(200, dropout=0.2, recurrent_dropout=0.2)(x)
out = Dense(5,activation='softmax')(x)
model = Model(inputs=Input_words, outputs=[out])
opt = Adam(lr=1e-3, decay=1e-3 / 200)
model.compile(loss = 'categorical_crossentropy', optimizer=opt,metrics = ['accuracy'])
</code></pre>
<p>If not what would a good solution for this on keras? Can I use <a href=""https://keras.io/api/layers/regularization_layers/dropout/"" rel=""nofollow noreferrer"">Dropout with noise_shape</a> to solve my problem?</p>
",3363978.0,,10375049.0,,2021-03-10 10:29:12,2021-03-13 09:32:14,Correct usage of keras SpatialDropout2D inside TimeDistributed layer - CNN LSTM network,<tensorflow><keras><conv-neural-network><lstm><dropout>,1,0,0.0,,,CC BY-SA 4.0
71890276,1,,,2022-04-16 01:06:39,,5,803,"<p>Every time I convert a model to a <code>tflite</code> format, I always receive this WARNING. I wonder if this library will further reduce the model size. If so, I hope to use it. But I can't find relevant information in Google, and <code>flatbuffer</code>'s documentation doesn't seem to mention how to simply install it so that tensorflow can invoke it.</p>
",17221142.0,,,,,2022-04-16 01:06:39,Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded. (Tensorflow Lite),<tensorflow><keras><deep-learning><flatbuffers>,0,0,,,,CC BY-SA 4.0
63656333,1,69949542.0,,2020-08-30 10:13:25,,5,5487,"<p>According to the <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/losses/Reduction"" rel=""noreferrer"">docs</a>, the <code>Reduction</code> parameter takes on 3 values - <code>SUM_OVER_BATCH_SIZE</code>, <code>SUM</code> and <code>NONE</code>.</p>
<pre><code>y_true = [[0., 2.], [0., 0.]]
y_pred = [[3., 1.], [2., 5.]]

mae = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM)
mae(y_true, y_pred).numpy()
&gt; 5.5

mae = tf.keras.losses.MeanAbsoluteError()
mae(y_true, y_pred).numpy()
&gt; 2.75
</code></pre>
<p>What I could infer about the calculation after various trials, is this:-</p>
<ul>
<li><p>when <code>REDUCTION = SUM</code>,</p>
<p><code>Loss = Sum over all samples {(Sum of differences between y_pred and y_target vector of each sample / No of element in y_target of the sample )} = { (abs(3-0) + abs(1-2))/2 } + { (abs(2-0) + abs(5-0))/2 } = {4/2} + {7/2} = 5.5</code>.</p>
</li>
<li><p>when <code>REDUCTION = SUM_OVER_BATCH_SIZE</code>,</p>
<p><code>Loss = [Sum over all samples {(Sum of differences between y_pred and y_target vector of each sample / No of element in y_target of the sample )}] / Batch_size or No of Samples  = [ { (abs(3-0)} + abs(1-2))/2 } + { (abs(2-0) + abs(5-0))/2 } ]/2 = [ {4/2} + {7/2} ]/2 = [5.5]/2 = 2.75</code>.</p>
</li>
</ul>
<p>As a result, <code>SUM_OVER_BATCH_SIZE</code> is nothing but <code>SUM/batch_size</code>. Then, why is it called <code>SUM_OVER_BATCH_SIZE</code> when <code>SUM</code> actually adds up the losses over the entire batch, while <code>SUM_OVER_BATCH_SIZE</code> calculates the average loss of the batch.</p>
<p>Is my assumption regarding the workings of <code>SUM_OVER_BATCH_SIZE</code> and <code>SUM</code> at all correct?</p>
",9895768.0,,9895768.0,,2020-08-30 10:18:44,2021-11-12 22:04:39,'Reduction' parameter in tf.keras.losses,<python><tensorflow><keras><tensorflow2.0>,1,2,,,,CC BY-SA 4.0
69914867,1,69914965.0,,2021-11-10 14:15:56,,5,4985,"<p>I have a dataset that includes video frames partially 1000 real videos and 1000 deep fake videos. each video after preprocessing phase converted to the 300 frames in other worlds I have a dataset with 300000 images with Real(0) label and 300000 images with Fake(1) label.
I want to train MesoNet with this data. I used costum DataGenerator class to handle train, validation, test data with 0.8,0.1,0.1 ratios but when I run the project show this message:</p>
<pre><code>Filling up shuffle buffer (this may take a while):
</code></pre>
<p>What can I do to solve this problem?</p>
<p>You can see the DataGenerator class below.</p>
<pre><code>class DataGenerator(keras.utils.Sequence):
'Generates data for Keras'
def __init__(self, df, labels, batch_size =32, img_size = (224,224),
             n_classes = 2, shuffle=True):
    'Initialization'
    self.batch_size = batch_size
    self.labels = labels
    self.df = df
    self.img_size = img_size
    self.n_classes = n_classes
    self.shuffle = shuffle
    self.batch_labels = []
    self.batch_names = []
    self.on_epoch_end()

def __len__(self):
    'Denotes the number of batches per epoch'
    return int(np.floor(len(self.df) / self.batch_size))

def __getitem__(self, index):
    
    batch_index = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]
    frame_paths = self.df.iloc[batch_index][&quot;framePath&quot;].values
    frame_label = self.df.iloc[batch_index][&quot;label&quot;].values

    imgs = [cv2.imread(frame) for frame in frame_paths]
    imgs = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in imgs]
    imgs = [
             cv2.resize(img, self.img_size) for img in imgs if img.shape != self.img_size
             ]
    batch_imgs = np.asarray(imgs)
    labels = list(map(int, frame_label))
    y = np.array(labels)
    self.batch_labels.extend(labels)
    self.batch_names.extend([str(frame).split(&quot;\\&quot;)[-1] for frame in frame_paths])

    return (
        batch_imgs,y  
    )

def on_epoch_end(self):
    'Updates indexes after each epoch'
    self.indexes = np.arange(len(self.df))
    if self.shuffle == True:
        np.random.shuffle(self.indexes)
</code></pre>
",5700343.0,,5752730.0,,2022-03-28 20:44:12,2022-03-28 20:44:12,Filling up shuffle buffer (this may take a while),<python><tensorflow><keras><deep-learning><bigdata>,1,0,,,,CC BY-SA 4.0
69960574,1,,,2021-11-14 05:39:09,,5,1425,"<p>I would like to use the trained model described in <a href=""https://keras.io/examples/vision/handwriting_recognition/"" rel=""noreferrer"">Keras's Handwriting recognition Example</a>, in another application and tried to load the model with the following;</p>
<pre><code>from keras.models import load_model
from tensorflow import keras

model = keras.models.load_model(&quot;test4_20211113.h5&quot;, custom_objects={'CTCLayer': CTCLayer}) 
</code></pre>
<p>I received &quot;ValueError: Unknown layer: Custom&gt;CTCLayer. Please ensure this object is passed to the <code>custom_objects</code> argument.&quot;</p>
<p>I added the custom_objects argument and modified the CTCLayer class by adding **kwargs following this article, &quot;<a href=""https://stackoverflow.com/questions/50837728/valueerror-unknown-layer-capsulelayer"">ValueError: Unknown layer: CapsuleLayer</a>&quot;.</p>
<pre><code>class CTCLayer(keras.layers.Layer):
    def __init__(self, name=None, **kwargs):
        self.name = name
        super().__init__(**kwargs)
        self.loss_fn = keras.backend.ctc_batch_cost

    def call(self, y_true, y_pred):
        batch_len = tf.cast(tf.shape(y_true)[0], dtype=&quot;int64&quot;)
        input_length = tf.cast(tf.shape(y_pred)[1], dtype=&quot;int64&quot;)
        label_length = tf.cast(tf.shape(y_true)[1], dtype=&quot;int64&quot;)

        input_length = input_length * \
            tf.ones(shape=(batch_len, 1), dtype=&quot;int64&quot;)
        label_length = label_length * \
            tf.ones(shape=(batch_len, 1), dtype=&quot;int64&quot;)
        loss = self.loss_fn(y_true, y_pred, input_length, label_length)
        self.add_loss(loss)

        # At test time, just return the computed predictions.
        return y_pred
</code></pre>
<p>I'm a beginner in both Python and Keras, and greatly appreciate it if you let me know how to fix this.</p>
",14474522.0,,,,,2022-12-07 16:04:24,ValueError: Unknown layer: Custom>CTCLayer. Please ensure this object is passed to the `custom_objects` argument,<python><tensorflow><keras><valueerror><custom-object>,1,1,,,,CC BY-SA 4.0
66501492,1,,,2021-03-06 01:22:11,,5,2354,"<p>I have a model trained in sagemaker (custom training job), and saved by my training script with the keras <code>model.save()</code> method that produces a <code>variables</code> directory with the weights and index, and a <code>.pb</code> file. The model is a <code>TFBertForSequenceClassification</code> from huggingface's <code>transformer</code> library, and according to their documentation, this model subclasses from a keras model. When I try to load the model with <code>keras.models.load_model()</code> however, I get the following error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py&quot;, line 187, in load_model
    return saved_model_load.load(filepath, compile, options)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 121, in load
    path, options=options, loader_cls=KerasObjectLoader)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py&quot;, line 633, in load_internal
    ckpt_options)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 194, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py&quot;, line 130, in __init__
    self._load_all()
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 215, in _load_all
    self._layer_nodes = self._load_layers()
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 315, in _load_layers
    layers[node_id] = self._load_layer(proto.user_object, node_id)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 341, in _load_layer
    obj, setter = self._revive_from_config(proto.identifier, metadata, node_id)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 368, in _revive_from_config
    obj, self._proto.nodes[node_id], node_id)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 298, in _add_children_recreated_from_config
    obj_child, child_proto, child_id)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 298, in _add_children_recreated_from_config
    obj_child, child_proto, child_id)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py&quot;, line 250, in _add_children_recreated_from_config
    metadata = json_utils.decode(proto.user_object.metadata)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/json_utils.py&quot;, line 60, in decode
    return json.loads(json_string, object_hook=_decode_helper)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/json/__init__.py&quot;, line 361, in loads
    return cls(**kw).decode(s)
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/json/decoder.py&quot;, line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File &quot;/home/tyarosevich/anaconda3/envs/fresh_env/lib/python3.7/json/decoder.py&quot;, line 355, in raw_decode
    raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
</code></pre>
<p>I'm stumped. The transformer library's own <code>save_pretrained()</code> method saves layer info in a <code>.json</code> file, but I don't see why the keras model saves would know/care about this (and I don't think that's what the issue is anyway). Any help?</p>
",6910488.0,,,,,2022-02-17 07:26:24,Can't load TF transformer model with keras.models.load_model(),<python><tensorflow><keras><huggingface-transformers>,2,2,,,,CC BY-SA 4.0
69970569,1,69970853.0,,2021-11-15 07:12:52,,5,18610,"<p>I have this model :</p>
<pre><code># Set random seed
tf.random.set_seed(42)

# Create some regression data
X_regression = np.expand_dims(np.arange(0, 1000, 5), axis=0)
y_regression = np.expand_dims(np.arange(100, 1100, 5), axis=0)

# Split it into training and test sets
X_reg_train = X_regression[:150]
X_reg_test = X_regression[150:]
y_reg_train = y_regression[:150]
y_reg_test = y_regression[150:]
</code></pre>
<pre><code># Setup random seed
tf.random.set_seed(42)

# Recreate the model
model_3 = tf.keras.Sequential([
  tf.keras.layers.Dense(100),
  tf.keras.layers.Dense(10),
  tf.keras.layers.Dense(1)
])

# Change the loss and metrics of our compiled model
model_3.compile(loss=tf.keras.losses.mae, # change the loss function to be regression-specific
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
                metrics=['mae']) # change the metric to be regression-specific

# Fit the recompiled model
model_3.fit(X_reg_train, y_reg_train, epochs=100)
</code></pre>
<p>To begin with, the model does not train well
<a href=""https://i.stack.imgur.com/bOXvO.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bOXvO.png"" alt=""enter image description here"" /></a></p>
<p>To add on, when I try to predict using that model, I get the following error :</p>
<p><a href=""https://i.stack.imgur.com/Slswy.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Slswy.png"" alt=""enter image description here"" /></a></p>
<p>Why am I getting the above error and how can I fix it?</p>
",,user14653534,,,,2021-11-15 07:41:37,"ValueError: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`",<python><tensorflow><machine-learning><keras><deep-learning>,1,0,,,,CC BY-SA 4.0
66389006,1,66393450.0,,2021-02-26 15:59:20,,5,20065,"<p>The conda install is only for tf 2.2.0 as there doesn't seem to be a cudnn 8.0 on anaconda.</p>
<p><a href=""https://anaconda.org/anaconda/tensorflow-gpu"" rel=""noreferrer"">https://anaconda.org/anaconda/tensorflow-gpu</a></p>
<p>Does anyone know of a method of getting tf 2.4&gt;= running within an anaconda environment?</p>
",10018352.0,,,,,2021-06-10 00:50:16,How do I install tensorflow 2.4> on anaconda?,<python><tensorflow><keras><anaconda><tensorflow2.0>,3,2,0.0,,,CC BY-SA 4.0
66705131,1,,,2021-03-19 08:55:19,,5,2190,"<p>I implemented a sequence generator object according to guidelines from <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"" rel=""nofollow noreferrer"">link</a>.</p>
<pre><code>import tensorflow as tf
from cv2 import imread, resize
from sklearn.utils import shuffle
from cv2 import imread, resize
import numpy as np
from tensorflow.keras import utils
import math
import keras as ks

class reader(tf.keras.utils.Sequence):

    def __init__(self, x, y, batch_size, n_class):
        self.x, self.y = x, y
        self.batch_size = batch_size
        self.n_class = n_class
        
    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        print('getitem', idx)
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        
        
        data_x = list()
        for batch in batch_x:
            tmp = list()
            for img_path in batch:
                try:
                    img = imread(img_path)
                    tmp.append(img)
                except Exception as e:
                    print(e)
                    print('failed to find path {}'.format(img_path))
            data_x.append(tmp)
        # 
        data_x = np.array(data_x, dtype='object')
        data_y = np.array(batch_y)
        data_y = utils.to_categorical(data_y, self.n_class)
        print('return item')
        print(data_x.shape)
        return (data_x, data_y)
    
    def on_epoch_end(self):
        # option method to run some logic at the end of each epoch: e.g. reshuffling
        print('on epoch end')
        seed = np.random.randint()
        self.x = shuffle(self.x, random_state=seed)
        self.y = shuffle(self.y, random_state=seed)
</code></pre>
<p>However, it doesn't work with tensorflow model's fit api. Below is the simple model architecture I used to replicate this issue.</p>
<pre><code>model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv3D(10, input_shape=(TEMPORAL_LENGTH,HEIGHT,WIDTH,CHANNEL), kernel_size=(2,2,2), strides=2))
model.add(tf.keras.layers.Conv3D(10, kernel_size=(2,3,3), strides=2))
model.add(tf.keras.layers.Conv3D(10, kernel_size=(2,3,3), strides=2))
model.add(tf.keras.layers.Conv3D(10, kernel_size=(2,3,3), strides=2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(10))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])
model.summary()
</code></pre>
<p>Let me create a reader</p>
<p><code>r1 = reader(x_train, y_train, 20, 10)</code></p>
<p>Then I call the model.fit api.</p>
<pre><code>train_history = model.fit(r1, epochs=3, steps_per_epoch=5, verbose=1)
### output ###
getitem 0
return item
(20, 16, 192, 256, 3)
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
Train for 5 steps
Epoch 1/3
</code></pre>
<p>It will stay like this forever if I don't interrupt. Out of curiosity, I tried this approach with model created from Keras api and to my surprise it just work!</p>
<pre><code>model = ks.models.Sequential()
model.add(ks.layers.Conv3D(10, input_shape=(TEMPORAL_LENGTH,HEIGHT,WIDTH,CHANNEL), kernel_size=(2,2,2), strides=2))
model.add(ks.layers.Conv3D(10, kernel_size=(2,3,3), strides=2))
model.add(ks.layers.Conv3D(10, kernel_size=(2,3,3), strides=2))
model.add(ks.layers.Conv3D(10, kernel_size=(2,3,3), strides=2))
model.add(ks.layers.Flatten())
model.add(ks.layers.Dense(10))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
train_history = model.fit(r1, epochs=3, steps_per_epoch=5, verbose=1)
### output ###
Epoch 1/3
getitem 586
return item
(20, 16, 192, 256, 3)
getitem 169
1/5 [=====&gt;........................] - ETA: 22s - loss: 11.0373 - accuracy: 0.0000e+00return item
(20, 16, 192, 256, 3)
getitem 601
2/5 [===========&gt;..................] - ETA: 12s - loss: 7.9983 - accuracy: 0.0250     return item
(20, 16, 192, 256, 3)
getitem 426
3/5 [=================&gt;............] - ETA: 8s - loss: 10.7049 - accuracy: 0.2500return item
(20, 16, 192, 256, 3)
getitem 243
4/5 [=======================&gt;......] - ETA: 3s - loss: 8.5093 - accuracy: 0.1875
</code></pre>
<p><strong>Dependencies</strong></p>
<ol>
<li>tensorflow-gpu: 2.1</li>
<li>keras-gpu: 2.3.1</li>
</ol>
",13928599.0,,9338741.0,,2021-03-19 10:32:26,2021-03-25 11:48:51,Custom data generator build from tf.keras.utils.Sequence doesn't work with tensorflow model's fit api,<python><tensorflow><keras><sequence-generators>,1,1,0.0,,,CC BY-SA 4.0
69994403,1,,,2021-11-16 18:32:33,,5,324,"<p>I am training multiple models in R. After a while, I run out of memory.</p>
<p>From rudimentary googling, the tensorflow sessions seems to hold things in memory after the objects have been overwritten in R. This has been a problem that others have encountered, however I have seen no answers that help for keras in R in particular.</p>
<p><a href=""https://stackoverflow.com/questions/51005147/keras-release-memory-after-finish-training-process/52354943"">Keras: release memory after finish training process</a></p>
<p><a href=""https://stackoverflow.com/questions/57188831/tensorflow2-0-gpu-runs-out-of-memory-during-hyperparameter-tuning-loop?noredirect=1&amp;lq=1"">Tensorflow2.0: GPU runs out of memory during hyperparameter tuning loop</a></p>
<p>I've tried running these commands after each loop:</p>
<p><code>rm(model)</code></p>
<p><code>k_clear_session()</code></p>
<p><code>tf$compat$v1$keras$backend$clear_session()</code></p>
<p>but these problems persist. Any ideas on how to release the memory Keras uses?</p>
<p>I'm running this code on a laptop, and I'm pretty sure I don't have a GPU.</p>
",8968617.0,,,,,2021-11-19 21:58:41,Keras in R: freeing up memory after multiple training sessions,<r><tensorflow><keras><memory><tensorflow2.0>,1,4,,,,CC BY-SA 4.0
63659585,1,,,2020-08-30 16:23:23,,5,1741,"<p>I'm a newbie at machine learning. I'm learning it using Keras by giving myself exercises.</p>
<p><a href=""https://www.dropbox.com/s/yhx8k6kbmdt6u7s/2020-08-30%20Flooro.mp4?dl=0"" rel=""noreferrer"">Here is the video</a> from my latest exercise. I've trained a convolutional neural network to identify three different objects. The phone sends the image to the web server on my desktop, which runs Keras.</p>
<p>It took a while until I got a model that worked. I started by training on video frames of these 3 objects against a sterile background. I don't know if there's an accepted name for this technique, but I used a sort of &quot;training wheels&quot; approach. First I trained the model on a really easy background. Then took more videos on backgrounds that are busier. I did 6 rounds, each round against a different background. At each round, I loaded the weights from the previous rounds, and trained the network on the combined data set from all the previous rounds. The idea was to get the neural net started on something that's easy, and then gradually expand its knowledge rather than try to give it a difficult task right away.</p>
<p>That seems to have worked, I have good accuracy now when identifying these objects on different backgrounds. I've saved the model weights to a file.</p>
<p>My question is: Now that I have good trained network, is it possible to change its structure? For example right now I'm cropping and resizing the images to 64x64. If I wanted to up it to 128x128, will I be able to use the weights I've trained so far? What if I wanted to add color (so 3 channels instead of 1), is that possible without starting the training from scratch?</p>
",76701.0,,,,,2020-08-30 23:40:32,Keras: Changing the structure of a trained model,<python><tensorflow><machine-learning><keras><neural-network>,1,0,,,,CC BY-SA 4.0
65679735,1,68061976.0,,2021-01-12 07:40:06,,5,1870,"<p>I am trying to measure FLOPS for a TFLite model in TF2.
I know that Tensorflow 1.x had the tf.profiler, which was awesome for measuring flops. It doesn't seem to work well with tf.keras.</p>
<p>Could anybody please describe how to measure FLOPs for a TFLite model in TF2? I can't seem to find an answer online.
Thank you all so much for your time.</p>
<p>Edit: The link commented below does not help with tflite.</p>
",14547190.0,,14547190.0,,2021-01-12 16:39:32,2021-06-21 03:31:49,Measuring Flops for TFLite Model in Tensorflow 2.X,<python><tensorflow><machine-learning><keras><tensorflow2.0>,2,2,0.0,,,CC BY-SA 4.0
67342988,1,67344134.0,,2021-05-01 04:50:13,,5,1835,"<p>I have implemented the <code>MultiAttention head</code> in <code>Transformers</code>. There are so many implementations around so it's confusing. Can someone please verify if my implementation is correct:</p>
<p>DotProductAttention referred from: <a href=""https://www.tensorflow.org/tutorials/text/transformer#setup"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/text/transformer#setup</a></p>
<pre><code>import tensorflow as tf

def scaled_dot_product(q,k,v):
    #calculates Q . K(transpose)
    qkt = tf.matmul(q,k,transpose_b=True)
    #caculates scaling factor
    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))
    scaled_qkt = qkt/dk
    softmax = tf.nn.softmax(scaled_qkt,axis=-1)
    
    z = tf.matmul(softmax,v)
    #shape: (m,Tx,depth), same shape as q,k,v
    return z

class MultiAttention(tf.keras.layers.Layer):
    def __init__(self,d_model,num_of_heads):
        super(MultiAttention,self).__init__()
        self.d_model = d_model
        self.num_of_heads = num_of_heads
        self.depth = d_model//num_of_heads
        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]
        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]
        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]
        self.wo = tf.keras.layers.Dense(d_model)
        
    def call(self,x):
        
        multi_attn = []
        for i in range(self.num_of_heads):
            Q = self.wq[i](x)
            K = self.wk[i](x)
            V = self.wv[i](x)
            multi_attn.append(scaled_dot_product(Q,K,V))
            
        multi_head = tf.concat(multi_attn,axis=-1)
        multi_head_attention = self.wo(multi_head)
        return multi_head_attention

#Calling the attention 
multi = MultiAttention(d_model=512,num_of_heads=8)
m = 5; sequence_length = 4; word_embedding_dim = 512
sample_ip = tf.constant(tf.random.normal(shape=(m,sequence_length,word_embedding_dim)))
attn =multi(sample_ip)
#shape of op (attn): (5,4,512)
</code></pre>
",5927701.0,,5927701.0,,2021-05-01 08:50:56,2021-05-01 08:50:56,Verifying the implementation of Multihead Attention in Transformer,<tensorflow><keras><deep-learning><nlp><lstm>,1,2,0.0,,,CC BY-SA 4.0
70998639,1,,,2022-02-05 13:50:54,,5,6980,"<p>I'm training a hand detection model with Tensorflow and I have a problem.</p>
<p>This is the code to train the model:</p>
<pre><code>!cd RealTimeObjectDetection/RealTimeObjectDetection &amp;&amp; python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=/content/RealTimeObjectDetection/RealTimeObjectDetection/Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000
</code></pre>
<p>I have this error:</p>
<pre><code>Node: 'ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D'
DNN library is not found.
     [[{{node ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D}}]] [Op:__inference__dummy_computation_fn_15081]
</code></pre>
",17530449.0,,,,,2022-06-01 01:34:20,DNN library is not found ssd_mobile_net_v2 in Colab,<python><tensorflow><keras>,2,0,,,,CC BY-SA 4.0
67256272,1,,,2021-04-25 17:24:29,,5,7016,"<pre><code>import os
from pylab import rcParams
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns; sns.set()
from numpy import *
from scipy import stats
from pandas.plotting import scatter_matrix
import sklearn
import warnings
from imblearn.over_sampling import SMOTE
import tensorflow as tf
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import GridSearchCV
from imblearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression


data = pd.read_excel(r'Attrition Data Exercise.xlsx')
X = data.iloc[:, 3:-1].values
y = data.iloc[:, -1].values

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import OrdinalEncoder
ct = ColumnTransformer(transformers=
                       [('one_encoder', OneHotEncoder(), [2, 5, 11, 13, 28]),
                       ('ord_encoder', OrdinalEncoder(), [0])],
                       remainder='passthrough')
X = np.array(ct.fit_transform(X))

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dropout(rate=0.3))
ann.add(tf.keras.layers.Dense(units=6, activation='relu', kernel_regularizer='l1', bias_regularizer='l2'))
ann.add(tf.keras.layers.Dropout(rate=0.3))
ann.add(tf.keras.layers.Dense(units=3, activation='relu', kernel_regularizer='l1', bias_regularizer='l2'))
ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))
opt = tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-08)
ann.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy', tf.keras.metrics.Recall()])
</code></pre>
<p>The above code runs successfully. It's when I run the below code in a cell that it causes an error.</p>
<pre><code>pipe = Pipeline([('smt', SMOTE()), ('model', KerasClassifier(build_fn = ann, verbose = 0, epochs=170))])
weights = np.linspace(0.5, 0.5, 1)
gsc = GridSearchCV(
estimator = pipe,
param_grid = {
    'smt__sampling_strategy' : weights
},
scoring = 'f1',
cv = 4)
grid_result = gsc.fit(X_train, y_train)
</code></pre>
<p>The code above results in the following error:</p>
<pre><code>ValueError: The first argument to `Layer.call` must always be passed
</code></pre>
<p>Any idea what I might be doing wrong or what can be improved?
I tried replacing KerasClassifier with KerasRegressor too just to see if something changes but nothing did. What essentially is going wrong?</p>
<p>I'm trying to use the Pipeline class from imblearn and GridSearchCV to get the best parameters for classifying the imbalanced dataset, I want to leave out resampling of the validation set and only resample the training set, which imblearn's Pipeline seems to be doing. However, I'm getting an error while implementing the accepted solution</p>
<p>Also link to the screenshot to the error trace is attached.<a href=""https://i.stack.imgur.com/3KxhP.png"" rel=""noreferrer"">Error Trace Complete</a></p>
",10715295.0,,10715295.0,,2021-04-26 18:12:06,2021-05-15 17:29:52,The first argument to `Layer.call` must always be passed,<python><machine-learning><keras><tensorflow2.0>,1,2,0.0,,,CC BY-SA 4.0
62805263,1,62805721.0,,2020-07-08 23:44:10,,5,5219,"<p>Say I have a folder of images such as:</p>
<pre><code>PetData
|
Dog - images
|
Cat - images
</code></pre>
<p>How would I transform it into (x_train, y_train),(x_test, y_test) format? I see this format used extensively with the MNIST dataset which goes like:</p>
<pre class=""lang-py prettyprint-override""><code>mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
</code></pre>
<p>However i'd like to do this with my own folder of images.</p>
",13424118.0,,5982359.0,,2020-12-15 17:46:11,2022-02-20 10:40:51,How to convert a folder of images into X and Y batches with Keras?,<python><tensorflow><keras>,3,0,0.0,,,CC BY-SA 4.0
62778635,1,62778710.0,,2020-07-07 15:24:36,,5,1615,"<p>If I create function like this:</p>
<pre><code>def mdl(input_shape):

    model = Sequential()
    model.add(Conv2D(depth=64, kernel_size=(3, 3), input_shape=input_shape, activation='relu'))
    model.add(Dense(32), activation='relu')
    model.add(Dropout(0.3))
    model.add(Dense(32), activation='relu')
    model.add(Dropout(0.3))
    model.add(Dense(16), activation='relu')
    model.add(Dropout(0.3))
    model.add(Dense(1))

    return model
</code></pre>
<p>and I care a lot about good programming practices, how should I indicate returning type of the function?</p>
",10588118.0,,,,,2023-05-10 08:26:20,Python type hinting for function with keras model,<python><keras><type-hinting>,1,0,,,,CC BY-SA 4.0
64380057,1,64399107.0,,2020-10-15 21:40:39,,5,2008,"<p>I am passing in sample_weight as the 3rd tuple in tf.data.Dataset (using it in the context of mask, so my sample_weight are either 0, or 1. The problem is that this sample_weight doesn't seem to get applied to metrics calculation. (Ref: <a href=""https://www.tensorflow.org/guide/keras/train_and_evaluate#sample_weights"" rel=""noreferrer"">https://www.tensorflow.org/guide/keras/train_and_evaluate#sample_weights</a>)</p>
<p>Here's code snippet:</p>
<pre><code>train_ds = tf.data.Dataset.from_tensor_slices((imgs, labels, masks))
train_ds = train_ds.shuffle(1024).repeat().batch(32).prefetch(buffer_size=AUTO)

model.compile(optimizer = Adam(learning_rate=1e-4),
             loss = SparseCategoricalCrossentropy(),
             metrics = ['sparse_categorical_accuracy'])

model.fit(train_ds, steps_per_epoch = len(imgs)//32, epochs = 20)
</code></pre>
<p>The loss after training is very close to zero, but sparse_categorical_accuracy is not (about 0.89). So I highly suspect whatever sample_weight (masks) that's passed in to construct the tf.dataset, does NOT get applied when the metrics is reported during training, while loss seems to be correct. I further confirmed by running prediction on the subset that are not masked separately, and confirmed the accuracy is 1.0</p>
<p>Also, according to documentation:</p>
<p><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy"" rel=""noreferrer"">https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy</a></p>
<p>the metric has 3 args: y_true, y_pred, sample_weight</p>
<p>So how does one pass the sample_weight during metric computation? Is this the responsibility of model.fit(...) within the keras framework? I can't find any example googling around so far.</p>
",1762295.0,,,,,2020-10-17 04:48:15,TF 2.3.0 training keras model using tf dataset with sample weights does not apply to metrics,<tensorflow><keras><metrics>,1,1,,,,CC BY-SA 4.0
63053427,1,,,2020-07-23 11:42:01,,5,8313,"<p>I need to add layers to an existing model. However, I need to add the layers at &quot;the main model level&quot;, that is I can't use the classic functional approach. For example, if I use something like:</p>
<pre><code>from keras.layers import Dense,Reshape, Input
inp = Input(shape=(15,))
d1 = Dense(224*224*3, activation='linear')(inp)
r1 = Reshape(input_shape)
from keras import Model
model_mod = r1(d1)
model_mod = mobilenet(model_mod)
model_mod = Model(inp, model_mod)
</code></pre>
<p>I obtain:</p>
<pre><code>Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         (None, 15)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 150528)            2408448   
_________________________________________________________________
reshape_4 (Reshape)          (None, 224, 224, 3)       0         
_________________________________________________________________
mobilenet_1.00_224 (Model)   (None, 1000)              4253864 
</code></pre>
<p>So, I obtain a model with a nested submodel. Instead, I would the nested submodel's layers (mobilenet) &quot;added&quot; to the new top layers (that is, after reshape_4). I tried with:</p>
<pre><code>modelB_input = modelB.input
for layer in modelB.layers:
    if layer == modelB_input:
        continue
    modelA.add(layer)  
</code></pre>
<p>It works for simple sequential models (e.g., vgg, mobilenet) but with more complex models with connections not strictly sequential (e.g., inception,resnet) this code is not good.
Any ideas?</p>
",1973451.0,,1973451.0,,2020-07-23 13:30:27,2022-09-20 08:54:36,keras : add layers to another model,<keras><neural-network><keras-layer><tf.keras>,2,0,0.0,,,CC BY-SA 4.0
63058383,1,63058937.0,,2020-07-23 15:58:24,,5,1668,"<p>I am a newcomer to convolutional neural networks and have the following question: Is there a way to create a CNN with multiple outputs, including 10 for classification and two more for regression with Keras in Python?</p>
",10632632.0,,15368978.0,,2022-01-12 19:44:04,2022-01-12 19:44:04,CNN with multiple output types,<python><tensorflow><keras><conv-neural-network>,1,1,0.0,,,CC BY-SA 4.0
63073760,1,63075401.0,,2020-07-24 12:39:26,,5,7127,"<p>In <a href=""https://deepmind.com/blog/article/wavenet-generative-model-raw-audio"" rel=""noreferrer"">WaveNet</a>, dilated convolution is used to increase receptive field of the layers above.</p>
<p><a href=""https://i.stack.imgur.com/7wJDc.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/7wJDc.gif"" alt=""Dilated convolution"" /></a></p>
<p>From the illustration, you can see that layers of dilated convolution with kernel size 2 and dilation rate of powers of 2 create a tree like structure of receptive fields. I tried to (very simply) replicate the above in Keras.</p>
<pre><code>import tensorflow.keras as keras
nn = input_layer = keras.layers.Input(shape=(200, 2))
nn = keras.layers.Conv1D(5, 5, padding='causal', dilation_rate=2)(nn)
nn = keras.layers.Conv1D(5, 5, padding='causal', dilation_rate=4)(nn)
nn = keras.layers.Dense(1)(nn)
model = keras.Model(input_layer, nn)
opt = keras.optimizers.Adam(lr=0.001)
model.compile(loss='mse', optimizer=opt)
model.summary()
</code></pre>
<p>And the output:</p>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_4 (InputLayer)         [(None, 200, 2)]          0
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 200, 5)            55
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 200, 5)            130
_________________________________________________________________
dense_2 (Dense)              (None, 200, 1)            6
=================================================================
Total params: 191
Trainable params: 191
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>I was expecting <code>axis=1</code> to shrink after each <code>conv1d</code> layer, similar to the gif. Why is this not the case?</p>
",1272975.0,,,,,2022-07-04 15:14:15,Using dilated convolution in Keras,<tensorflow><keras><conv-neural-network>,2,0,0.0,,,CC BY-SA 4.0
67068303,1,67220052.0,,2021-04-13 03:22:32,,5,432,"<p>The current <a href=""https://keras.io/examples/vision/captcha_ocr/"" rel=""noreferrer"">Keras Captcha OCR model</a> returns a CTC encoded output, which requires decoding after inference.</p>
<p>To decode this, one needs to run a decoding utility function after inference as a separate step.</p>
<pre><code>preds = prediction_model.predict(batch_images)
pred_texts = decode_batch_predictions(preds)
</code></pre>
<p>The decoded utility function uses <code>keras.backend.ctc_decode</code>, which in turn uses either a greedy or beam search decoder.</p>
<pre><code># A utility function to decode the output of the network
def decode_batch_predictions(pred):
    input_len = np.ones(pred.shape[0]) * pred.shape[1]
    # Use greedy search. For complex tasks, you can use beam search
    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][
        :, :max_length
    ]
    # Iterate over the results and get back the text
    output_text = []
    for res in results:
        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(&quot;utf-8&quot;)
        output_text.append(res)
    return output_text
</code></pre>
<p>I would like to train a Captcha OCR model using Keras that returns the CTC decoded as an output, without requiring an additional decoding step after inference.</p>
<p>How would I achieve this?</p>
",1594557.0,,,,,2021-04-22 20:04:49,How can I add the decode_batch_predictions() method into the Keras Captcha OCR model?,<keras><ocr><decoding><ctc>,2,0,0.0,,,CC BY-SA 4.0
66952606,1,66952857.0,,2021-04-05 11:53:30,,5,4645,"<p>I am creating an LSTM for sentiment analysis with (a subset of) the IMDB database, using Keras. My training, validation and testing accuracy dramatically improves if I add a flatten layer before the final dense layer:</p>
<pre><code>def lstm_model_flatten():
    embedding_dim = 128
    model = Sequential()
    model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))
    model.add(layers.LSTM(128, return_sequences = True,  dropout=0.2)) 
    # Flatten layer
    model.add(layers.Flatten())
    model.add(layers.Dense(1,activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.summary()
    return model
</code></pre>
<p>This overfits quickly, but the validation accuracy gets up to around 76%:</p>
<pre><code>Model: &quot;sequential_43&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_42 (Embedding)     (None, 500, 128)          4768256   
_________________________________________________________________
lstm_63 (LSTM)               (None, 500, 128)          131584    
_________________________________________________________________
flatten_10 (Flatten)         (None, 64000)             0         
_________________________________________________________________
dense_40 (Dense)             (None, 1)                 64001     
=================================================================
Total params: 4,963,841
Trainable params: 4,963,841
Non-trainable params: 0
_________________________________________________________________
Epoch 1/7
14/14 [==============================] - 26s 2s/step - loss: 0.6911 - accuracy: 0.5290 - val_loss: 0.6802 - val_accuracy: 0.5650
Epoch 2/7
14/14 [==============================] - 23s 2s/step - loss: 0.6451 - accuracy: 0.6783 - val_loss: 0.6074 - val_accuracy: 0.6950
Epoch 3/7
14/14 [==============================] - 23s 2s/step - loss: 0.4594 - accuracy: 0.7910 - val_loss: 0.5237 - val_accuracy: 0.7300
Epoch 4/7
14/14 [==============================] - 23s 2s/step - loss: 0.2566 - accuracy: 0.9149 - val_loss: 0.4753 - val_accuracy: 0.7650
Epoch 5/7
14/14 [==============================] - 23s 2s/step - loss: 0.1397 - accuracy: 0.9566 - val_loss: 0.6011 - val_accuracy: 0.8050
Epoch 6/7
14/14 [==============================] - 23s 2s/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.7648 - val_accuracy: 0.8100
Epoch 7/7
14/14 [==============================] - 23s 2s/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.8829 - val_accuracy: 0.8150
</code></pre>
<p>Using the same architecture without the flatten layer (and using return_sequences = False on the LSTM layer) only produces a validation accuracy of around 50%.</p>
<p>The comments on <a href=""https://stackoverflow.com/questions/62787684/understand-the-role-of-flatten-in-keras-and-determine-when-to-use-it"">this post</a> recommend that <code>return_sequences = False</code> is used before the dense layer, rather than a flatten layer.</p>
<p>But why is that the case? Is it ok to use a flatten layer if it improves my model? What exactly is the flatten layer doing here, and why does it improve the accuracy?</p>
",15557058.0,,4685471.0,,2021-04-05 11:59:22,2021-04-05 12:11:25,What is this flatten layer doing in my LSTM?,<python><machine-learning><keras><lstm><flatten>,1,4,,,,CC BY-SA 4.0
63093045,1,63093113.0,,2020-07-25 20:05:06,,5,2576,"<p>This is the last layer of a Keras model.</p>
<pre><code>model.add(Dense(3, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>
<p>I know that the output of the softmax layer is an array, with probability summing up to 1, such as <code>[0.1, 0.4, 0.5]</code>.</p>
<p>I have one question about using accuracy as a metric.</p>
<p>e.g., when the true class is <code>[0, 0, 1]</code> and predicted probability is <code>[0.1, 0.4, 0.5]</code>, even if <code>0.5</code> is the largest probability, the accuracy of this prediction should be <code>0</code>, because <code>0.5 != 1</code>. Is that correct?</p>
<p>More generally, when the output layer activation is <code>softmax</code>, we will normally get floating probability predictions, and in very very little chance will we get integer probability predictions like  <code>[0, 0, 1]</code>. So we can't use <code>accuracy</code> as a metric when using <code>softmax</code> as activation. Is that correct?</p>
",12162096.0,,,,,2020-07-25 20:38:30,Keras softmax output and accuracy,<python><tensorflow><keras><neural-network>,1,0,,,,CC BY-SA 4.0
70979055,1,,,2022-02-03 22:15:08,,5,543,"<p>I'm running Python 3.9.7 and TensorFlow 2.5 on my MacBook Pro with M1 Max chip, in a virtual environment managed through MiniForge. (Setup due to <a href=""https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-mac-metal-jul-2021.ipynb"" rel=""nofollow noreferrer"">Jeff Heaton</a>).</p>
<p>I have a custom loss function in the model. This code runs fine on my other machine, which is Ubuntu-based Pop!OS.</p>
<p>When I run model.fit from Keras, I <strong>occasionally</strong> get the following errors. Sometimes it runs just fine. Any idea what's causing it, why it only happens sometimes, and how to fix it?</p>
<p>In addition, it only produces this error from my custom loss function. Not from any Keras-native.</p>
<p>Thanks!</p>
<pre><code>:5:10: error: invalid length (0) for size 20                                                                                                                             | 0.00/1.00 [00:00&lt;?, ?batch/s]
-:5:10: error: 'mps.slice' op failed to fold or infer return types
-:5:10: note: see current operation: %2 = &quot;mps.slice&quot;(%arg0) {axis = 0 : si32, length = 999 : i32, start = 1 : i32} : (tensor&lt;20xf32&gt;) -&gt; tensor&lt;*xf32&gt;
/System/Volumes/Data/SWE/macOS/BuildRoots/5b2e67f8af/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/MetalPerformanceShadersGraph-2.2.1/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphExecutable.mm:1179: failed assertion `Error: MLIR pass manager failed'
model.fit(tf.convert_to_tensor(Σ),tf.zeros((T,output)),batch_size=T,epochs=1,verbose=0,callbacks=[TqdmCallback()])#,tbc])
zsh: abort      python3
(tensorflow) kpmott@kevins-mbp-7 tf.olg % model.fit(tf.convert_to_tensor(Σ),tf.zeros((T,output)),batch_size=T,epochs=1,verbose=0,callbacks=[TqdmCallback()])#,tbc])
zsh: parse error near `)'
(tensorflow) kpmott@kevins-mbp-7 tf.olg % /opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
model.fit(tf.convert_to_tensor(Σ),tf.zeros((T,output)),batch_size=T,epochs=1,verbose=0,callbacks=[TqdmCallback()])#,tbc])
zsh: parse error near `)'
</code></pre>
",18113995.0,,872328.0,,2022-11-22 08:10:17,2022-11-22 08:10:17,`Error: MLIR Pass Manager Failed': TensorFlow on MacBook Pro M1 Max,<python><tensorflow><keras><apple-m1><apple-silicon>,0,1,,,,CC BY-SA 4.0
68374999,1,68454267.0,,2021-07-14 08:56:59,,5,5441,"<p>I am training a neural network with tf-keras. It is a multi-label classification where each sample belongs to multiple classes [1,0,1,0..etc] .. the final model line (just for clarity) is:</p>
<pre><code>model.add(tf.keras.layers.Dense(9, activation='sigmoid'))#final layer

model.compile(loss='binary_crossentropy', optimizer=optimizer, 
                metrics=[tf.keras.metrics.BinaryAccuracy(), 
                tfa.metrics.F1Score(num_classes=9, average='macro',threshold=0.5)])
</code></pre>
<p>I need to generate precision, recall and F1 scores for these (I already get the F1 score reported during training). For this I am using sklearns classification report, but I need to confirm that I am using it correctly in the multi-label setting.</p>
<pre><code>from sklearn.metrics import classification_report

pred = model.predict(x_test)
pred_one_hot = np.around(pred)#this generates a one hot representation of predictions

print(classification_report(one_hot_ground_truth, pred_one_hot))
</code></pre>
<p>This works fine and i get the full report for every class including F1 scores that match the F1score metric from tensorflow addons (for macro F1). Sorry this post is verbose but what I am unsure about is:</p>
<p>Is it correct that the predictions need to be one-hot encoded in the case of the multi-label setting? If I pass in the normal prediction scores (sigmoid probabilities) an error is thrown...</p>
<p>thank you.</p>
",,user9317212,,,,2021-07-20 11:55:46,Is this the correct use of sklearn classification report for multi-label classification reports?,<keras><scikit-learn><multilabel-classification><precision-recall>,1,0,,,,CC BY-SA 4.0
65310020,1,,,2020-12-15 16:39:31,,5,2180,"<p>If I want to train Keras models and have multiple GPUs available, there are several ways of using them effectively:</p>
<ol>
<li><p>Assign a GPU each to a different model, and train them in parallel (For example, for hyperparameter tuning, or comparison between different architectures). For example, I have model1 that I assign to GPU1, and model2 to GPU2, and after one global data loading operation, Keras would run model.fit() for each model in parallel on each GPU.</p>
</li>
<li><p>Dividing one model and train in parallel on all GPUs.  This is done by splitting the model into sequential chunks, and then computing all gradients for the whole model. The way it is implemented it would not work for different independent models.</p>
</li>
<li><p>Diving data and feeding different batches to the same model on different GPUs.</p>
</li>
</ol>
<p>There seem to be a lot of documentation of 2) and 3)</p>
<p><a href=""https://keras.io/guides/distributed_training/"" rel=""nofollow noreferrer"">https://keras.io/guides/distributed_training/</a></p>
<p><a href=""https://www.run.ai/guides/multi-gpu/keras-multi-gpu-a-practical-guide/"" rel=""nofollow noreferrer"">https://www.run.ai/guides/multi-gpu/keras-multi-gpu-a-practical-guide/</a></p>
<p><a href=""https://www.pyimagesearch.com/2017/10/30/how-to-multi-gpu-training-with-keras-python-and-deep-learning/"" rel=""nofollow noreferrer"">https://www.pyimagesearch.com/2017/10/30/how-to-multi-gpu-training-with-keras-python-and-deep-learning/</a></p>
<p>But I can't find any solution for 1), and the posts asking for it don't have a solution:</p>
<p><a href=""https://stackoverflow.com/questions/50992771/train-multiple-keras-tensorflow-models-on-different-gpus-simultaneously"">Train multiple keras/tensorflow models on different GPUs simultaneously</a></p>
<p>It seems that, with those options already available, it should be trivial to also have the option to assign a different GPU to each model, and train in parallel. Is there something I am missing?</p>
<p>EDIT: One proposed solution is just to run different python scripts. But this is not optimal, as it is dividing each GPU per script, not per model, which means all other parts of the script will need to be run twice, redundantly. If the data loading part is expensive, this will be very inefficient, as both scripts will be competing for data access.</p>
",2723396.0,,2723396.0,,2020-12-15 18:26:09,2020-12-17 10:09:49,Is it possible to train multiple Keras models in parallel on multiple GPUs in a single python script?,<python><tensorflow><keras><deep-learning>,1,7,,,,CC BY-SA 4.0
66654250,1,,,2021-03-16 11:23:07,,5,574,"<p>Here is the example of CycleGAN from the Keras
<a href=""https://keras.io/examples/generative/cyclegan/"" rel=""nofollow noreferrer"">CycleGAN Example Using Keras.</a></p>
<p>Here is my modified implementation to use multiple GPUs. To implement the custom training I have used a reference <a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">Custom training with tf.distribute.Strategy</a></p>
<p>I want an example of CycleGAN from the Keras to run fast using GPUs. As further I need to process and train a huge amount of data. As well as CycleGAN uses multiple loss functions <code>train_step</code> will return 4 types of losses, currently, I am just returning one for easier understanding. Still, the training on GPUs is dead slow. I am not able to find the reason behind this.</p>
<p>Am I using <code>tf.distribute.Strategy</code> wrongly?</p>
<pre><code>&quot;&quot;&quot;
Title: CycleGAN
Author: [A_K_Nain](https://twitter.com/A_K_Nain)
Date created: 2020/08/12
Last modified: 2020/08/12
Description: Implementation of CycleGAN.
&quot;&quot;&quot;

&quot;&quot;&quot;
## CycleGAN
CycleGAN is a model that aims to solve the image-to-image translation
problem. The goal of the image-to-image translation problem is to learn the
mapping between an input image and an output image using a training set of
aligned image pairs. However, obtaining paired examples isn't always feasible.
CycleGAN tries to learn this mapping without requiring paired input-output images,
using cycle-consistent adversarial networks.
- [Paper](https://arxiv.org/pdf/1703.10593.pdf)
- [Original implementation](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
&quot;&quot;&quot;

&quot;&quot;&quot;
## Setup
&quot;&quot;&quot;

import os
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

import tensorflow_addons as tfa
import tensorflow_datasets as tfds

tfds.disable_progress_bar()
autotune = tf.data.experimental.AUTOTUNE

# Create a MirroredStrategy.
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

&quot;&quot;&quot;
## Prepare the dataset
In this example, we will be using the
[horse to zebra](https://www.tensorflow.org/datasets/catalog/cycle_gan#cycle_ganhorse2zebra)
dataset.
&quot;&quot;&quot;

# Load the horse-zebra dataset using tensorflow-datasets.
dataset, _ = tfds.load(&quot;cycle_gan/horse2zebra&quot;, with_info=True, as_supervised=True)
train_horses, train_zebras = dataset[&quot;trainA&quot;], dataset[&quot;trainB&quot;]
test_horses, test_zebras = dataset[&quot;testA&quot;], dataset[&quot;testB&quot;]

# Define the standard image size.
orig_img_size = (286, 286)
# Size of the random crops to be used during training.
input_img_size = (256, 256, 3)
# Weights initializer for the layers.
kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)
# Gamma initializer for instance normalization.
gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)

buffer_size = 256
batch_size = 1


def normalize_img(img):
    img = tf.cast(img, dtype=tf.float32)
    # Map values in the range [-1, 1]
    return (img / 127.5) - 1.0


def preprocess_train_image(img, label):
    # Random flip
    img = tf.image.random_flip_left_right(img)
    # Resize to the original size first
    img = tf.image.resize(img, [*orig_img_size])
    # Random crop to 256X256
    img = tf.image.random_crop(img, size=[*input_img_size])
    # Normalize the pixel values in the range [-1, 1]
    img = normalize_img(img)
    return img


def preprocess_test_image(img, label):
    # Only resizing and normalization for the test images.
    img = tf.image.resize(img, [input_img_size[0], input_img_size[1]])
    img = normalize_img(img)
    return img


&quot;&quot;&quot;
## Create `Dataset` objects
&quot;&quot;&quot;
BATCH_SIZE_PER_REPLICA = batch_size
GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync  


# Apply the preprocessing operations to the training data
train_horses = (
    train_horses.map(preprocess_train_image, num_parallel_calls=autotune)
    .cache()
    .shuffle(buffer_size)
    .batch(GLOBAL_BATCH_SIZE)
)
train_zebras = (
    train_zebras.map(preprocess_train_image, num_parallel_calls=autotune)
    .cache()
    .shuffle(buffer_size)
    .batch(GLOBAL_BATCH_SIZE)
)

# Apply the preprocessing operations to the test data
test_horses = (
    test_horses.map(preprocess_test_image, num_parallel_calls=autotune)
    .cache()
    .shuffle(buffer_size)
    .batch(GLOBAL_BATCH_SIZE)
)
test_zebras = (
    test_zebras.map(preprocess_test_image, num_parallel_calls=autotune)
    .cache()
    .shuffle(buffer_size)
    .batch(GLOBAL_BATCH_SIZE)
)

# Visualize some samples

_, ax = plt.subplots(4, 2, figsize=(10, 15))
for i, samples in enumerate(zip(train_horses.take(4), train_zebras.take(4))):
    horse = (((samples[0][0] * 127.5) + 127.5).numpy()).astype(np.uint8)
    zebra = (((samples[1][0] * 127.5) + 127.5).numpy()).astype(np.uint8)
    ax[i, 0].imshow(horse)
    ax[i, 1].imshow(zebra)
plt.show()
plt.savefig('Visualize_Some_Samples')
plt.close()     


# Building blocks used in the CycleGAN generators and discriminators

class ReflectionPadding2D(layers.Layer):
    &quot;&quot;&quot;Implements Reflection Padding as a layer.
    Args:
        padding(tuple): Amount of padding for the
        spatial dimensions.
    Returns:
        A padded tensor with the same type as the input tensor.
    &quot;&quot;&quot;

    def __init__(self, padding=(1, 1), **kwargs):
        self.padding = tuple(padding)
        super(ReflectionPadding2D, self).__init__(**kwargs)

    def call(self, input_tensor, mask=None):
        padding_width, padding_height = self.padding
        padding_tensor = [
            [0, 0],
            [padding_height, padding_height],
            [padding_width, padding_width],
            [0, 0],
        ]
        return tf.pad(input_tensor, padding_tensor, mode=&quot;REFLECT&quot;)


def residual_block(
    x,
    activation,
    kernel_initializer=kernel_init,
    kernel_size=(3, 3),
    strides=(1, 1),
    padding=&quot;valid&quot;,
    gamma_initializer=gamma_init,
    use_bias=False,
):
    dim = x.shape[-1]
    input_tensor = x

    x = ReflectionPadding2D()(input_tensor)
    x = layers.Conv2D(
        dim,
        kernel_size,
        strides=strides,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    x = activation(x)

    x = ReflectionPadding2D()(x)
    x = layers.Conv2D(
        dim,
        kernel_size,
        strides=strides,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    x = layers.add([input_tensor, x])
    return x


def downsample(
    x,
    filters,
    activation,
    kernel_initializer=kernel_init,
    kernel_size=(3, 3),
    strides=(2, 2),
    padding=&quot;same&quot;,
    gamma_initializer=gamma_init,
    use_bias=False,
):
    x = layers.Conv2D(
        filters,
        kernel_size,
        strides=strides,
        kernel_initializer=kernel_initializer,
        padding=padding,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    if activation:
        x = activation(x)
    return x


def upsample(
    x,
    filters,
    activation,
    kernel_size=(3, 3),
    strides=(2, 2),
    padding=&quot;same&quot;,
    kernel_initializer=kernel_init,
    gamma_initializer=gamma_init,
    use_bias=False,
):
    x = layers.Conv2DTranspose(
        filters,
        kernel_size,
        strides=strides,
        padding=padding,
        kernel_initializer=kernel_initializer,
        use_bias=use_bias,
    )(x)
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    if activation:
        x = activation(x)
    return x




def get_resnet_generator(
    filters=64,
    num_downsampling_blocks=2,
    num_residual_blocks=9,
    num_upsample_blocks=2,
    gamma_initializer=gamma_init,
    name=None,
):
    img_input = layers.Input(shape=input_img_size, name=name + &quot;_img_input&quot;)
    x = ReflectionPadding2D(padding=(3, 3))(img_input)
    x = layers.Conv2D(filters, (7, 7), kernel_initializer=kernel_init, use_bias=False)(
        x
    )
    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)
    x = layers.Activation(&quot;relu&quot;)(x)

    # Downsampling
    for _ in range(num_downsampling_blocks):
        filters *= 2
        x = downsample(x, filters=filters, activation=layers.Activation(&quot;relu&quot;))

    # Residual blocks
    for _ in range(num_residual_blocks):
        x = residual_block(x, activation=layers.Activation(&quot;relu&quot;))

    # Upsampling
    for _ in range(num_upsample_blocks):
        filters //= 2
        x = upsample(x, filters, activation=layers.Activation(&quot;relu&quot;))

    # Final block
    x = ReflectionPadding2D(padding=(3, 3))(x)
    x = layers.Conv2D(3, (7, 7), padding=&quot;valid&quot;)(x)
    x = layers.Activation(&quot;tanh&quot;)(x)

    model = keras.models.Model(img_input, x, name=name)
    return model


&quot;&quot;&quot;
## Build the discriminators
The discriminators implement the following architecture:
`C64-&gt;C128-&gt;C256-&gt;C512`
&quot;&quot;&quot;

def get_discriminator(
    filters=64, kernel_initializer=kernel_init, num_downsampling=3, name=None
):
    img_input = layers.Input(shape=input_img_size, name=name + &quot;_img_input&quot;)
    x = layers.Conv2D(
        filters,
        (4, 4),
        strides=(2, 2),
        padding=&quot;same&quot;,
        kernel_initializer=kernel_initializer,
    )(img_input)
    x = layers.LeakyReLU(0.2)(x)

    num_filters = filters
    for num_downsample_block in range(3):
        num_filters *= 2
        if num_downsample_block &lt; 2:
            x = downsample(
                x,
                filters=num_filters,
                activation=layers.LeakyReLU(0.2),
                kernel_size=(4, 4),
                strides=(2, 2),
            )
        else:
            x = downsample(
                x,
                filters=num_filters,
                activation=layers.LeakyReLU(0.2),
                kernel_size=(4, 4),
                strides=(1, 1),
            )

    x = layers.Conv2D(
        1, (4, 4), strides=(1, 1), padding=&quot;same&quot;, kernel_initializer=kernel_initializer
    )(x)

    model = keras.models.Model(inputs=img_input, outputs=x, name=name)
    return model



&quot;&quot;&quot;
## Build the CycleGAN model
&quot;&quot;&quot;

class CycleGan(keras.Model):
    def __init__(
        self,
        generator_G,
        generator_F,
        discriminator_X,
        discriminator_Y,
        lambda_cycle=10.0,
        lambda_identity=0.5,
    ):
        super(CycleGan, self).__init__()
        self.gen_G = generator_G
        self.gen_F = generator_F
        self.disc_X = discriminator_X
        self.disc_Y = discriminator_Y
        self.lambda_cycle = lambda_cycle
        self.lambda_identity = lambda_identity

    def compile(
        self,
        gen_G_optimizer,
        gen_F_optimizer,
        disc_X_optimizer,
        disc_Y_optimizer,
        gen_loss_fn,
        disc_loss_fn,
        cycle_loss_fn,
        identity_loss_fn
    ):
        super(CycleGan, self).compile()
        self.gen_G_optimizer = gen_G_optimizer
        self.gen_F_optimizer = gen_F_optimizer
        self.disc_X_optimizer = disc_X_optimizer
        self.disc_Y_optimizer = disc_Y_optimizer
        self.generator_loss_fn = gen_loss_fn
        self.discriminator_loss_fn = disc_loss_fn
        #self.cycle_loss_fn = keras.losses.MeanAbsoluteError()
        #self.identity_loss_fn = keras.losses.MeanAbsoluteError()
        self.cycle_loss_fn = cycle_loss_fn
        self.identity_loss_fn = identity_loss_fn
        
    def train_step(self, batch_data):
        # x is Horse and y is zebra
        real_x, real_y = batch_data

        with tf.GradientTape(persistent=True) as tape:
            # Horse to fake zebra
            fake_y = self.gen_G(real_x, training=True)
            # Zebra to fake horse -&gt; y2x
            fake_x = self.gen_F(real_y, training=True)

            # Cycle (Horse to fake zebra to fake horse): x -&gt; y -&gt; x
            cycled_x = self.gen_F(fake_y, training=True)
            # Cycle (Zebra to fake horse to fake zebra) y -&gt; x -&gt; y
            cycled_y = self.gen_G(fake_x, training=True)

            # Identity mapping
            same_x = self.gen_F(real_x, training=True)
            same_y = self.gen_G(real_y, training=True)

            # Discriminator output
            disc_real_x = self.disc_X(real_x, training=True)
            disc_fake_x = self.disc_X(fake_x, training=True)

            disc_real_y = self.disc_Y(real_y, training=True)
            disc_fake_y = self.disc_Y(fake_y, training=True)

            # Generator adverserial loss
            gen_G_loss = self.generator_loss_fn(disc_fake_y)
            gen_F_loss = self.generator_loss_fn(disc_fake_x)

            # Generator cycle loss
            cycle_loss_G = self.cycle_loss_fn(real_y, cycled_y) * self.lambda_cycle
            cycle_loss_F = self.cycle_loss_fn(real_x, cycled_x) * self.lambda_cycle

            # Generator identity loss
            id_loss_G = (
                self.identity_loss_fn(real_y, same_y)
                * self.lambda_cycle
                * self.lambda_identity
            )
            id_loss_F = (
                self.identity_loss_fn(real_x, same_x)
                * self.lambda_cycle
                * self.lambda_identity
            )

            # Total generator loss
            total_loss_G = gen_G_loss + cycle_loss_G + id_loss_G
            total_loss_F = gen_F_loss + cycle_loss_F + id_loss_F

            # Discriminator loss
            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)
            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)

        # Get the gradients for the generators
        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)
        grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)

        # Get the gradients for the discriminators
        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)
        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)

        # Update the weights of the generators
        self.gen_G_optimizer.apply_gradients(
            zip(grads_G, self.gen_G.trainable_variables)
        )
        self.gen_F_optimizer.apply_gradients(
            zip(grads_F, self.gen_F.trainable_variables)
        )

        # Update the weights of the discriminators
        self.disc_X_optimizer.apply_gradients(
            zip(disc_X_grads, self.disc_X.trainable_variables)
        )
        self.disc_Y_optimizer.apply_gradients(
            zip(disc_Y_grads, self.disc_Y.trainable_variables)
        )

        return total_loss_G
        # return [total_loss_G, total_loss_F, disc_X_loss, disc_Y_loss]
        


# Open a strategy scope.
with strategy.scope():
   mae_loss_fn = keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)
    
    # Loss function for evaluating cycle consistency loss
    def cycle_loss_fn(real, cycled):
        cycle_loss = mae_loss_fn(real, cycled)
        cycle_loss = tf.nn.compute_average_loss(cycle_loss, global_batch_size=GLOBAL_BATCH_SIZE)
        return cycle_loss
         

    # Loss function for evaluating identity mapping loss
    def identity_loss_fn(real, same):
        identity_loss = mae_loss_fn(real, same)
        identity_loss = tf.nn.compute_average_loss(identity_loss, global_batch_size=GLOBAL_BATCH_SIZE)
        return identity_loss

    # Loss function for evaluating adversarial loss
    adv_loss_fn = keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)

    # Define the loss function for the generators
    def generator_loss_fn(fake):
        fake_loss = adv_loss_fn(tf.ones_like(fake), fake)
        fake_loss = tf.nn.compute_average_loss(fake_loss, global_batch_size=GLOBAL_BATCH_SIZE)
        return fake_loss


    # Define the loss function for the discriminators
    def discriminator_loss_fn(real, fake):
        real_loss = adv_loss_fn(tf.ones_like(real), real)
        fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)
        real_loss = tf.nn.compute_average_loss(real_loss, global_batch_size=GLOBAL_BATCH_SIZE)
        fake_loss = tf.nn.compute_average_loss(fake_loss, global_batch_size=GLOBAL_BATCH_SIZE)  
        return (real_loss + fake_loss) * 0.5

    # Get the generators
    gen_G = get_resnet_generator(name=&quot;generator_G&quot;)
    gen_F = get_resnet_generator(name=&quot;generator_F&quot;)

    # Get the discriminators
    disc_X = get_discriminator(name=&quot;discriminator_X&quot;)
    disc_Y = get_discriminator(name=&quot;discriminator_Y&quot;)



    # Create cycle gan model
    cycle_gan_model = CycleGan(
        generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y
    )
    optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)    
    # Compile the model
    cycle_gan_model.compile(
        gen_G_optimizer=optimizer,
        gen_F_optimizer=optimizer,
        disc_X_optimizer=optimizer,
        disc_Y_optimizer=optimizer,
        gen_loss_fn=generator_loss_fn,
        disc_loss_fn=discriminator_loss_fn,
        cycle_loss_fn=cycle_loss_fn,
        identity_loss_fn=identity_loss_fn
    )


train_dist_dataset = strategy.experimental_distribute_dataset(
    tf.data.Dataset.zip((train_horses, 
    train_zebras)))

# `run` replicates the provided computation and runs it
# with the distributed input.
@tf.function
def distributed_train_step(dataset_inputs):
  per_replica_losses = strategy.run(cycle_gan_model.train_step, args=(dataset_inputs,))
  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                         axis=None)

&quot;&quot;&quot;
## Train the end-to-end model
&quot;&quot;&quot;
for epoch in range(1):
    # TRAIN LOOP
    all_loss = 0.0
    num_batches = 0.0
    for one_batch in train_dist_dataset:
        all_loss +=  distributed_train_step(one_batch)
        num_batches += 1
    train_loss = all_loss/num_batches
    print(train_loss)
</code></pre>
",4755781.0,,4755781.0,,2021-03-19 17:52:12,2021-03-21 16:33:05,How to modify the Keras CycleGAN example code to run parallelly on GPUs using tf.strategy,<tensorflow><keras><parallel-processing><generative-adversarial-network><multi-gpu>,0,0,,,,CC BY-SA 4.0
65323657,1,,,2020-12-16 12:51:17,,5,382,"<p>The example code is as follows:</p>
<pre><code>import tensorflow as tf     # tf-2.4 or tf-2.x
from datetime import datetime

# Define a layer with an eager side effect
class EagerLayer(tf.keras.layers.Layer):
  def __init__(self, **kwargs):
    super(EagerLayer, self).__init__(**kwargs)
    # Do some kind of initialization here
    self.dense = tf.keras.layers.Dense(32)

  def call(self, inputs):
    print(&quot;\nCurrently running eagerly&quot;, str(datetime.now()))
    return self.dense(inputs)

input_data = tf.random.uniform([60, 28, 28])
layer = EagerLayer()
tf_func_layer = tf.function(layer)
print(&quot;=============&quot;)
_ = tf_func_layer(input_data)
</code></pre>
<p>The output is</p>
<pre><code>=============

Currently running eagerly 2020-12-16 20:46:38.482592

Currently running eagerly 2020-12-16 20:46:38.503605
</code></pre>
<p>The printing side effect shows up twice, which means the function is traced twice.</p>
<p>I am just wondering why the layer is traced twice.</p>
<p>A colab notebook can be found <a href=""https://colab.research.google.com/drive/1bXO9Ru0_GtE4GDcGlUD5UGBupQSuKZ8f?usp=sharing"" rel=""nofollow noreferrer"">here</a>.</p>
",7641937.0,,7641937.0,,2020-12-17 05:24:44,2022-05-14 23:20:11,Why tf.function traces layers twice?,<tensorflow><keras><tensorflow2.0><tf.keras>,2,5,0.0,,,CC BY-SA 4.0
63776452,1,63776652.0,,2020-09-07 11:11:07,,5,3941,"<p>I have a set of grayscale png images split over 2 directories. I have used image_dataset_from_directory to load them as a Dataset object, as per documentation. When I use element_spec to inspect what has been loaded, it says the images have 3 channels:</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras.preprocessing import image_dataset_from_directory
Dataset = image_dataset_from_directory('path/to/files')
Dataset.element_spec
</code></pre>
<p>Returns:</p>
<blockquote>
<p>Found 14000 files belonging to 2 classes.</p>
<p>(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))</p>
</blockquote>
<p>The images were saved as grayscale pngs using MATLAB, and I have confirmed that they are grayscale using the Linux command file:</p>
<pre><code>$ file path/to/files/class_1/file_1.png
</code></pre>
<blockquote>
<p>path/to/files/class_1/file_1.png: PNG image data, 256 x 256, 8-bit grayscale, non-interlaced</p>
</blockquote>
<h3>So now I either need to tell image_dataset_from_directory to load these files as grayscale, or I need to convert the 3-channel tensor Dataset object to a 1-channel tensor. How can I do either?</h3>
<p>Edit:</p>
<p>More information about the file on disk using identify (from ImageMagick):</p>
<pre><code>$ identify -verbose path/to/files/class_1/file_1.png
</code></pre>
<pre><code>Image: AI_Optrap/Samples/Set4/relaxed/HL60_normoxia_1_1.png
  Format: PNG (Portable Network Graphics)
  Mime type: image/png
  Class: PseudoClass
  Geometry: 256x256+0+0
  Units: Undefined
  Type: Grayscale
  Base type: Grayscale
  Endianess: Undefined
  Colorspace: Gray
  Depth: 8-bit
  Channel depth:
    gray: 8-bit
  Channel statistics:
    Pixels: 65536
    Gray:
      min: 0 (0)
      max: 255 (1)
      mean: 135.92 (0.533021)
      standard deviation: 36.3709 (0.142631)
      kurtosis: 1.51412
      skewness: 0.035325
      entropy: 0.87207
  Colors: 256
</code></pre>
",14234947.0,,14234947.0,,2020-09-07 11:22:37,2022-12-15 22:02:20,Loading grayscale pngs with image_dataset_from_directory returns a 3-channel tensor,<python><tensorflow><keras><png><tensorflow-datasets>,1,0,,,,CC BY-SA 4.0
67484449,1,,,2021-05-11 09:56:22,,5,4476,"<p>stream did not block host until done; was already in an error state how to fix it
using tensorflow keras</p>
<pre><code>model.compile(
optimizer=&quot;adam&quot;,
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
metrics=['acc'])    
model.fit(X_train_scaled, y_train, epochs=5)
</code></pre>
<p>this error appears</p>
<p><a href=""https://i.stack.imgur.com/XTU0e.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/XTU0e.png"" alt=""enter image description here"" /></a></p>
<p><a href=""https://i.stack.imgur.com/zIq9F.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/zIq9F.png"" alt=""enter image description here"" /></a></p>
",9743512.0,,,,,2021-07-08 05:26:26,InternalError: stream did not block host until done; was already in an error state,<python><tensorflow><keras><model-fitting>,1,2,,,,CC BY-SA 4.0
63989328,1,63990236.0,,2020-09-21 09:13:37,,5,3548,"<p>The keras Conv2D layer does not come with an activation function itself. I am currently rebuilding the YOLOv1 model for practicing. In the YOLOv1 model, there are several Conv2D layers followed by activations using the leaky relu function. Is there a way to combine</p>
<pre><code>from keras.layers import Conv2D, LeakyReLU

...

def model(input):
    ...

    X = Conv2D(filters, kernel_size)(X)
    X = LeakyReLU(X)

    ...
</code></pre>
<p>into a single line of code, like <code>X = conv_with_leaky_relu(X)</code>? I think it should be similar to</p>
<pre><code>def conv_with_leaky_relu(*args, **kwargs):
    X = Conv2D(*args, **kwargs)(X)
    X = LeakyReLU(X)
    return X
</code></pre>
<p>but this of course doesn't work because it is undefined what X ist. Any ideas?</p>
",12463491.0,,4685471.0,,2020-09-21 14:47:56,2022-10-25 17:19:54,Can I combine Conv2D and LeakyReLU into a single layer?,<python><tensorflow><keras><neural-network>,1,0,,,,CC BY-SA 4.0
64276472,1,,,2020-10-09 08:26:59,,5,13590,"<p>I am trying to use Transfer learning with VGG16. I am using Keras. But I got error on</p>
<pre><code>vgg = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 1))
</code></pre>
<p>Any help what is wrong ?</p>
<p>Note: <code>IMG_SIZE</code> = 200</p>
<p>The trace of error is</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-5-1b17094c93e2&gt; in &lt;module&gt;
      3 import keras
      4 
----&gt; 5 vgg = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 1))
      6 
      7 output = vgg.layers[-1].output

c:\users\hiteshsom\documents\deepanshu_q2\env\lib\site-packages\tensorflow\python\keras\applications\vgg16.py in VGG16(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)
    124                      ' as true, `classes` should be 1000')
    125   # Determine proper input shape
--&gt; 126   input_shape = imagenet_utils.obtain_input_shape(
    127       input_shape,
    128       default_size=224,

c:\users\hiteshsom\documents\deepanshu_q2\env\lib\site-packages\tensorflow\python\keras\applications\imagenet_utils.py in obtain_input_shape(input_shape, default_size, min_size, data_format, require_flatten, weights)
    363           raise ValueError('`input_shape` must be a tuple of three integers.')
    364         if input_shape[-1] != 3 and weights == 'imagenet':
--&gt; 365           raise ValueError('The input must have 3 channels; got '
    366                            '`input_shape=' + str(input_shape) + '`')
    367         if ((input_shape[0] is not None and input_shape[0] &lt; min_size) or

ValueError: The input must have 3 channels; got `input_shape=(200, 200, 1)`
</code></pre>
",5687866.0,,,,,2023-01-18 09:18:01,"ValueError: The input must have 3 channels; got `input_shape=(200, 200, 1)`",<tensorflow><keras><deep-learning><transfer-learning><vgg-net>,2,4,,,,CC BY-SA 4.0
65620186,1,65620420.0,,2021-01-07 21:28:23,,5,3877,"<p>When adding an <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay"" rel=""noreferrer""><code>ExponentialDecay</code></a> learning rate schedule to my <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"" rel=""noreferrer""><code>Adam</code></a> optimizer, it changed the training behavior even before it should become effective. I used the following definition for the schedule:</p>
<pre class=""lang-py prettyprint-override""><code>lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    1e-3, decay_steps=25, decay_rate=0.95, staircase=True)
</code></pre>
<p>Since I'm using <code>staircase=True</code>, there should be no difference for the first 25 epochs compared to using a static learning rate of the same value. So the following two optimizers should yield identical training results for the first 25 epochs:</p>
<pre class=""lang-py prettyprint-override""><code>optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)
</code></pre>
<p>However I observed that the behavior is different already before:</p>
<p><a href=""https://i.stack.imgur.com/6KhCL.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/6KhCL.png"" alt=""Example loss curve"" /></a></p>
<p>This is the test code I used:</p>
<pre class=""lang-py prettyprint-override""><code>import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, Dropout

np.random.seed(0)

x_data = 2*np.random.random(size=(1000, 1))
y_data = np.random.normal(loc=x_data**2, scale=0.05)

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    1e-3, decay_steps=25, decay_rate=0.95, staircase=True)

histories = []
learning_rates = [1e-3, lr_schedule]
for lr in learning_rates:
    tf.random.set_seed(0)

    model = tf.keras.models.Sequential([
        Dense(10, activation='tanh', input_dim=1), Dropout(0.2),
        Dense(10, activation='tanh'), Dropout(0.2),
        Dense(1)
    ])
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    model.compile(optimizer=optimizer, loss='mse')
    history = model.fit(x_data, y_data, epochs=50)
    histories.append(history.history['loss'])

fig, ax = plt.subplots()
ax.set(xlabel='Epoch', ylabel='Loss')
ax.plot(histories[0], label='Static learning rate')
ax.plot(histories[1], label='Learning rate schedule')
ax.legend()
plt.show()
</code></pre>
<p>I'm using Python 3.7.9 and the following install of Tensorflow:</p>
<pre class=""lang-none prettyprint-override""><code>$ conda list | grep tensorflow
tensorflow                2.1.0           mkl_py37h80a91df_0  
tensorflow-base           2.1.0           mkl_py37h6d63fb7_0  
tensorflow-estimator      2.1.0              pyhd54b08b_0
</code></pre>
",3767239.0,,,,,2021-12-15 10:01:36,ExponentialDecay learning rate schedule with 'staircase=True' changes the training behavior even before it should become effective,<python><tensorflow><machine-learning><keras>,2,0,,,,CC BY-SA 4.0
64474463,1,64477522.0,,2020-10-22 02:40:16,,5,8036,"<p>I want to implement the f1_score metric for tf.keras.</p>
<pre><code>from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.metrics import Accuracy, BinaryAccuracy
from sklearn.metrics import accuracy_score
import numpy as np
import tensorflow as tf

class F1_Score(tf.keras.metrics.Metric):

    def __init__(self, name='f1_score', **kwargs):
        super().__init__(name=name, **kwargs)
        self.f1 = self.add_weight(name='f1', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        p = Precision(thresholds=0.5)(y_true, y_pred)
        r = Recall(thresholds=0.5)(y_true, y_pred)
        self.f1 = 2 * ((p * r) / (p + r + 1e-6))

    def result(self):
        return self.f1

    def reset_states(self):
        self.f1.assign(0)
        
model = Sequential([
  Dense(64, activation='relu', input_shape=(784,)),
  Dense(64, activation='relu'),
  Dense(4, activation='sigmoid'),
])
x = np.random.normal(size=(10, 784))
y = np.random.choice(2, size=(10, 4))
model.compile(optimizer=Adam(0.001), loss='binary_crossentropy',
                  metrics=['accuracy', , F1_Score()])
model.fit(x[:1], y[:1], batch_size=1, epochs=1, verbose=1)
</code></pre>
<p>I got an error:</p>
<blockquote>
<p>ValueError: tf.function-decorated function tried to create variables
on non-first call.</p>
</blockquote>
",2130515.0,,6117017.0,,2022-11-06 15:45:51,2022-11-07 08:31:42,Custom f1_score metric in tensorflow,<tensorflow><machine-learning><keras><deep-learning><metrics>,3,0,,,,CC BY-SA 4.0
63034145,1,,,2020-07-22 12:24:55,,5,3330,"<p>I have this warning when running a keras multiple input model using functional API. The model works fine and without warnings when runing on single GPU. When I use <code>tf.distribute.MirroredStrategy</code> to use two GPUs the final result of the model is ok but I get the warning. I think this can lead to performance issues?</p>
<pre><code>tf.__version__ : 2.2.0
tf.keras.__version__ : 2.3.0-tf
NVIDIA-SMI 410.72       Driver Version: 410.72       CUDA Version: 10.1
</code></pre>
<p>The model I am generating is:</p>
<pre><code>def build_model_():

input_a_size = 200
input_b_size = 4
num_classes = 2
len_embedding = 100

mirrored_strategy = tf.distribute.MirroredStrategy(['/gpu:0', '/gpu:1'])

with mirrored_strategy.scope():

    input_a = Input(shape=(input_a_size,), name='input_a', dtype=np.uint8)
    input_b = Input(shape=(input_b_size,), name='input_b', dtype=np.float32)

    x = Embedding(len_embedding, 100)(input_a)
    x = Conv1D(32, 4, activation='relu')(x)
    x = Flatten()(x)
    branch_a = Dense(64, activation='relu')(x)

    x = Dense(32, activation='relu')(input_b)
    branch_b = Dense(32, activation='relu')(x)

    concat = Concatenate()([
                            branch_a,
                            branch_b,
                           ])

    x = Dense(256, activation = 'relu')(concat)
    output = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=[
                          input_a,
                          input_b,
                         ],
                  outputs=[output])
        
    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

model.summary()

return model
</code></pre>
<p>Model summary:</p>
<pre><code>INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
Model: &quot;model&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_a (InputLayer)            [(None, 200)]        0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 200, 100)     10000       input_a[0][0]                    
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 197, 128)     51328       embedding[0][0]                  
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 49, 128)      0           conv1d[0][0]                     
__________________________________________________________________________________________________
input_b (InputLayer)            [(None, 4)]          0                                            
__________________________________________________________________________________________________
flatten (Flatten)               (None, 6272)         0           max_pooling1d[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 32)           160         input_b[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 64)           401472      flatten[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 32)           1056        dense_1[0][0]                    
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 96)           0           dense[0][0]                      
                                                                 dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          24832       concatenate[0][0]                
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 2)            514         dense_3[0][0]                    
==================================================================================================
Total params: 489,362
Trainable params: 489,362
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre>
<p>The way I am generating the inputs:</p>
<pre><code>input_a_train.shape: (35000, 200)
input_b_train.shape: (35000, 4)
y_train.shape: (35000, 2)

train_dataset = tf.data.Dataset.from_tensor_slices(({
                                                     &quot;input_a&quot;: input_a_train,
                                                     &quot;input_b&quot;: input_b_train,
                                                     }, y_train))
&lt;TensorSliceDataset shapes: ({input_a: (200,), input_b: (4,)}, (2,)), types: ({input_a: tf.uint8, input_b: tf.float64}, tf.float32)&gt;

val_dataset = tf.data.Dataset.from_tensor_slices(({
                                                     &quot;input_a&quot;: input_a_val,
                                                     &quot;input_b&quot;: input_b_val,
                                                     }, y_val))
&lt;TensorSliceDataset shapes: ({input_a: (200,), input_b: (4,)}, (2,)), types: ({input_a: tf.uint8, input_b: tf.float64}, tf.float32)&gt;

train_batches = train_dataset.padded_batch(128)
val_batches = val_dataset.padded_batch(128)
</code></pre>
<p>I get the warning during the training phase,</p>
<pre><code>history = my_model.fit(
    x = train_batches,
    epochs=3,
    verbose = 1,
    validation_data = val_batches,
)
</code></pre>
<p>Here is the output:</p>
<pre><code>Epoch 1/3
INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1
WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 12 all-reduces with algorithm = nccl, num_packs = 1
WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
274/274 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9324
...
</code></pre>
<p>There is a similar question here: <a href=""https://stackoverflow.com/questions/56843876/efficient-allreduce-is-not-supported-for-2-indexedslices"">Efficient allreduce is not supported for 2 IndexedSlices</a> but it has no answers.</p>
<p><strong>EDIT 1 (31/7/2020)</strong></p>
<p>Implemented custom training loop as described in this guides:</p>
<p><a href=""https://www.tensorflow.org/tutorials/distribute/custom_training"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/distribute/custom_training</a></p>
<p><a href=""https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops</a></p>
<p><a href=""https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough</a></p>
<p><a href=""https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch</a></p>
<p>Same warning, and same behaviour on multiple GPUs. Performance decreases while I increase number of GPUs. Training on 1 GPU is faster than training in 2 GPUs, with worst case using 8 GPUs.
I thought the problem could be in the keras.model.fit method, but no.
My guess is a problem on the input data format for multi-input keras using functional api model.</p>
",11524722.0,,11524722.0,,2020-07-31 12:30:33,2020-08-06 13:03:14,WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices,<python><tensorflow><keras><gpu>,1,1,0.0,,,CC BY-SA 4.0
64990551,1,,,2020-11-24 16:21:09,,5,3059,"<p>I got an error of ValueError: Input tensors to a Functional must come from <code>tf.keras.Input</code>. Received: 0 (missing previous layer metadata) and i cant find the cause</p>
<p>this is my error trace and my code</p>
<pre><code>    ---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-15-8058f3a2fd50&gt; in &lt;module&gt;()
      6   test_loss, test_accuracy = eg.test(dg.user_test)
      7   print('Test set: Loss=%.4f ; Accuracy=%.1f%%' % (test_loss, test_accuracy * 100))
----&gt; 8   eg.save_embeddings('embeddings.csv')

7 frames
&lt;ipython-input-5-54ff9897b1c3&gt; in save_embeddings(self, file_name)
     66     inp = self.m.input                                           # input placeholder
     67     outputs = [layer.output for layer in self.m.layers]          # all layer outputs
---&gt; 68     functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function
     69 
     70     #append embeddings to vectors

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in function(inputs, outputs, updates, name, **kwargs)
   3934     from tensorflow.python.keras import models  # pylint: disable=g-import-not-at-top
   3935     from tensorflow.python.keras.utils import tf_utils  # pylint: disable=g-import-not-at-top
-&gt; 3936     model = models.Model(inputs=inputs, outputs=outputs)
   3937 
   3938     wrap_outputs = isinstance(outputs, list) and len(outputs) == 1

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in __new__(cls, *args, **kwargs)
    240       # Functional model
    241       from tensorflow.python.keras.engine import functional  # pylint: disable=g-import-not-at-top
--&gt; 242       return functional.Functional(*args, **kwargs)
    243     else:
    244       return super(Model, cls).__new__(cls, *args, **kwargs)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--&gt; 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in __init__(self, inputs, outputs, name, trainable)
    113     #     'arguments during initialization. Got an unexpected argument:')
    114     super(Functional, self).__init__(name=name, trainable=trainable)
--&gt; 115     self._init_graph_network(inputs, outputs)
    116 
    117   @trackable.no_automatic_dependency_tracking

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--&gt; 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _init_graph_network(self, inputs, outputs)
    142       base_layer_utils.create_keras_history(self._nested_outputs)
    143 
--&gt; 144     self._validate_graph_inputs_and_outputs()
    145 
    146     # A Network does not create weights of its own, thus it is already

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in _validate_graph_inputs_and_outputs(self)
    637                          'must come from `tf.keras.Input`. '
    638                          'Received: ' + str(x) +
--&gt; 639                          ' (missing previous layer metadata).')
    640       # Check that x is an input tensor.
    641       # pylint: disable=protected-access

ValueError: Input tensors to a Functional must come from `tf.keras.Input`. Received: 0 (missing previous layer metadata).
</code></pre>
<p>and this is my snipped code:</p>
<pre><code>class EmbeddingsGenerator:
  def  __init__(self, train_users, data):
    self.train_users = train_users

    #preprocess
    self.data = data.sort_values(by=['timestamp'])
    #make them start at 0
    self.data['userId'] = self.data['userId'] - 1
    self.data['itemId'] = self.data['itemId'] - 1
    self.user_count = self.data['userId'].max() + 1
    self.movie_count = self.data['itemId'].max() + 1
    self.user_movies = {} #list of rated movies by each user
    for userId in range(self.user_count):
      self.user_movies[userId] = self.data[self.data.userId == userId]['itemId'].tolist()
    self.m = self.model()

  def model(self, hidden_layer_size=100):
    m = Sequential()
    m.add(Dense(hidden_layer_size, input_shape=(1, self.movie_count)))
    m.add(Dropout(0.2))
    m.add(Dense(self.movie_count, activation='softmax'))
    m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return m
  
  def generate_input(self, user_id):
    '''
    Returns a context and a target for the user_id
    context: user's history with one random movie removed
    target: id of random removed movie
    '''
    user_movies_count = len(self.user_movies[user_id])
    #picking random movie
    random_index = np.random.randint(0, user_movies_count-1) # -1 avoids taking the last movie
    #setting target
    target = np.zeros((1, self.movie_count))
    target[0][self.user_movies[user_id][random_index]] = 1
    #setting context
    context = np.zeros((1, self.movie_count))
    context[0][self.user_movies[user_id][:random_index] + self.user_movies[user_id][random_index+1:]] = 1
    return context, target

  def train(self, nb_epochs = 300, batch_size = 10000):
    '''
    Trains the model from train_users's history
    '''
    for i in range(nb_epochs):
      print('%d/%d' % (i+1, nb_epochs))
      batch = [self.generate_input(user_id=np.random.choice(self.train_users) - 1) for _ in range(batch_size)]
      X_train = np.array([b[0] for b in batch])
      y_train = np.array([b[1] for b in batch])
      self.m.fit(X_train, y_train, epochs=1, validation_split=0.5)

  def test(self, test_users, batch_size = 100000):
    '''
    Returns [loss, accuracy] on the test set
    '''
    batch_test = [self.generate_input(user_id=np.random.choice(test_users) - 1) for _ in range(batch_size)]
    X_test = np.array([b[0] for b in batch_test])
    y_test = np.array([b[1] for b in batch_test])
    return self.m.evaluate(X_test, y_test)

  def save_embeddings(self, file_name):
    '''
    Generates a csv file containg the vector embedding for each movie.
    '''
    inp = self.m.input                                           # input placeholder
    outputs = [layer.output for layer in self.m.layers]          # all layer outputs
    functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function

    #append embeddings to vectors
    vectors = []
    for movie_id in range(self.movie_count):
      movie = np.zeros((1, 1, self.movie_count))
      movie[0][0][movie_id] = 1
      layer_outs = functor([movie])
      vector = [str(v) for v in layer_outs[0][0][0]]
      vector = '|'.join(vector)
      vectors.append([movie_id, vector])

    #saves as a csv file
    embeddings = pd.DataFrame(vectors, columns=['item_id', 'vectors']).astype({'item_id': 'int32'})
    embeddings.to_csv(file_name, sep=';', index=False)
    files.download(file_name)
</code></pre>
<p>this is the part of code which call the save_embeddings method</p>
<pre><code>if True: # Generate embeddings?
  eg = EmbeddingsGenerator(dg.user_train, pd.read_csv('ml-100k/u.data', sep='\t', names=['userId', 'itemId', 'rating', 'timestamp']))
  eg.train(nb_epochs=300)
  train_loss, train_accuracy = eg.test(dg.user_train)
  print('Train set: Loss=%.4f ; Accuracy=%.1f%%' % (train_loss, train_accuracy * 100))
  test_loss, test_accuracy = eg.test(dg.user_test)
  print('Test set: Loss=%.4f ; Accuracy=%.1f%%' % (test_loss, test_accuracy * 100))
  eg.save_embeddings('embeddings.csv')
</code></pre>
",13433275.0,,,,,2021-08-29 10:10:04,Input tensors to a Functional must come from `tf.keras.Input`. Received: 0 (missing previous layer metadata) and cant find the cause,<python><tensorflow><keras>,0,1,,,,CC BY-SA 4.0
64130293,1,64132995.0,,2020-09-30 03:10:14,,5,2203,"<p>I am trying to train an Autoencoder with a custom loss function shown below. The input, missing_matrix, is an n x m array of 1s and 0s corresponding to the n x m features array.  I need to do an element by element multiplication of the missing_array with y_pred, which should be a reconstruction of the input features so that I can mask those that get multiplied by 0 to neglect their contribution in the cost function.  I have never written a custom loss function before, the one below doesn't work at all.  I have tried to search for similar custom cost functions but haven't been able to find one that brings in some input array like this.  I would appreciate the help or a point in the right direction.</p>
<pre><code>def custom_loss(missing_array):
    
    def missing_mse(y_true, y_pred):
        mse = MeanSquaredError()
        y_pred_masked = tf.math.multiply(y_pred, missing_array)
        return mse(y_true = y_true, y_pred = y_pred_masked)

    return missing_mse
</code></pre>
<p>Edit:  Got a bit further</p>
<pre><code>from keras.losses import MeanSquaredError
import tensorflow as tf

def custom_loss(missing_matrix):
    
    def missing_mse(y_true, y_pred):
        mse = MeanSquaredError()
        y_pred_masked = tf.math.multiply(y_pred, tf.convert_to_tensor(missing_matrix, dtype=tf.float32))
        return mse(y_true = y_true, y_pred = y_pred_masked)

    return missing_mse
</code></pre>
<p>with error</p>
<pre><code>InvalidArgumentError:  Incompatible shapes: [64,1455] vs. [13580,1455]
     [[node gradient_tape/missing_mse/BroadcastGradientArgs (defined at &lt;ipython-input-454-b60d74568bf2&gt;:64) ]] [Op:__inference_train_function_25950]

Function call stack:
train_function
</code></pre>
<p>The 64 makes me think it is the batch.  Likely I need to take batches of 64 of my missing matrix?</p>
<p>Edit2:  This is fun!  So I verified that the custom loss function will train if I do something like</p>
<pre><code>def train(self, model, X_train):
        &quot;&quot;&quot;
        Model training
        &quot;&quot;&quot;
        #model.fit(X_train, X_train, epochs = 10, batch_size = 64, validation_split = 0.10)
        for batch_idx in range(0, len(X_train), 70):
            self.batch_start = batch_idx
            self.batch_end = batch_idx + 70
            model.train_on_batch(X_train[self.batch_start:self.batch_end,:], X_train[self.batch_start:self.batch_end,:])
        return model
</code></pre>
<p>and modify my custom loss</p>
<pre><code>def custom_loss2(self, missing_matrix):
    
        def missing_mse(y_true, y_pred):
            mse = MeanSquaredError()
            y_pred_masked = tf.math.multiply(y_pred, tf.convert_to_tensor(missing_matrix[self.batch_start:self.batch_end,:], dtype=tf.float32))
            return mse(y_true = y_true[self.batch_start:self.batch_end,:], y_pred = y_pred_masked[self.batch_start:self.batch_end,:])

        return missing_mse
</code></pre>
<p>So now how can I get epochs and print out validation loss etc...?  Or rather what is the better way to do this?  Thats it for me tonight.  Goodnight!</p>
",1731970.0,,10375049.0,,2021-10-15 22:07:19,2021-10-15 22:07:19,custom loss function in Keras with masking array as input,<python><tensorflow><machine-learning><keras><deep-learning>,1,0,,,,CC BY-SA 4.0
64539144,1,64541118.0,,2020-10-26 14:31:31,,5,5445,"<p>Using the Tensorflow <a href=""https://www.tensorflow.org/tutorials/images/cnn"" rel=""noreferrer"">CIFAR CNN demonstration</a>, I verified that my TF was properly using my GPU. TF used the GPU to run model.fit(), and it saw about 50% usage in HWiNFO64. However, if I then add this cell to the notebook, which uses the model to predict the label of images in the test set:</p>
<pre><code>import numpy as np
for img in test_images:
    prediction = model.predict(np.expand_dims(img, axis=0)) # Here
    print(class_names[np.argmax(prediction)])
</code></pre>
<p>I see only 1% GPU usage (which is used by Chrome and other processes). Is there a way for me to run model.predict() on a GPU, or are there any alternatives where I can have a model output for a single input?</p>
",12521633.0,,,,,2020-10-26 16:26:07,How to use GPU to run Keras Model.Predict(),<python><tensorflow><keras><tensorflow2.0>,1,4,,,,CC BY-SA 4.0
63365653,1,63390189.0,,2020-08-11 20:07:38,,5,1241,"<p>Some notes: I'm using tensorflow 2.3.0, python 3.8.2, and numpy 1.18.5 (not sure if that one matters though)</p>
<p>I'm writing a custom layer that stores a non-trainable tensor N of shape (a, b) internally, where a, b are known values (this tensor is created during init). When called on an input tensor, it flattens the input tensor, flattens its stored tensor, and concatenates the two together. Unfortunately, I can't seem to figure out how to preserve the unknown batch dimension during this concatenation. Here's minimal code:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.layers import Layer, Flatten

class CustomLayer(Layer):
   def __init__(self, N):                     # N is a tensor of shape (a, b), where a, b &gt; 1
      super(CustomLayer, self).__init__()
      self.N = self.add_weight(name=&quot;N&quot;, shape=N.shape, trainable=False, initializer=lambda *args, **kwargs: N)

      # correct me if I'm wrong in using this initializer approach, but for some reason, when I
      # just do self.N = N, this variable would disappear when I saved and loaded the model

   def build(self, input_shape):
      pass                                    # my reasoning is that all the necessary stuff is handled in init

   def call(self, input_tensor):
      input_flattened = Flatten()(input_tensor)
      N_flattened = Flatten()(self.N)
      return tf.concat((input_flattened, N_flattened), axis=-1)
</code></pre>
<p>The first problem I noticed was that <code>Flatten()(self.N)</code> would return a tensor with the same shape (a, b) as the original <code>self.N</code>, and as a result, the returned value would have a shape of (a, num_input_tensor_values+b). My reasoning for this was that the first dimension, a, was treated as the batch size. I modified the <code>call</code> function:</p>
<pre><code>   def call(self, input_tensor):
      input_flattened = Flatten()(input_tensor)
      N = tf.expand_dims(self.N, axis=0)       # N would now be shape (1, a, b)
      N_flattened = Flatten()(N)
      return tf.concat((input_flattened, N_flattened), axis=-1)
</code></pre>
<p>This would return a tensor with shape (1, num_input_vals + a*b), which is great, but now the batch dimension is permanently 1, which I realized when I started training a model with this layer and it would only work for a batch size of 1. This is also really apparent in the model summary - if I were to put this layer after an input and add some other layers afterwards, the first dimension of the output tensors goes like <code>None, 1, 1, 1, 1...</code>. Is there a way to store this internal tensor and use it in <code>call</code> while preserving the variable batch size? (For example, with a batch size of 4, a copy of the same flattened N would be concatenated onto the end of each of the 4 flattened input tensors.)</p>
",13810097.0,,13810097.0,,2020-08-12 15:04:15,2020-08-13 07:29:56,Preserving unknown batch dimension for custom static tensors in Tensorflow,<python><tensorflow><keras>,1,2,,,,CC BY-SA 4.0
64128947,1,,,2020-09-29 23:26:05,,5,1246,"<p>I have written a custom keras callback to check the augmented data from a generator. (See <a href=""https://stackoverflow.com/a/63910397/1295595"">this answer</a> for the full code.) However, when I tried to use the same callback for a <code>tf.data.Dataset</code>, it gave me an error:</p>
<pre><code>  File &quot;/path/to/tensorflow_image_callback.py&quot;, line 16, in on_batch_end
imgs = self.train[batch][images_or_labels]
TypeError: 'PrefetchDataset' object is not subscriptable
</code></pre>
<p>Do keras callbacks in general only work with generators, or is it something about the way I've written my one? Is there a way to modify either my callback or the dataset to make it work?</p>
<p>I think there are three pieces to this puzzle. I'm open to changes to any and all of them. Firstly, the init function in the custom callback class:</p>
<pre><code>class TensorBoardImage(tf.keras.callbacks.Callback):
    def __init__(self, logdir, train, validation=None):
        super(TensorBoardImage, self).__init__()
        self.logdir = logdir
        self.file_writer = tf.summary.create_file_writer(logdir)
        self.train = train
        self.validation = validation
</code></pre>
<p>Secondly, the <code>on_batch_end</code> function within that same class</p>
<pre><code>def on_batch_end(self, batch, logs):
    images_or_labels = 0 #0=images, 1=labels
    imgs = self.train[batch][images_or_labels]
</code></pre>
<p>Thirdly, instantiating the callback</p>
<pre><code>import tensorflow_image_callback
tensorboard_image_callback = tensorflow_image_callback.TensorBoardImage(logdir=tensorboard_log_dir, train=train_dataset, validation=valid_dataset)
model.fit(train_dataset,
          epochs=n_epochs,
          validation_data=valid_dataset, 
          callbacks=[
                    tensorboard_callback,
                    tensorboard_image_callback
                    ])
</code></pre>
<p>Some related threads which haven't led me to an answer yet:</p>
<p><a href=""https://stackoverflow.com/questions/47676248/accessing-validation-data-within-a-custom-callback"">Accessing validation data within a custom callback</a></p>
<p><a href=""https://stackoverflow.com/questions/47079111/create-keras-callback-to-save-model-predictions-and-targets-for-each-batch-durin/59697739#59697739"">Create keras callback to save model predictions and targets for each batch during training</a></p>
",1295595.0,,,,,2021-06-15 01:09:45,how to access tf.data.Dataset within a keras custom callback?,<python><tensorflow><keras><callback><tf.data.dataset>,1,1,,,,CC BY-SA 4.0
70369851,1,,,2021-12-15 20:21:32,,5,3726,"<p>I'm struggling to install Spyder (5.1.5) after installing Keras and Tensorflow.</p>
<p>Here are the steps I have taken so far:</p>
<ol>
<li>Install Anaconda</li>
<li>Within Anaconda Navigator create a new environment named 'tensorflow'</li>
<li>Install tensorflow and keras within Anaconda Navigator in the 'tensorflow' environment.</li>
<li>attempt to install Spyder from Anaconda Navigator in the 'tensorflow' environment. I get the following error message when I do this:</li>
</ol>
<p>'spyder cannot be installed on this environment. Do you want to install the package in an existing environment or create a new environment?'</p>
<p>The other thing I've tried, from the Anaconda prompt:</p>
<ol>
<li>conda activate tensorflow (activate tensorflow environment)</li>
<li>conda install spyder</li>
</ol>
<p>I get the following error:</p>
<p>Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: -
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.</p>
<p>Thanks for any help!</p>
",17686420.0,,,,,2022-05-22 07:19:28,Can't install Spyder after installing Tensorflow and Keras,<python><tensorflow><keras><anaconda><spyder>,3,3,0.0,,,CC BY-SA 4.0
69477169,1,69550674.0,,2021-10-07 07:38:50,,5,522,"<p>I am training 2 autoencoders with 2 separate input paths jointly and I would like to randomly set one of the input paths to zero.</p>
<p>I use tensorflow with keras backend (functional API).</p>
<p>I am computing a joint loss (sum of two losses) for backpropagation.</p>
<p>A -&gt; A' &amp; B -&gt;B'</p>
<p>loss =&gt; l2(A,A')+l2(B,B')</p>
<p>networks taking A and B are connected in latent space.
I would like to randomly set A or B to zero and compute the loss only on the corresponding path, meaning if input path A is set to zero loss be computed only by using outputs of only path B and vice versa; e.g.:</p>
<p>0 -&gt; A' &amp; B -&gt;B'</p>
<p>loss: l2(B,B')</p>
<p>How do I randomly set input path to zero? How do I write a callback which does this?</p>
",7815941.0,,9657861.0,,2021-12-02 08:17:38,2021-12-02 08:17:38,How to randomly set inputs to zero in keras during training autoencoder (callback)?,<python><tensorflow><keras><deep-learning><autoencoder>,2,2,0.0,,,CC BY-SA 4.0
73636196,1,73679598.0,,2022-09-07 13:14:12,,5,697,"<p>I use <code>MultiHeadAttention</code> layer in my transformer model (my model is very similar to the named entity recognition models). Because my data comes with different lengths, I use padding and <code>attention_mask</code> parameter in <code>MultiHeadAttention</code> to mask padding. If I would use the <code>Masking</code> layer before <code>MultiHeadAttention</code>, will it have the same effect as <code>attention_mask</code> parameter? Or should I use both: <code>attention_mask</code> and <code>Masking</code> layer?</p>
",8973620.0,,8973620.0,,2022-09-12 09:01:29,2022-09-18 18:45:19,Masking layer vs attention_mask parameter in MultiHeadAttention,<python><tensorflow><keras><transformer-model>,2,0,,,,CC BY-SA 4.0
69491795,1,69498829.0,,2021-10-08 07:03:47,,5,1048,"<p>I know this is one of the popular questions, but none of the solutions worked for me, so far.</p>
<p>I'm running a legacy code that is written in <code>tensorflow v1.13.1</code> and <code>keras v2.2.4</code>. I cannot modify the code to run latest tensorflow version. Since keras has now been merged into tensorflow, I'm facing problems installing the specific versions of tensorflow and keras via pip. I found that anaconda has option to install keras and tensorflow with the above version. So, I installed it with</p>
<pre><code>conda install -c conda-forge keras-gpu=2.2.4 tensorflow-gpu=1.13.1
</code></pre>
<p>It installed the version and all works too. But it doesn't use GPU, and instead runs on CPU. I noticed that anaconda installed both CPU and GPU versions of tensorflow and I guess this is why it is defaulting to CPU version. So, my question is, how can I force it to use GPU version?</p>
<p>PS: There are many answers out there that suggest to remove CPU version of tensorflow. But when I try to remove CPU version, conda uninstalls everything including keras. So, I assume there should be a way to use tensorflow-gpu when both of them are installed. Any help in this regard is appreciated!</p>
",3337089.0,,,,,2021-10-08 16:10:49,How to force keras to use tensorflow GPU backend,<python><tensorflow><keras>,2,4,,,,CC BY-SA 4.0
70535072,1,,,2021-12-30 17:51:39,,5,485,"<p>I am using a pre-trained model to train an image classifier. Below Code is running fine on CPU and single unit GPU (i.e. when #GPU=1)</p>
<pre><code>class Metrics(tf.keras.callbacks.Callback):
    def __init__(self, train_tf_data, val_tf_data, CLASSES, logs={}, **kwargs):
        super().__init__(**kwargs)
        # self.keras_metric = tf.keras.metrics.Mean(&quot;val_f1_after_epoch&quot;)
        self.train_tf_data = train_tf_data
        self.val_tf_data = val_tf_data
        # self.model = model
        self.CLASSES = CLASSES

    def on_epoch_end(self, epoch, logs={}):
        # self.keras_metric.reset_state()
        # for train data
        self.train_reports = test_model(model=self.model, data=self.train_tf_data, CLASSES=self.CLASSES)
        self.train_f1_after_epoch = self.train_reports['f1_score']
        self.train_recall_after_epoch = self.train_reports['recall']
        self.train_prec_after_epoch = self.train_reports['precision']

        # for val data
        self.val_reports = test_model(model=self.model, data=self.val_tf_data, CLASSES=self.CLASSES)
        self.val_f1_after_epoch = self.val_reports['f1_score']
        self.val_recall_after_epoch = self.val_reports['recall']
        self.val_prec_after_epoch = self.val_reports['precision']

        # saving train results to log dir
        logs[&quot;f1_after_epoch&quot;]=self.train_f1_after_epoch
        logs['precision_after_epoch'] = self.train_prec_after_epoch
        logs['recall_after_epoch'] = self.train_recall_after_epoch
        
        # saving val results to log dir
        logs['val_f1_after_epoch'] = self.val_f1_after_epoch
        logs['val_precision_after_epoch'] = self.val_prec_after_epoch
        logs['val_recall_after_epoch'] = self.val_recall_after_epoch
        # self.keras_metric.update_state(self.val_f1_after_epoch)

        print('reports_after_epoch', self.train_reports)
        print('val_reports_after_epoch', self.val_reports)
        



with strategy.scope():
    pretrained_model = tf.keras.applications.MobileNetV2(
                                                    weights='imagenet',
                                                    include_top=False,
                                                    input_shape=[*IMAGE_SIZE, IMG_CHANNELS])
    pretrained_model.trainable = True #fine tuning
    q_aware_pretrained_model = tf.keras.models.clone_model(pretrained_model,
                                                          clone_function=apply_quantization_to_dense,)
    base_model = tf.keras.Sequential([
                            tf.keras.layers.Lambda(# Convert image from int[0, 255] to the format expect by this base_model
                            lambda data:tf.keras.applications.mobilenet.preprocess_input(
                                tf.cast(data, tf.float32)), input_shape=[*IMAGE_SIZE, 3]),
                            q_aware_pretrained_model,
                            tf.keras.layers.GlobalAveragePooling2D()])
    base_model.layers[1]._name = 'custom_mnet_trainable'
    base_model.add(tf.keras.layers.Dense(64, name='object_dense',kernel_regularizer=tf.keras.regularizers.l2(l2=0.1)))
    base_model.add(tf.keras.layers.BatchNormalization(scale=False, center = False))
    base_model.add(tf.keras.layers.Activation('relu', name='relu_dense_64'))
    base_model.add(tf.keras.layers.Dropout(rate=0.5, name='dropout_dense_64'))
    base_model.add(tf.keras.layers.Dense(32, name='object_dense_2',kernel_regularizer=tf.keras.regularizers.l2(l2=0.1)))
    base_model.add(tf.keras.layers.BatchNormalization(scale=False, center = False))
    base_model.add(tf.keras.layers.Activation('relu', name='relu_dense_32'))
    base_model.add(tf.keras.layers.Dropout(rate=0.4, name='dropout_dense_32'))
    base_model.add(tf.keras.layers.Dense(16, name='object_dense_16', kernel_regularizer=tf.keras.regularizers.l2(l2=0.1)))
    base_model.add(tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax', name='object_prob'))
    m1 = tf.keras.metrics.CategoricalAccuracy()
    m2 = tf.keras.metrics.Recall()
    m3 = tf.keras.metrics.Precision()

    m4 = Metrics(train_tf_data=train_data, val_tf_data=test_data, CLASSES=CLASS_NAMES)


    optimizers = [
        tfa.optimizers.AdamW(learning_rate=lr * .001 , weight_decay=wd),
        tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)
            ]

    optimizers_and_layers = [(optimizers[0], base_model.layers[0]), (optimizers[1], base_model.layers[1:])]

    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)

    annotated_model = tf.keras.models.clone_model(
        base_model,
        clone_function=apply_quantization_to_dense,
    )


    model = tfmot.quantization.keras.quantize_apply(annotated_model)
    model.compile(
        optimizer= optimizer, loss=tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.AUTO),
        metrics=[m1, m2, m3],
        )

tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)

checkpoint_name = os.getcwd() + os.sep + CUSTOM_MODEL_PATH + os.sep + &quot;training_chkpts/cp-{epoch:04d}-{val_f1_after_epoch:.2f}.ckpt&quot;
checkpoint_dir_path  = os.getcwd() + os.sep + CUSTOM_MODEL_PATH + os.sep+ &quot;training_chkpts&quot;
checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_name, 
                                                    monitor = 'val_f1_after_epoch',
                                                    save_best_only=True,
                                                    save_weights_only=True,
                                                    mode='max',
                                                    save_freq='epoch',
                                                    verbose=1)

checkpoint_cb._supports_tf_logs = False
current_dir = os.getcwd()
history = model.fit(train_data, validation_data=test_data, 
                    epochs=N_EPOCHS,
                    callbacks=[m4, checkpoint_cb, tensorboard_cb])
</code></pre>
<p><strong>But If I use a system when the number of GPU &gt; 1 then it is throwing the below error.</strong></p>
<p>Epoch 1/2
6/Unknown - 44s 150ms/step - loss: 19.2255 - categorical_accuracy: 0.0625 - recall: 0.0000e+00 - precision: 0.0000e+00</p>
<p>/bwz_venv/lib/python3.8/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
layer_config = serialize_layer_fn(layer)
288/Unknown - 84s 141ms/step - loss: 13.7873 - categorical_accuracy: 0.1788 - recall: 0.0080 - precision: 0.77082021-12-30 15:08:31.404434: W tensorflow/core/framework/op_kernel.cc:1745] <strong>OP_REQUIRES failed at transpose_op.cc:142 : INVALID_ARGUMENT: transpose expects a vector of size 0. But input(1) is a vector of size 4</strong></p>
<p>Traceback (most recent call last):
File &quot;/usr/lib/python3.8/runpy.py&quot;, line 194, in _run_module_as_main
return _run_code(code, main_globals, None,
File &quot;/usr/lib/python3.8/runpy.py&quot;, line 87, in _run_code
exec(code, run_globals)
File &quot;/ssd/custom_mnet_v2.py&quot;, line 536, in 
history = model.fit(train_data, validation_data=test_data,
File &quot;bwz_venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py&quot;, line 67, in error_handler
raise e.with_traceback(filtered_tb) from None
File &quot;/bwz_venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py&quot;, line 58, in quick_execute
tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.</p>
<p>(0) <strong>INVALID_ARGUMENT:  transpose expects a vector of size 0. But input(1) is a vector of size 4</strong>
[[{{node gradient_tape/replica_1/sequential/custom_mnet_trainable/Conv1/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]
[[div_no_nan_3/ReadVariableOp/_558]]</p>
<p>(1) <strong>INVALID_ARGUMENT:  transpose expects a vector of size 0. But input(1) is a vector of size 4</strong>
[[{{node gradient_tape/replica_1/sequential/custom_mnet_trainable/Conv1/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]
[[assert_less_equal/Assert/AssertGuard/else/_4049/assert_less_equal/Assert/AssertGuard/Assert/data_4/_546]]</p>
<p><strong>(2) INVALID_ARGUMENT:  transpose expects a vector of size 0. But input(1) is a vector of size 4</strong>
[[{{node gradient_tape/replica_1/sequential/custom_mnet_trainable/Conv1/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_1079980]</p>
<p>Function call stack:
train_function -&gt; train_function -&gt; train_function</p>
<p>Few things that I have already tested</p>
<ol>
<li>Tried out different metrics (categorical_accuracy) to check whether the issue is realted to the custom monitoring metrics or not.</li>
<li>Run the code in CPU and single GPU enviroment and it is working perfectly fine</li>
</ol>
<p><a href=""https://colab.research.google.com/drive/1n9MmaLKZORa0vQvluQcY3t-VuX-yiSxf?usp=sharing"" rel=""noreferrer"">Here</a> is the link to the Google Colab Notebook to reproduce the error(please set #GPU&gt;1)</p>
",6244166.0,,,,,2022-01-10 02:19:15,INVALID_ARGUMENT: transpose expects a vector of size 0 (when GPU units are more than 1),<python><tensorflow><keras><tensorflow2.0>,1,3,,,,CC BY-SA 4.0
63271509,1,,,2020-08-05 18:34:45,,5,1739,"<p>I am new to machine learning and I am performing a Multivariate Time Series Forecast using LSTMs in Keras. I have a monthly timeseries dataset with 4 input variables (temperature, precipitation, Dew and wind_spreed) and 1 output variable (pollution). Using this data i framed a forecasting problem where, given the weather conditions and pollution for prior months, I forecast the pollution at the next month. Below is my code</p>
<pre><code>X = df[['Temperature', 'Precipitation', 'Dew', 'Wind_speed' ,'Pollution (t_1)']].values
y = df['Pollution (t)'].values
y = y.reshape(-1,1)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
scaled = scaler.fit_transform(X)

#dataset has 359 samples in total
train_X, train_y = X[:278], y[:278]
test_X, test_y = X[278:], y[278:]
# reshape input to be 3D [samples, timesteps, features]
train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))
test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))
print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) 


model = Sequential()
model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))
model.add(Dropout(0.2))
#    model.add(LSTM(70))
#    model.add(Dropout(0.3))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

history = model.fit(train_X, train_y, epochs=700, batch_size=70, validation_data=(test_X, test_y), verbose=2, shuffle=False)

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()
</code></pre>
<p>To do predictions i use the following code</p>
<pre><code>from sklearn.metrics import mean_squared_error,r2_score
yhat = model.predict(test_X)
mse  = mean_squared_error(test_y, yhat)
rmse = np.sqrt(mse)
r2   = r2_score(test_y, yhat)

print(&quot;test set performance&quot;)
print(&quot;--------------------&quot;)
print(&quot;MSE:&quot;,mse)
print(&quot;RMSE:&quot;,rmse)
print(&quot;R^2: &quot;,r2)

fig, ax = plt.subplots(figsize=(10,5))
ax.plot(range(len(test_y)), test_y, '-b',label='Actual')
ax.plot(range(len(yhat)), yhat, 'r', label='Predicted')
plt.legend()
plt.show()
</code></pre>
<p><strong>Running this code i fell into the following issues:</strong></p>
<ol>
<li>For some reason am getting a lagged result for my test set which is not in my training data as shown on the below image. I do not understand why i have these lagged results (does it have something to do with including 'pollution (t_1)' as part of my inputs)?</li>
</ol>
<p>Graph Results:</p>
<p><a href=""https://i.stack.imgur.com/i2Alo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/i2Alo.png"" alt=""enter image description here"" /></a></p>
<ol start=""2"">
<li>By adding &quot;pollution (t_1)&quot; which is a shift by 1 lag of the polution variable as part of my inputs this variable now seems to dominate the prediction as removing the other varibales seems to have no influence on my results (r-squared and rmse) which is strange since all these variables do assit in pollution prediction.</li>
</ol>
<p>Is there something i am doing wrong in my code which is the reason for these issues? I am new to python so any help to answer the above 2 questions will be greatly appreaciated.</p>
",14055785.0,,14055785.0,,2020-08-06 12:46:31,2020-08-07 09:59:48,Why do i get lagged results on my LSTM model,<python><tensorflow><keras><time-series><lstm>,1,4,0.0,,,CC BY-SA 4.0
64107989,1,64108200.0,,2020-09-28 18:51:41,,5,11845,"<pre><code>values = df.values
train, test = train_test_split(values)

#Split into train and test
X_train, y_train = train[:, :-1], train[:, -1]
X_test, y_test = test[:, :-1], test[:, -1]
</code></pre>
<p>Executing the above code splits the time series dataset into training- 75% and testing 25%. I want to control the train-test split as 80-20 or 90-10. <strong>Can someone please help me understand how to split the dataset into any ratio I want?</strong></p>
<p>The concept is borrowed from <a href=""https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"" rel=""noreferrer"">https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/</a>.</p>
<p>Note : <strong>I cannot split the dataset randomly for train and  test and the most recent values have to be for testing</strong>. I have included a screenshot of my dataset.</p>
<p><a href=""https://i.stack.imgur.com/Y1zOg.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Y1zOg.png"" alt=""enter image description here"" /></a>If anyone can interpret the code, please do help me understand the above. Thanks.</p>
",11482667.0,,,,,2020-09-28 19:09:15,Train-Test split for Time Series Data to be used for LSTM,<python><keras><time-series><regression><lstm>,2,1,0.0,,,CC BY-SA 4.0
76324768,1,,,2023-05-24 14:45:08,,5,142,"<p>I am looking at the definition of <code>clipvalue, clipnorm, global_clipnorm</code> arguments in <code>tf.keras.optimizers.Adam</code> <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"" rel=""noreferrer"">here</a>. I have some questions related to that. The description of the arguments mentions following:</p>
<ul>
<li><code>clipnorm</code>:   Float. If set, the gradient of each weight is individually clipped so that its norm is no higher than this value.</li>
<li><code>clipvalue</code>:  Float. If set, the gradient of each weight is clipped to be no higher than this value.</li>
<li><code>global_clipnorm</code>:    Float. If set, the gradient of all weights is clipped so that their global norm is no higher than this value.</li>
</ul>
<p>Questions:</p>
<ul>
<li>As gradient of a weight (as the description says each weight) is 1-dimensional, clipnorm and clipvalue should be the same. Are there some scenarios in which clipnorm and clipvalue are different?</li>
<li>Seems global_clipnorm computes norm over all the weights in the model. From the available options, it seems we don’t have any argument in tf.keras.optimizers.Adam to do that clipnorm over the weights of a layer. Do we have that option with the api?</li>
</ul>
",7561372.0,,,,,2023-06-04 09:27:04,clipnorm vs clipvalue vs global_clipnorm in tf.keras.optimizers.Adam,<tensorflow><keras><deep-learning>,2,0,,,,CC BY-SA 4.0
68573265,1,,,2021-07-29 09:15:50,,5,1664,"<p>I'm trying to implement the Keras Retinanet example from the source:</p>
<p><a href=""https://keras.io/examples/vision/retinanet/"" rel=""noreferrer"">https://keras.io/examples/vision/retinanet/</a></p>
<p>and I do get the example run perfectly with the COCO-dataset. Now I would like to run the example with my own custom object detection dataset. After doing couple of days some research on the web it still isn't that clear for me, how I would need to edit the example code to use my own dataset (that is a set of .jpg images + annotation .xml files produced with <a href=""https://github.com/tzutalin/labelImg"" rel=""noreferrer"">labelImg</a>).</p>
<p>I suspect I would need to get familiar with the <a href=""https://www.tensorflow.org/datasets/overview"" rel=""noreferrer"">tensorflow_dataset-library</a>? My guess is that this part in the code is where I should do the customization for my own dataset:</p>
<p><a href=""https://keras.io/examples/vision/retinanet/#load-the-coco2017-dataset-using-tensorflow-datasets"" rel=""noreferrer"">https://keras.io/examples/vision/retinanet/#load-the-coco2017-dataset-using-tensorflow-datasets</a></p>
<p>Any advices or good references worth investigating to get the Keras  Retinanet object detection example working with my own dataset?</p>
",1565754.0,,1565754.0,,2021-07-29 09:21:51,2021-08-23 13:31:24,How to run Keras Retinanet object detection code example with custom dataset?,<python><keras><customization><object-detection><retinanet>,1,1,,,,CC BY-SA 4.0
67570696,1,,,2021-05-17 13:30:28,,5,4567,"<p>I'm Trying to do text Classification with <code>tensorflow.keras.layers.Embedding</code>
and Glove.
when I run the code:</p>
<pre><code>model.add(Embedding(len(word_index) + 1,
 100,
 weights=[embedding_matrix],
 input_length=MAX_LENGTH,
 trainable=False))
</code></pre>
<p>I get the error :</p>
<pre><code>TypeError: Parameter to MergeFrom() must be instance of same class: expected TensorShapeProto got TensorShapeProto.
</code></pre>
<p>My TensorFlow ver: 1.14.0
I'm using Win-64</p>
",15352688.0,,1821877.0,,2021-05-18 10:38:02,2021-12-20 09:15:21,TypeError: Parameter to MergeFrom() must be instance of same class: expected TensorShapeProto got TensorShapeProto. in tf.keras.layers.Embedding,<python><tensorflow><keras><nlp>,1,1,,,,CC BY-SA 4.0
64326568,1,64327212.0,,2020-10-12 23:24:17,,5,13612,"<p>So I just followed someone project and make it to here when I got this error:</p>
<pre><code>[2020-10-12 15:33:21,128] ERROR in app: Exception on /predict/ [POST]
Traceback (most recent call last):
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\flask\app.py&quot;, line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\flask\app.py&quot;, line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\flask\app.py&quot;, line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\flask\_compat.py&quot;, line 39, in reraise
    raise value
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\flask\app.py&quot;, line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\flask\app.py&quot;, line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File &quot;D:\Ngoding Python\Skripsi\deploy\app.py&quot;, line 70, in predict
    out = model.predict(img)
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 130, in _method_wrapper
    return method(self, *args, **kwargs)
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 1562, in predict
    version_utils.disallow_legacy_graph('Model', 'predict')
  File &quot;c:\users\mr777\anaconda3\envs\gpu\lib\site-packages\tensorflow\python\keras\utils\version_utils.py&quot;, line 122, in disallow_legacy_graph
    raise ValueError(error_msg)
ValueError: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled.
</code></pre>
<p>Here's the code I wrote:</p>
<pre><code>with graph.as_default():
        # perform the prediction
        out = model.predict(img)
        print(out)
        print(class_names[np.argmax(out)])
        # convert the response to a string
        response = class_names[np.argmax(out)]
        return str(response)
</code></pre>
<p>any idea with this? because I found the same question <a href=""https://stackoverflow.com/questions/62465189/why-is-show-error-when-trying-to-run-my-flask-on-server"">here</a></p>
",8622264.0,,8622264.0,,2020-10-12 23:31:39,2021-01-23 21:32:35,Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled,<tensorflow><flask><web><keras>,2,3,,,,CC BY-SA 4.0
64015600,1,64015959.0,,2020-09-22 18:22:43,,5,2219,"<p><code>x</code> is a <code>(64, 1)</code> dimensional vector created randomly using <code>tf.random.uniform((BATCH_SIZE, 1))</code>, where the <code>BATCH_SIZE = 64</code>.</p>
<p>A random initialization looks like this:</p>
<pre><code>tf.Tensor(
[[0.76922464]
 [0.7928164 ]
 [0.91224647]
 [0.41210544]
 [0.33040464]
 [0.20977008]
 [0.96211743]
 [0.59516513]
 [0.67317   ]
 [0.7600033 ]
 [0.93105805]
 [0.55348516]
 [0.50683343]
 [0.7563635 ]
 [0.06255531]
 [0.93398154]
 [0.5622641 ]
 [0.9913852 ]
 [0.3019762 ]
 [0.519048  ]
 [0.57998526]
 [0.21162748]
 [0.9783536 ]
 [0.38307965]
 [0.6527189 ]
 [0.8094288 ]
 [0.97980523]
 [0.5955998 ]
 [0.7002481 ]
 [0.6879872 ]
 [0.50365186]
 [0.57166266]
 [0.97805905]
 [0.458856  ]
 [0.3485204 ]
 [0.29394794]
 [0.19313121]
 [0.29782188]
 [0.45194447]
 [0.49442303]
 [0.04192603]
 [0.26818407]
 [0.822567  ]
 [0.8573874 ]
 [0.15510845]
 [0.76052403]
 [0.4066763 ]
 [0.17861617]
 [0.458804  ]
 [0.25463438]
 [0.89405084]
 [0.854866  ]
 [0.9855745 ]
 [0.04673469]
 [0.6193329 ]
 [0.9060414 ]
 [0.17602026]
 [0.20119262]
 [0.08522642]
 [0.7849103 ]
 [0.34081244]
 [0.2556857 ]
 [0.75679326]
 [0.635311  ]], shape=(64, 1), dtype=float32)
</code></pre>
<p>The embedding layer is defined as <code>self.embedding = tf.keras.layers.Embedding(4934, 256)</code></p>
<p><code>x</code>, created above, is passed through this embedding layer as follows:</p>
<p><code>x = self.embedding(x)</code></p>
<p><code>x</code> resulting from this embedding has dimensions <code>(64, 1, 256)</code>. So each of the 64 float values in <code>x</code> has a 256 dimensional vector representation.</p>
<p>My question is:
<code>x</code> was initially a randomly generated float vector with each vector of length <code>1</code>.</p>
<p>By definition, I understand the embedding layer as mapping from a word to an index and the index has a vector representation of length equal to &quot;embedding dimensions&quot;, 256 in this example. So the word that mapped to the index also has this same vector representation.</p>
<p>But <code>x</code> in our example is just a vector of random float values. How did the embedding layer come up with a 256-dimensional vector representation for these <strong>float values</strong>? Any <strong>float value</strong> in this list does not represent a word. Why should it have an embedding?</p>
<p>It's line 36 in the image included below (link to code page: <a href=""https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb#scrollTo=yJ_B3mhW3jFk"" rel=""noreferrer"">Google colab code location</a></p>
<p><a href=""https://i.stack.imgur.com/oSV2S.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/oSV2S.jpg"" alt=""Code Image"" /></a></p>
",1216456.0,,2099607.0,,2020-09-22 18:50:06,2020-09-22 18:50:06,How does Embedding layer in Keras work on float input values?,<python><tensorflow><keras><keras-layer><tf.keras>,1,0,0.0,,,CC BY-SA 4.0
63315046,1,,,2020-08-08 11:51:43,,5,32299,"<p>I am getting following error while training the functional model created using keras:</p>
<pre><code>File &quot;D:\Age_prediction\testmatrixshape.py&quot;, line 34, in &lt;module&gt;
    cnn_lstm.fit(X_train, y_train, batch_size=10, epochs=10)
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 848, in fit
    tmp_logs = train_function(iterator)
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 580, in __call__
    result = self._call(*args, **kwds)
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 1661, in _filtered_call
    return self._call_flat(
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 1745, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 593, in call
    outputs = execute.execute(
  File &quot;C:\Users\Pranaswi Reddy\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\execute.py&quot;, line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnimplementedError:  Cast string to float is not supported
     [[node Cast (defined at D:\Age_prediction\testmatrixshape.py:34) ]] [Op:__inference_train_function_2171]

Function call stack:
train_function
</code></pre>
<p>This is my code:</p>
<pre><code>from tensorflow import keras
from tensorflow.keras.layers import Input,Dense,Conv1D,MaxPooling1D,LSTM
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model


file = pd.read_csv(&quot;D:\\Age_prediction\\final_FE.csv&quot;, header=None)

file.rename(columns={12:'class'},inplace=True)
y = file['class']
X = file.drop(columns = 'class', axis =1 )
#X=X.values.reshape(X.shape[0],X.shape[1],1)
X_train, X_test, y_train, y_test = train_test_split(X, y,  train_size=None, test_size=0.20, random_state= 6)
X=X_train.values.reshape(X_train.shape[0],X_train.shape[1],1)
X_test=X_test.values.reshape(X_test.shape[0],X_test.shape[1],1)

input_layer=Input(shape=(12,1))
conv1d=Conv1D(filters=64,
              kernel_size=12,
              strides=1,
              padding='causal',
              activation='relu')(input_layer)
pool=MaxPooling1D(pool_size=2,
                   padding='same',
                   strides=1)(conv1d)
lstm=LSTM(25,activation='relu')(pool)
output_layer=Dense(10,activation='softmax')(lstm)
cnn_lstm=Model(inputs=input_layer,outputs=output_layer,name=&quot;cnn_lstm&quot;)
cnn_lstm.compile(optimizer='adam',loss='binary_crossentropy')
cnn_lstm.summary()

cnn_lstm.fit(X_train, y_train, batch_size=10, epochs=10)
</code></pre>
",14063569.0,,4685471.0,,2020-08-08 11:54:14,2023-03-20 04:38:36,Function call stack: train_function,<python><python-3.x><tensorflow><machine-learning><keras>,5,0,,,,CC BY-SA 4.0
64204659,1,,,2020-10-05 08:03:51,,5,605,"<p>Fasttext could handle OOV easily, i.e., it could be assumed that <code>emb = fasttext_model(raw_input)</code> always holds. However, I am not sure how I could build this layer into <code>tf.keras</code> embedding. I couldn't simply load the matrix into <code>Embedding</code> because in that way the OOV couldn't be handled. Is there a walkaround that I could use <code>fasttext_model</code> in a <code>tf.keras</code> model?</p>
",6659095.0,,,,,2020-10-05 08:03:51,Incorporate fasttext vectors in tf.keras embedding layer?,<tensorflow><keras><tensorflow2.0><embedding><fasttext>,0,1,,,,CC BY-SA 4.0
70429982,1,70430235.0,,2021-12-21 02:18:30,,5,8358,"<p>I have a for loop with several different deep learning models in it that generates this warning:</p>
<pre><code>WARNING:tensorflow:5 out of the last 5 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000001B0A8CC90D0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000001B0A6C01940&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
</code></pre>
<p>I have tried many different things in the for loop to stop it from popping up with no success. Is there simply a way to disable all warnings?</p>
",15363651.0,,,,,2021-12-21 14:36:57,How to disable all tensorflow warnings?,<python><tensorflow><keras>,3,1,,,,CC BY-SA 4.0
67555954,1,,,2021-05-16 11:10:16,,5,10198,"<p>when I use 'import talos' I get the following error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;C:/Users/Mirijam/Desktop/rp/RNN_classification/classification.py&quot;, line 4, in &lt;module&gt;
    import talos
  File &quot;C:\Users\Mirijam\Desktop\rp\venv\lib\site-packages\talos\__init__.py&quot;, line 14, in &lt;module&gt;
    from . import utils
  File &quot;C:\Users\Mirijam\Desktop\rp\venv\lib\site-packages\talos\utils\__init__.py&quot;, line 11, in &lt;module&gt;
    from .sequence_generator import SequenceGenerator
  File &quot;C:\Users\Mirijam\Desktop\rp\venv\lib\site-packages\talos\utils\sequence_generator.py&quot;, line 1, in &lt;module&gt;
    from keras.utils import Sequence
ImportError: cannot import name 'Sequence' from 'keras.utils' (C:\Users\Mirijam\Desktop\rp\venv\lib\site-packages\keras\utils\__init__.py)
</code></pre>
<p>My keras version is 2.5.0. My other Keras imports seems to be working.</p>
",,user14595340,,,,2021-05-27 14:22:38,cannot import name 'Sequence' from 'keras.utils',<python><tensorflow><keras><pycharm>,1,0,0.0,,,CC BY-SA 4.0
64255154,1,64258851.0,,2020-10-08 02:57:54,,5,10532,"<p>how can I change</p>
<pre><code>tf.contrib.layers.xavier_initializer()
</code></pre>
<p>to tf version &gt;= 2.0.0 ??</p>
<p>all codes:</p>
<pre><code>W1 = tf.get_variable(&quot;W1&quot;, shape=[self.input_size, h_size],
                             initializer=tf.contrib.layers.xavier_initializer())
</code></pre>
",13514723.0,,10396469.0,,2020-10-08 08:40:10,2022-07-05 11:07:13,change tf.contrib.layers.xavier_initializer() to 2.0.0,<python><tensorflow><keras><tensorflow2.0>,2,0,0.0,,,CC BY-SA 4.0
70420155,1,70421046.0,,2021-12-20 10:02:18,,5,3972,"<p>I have trained my stock price prediction model by splitting the dataset into train &amp; test.
I have also tested the predictions by comparing the valid data with the predicted data, and the model works fine.
But I want to predict <em><strong>actual</strong></em> future values.</p>
<p>What do I need to change in my code below?</p>
<p>How can I make predictions up to a specific date in the <em><strong>actual</strong></em> future?</p>
<hr />
<p>Code (in a Jupyter Notebook):</p>
<p>(To run the code, please try it in a similar csv file you have, or install nsepy python library using command <code>pip install nsepy</code>)</p>
<pre><code># imports
import pandas as pd  # data processing
import numpy as np  # linear algebra
import matplotlib.pyplot as plt  # plotting
from datetime import date  # date
from nsepy import get_history  # NSE historical data
from keras.models import Sequential  # neural network
from keras.layers import LSTM, Dropout, Dense  # LSTM layer
from sklearn.preprocessing import MinMaxScaler  # scaling

nseCode = 'TCS'
stockTitle = 'Tata Consultancy Services'

# API call
apiData = get_history(symbol = nseCode, start = date(2017,1,1), end = date(2021,12,19))
data = apiData  # copy the dataframe (not necessary)

# remove columns you don't need
del data['Symbol']
del data['Series']
del data['Prev Close']
del data['Volume']
del data['Turnover']
del data['Trades']
del data['Deliverable Volume']
del data['%Deliverble']

# store the data in a csv file
data.to_csv('infy2.csv')

# Read the csv file
data = pd.read_csv('infy2.csv')

# convert the date column to datetime; if you read data from csv, do this. Otherwise, no need if you read data from API
data['Date'] = pd.to_datetime(data['Date'], format = '%Y-%m-%d')
data.index = data['Date']

# plot
plt.xlabel('Date')
plt.ylabel('Close Price (Rs.)')
data['Close'].plot(legend = True, figsize = (10,6), title = stockTitle, grid = True, color = 'blue')

# Sort data into Date and Close columns
data2 = data.sort_index(ascending = True, axis = 0)

newData = pd.DataFrame(index = range(0,len(data2)), columns = ['Date', 'Close'])

for i in range(0, len(data2)):  # only if you read data from csv
    newData['Date'][i] = data2['Date'][i]
    newData['Close'][i] = data2['Close'][I]

# Calculate the row number to split the dataset into train and test
split = len(newData) - 100

# normalize the new dataset
scaler = MinMaxScaler(feature_range = (0, 1))
finalData = newData.values

trainData = finalData[0:split, :]
validData = finalData[split:, :]

newData.index = newData.Date
newData.drop('Date', axis = 1, inplace = True)
scaler = MinMaxScaler(feature_range = (0, 1))
scaledData = scaler.fit_transform(newData)

xTrainData, yTrainData = [], []

for i in range(60, len(trainData)):  # data-flair has used 60 instead of 30
    xTrainData.append(scaledData[i-60:i, 0])
    yTrainData.append(scaledData[i, 0])

xTrainData, yTrainData = np.array(xTrainData), np.array(yTrainData)

xTrainData = np.reshape(xTrainData, (xTrainData.shape[0], xTrainData.shape[1], 1))

# build and train the LSTM model
lstmModel = Sequential()
lstmModel.add(LSTM(units = 50, return_sequences = True, input_shape = (xTrainData.shape[1], 1)))
lstmModel.add(LSTM(units = 50))
lstmModel.add(Dense(units = 1))

inputsData = newData[len(newData) - len(validData) - 60:].values
inputsData = inputsData.reshape(-1,1)
inputsData = scaler.transform(inputsData)

lstmModel.compile(loss = 'mean_squared_error', optimizer = 'adam')
lstmModel.fit(xTrainData, yTrainData, epochs = 1, batch_size = 1, verbose = 2)

# Take a sample of a dataset to make predictions
xTestData = []

for i in range(60, inputsData.shape[0]):
    xTestData.append(inputsData[i-60:i, 0])

xTestData = np.array(xTestData)

xTestData = np.reshape(xTestData, (xTestData.shape[0], xTestData.shape[1], 1))

predictedClosingPrice = lstmModel.predict(xTestData)
predictedClosingPrice = scaler.inverse_transform(predictedClosingPrice)

# visualize the results
trainData = newData[:split]
validData = newData[split:]

validData['Predictions'] = predictedClosingPrice

plt.xlabel('Date')
plt.ylabel('Close Price (Rs.)')

trainData['Close'].plot(legend = True, color = 'blue', label = 'Train Data')
validData['Close'].plot(legend = True, color = 'green', label = 'Valid Data')
validData['Predictions'].plot(legend = True, figsize = (12,7), grid = True, color = 'orange', label = 'Predicted Data', title = stockTitle)
</code></pre>
",17722368.0,,11989081.0,,2021-12-21 20:45:03,2021-12-22 10:12:53,How to predict actual future values after testing the trained LSTM model?,<python><tensorflow><machine-learning><keras><lstm>,1,0,,,,CC BY-SA 4.0
63027146,1,63306008.0,,2020-07-22 04:56:02,,5,1887,"<p>I am using CNN for multi-class image classification, but accuracy is not very good. I assume I need to normalize training data with channel means and standard deviation so it might contribute to better accuracy. I came out one way for doing this, but it is not very efficient because I just put random value for means and standard deviation for normalization. I am not  sure how to find channel means and its standard deviation. I was wondering is there any way of doing this. can anyone point me out how to achieve this? Any possible thoughts?</p>
<p><strong>my current attempt</strong>:</p>
<pre><code>import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Input
from keras.datasets import cifar10
from keras.utils import to_categorical

(X_train, y_train), (X_test, y_test)= cifar10.load_data()
output_class = np.unique(y_train)
n_class = len(output_class)

input_shape = (32, 32, 3)
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
y_train_one_hot = to_categorical(y_train)
y_test_one_hot = to_categorical(y_test)

x = tf.keras.Input(shape=(32, 32, 3))
conv = Conv2D(128, (3, 3), activation='relu',input_shape=(32, 32, 3))(x)
conv = MaxPooling2D(pool_size=(2,2))(conv)
conv = Conv2D(64, (2,2))(conv)
conv = MaxPooling2D(pool_size=(2,2))(conv)
conv = Flatten()(conv)
conv = Dense(64, activation='relu')(conv)
conv = Dense(10, activation='softmax')(conv)
model = Model(inputs = x, outputs = conv)
</code></pre>
<p><strong>my attempt for normalization</strong>:</p>
<p>here is my way of normalization, where I just assigned random value to means and standard deviation:</p>
<pre><code>mean = [125.307, 122.95, 113.865]  ## random value
std = [62.9932, 62.0887, 66.7048]  ## random value

for i in range(3):
  X_train[:,:,:,i] = (X_train[:,:,:,i] - mean[i]) / std[i]
  X_test[:,:,:,i] = (X_test[:,:,:,i] - mean[i]) / std[i]
</code></pre>
<p>I am wondering is there any way programmatically find channel means and its standard deviation so we could do normalization. Any better idea of doing this? what else possibly do for increasing accuracy of my sample model? How can I find channel means and its standard deviation? any possible strategy or coding attempt?</p>
",10708392.0,,10708392.0,,2020-07-22 14:33:42,2020-08-07 16:42:02,normalize training data with channel means and standard deviation in CNN model,<python><tensorflow><keras><conv-neural-network>,2,0,,,,CC BY-SA 4.0
65372223,1,65375382.0,,2020-12-19 16:54:46,,5,1210,"<p>I'm training a Keras model which sits in a Scikit pipeline with some preprocessing. The Keras model is defined as</p>
<pre><code>from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Input, Dropout
from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.wrappers.scikit_learn import KerasRegressor
from sklearn.pipeline import make_pipeline


def create_model(X_train):
    inp = Input(shape=(X_train.shape[1],))
    x = Dense(150, activation=&quot;relu&quot;)(inp)
    x = Dropout(0.4)(x)
    mean = Dense(1, activation=&quot;linear&quot;)(x)
    train_model_1 = Model(inp, mean)
    adam = optimizers.Adam(lr=0.01)
    train_model_1.compile(loss=my_loss_function, optimizer=adam)
    return train_model_1


clf = KerasRegressor(build_fn=create_model, epochs=250, batch_size=64)
</code></pre>
<p>Which is then used in a <code>Pipeline</code> with</p>
<pre><code>pipeline = make_pipeline(
                other_steps,
                clf(X_train)
            )


pipeline.fit(X_train, y_train)
</code></pre>
<p>I want to use <code>EarlyStopping</code> where the test data (<code>X_test, y_test</code>) is used to validate against. This would normally be straightforward with</p>
<pre><code>callbacks=[EarlyStopping(monitor='val_loss', patience=5)]

train_model_1.fit(X_train, y_train,
                  validation_data=(X_test, y_test),
                  callbacks=callbacks,
                  )
</code></pre>
<p>But I can't figure out where this would go in the pipeline. What is the right way to structure this?</p>
",8564860.0,,8564860.0,,2020-12-19 17:04:46,2020-12-19 23:11:14,Keras model in Scikit-learn pipeline with early stopping,<python><tensorflow><keras><scikit-learn><pipeline>,1,0,,2020-12-19 22:24:16,,CC BY-SA 4.0
67496915,1,,,2021-05-12 03:21:51,,5,3250,"<p>I'm trying to reload or access the <strong>Keras-Tuner</strong> <code>Trials</code> after the <code>Tuner</code>'s search has completed for inspecting the results. I'm not able to find any documentation or answers related to this issue.</p>
<p>For example, I set up <code>BayesianOptimization</code> to search for the best hyper-parameters as follows:</p>
<pre><code>## Build Hyper Parameter Search
tuner = kt.BayesianOptimization(build_model,
                     objective='val_categorical_accuracy',
                     max_trials=10,
                     directory='kt_dir',
                     project_name='lstm_dense_bo')

tuner.search((X_train_seq, X_train_num), y_train_cat,
             epochs=30,
             batch_size=64,
             validation_data=((X_val_seq, X_val_num), y_val_cat),
             callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=3, 
                                                restore_best_weights=True)])
</code></pre>
<p>I see this creates trial files in the directory <code>kt_dir</code> with project name <code>lstm_dense_bo</code> such as below:
<a href=""https://i.stack.imgur.com/3PyhN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/3PyhN.png"" alt=""Tuner Objects"" /></a></p>
<p>Now, if I restart my Jupyter kernel, how can I reload these trials into a <code>Tuner</code> object and subsequently inspect the best model or the best hyperparameters or the best trial?</p>
<p>I'd very much appreciate your help. Thank you</p>
",6395618.0,,,,,2023-04-21 09:17:30,Reload Keras-Tuner Trials from the directory,<tensorflow><keras><tensorflow2.0><tf.keras><keras-tuner>,6,0,0.0,,,CC BY-SA 4.0
62991082,1,,,2020-07-20 08:04:22,,5,5395,"<p>I would like to know more details about the merge mode when using Bidirectional LSTM for sequence classification, and especially for the &quot;Concat&quot; merge mode which is still quite unclear to me.</p>
<p>From what I understood with this scheme:</p>
<p><a href=""https://i.stack.imgur.com/GmKNd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GmKNd.png"" alt=""enter image description here"" /></a></p>
<p>The output y_t is computed after passing the merged results of the forward and backward layers into the sigmoid function. It seems rather intuitive for the &quot;add&quot;,&quot;mul&quot; and &quot;average&quot; merge modes but I don't understand how the output y_t is computed when 'concat' merge mode is chosen. Indeed, with this merge mode we now have a vector instead of a single value before the sidmoid function.</p>
",13749215.0,,9046247.0,,2020-07-20 10:45:34,2020-07-20 11:20:06,Bidirectional LSTM Merge Mode explanation,<python><keras><lstm><recurrent-neural-network>,2,0,0.0,,,CC BY-SA 4.0
70342506,1,,,2021-12-14 00:37:45,,5,827,"<p>I'm trying to visualize the model in Tensorboard without training.</p>
<p>I checked <a href=""https://stackoverflow.com/questions/60639731/tensorboard-for-custom-training-loop-in-tensorflow-2"">this</a> and <a href=""https://stackoverflow.com/questions/61172053/tensorboard-graph-with-custom-training-loop-does-not-include-my-model/61173028#61173028"">that</a>, but this still doesn't work even for the simplest model.</p>
<pre><code>import tensorflow as tf
import tensorflow.keras as keras
# Both tf.__version__ tensorboard.__version__ are 2.5.0

s_model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10, activation='softmax')
])

logdir = '.../logs'
_callbacks = keras.callbacks.TensorBoard(log_dir=logdir)
_callbacks.set_model(s_model) # This is exactly suggested in the link
</code></pre>
<p>When I did the above, I get the error message:</p>
<blockquote>
<p>Graph visualization failed.</p>
<p>Error: Malformed GraphDef. This can sometimes be caused by a bad
network connection or difficulty reconciling mulitple GraphDefs; for
the latter case, please refer to
<a href=""https://github.com/tensorflow/tensorboard/issues/1929"" rel=""noreferrer"">https://github.com/tensorflow/tensorboard/issues/1929</a>.</p>
</blockquote>
<p>I don't think this is a reconciliation problem because it is not a custom function, and if I compile the model, train, then I can get the graph visualization I wanted.</p>
<pre><code>s_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'])

(train_images, train_labels), _ = keras.datasets.fashion_mnist.load_data()
train_images = train_images / 255.0

logdir = '.../logs'
tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)

s_model.fit(
    train_images,
    train_labels, 
    batch_size=64,
    epochs=5, 
    callbacks=[tensorboard_callback])
</code></pre>
<p>This gives the wanted graph visualization. But is there any other way to get graph visualization in Tensorboard without training?</p>
<p>Of course, I'm also aware that workaround, i.e. train with the <code>tf.random.normal()</code> for a while, would do the trick but I'm looking for the neat way like <code>_callbacks.set_model(s_model)</code>...</p>
",7820717.0,,,,,2023-02-03 06:17:38,How to visualize graph without training the model using Tensorboard?,<tensorflow><keras><tensorboard><graph-visualization>,0,3,,,,CC BY-SA 4.0
67638993,1,,,2021-05-21 14:37:18,,5,349,"<p>I have a document classification task, that classifies documents as good (1) or bad (0), and I use some sentence embeddings for each document to classify the documents accordingly.</p>
<p><strong>What I like to do is retrieving the attention scores for each document, to obtain the most &quot;relevant&quot; sentences (i.e., those with high attention scores)</strong></p>
<p><em>I padded each document to the same length</em> (i.e., 1000 sentences per document). So my tensor for 5000 documents looks like this <code>X = np.ones(shape=(5000, 1000, 200))</code> (5000 documents with each having a 1000 sequence of sentence vectors and each sentence vector consisting of 200 features).</p>
<p>My network looks like this:</p>
<pre><code>no_sentences_per_doc = 1000
sentence_embedding = 200

sequence_input  = Input(shape=(no_sentences_per_doc, sentence_embedding))
gru_layer = Bidirectional(GRU(50,
                          return_sequences=True
                          ))(sequence_input)
sent_dense = Dense(100, activation='relu', name='sent_dense')(gru_layer)  
sent_att,sent_coeffs = AttentionLayer(100,return_coefficients=True, name='sent_attention')(sent_dense)
preds = Dense(1, activation='sigmoid',name='output')(sent_att)  
model = Model(sequence_input, preds)

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=[TruePositives(name='true_positives'),
                      TrueNegatives(name='true_negatives'),
                      FalseNegatives(name='false_negatives'),
                      FalsePositives(name='false_positives')
                      ])

history = model.fit(X, y, validation_data=(x_val, y_val), epochs=10, batch_size=32)
</code></pre>
<p>After training I retrieved the attention scores as follows:</p>
<pre><code>sent_att_weights = Model(inputs=sequence_input,outputs=sent_coeffs)

## load a single sample
## from file with 150 sentences (one sentence per line)
## each sentence consisting of 200 features
x_sample = np.load(x_sample)
## and reshape to (1, 1000, 200)
x_sample = x_sample.reshape(1,1000,200) 

output_array = sent_att_weights.predict(x_sample)
</code></pre>
<p><em>However,</em> if I show the top 3 attention scores for the sentences, I also obtain sentence indices that are, for example, <code>[432, 434, 999]</code> for a document that has only 150 sentences (the rest is padded, i.e., just zeros).</p>
<p><strong>Does that make sense or am I doing something wrong here?</strong> (is there a mistake in my attention layer? Or is due to a low F-score?)</p>
<p>The attention layer I use is the following:</p>
<pre><code>class AttentionLayer(Layer):
    &quot;&quot;&quot;
    https://humboldt-wi.github.io/blog/research/information_systems_1819/group5_han/
    &quot;&quot;&quot;
    def __init__(self,attention_dim=100,return_coefficients=False,**kwargs):
        # Initializer 
        self.supports_masking = True
        self.return_coefficients = return_coefficients
        self.init = initializers.get('glorot_uniform') # initializes values with uniform distribution
        self.attention_dim = attention_dim
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        # Builds all weights
        # W = Weight matrix, b = bias vector, u = context vector
        assert len(input_shape) == 3
        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)),name='W')
        self.b = K.variable(self.init((self.attention_dim, )),name='b')
        self.u = K.variable(self.init((self.attention_dim, 1)),name='u')
        self.trainable_weights = [self.W, self.b, self.u]

        super(AttentionLayer, self).build(input_shape)

    def compute_mask(self, input, input_mask=None):
        return None

    def call(self, hit, mask=None):
        # Here, the actual calculation is done
        uit = K.bias_add(K.dot(hit, self.W),self.b)
        uit = K.tanh(uit)
        
        ait = K.dot(uit, self.u)
        ait = K.squeeze(ait, -1)
        ait = K.exp(ait)
        
        if mask is not None:
            ait *= K.cast(mask, K.floatx())

        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())
        ait = K.expand_dims(ait)
        weighted_input = hit * ait
        
        if self.return_coefficients:
            return [K.sum(weighted_input, axis=1), ait]
        else:
            return K.sum(weighted_input, axis=1)

    def compute_output_shape(self, input_shape):
        if self.return_coefficients:
            return [(input_shape[0], input_shape[-1]), (input_shape[0], input_shape[-1], 1)]
        else:
            return input_shape[0], input_shape[-1]
</code></pre>
<p>Note that I use <code>keras</code> with <code>tensorflow</code> backend version 2.1.; the attention layer was originally written for theano, but I use <code>import tensorflow.keras.backend as K</code></p>
",10053244.0,,9215780.0,,2021-05-25 12:14:19,2021-05-25 12:14:19,Retrieving attention weights for sentences? Most attentive sentences are zero vectors,<python><tensorflow><keras><nlp><attention-model>,0,0,0.0,,,CC BY-SA 4.0
63016740,1,63020188.0,,2020-07-21 14:26:10,,5,5326,"<p>The following content comes from Keras tutorial</p>
<blockquote>
<p>This behavior has been introduced in TensorFlow 2.0, in order to enable layer.trainable = False to produce the most commonly expected behavior in the convnet fine-tuning use case.</p>
</blockquote>
<p>Why we should freeze the layer when fine-tuning a convolutional neural network? Is it because some mechanisms in tensorflow keras or because of the algorithm of batch normalization? I run an experiment myself and I found that if trainable is not set to false the model tends to catastrophic forgetting what has been learned before and returns very large loss at first few epochs. What's the reason for that?</p>
",13241995.0,,,,,2020-07-21 17:53:00,Why it's necessary to frozen all inner state of a Batch Normalization layer when fine-tuning,<python><tensorflow><keras><tensorflow2.0><batch-normalization>,1,0,0.0,,,CC BY-SA 4.0
64256735,1,,,2020-10-08 06:11:40,,5,2391,"<p>After loading a trained model in keras, <code>model.summary()</code> gives the description of the network layers. But it doesn't contain the information about the activation function in the layers.</p>
<p>How to identify which activation function is used in a specific layer?</p>
",9127141.0,,10375049.0,,2022-06-26 16:05:59,2022-06-26 16:05:59,How to identify the activation function at a specific layer of a loaded keras model?,<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0
64144916,1,,,2020-09-30 20:02:49,,5,6120,"<p>I have used the pima-indians-diabetes.csv dataset. I have built a neural network containing architecture 12-8-1 using Keras and I was able to visualize the training history perfectly. Next, I tried to implement the same model using MLPCLassifier from scikit learn. Is it possible to implement training history curves in this case like I did with Keras? I just need to visualize my training history, that is, training accuracy, validation accuracy, training loss and validation loss, like I did with Keras. My code and curves using Keras:</p>
<pre><code>from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import StratifiedKFold
import numpy
numpy.random.seed(42)

# load pima indians dataset
dataset = numpy.loadtxt(&quot;/content/gdrive/My Drive/pima-indians-diabetes.csv&quot;, delimiter=&quot;,&quot;)

# split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]

model = Sequential()
model.add(Dense(12, input_dim=8, kernel_initializer= 'uniform' , activation= 'relu' ))
model.add(Dense(8, kernel_initializer= 'uniform' , activation= 'relu' ))
model.add(Dense(1, kernel_initializer= 'uniform' , activation= 'sigmoid' ))
# Compile model
model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])

history= model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)

import matplotlib.pyplot as plt
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[ 'accuracy' ])
plt.plot(history.history[ 'val_accuracy' ])
plt.title( 'model accuracy' )
plt.ylabel( 'accuracy' )
plt.xlabel( 'epoch' )
plt.legend([ 'train' , 'test' ], loc= 'lower right' )
plt.show()

import matplotlib.pyplot as plt
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history[ 'loss' ])
plt.plot(history.history[ 'val_loss' ])
plt.title( 'model loss' )
plt.ylabel( 'loss' )
plt.xlabel( 'epoch' )
plt.legend([ 'train' , 'test' ], loc= 'upper left' )
plt.show()
</code></pre>
<p><a href=""https://i.stack.imgur.com/daKMG.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/daKMG.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/T5GL2.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/T5GL2.png"" alt=""enter image description here"" /></a></p>
<p>My code using sklearn's MLP classifier:</p>
<pre><code>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

#Using MLPclassifier from sklearn
from sklearn.neural_network import MLPClassifier

clf1 = MLPClassifier(batch_size=10, max_iter=150, hidden_layer_sizes=(12, 8), verbose=True, 
early_stopping=True, random_state=42)

clf1.fit(X_train, y_train)

from sklearn.metrics import classification_report
#Predicting y for X_val
y_pred = clf1.predict(X_test)

print(classification_report(y_test, y_pred))
</code></pre>
<p>I was able to generate a classification report but no graphical visualization. How can I generate curves like those attached using sklearn's MLPClassifier like I did with Keras?</p>
",14056203.0,,14056203.0,,2020-10-01 09:56:56,2020-10-01 09:56:56,How to visualize model training history using scikit learn's MLP classifier?,<keras><scikit-learn><neural-network><curve><mlp>,0,2,,,,CC BY-SA 4.0
64227483,1,,,2020-10-06 14:05:28,,5,4467,"<p>I use transfer leaning with efficientnet_B0, and what im trying to do is to gradually unfreeze layers while network is learning. At first, I train 1 dense layer on top of whole network, while every other layer is frozen. I use this code to freeze layers:</p>
<pre><code>for layer in model_base.layers[:-2]:
  layer.trainable = False
</code></pre>
<p>then I unfreeze the whole model and freeze the exact layers I need using this code:</p>
<pre><code>model.trainable = True
for layer in model_base.layers[:-13]:
  layer.trainable = False
</code></pre>
<p>Everything works fine. I model.compile one more time and it starts to train from where it left, great. But then, when I unfreeze all layers one more time with</p>
<pre><code>model.trainable = True
</code></pre>
<p>and try to do fine-tuning, my model start to learn from the scratch.</p>
<p>I tried different approaches and ways to fix this, but nothing seems to work. I tried to use <code>layer.training = False</code> and <code>layer.trainable = False</code> for all batch_normalization layers in the model too, but it doesn't help either.</p>
",11907871.0,,6117017.0,,2022-04-06 14:58:39,2022-04-06 14:58:39,What is the right way to gradually unfreeze layers in neural network while learning with tensorflow?,<python><tensorflow><keras><deep-learning><neural-network>,4,1,,,,CC BY-SA 4.0
64141816,1,64163553.0,,2020-09-30 16:26:18,,5,1067,"<p>I am trying to use keras to fit a CNN model to classify 2 classes of data . I have imbalanced dataset I want to balance the data. I don't know can I use class_weight in <code>model.fit_generator</code> . I wonder if I used <code>class_weight=&quot;balanced&quot;</code>  in  <code>model.fit_generator</code></p>
<p><strong>The main code</strong>:</p>
<pre><code>def generate_arrays_for_training(indexPat, paths, start=0, end=100):      
    while True:
        from_=int(len(paths)/100*start)
        to_=int(len(paths)/100*end)
        for i in range(from_, int(to_)):
            f=paths[i]
            x = np.load(PathSpectogramFolder+f) 
            x = np.expand_dims(x, axis=0) 
            
            if('P' in f):
                y = np.repeat([[0,1]],x.shape[0], axis=0)
            else:
                y =np.repeat([[1,0]],x.shape[0], axis=0)
            yield(x,y)   
history=model.fit_generator(generate_arrays_for_training(indexPat, filesPath, end=75), 
                                validation_data=generate_arrays_for_training(indexPat, filesPath, start=75),
                                steps_per_epoch=int((len(filesPath)-int(len(filesPath)/100*25))), 
                                validation_steps=int((len(filesPath)-int(len(filesPath)/100*75))),
                                verbose=2,
                                epochs=15, max_queue_size=2, shuffle=True, callbacks=[callback])

</code></pre>
",13065840.0,,13065840.0,,2020-10-01 17:46:02,2020-10-01 21:38:01,How to balance dataset using fit_generator() in Keras?,<python><machine-learning><keras><deep-learning><generator>,1,5,,,,CC BY-SA 4.0
63927011,1,,,2020-09-16 19:45:20,,5,891,"<p>When using Keras Tuner, there doesn't seem to be a way to allow the skipping of a problematic combination of hyperparams. For example, the number of filters in a Conv1D layer may not be compatible with all values of pool size in the following MaxPooling1D layer and thus lead to an error in model building. However, this may not be known before running the tuner. Once the tuner is run, this will lead to an error that will terminate the whole tuning process. Is there a way to skip any hyperparam combinations that result in an error?</p>
<p>Sample code:</p>
<pre><code>def model_builder(hp):
    model = Sequential()
    model.add(
        Embedding(
            input_dim=hp.Int(
                'vocab_size', 
                min_value=4000,
                max_value=10000,
                step=1000,
                default=4000
            ), 
            output_dim=hp.Choice(
                'embedding_dim',
                values=[32, 64, 128, 256],
                default=32
            ), 
            input_length=hp.Int(
                'max_length',
                min_value=50,
                max_value=200,
                step=10,
                default=50
            )
        )
    )
    model.add(
        Conv1D(
            filters=hp.Choice(
                'num_filters_1',
                values=[32, 64],
                default=32
            ), 
            kernel_size=hp.Choice(
                'kernel_size_1',
                values=[3, 5, 7, 9],
                default=7
            ),
            activation='relu'
        )
    )
    model.add(
        MaxPooling1D(
            pool_size=hp.Choice(
                'pool_size', 
                values=[3, 5],
                default=5
            )
        )
    )
    model.add(
        Conv1D(
            filters=hp.Choice(
                'num_filters_2',
                values=[32, 64],
                default=32
            ), 
            kernel_size=hp.Choice(
                'kernel_size_2',
                values=[3, 5, 7, 9],
                default=7
            ), 
            activation='relu'
        )
    )
    model.add(
        GlobalMaxPooling1D()
    )
    model.add(
        Dropout(
            rate=hp.Float(
                'dropout_1',
                min_value=0.0,
                max_value=0.5,
                default=0.5,
                step=0.05
            )
        )
    )
    model.add(
        Dense(
            units=hp.Int(
                'units',
                min_value=10,
                max_value=100,
                step=10,
                default=10
            ), 
            kernel_regularizer=tf.keras.regularizers.l2(
                hp.Float(
                    'regularizer_1',
                    min_value=1e-4,
                    max_value=1e-1,
                    sampling='LOG',
                    default=1e-2
                )
            ), 
            activation='relu'
        )
    )
    model.add(
        Dropout(
            hp.Float(
                'dropout_2',
                min_value=0.0,
                max_value=0.5,
                default=0.5,
                step=0.05
            )
        )
    )
    model.add(
        Dense(
            1, 
            kernel_regularizer=tf.keras.regularizers.l2(
                hp.Float(
                    'regularizer_2',
                    min_value=1e-4,
                    max_value=1e-1,
                    sampling='LOG',
                    default=1e-2
                )
            ), 
            activation='sigmoid'
        )
    )

    
    model.compile(
        loss='binary_crossentropy', 
        optimizer=hp.Choice(
            'optimizer',
            values=['rmsprop', 'adam', 'sgd']
        ), 
        metrics=['accuracy']
    )
    
    return model


tuner = kt.Hyperband(
    model_builder,
    objective='val_accuracy', 
    max_epochs=20,
    #factor=3,
    directory='my_dir',
    project_name='cec',
    seed=seed
)   

class ClearTrainingOutput(tf.keras.callbacks.Callback):
  def on_train_end(*args, **kwargs):
    IPython.display.clear_output(wait=True)
    
tuner.search(
    X_train, 
    y_train, 
    epochs=20, 
    validation_data=(X_test, y_test), 
    callbacks=[ClearTrainingOutput()]
)
</code></pre>
<p>The error message:</p>
<pre><code>Epoch 1/3
WARNING:tensorflow:Model was constructed with shape (None, 150) for input Tensor(&quot;embedding_input:0&quot;, shape=(None, 150), dtype=float32), but it was called on an input with incompatible shape (32, 50).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-62-16a1eae457d8&gt; in &lt;module&gt;
      3     IPython.display.clear_output(wait=True)
      4 
----&gt; 5 tuner.search(
      6     X_train,
      7     y_train,

~/anaconda3/envs/cec/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py in search(self, *fit_args, **fit_kwargs)
    128 
    129             self.on_trial_begin(trial)
--&gt; 130             self.run_trial(trial, *fit_args, **fit_kwargs)
    131             self.on_trial_end(trial)
    132         self.on_search_end()

~/anaconda3/envs/cec/lib/python3.8/site-packages/kerastuner/tuners/hyperband.py in run_trial(self, trial, *fit_args, **fit_kwargs)
    385             fit_kwargs['epochs'] = hp.values['tuner/epochs']
    386             fit_kwargs['initial_epoch'] = hp.values['tuner/initial_epoch']
--&gt; 387         super(Hyperband, self).run_trial(trial, *fit_args, **fit_kwargs)
    388 
    389     def _build_model(self, hp):

~/anaconda3/envs/cec/lib/python3.8/site-packages/kerastuner/engine/multi_execution_tuner.py in run_trial(self, trial, *fit_args, **fit_kwargs)
     94 
     95             model = self.hypermodel.build(trial.hyperparameters)
---&gt; 96             history = model.fit(*fit_args, **copied_fit_kwargs)
     97             for metric, epoch_values in history.history.items():
     98                 if self.oracle.objective.direction == 'min':

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---&gt; 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    846                 batch_size=batch_size):
    847               callbacks.on_train_batch_begin(step)
--&gt; 848               tmp_logs = train_function(iterator)
    849               # Catch OutOfRangeError for Datasets of unknown size.
    850               # This blocks until the batch has finished executing.

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--&gt; 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    625       # This is the first call of __call__, so we have to initialize.
    626       initializers = []
--&gt; 627       self._initialize(args, kwds, add_initializers_to=initializers)
    628     finally:
    629       # At this point we know that the initialization is complete (or less

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    503     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    504     self._concrete_stateful_fn = (
--&gt; 505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    506             *args, **kwds))
    507 

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2444       args, kwargs = None, None
   2445     with self._lock:
-&gt; 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2447     return graph_function
   2448 

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)
-&gt; 2777       graph_function = self._create_graph_function(args, kwargs)
   2778       self._function_cache.primary[cache_key] = graph_function
   2779       return graph_function, args, kwargs

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2655     arg_names = base_arg_names + missing_arg_names
   2656     graph_function = ConcreteFunction(
-&gt; 2657         func_graph_module.func_graph_from_py_func(
   2658             self._name,
   2659             self._python_function,

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

~/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, &quot;ag_error_metadata&quot;):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **
        y_pred = self(x, training=True)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:277 call
        return super(Sequential, self).call(inputs, training=training, mask=mask)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:717 call
        return self._run_internal_graph(
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph
        output_tensors = layer(computed_tensors, **kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py:207 call
        outputs = self._convolution_op(inputs, self.kernel)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:1106 __call__
        return self.conv_op(inp, filter)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:638 __call__
        return self.call(inp, filter)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:231 __call__
        return self.conv_op(
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:220 _conv1d
        return conv1d(
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:574 new_func
        return func(*args, **kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:574 new_func
        return func(*args, **kwargs)
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:1655 conv1d
        result = gen_nn_ops.conv2d(
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py:965 conv2d
        _, _, _op, _outputs = _op_def_library._apply_op_helper(
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper
        op = g._create_op_internal(op_type_name, inputs, dtypes=None,
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal
        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3319 _create_op_internal
        ret = Operation(
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1816 __init__
        self._c_op = _create_c_op(self._graph, node_def, inputs,
    /home/george/anaconda3/envs/cec/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1657 _create_c_op
        raise ValueError(str(e))

    ValueError: Negative dimension size caused by subtracting 7 from 6 for '{{node sequential/conv1d_1/conv1d}} = Conv2D[T=DT_FLOAT, data_format=&quot;NHWC&quot;, dilations=[1, 1, 1, 1], explicit_paddings=[], padding=&quot;VALID&quot;, strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential/conv1d_1/conv1d/ExpandDims, sequential/conv1d_1/conv1d/ExpandDims_1)' with input shapes: [32,1,6,32], [1,7,32,32].

</code></pre>
",4896087.0,,,,,2022-04-26 10:10:55,How to skip problematic hyperparameter combinations when tuning models using Keras Tuner?,<tensorflow><keras><tf.keras><keras-tuner>,1,1,0.0,,,CC BY-SA 4.0
66017188,1,,,2021-02-02 20:31:24,,5,18614,"<p>I am working on windows 7.
Currently I have tensorflow 2.4.1 and keras 2.3.1 installed in my laptop.</p>
<p>I have trained a model on coalab and saved t on my laptop. When I try to load it it gives error :</p>
<pre><code>ValueError: Unknown layer: Functional
</code></pre>
<p>It may be due to difference in version of Keras. Google colab uses Keras 2.4.3.</p>
<p>When I tried to install keras 2.4.3 using command:</p>
<pre><code>pip install Keras==2.4.3
</code></pre>
<h2><em>I got the following error:
Loading library to get version: hdf5.dll
error: Unable to load dependency HDF5, make sure HDF5 is installed properly
error: Could not find module 'hdf5.dll' (or one of its dependencies). Try using the full path with constructor syntax.</em></h2>
<p>ERROR: Failed building wheel for h5py
Failed to build h5py
ERROR: Could not build wheels for h5py which use PEP 517 and cannot be installed directly*.</p>
<p>I tried to install h5py as well but it gives an error too!</p>
<p><a href=""https://i.stack.imgur.com/UO3bN.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/UO3bN.png"" alt=""enter image description here"" /></a></p>
<p>Please let me know if anyone has a solution for this.</p>
",15125750.0,,,,,2021-10-02 17:51:13,How to resolve the ERROR: Failed building wheel for h5py,<python><tensorflow><keras><model><h5py>,1,0,,,,CC BY-SA 4.0
71006896,1,,,2022-02-06 11:57:59,,4,371,"<p>In the TensorFlow documentation it is highlighted that it is important during fine tuning to set the base_model to ’inference mode’ setting the parameter <code>training = False</code> when calling the <code>base_model</code>. The reason to do so is because of the <code>tf.keras.layers.BatchNormalization</code> layers, that should be executed in inference mode during fine tuning.<br />
<a href=""https://www.tensorflow.org/tutorials/images/transfer_learning#fine_tuning"" rel=""nofollow noreferrer"">TensorFlow documentation on Fine Tuning</a></p>
<p>But setting the <code>base_model</code> to inference mode will also affect the <code>tf.keras.layers.Dropout</code> in the <code>base_model</code> as these will then also run in inference mode and will not apply any dropout at all.</p>
<p>What is useful for getting meaningful results when fine tuning a model?</p>
<p>Running the dropout layers in the <code>base_model</code> in inference mode (no dropout at all) or running them in training mode applying the dropout as defined in the <code>base_model</code>?</p>
",11687201.0,,,,,2022-02-06 11:57:59,Fine tuning a model - base_model Dropout in inference or training mode?,<tensorflow><keras><tensorflow2.0><tf.keras>,0,6,,,,CC BY-SA 4.0
68384466,1,,,2021-07-14 20:07:32,,4,5927,"<p>I'm on a project that is taking the Oxford Pets code <a href=""https://keras.io/examples/vision/oxford_pets_image_segmentation/"" rel=""nofollow noreferrer"">https://keras.io/examples/vision/oxford_pets_image_segmentation/</a> and modifying it various ways. We're getting the following warning (when running on Google Colab), and it turns out that the original Oxford Pets code gets that too (also on Google Colab). Is there a way to change the code to not cause the warning?</p>
<p>Here is the warning we get when saving and training the model:</p>
<p>/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
category=CustomMaskWarning)</p>
",16450339.0,,2290436.0,,2021-07-21 03:02:28,2021-07-28 09:26:51,CustomMaskWarning when using Keras OxfordPets code,<python><keras><tf.keras>,1,1,0.0,,,CC BY-SA 4.0
65302480,1,,,2020-12-15 08:36:52,,4,12933,"<p>I am trying train my images. This data's size is 50.000 images.</p>
<p>My images properities are:</p>
<p><a href=""https://i.stack.imgur.com/bkU75.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bkU75.png"" alt=""enter image description here"" /></a></p>
<p>If i should change my images properities, how can i do that?</p>
<p>This is my first image classifier work so there can be a lot of mistake. Please understand.</p>
<p>Can you help improve my code?</p>
<p><strong>This is my code</strong></p>
<pre><code>from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D,MaxPooling2D,Activation,Dropout,Flatten,Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img
import matplotlib.pyplot as plt
from glob import glob
from PIL import Image
import os


import numpy as np

train_path=&quot;Düzgün2/&quot;

images = [train_path for train_path in os.listdir() if train_path.endswith(('jpeg', 'png', 'jpg'))]
for x in images:
    img = Image.open(x)
    img.thumbnail((600,600))
    img.save(&quot;resized_&quot;+x, optimize=True, quality=40)
test_path=&quot;Test/&quot;
data=load_img(train_path + &quot;Basler_acA1440-220um__40052667__20201123_114618747_7932_result.jpg&quot;)
x=np.asarray(data)

plt.imshow(data)
plt.axis(&quot;off&quot;)
plt.show()


print(x.shape)
className=glob(train_path + &quot;/*&quot;)
print(className)
numberOfClass=len(className)
print(&quot;NumberOfClass:&quot;,numberOfClass)

#CNN model

model=Sequential()
model.add(Conv2D(32,(3,3),input_shape=(224,224,3)))#xshape burada gelen resimin pixseli 3 ise rgb yi tesmil ediyor so that senin çivi resimlerine göre ayarla
model.add(Activation(&quot;relu&quot;))
model.add(MaxPooling2D())
model.add(Conv2D(32,(3,3)))#xshape burada gelen resimin pixseli 3 ise rgb yi tesmil ediyor so that senin çivi resimlerine göre ayarla&quot;&quot;&quot;
model.add(Activation(&quot;relu&quot;))
model.add(MaxPooling2D())

model.add(Flatten())
model.add(Dense(1024))#1024 nörondan oluşuyor
model.add(Activation(&quot;relu&quot;))
model.add(Dropout(0.5))
model.add(Dense(numberOfClass))#output
model.add(Activation(&quot;softmax&quot;))

model.compile(loss=&quot;categorical_crossentropy&quot;,optimizer=&quot;rmsprop&quot;,metrics=[&quot;accuracy&quot;])

batch_size=32# her iterasyonda 32 resmi kullan

#data generator

train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.3,
                   horizontal_flip=True,zoom_range=0.3)#rgb 0-255 0-1 ile bir arası değer alıyoruz,shear sağa sola yatırma
test_datagen=(ImageDataGenerator(rescale=1./255))

train_generator=train_datagen.flow_from_directory(train_path,
                                                 target_size=x.shape[:2],batch_size=batch_size,color_mode=&quot;rgb&quot;,
                                                 class_mode=&quot;categorical&quot;)
test_generator=test_datagen.flow_from_directory(test_path,
                                                 target_size=x.shape[:2],batch_size=batch_size,color_mode=&quot;rgb&quot;,
                                                 class_mode=&quot;categorical&quot;)

model.fit_generator(generator=train_generator,steps_per_epoch=1600 // batch_size,epochs=100,validation_data=test_generator,
                        validation_steps=800 // batch_size)
   
</code></pre>
<p><strong>This my output:</strong></p>
<pre><code>NumberOfClass: 11376
2020-12-15 14:10:26.449262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-12-15 14:10:27.159243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s
2020-12-15 14:10:27.159530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-12-15 14:10:27.221768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-12-15 14:10:27.269324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-12-15 14:10:27.275602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-12-15 14:10:27.301737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-12-15 14:10:27.314461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-12-15 14:10:27.407152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-15 14:10:27.407410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-12-15 14:10:27.407830: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-12-15 14:10:27.416924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x193e2fdee00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-15 14:10:27.417440: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-15 14:10:27.417880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s
2020-12-15 14:10:27.418242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-12-15 14:10:27.418413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-12-15 14:10:27.418586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-12-15 14:10:27.418754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-12-15 14:10:27.418922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-12-15 14:10:27.419095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-12-15 14:10:27.419268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-15 14:10:27.419477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-12-15 14:10:28.461954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-15 14:10:28.462106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-12-15 14:10:28.462194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-12-15 14:10:28.462442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4750 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-12-15 14:10:28.465422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1942c7ee0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-15 14:10:28.465660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1660 Ti, Compute Capability 7.5
Found 0 images belonging to 0 classes.
Found 0 images belonging to 0 classes.
WARNING:tensorflow:From C:/Users/tatu/PycharmProjects/pythonProject4/main.py:70: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/100
2020-12-15 14:10:30.182839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
Traceback (most recent call last):
  File &quot;C:/Users/tatu/PycharmProjects/pythonProject4/main.py&quot;, line 70, in &lt;module&gt;
    validation_steps=800 // batch_size)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\util\deprecation.py&quot;, line 324, in new_func
    return func(*args, **kwargs)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 1479, in fit_generator
    initial_epoch=initial_epoch)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 848, in fit
    tmp_logs = train_function(iterator)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 580, in __call__
    result = self._call(*args, **kwds)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 1665, in _filtered_call
    self.captured_inputs)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 598, in call
    ctx=ctx)
  File &quot;C:\Users\tatu\miniconda3\envs\tensorfloww\lib\site-packages\tensorflow\python\eager\execute.py&quot;, line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Reduction axis -1 is empty in shape [0,0]
     [[node ArgMax (defined at /Users/tatu/PycharmProjects/pythonProject4/main.py:70) ]] [Op:__inference_train_function_921]

Function call stack:
train_function

2020-12-15 14:10:30.637723: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
     [[{{node PyFunc}}]]

Process finished with exit code 1

</code></pre>
<p><strong>This is my error</strong></p>
<pre><code>Function call stack:
train_function

2020-12-15 14:10:30.637723: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
     [[{{node PyFunc}}]]
</code></pre>
",14828703.0,,14828703.0,,2020-12-15 12:43:50,2022-06-06 13:57:34,Failed precondition: Python interpreter state is not initialized. The process may be terminated,<python><tensorflow><machine-learning><keras><deep-learning>,2,1,,,,CC BY-SA 4.0
70349395,1,,,2021-12-14 13:08:52,,4,542,"<p>I'm trying to log my ML trials with <code>mlflow.keras.autolog</code> and <code>mlflow.log_param</code> simultaneously (<code>mlflow v 1.22.0</code>). However, the only things that are recorded are <code>autolog</code>'s products, but not those of <code>log_param</code>.</p>
<pre><code>experiment = mlf_client.get_experiment_by_name(experiment_name)
with mlflow.start_run(experiment_id=experiment.experiment_id):
    mlflow.keras.autolog(log_input_examples=True)
    mlflow.log_param('batch_size', self.batch_size)
    mlflow.log_param('training_set_size', len(kwargs['training_ID_list']))
    mlflow.log_param('testing_set_size', len(kwargs['testing_ID_list']))
    
    history = self.train_NN_model(**kwargs)
</code></pre>
<p>I know I can use <code>log_param</code> with <code>log_model</code> to save the model itself, but then I lose some useful stuff that <code>autolog</code> can record for me automatically (e.g., model summary).</p>
<p>Is it possible to use <strong><code>autolog</code></strong> with <strong>custom</strong> parameters for logging?</p>
",13542295.0,,948768.0,,2022-08-08 23:10:44,2023-05-20 06:26:40,how to mlflow autolog with custom parameters,<machine-learning><keras><mlflow>,1,0,0.0,,,CC BY-SA 4.0
68012351,1,68012849.0,,2021-06-17 03:06:59,,4,12568,"<p>while I am trying to run the <code>Parking_Slot_mask_rcnn.py</code> file I got the error as follows in <code>mrcnn/model.py</code> file how can I solve</p>
<p>**&gt; 2021-06-17 08:25:18.585897: W</p>
<blockquote>
<p>tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could
not load dynamic library 'cudart64_110.dll';  dlerror:
cudart64_110.dll not found 2021-06-17 08:25:18.586852: I
tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart
dlerror if you do not have a GPU set up on your machine. Using
TensorFlow backend. Traceback (most recent call last):   File
&quot;Parking_Slot_mask_rcnn.py&quot;, line 20, in 
import coco   File &quot;C:\Users\nusry\Desktop\parkingslot-master\coco.py&quot;, line 56, in

from mrcnn import model as modellib, utils   File &quot;C:\Users\nusry\Desktop\parkingslot-master\mrcnn\model.py&quot;, line 268,
in 
class ProposalLayer(KE.Layer): AttributeError: module 'keras.engine' has no attribute 'Layer**</p>
</blockquote>
<p>here all the import in this model file file</p>
<pre><code>import os
import random
import datetime
import re
import math
import logging
from collections import OrderedDict
import multiprocessing
import numpy as np
import tensorflow as tf
import keras
import keras.backend as K
import keras.layers as KL
import keras.engine as KE
import keras.models as KM

from mrcnn import utils
</code></pre>
<p>And this is line No 268 Code:</p>
<pre><code>class ProposalLayer(KE.Layer):
</code></pre>
<p>Installed:</p>
<pre><code>  Tensorflow version Version: 2.5.0
    
  Keras  Version Version: 2.2.0
</code></pre>
<p>Please help me to sort out</p>
",12102173.0,,12102173.0,,2021-06-17 03:47:18,2022-12-08 17:56:27,AttributeError: module 'keras.engine' has no attribute 'Layer',<python><tensorflow><machine-learning><keras><computer-vision>,3,0,0.0,,,CC BY-SA 4.0
63350484,1,64092221.0,,2020-08-11 02:04:03,,4,5195,"<p>I'm going through the tutorial given in:</p>
<p><a href=""https://www.tensorflow.org/tutorials/structured_data/time_series"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/structured_data/time_series</a></p>
<p>Funny thing, when I ran the code I got the error:</p>
<p><code>AttributeError: module 'tensorflow_core.keras.preprocessing' has no attribute 'timeseries_dataset_from_array'</code></p>
<p>I tried explicitly importing the method like:</p>
<p><code>from tensorflow.keras.preprocessing import timeseries_dataset_from_array</code></p>
<p>but then:</p>
<p><code>ImportError: cannot import name 'timeseries_dataset_from_array'</code></p>
<p>I'm using Spyder 4, Python 3.6.9, TensorFlow 2.1.0 and Keras 2.2.4-tf. Can anyone clarify this to me?</p>
",14051168.0,,14051168.0,,2020-08-12 14:43:45,2020-09-27 19:01:35,Error when calling the method timeseries_dataset_from_array from Keras,<python><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0
63348110,1,,,2020-08-10 21:13:23,,4,3912,"<p>I build the following DL model based on Tensorflow/Keras
but it raises the following error</p>
<pre class=""lang-py prettyprint-override""><code>    model = keras.Sequential()
    model.add(layers.Dense(263, input_dim=263, activation='relu'))
    model.add(layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.1))
    model.add(layers.Dense(56, activation='relu'))
    model.add(layers.Dense(16, activation='relu'))
    model.add(layers.Dropout(0.1))
    model.add( layers.Dense(1, activation='sigmoid', name='class'))
    model.compile(loss='binary_crossentropy',loss_weights={'class':0.5}, optimizer='adam', metrics=['accuracy'])
    model.fit(X_train,Y_train, epochs=20, verbose=0)
</code></pre>
<pre><code>&lt;tensorflow.python.keras.callbacks.History at 0x279ceba2288&gt;
</code></pre>
<p>any one help  me why this error arises ???</p>
<p>is it related to tensorflow version?</p>
",12136050.0,,1021819.0,,2021-07-23 09:44:41,2022-08-10 09:17:42,<tensorflow.python.keras.callbacks.History at 0x279ceba2288>,<python><python-3.x><python-2.7><tensorflow><keras>,1,3,0.0,,,CC BY-SA 4.0
67649606,1,68054756.0,,2021-05-22 12:44:36,,4,921,"<p>I used the LSTM model to predict the future <code>open</code> price of a stock. Here the data was preprocessed and the model was built and trained without any errors, and I used Standard Scaler to scale down the values in the DataFrame. But while retrieving the predictions from the model, when I used the <code>scaler.reverse()</code> method it gave the following error.</p>
<pre><code>ValueError: non-broadcastable output operand with shape (59,1) doesn't match the broadcast shape (59,4)
</code></pre>
<p>The complete code is a too big jupyter notebook to directly show, so I have uploaded it in a <a href=""https://github.com/Samar-080301/help_please"" rel=""nofollow noreferrer"">git repository</a></p>
",11589463.0,,11589463.0,,2021-05-22 12:52:38,2021-06-25 06:00:48,Error in reverse scaling outputs predicted by a LSTM RNN,<python><tensorflow><keras><lstm><recurrent-neural-network>,2,0,,,,CC BY-SA 4.0
63053478,1,,,2020-07-23 11:44:32,,4,1769,"<p>I am exporting tf.Keras 2.2 model using default converter, and everything works good, except it can't use CoreML/GPU accelerator. The reason is &quot;Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.&quot; It is common problem, even in NNDelegate it described. But there is no info in the docs how to solve this.</p>
",13982276.0,,,,,2020-09-28 09:19:44,Export tf.Keras 2.2 model to tflite with Static Tensors for accelerating using delegates,<python><tensorflow><keras><coreml><tensorflow-lite>,0,4,0.0,,,CC BY-SA 4.0
63950888,1,64318155.0,,2020-09-18 07:10:00,,4,8852,"<p>I am building a text classification model for imdb sentiment analysis dataset. I downloaded the dataset and followed the tutorial given here - <a href=""https://developers.google.com/machine-learning/guides/text-classification/step-4"" rel=""nofollow noreferrer"">https://developers.google.com/machine-learning/guides/text-classification/step-4</a></p>
<p>The error I get is</p>
<pre><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt; to Tensor. Contents: SparseTensor(indices=Tensor(&quot;DeserializeSparse:0&quot;, shape=(None, 2), dtype=int64), values=Tensor(&quot;DeserializeSparse:1&quot;, shape=(None,), dtype=float32), dense_shape=Tensor(&quot;stack:0&quot;, shape=(2,), dtype=int64)). Consider casting elements to a supported type.
</code></pre>
<p>the type of x_train and x_val are scipy.sparse.csr.csr_matrix. This give an error when passed to sequential model. How to solve?</p>
<pre><code>import tensorflow as tf
import numpy as np

from tensorflow.python.keras.preprocessing import sequence
from tensorflow.python.keras.preprocessing import text
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

# Vectorization parameters

# Range (inclusive) of n-gram sizes for tokenizing text.
NGRAM_RANGE = (1, 2)

# Limit on the number of features. We use the top 20K features.
TOP_K = 20000

# Whether text should be split into word or character n-grams.
# One of 'word', 'char'.
TOKEN_MODE = 'word'

# Minimum document/corpus frequency below which a token will be discarded.
MIN_DOCUMENT_FREQUENCY = 2

# Limit on the length of text sequences. Sequences longer than this
# will be truncated.
MAX_SEQUENCE_LENGTH = 500


def ngram_vectorize(train_texts, train_labels, val_texts):
    &quot;&quot;&quot;Vectorizes texts as ngram vectors.
    1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.
    # Arguments
        train_texts: list, training text strings.
        train_labels: np.ndarray, training labels.
        val_texts: list, validation text strings.
    # Returns
        x_train, x_val: vectorized training and validation texts
    &quot;&quot;&quot;
    # Create keyword arguments to pass to the 'tf-idf' vectorizer.
    kwargs = {
            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.
            'dtype': 'int32',
            'strip_accents': 'unicode',
            'decode_error': 'replace',
            'analyzer': TOKEN_MODE,  # Split text into word tokens.
            'min_df': MIN_DOCUMENT_FREQUENCY,
    }
    vectorizer = TfidfVectorizer(**kwargs)

    # Learn vocabulary from training texts and vectorize training texts.
    x_train = vectorizer.fit_transform(train_texts)

    # Vectorize validation texts.
    x_val = vectorizer.transform(val_texts)

    # Select top 'k' of the vectorized features.
    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))
    selector.fit(x_train, train_labels)
    x_train = selector.transform(x_train)
    x_val = selector.transform(x_val)

    x_train = x_train.astype('float32')
    x_val = x_val.astype('float32')
    return x_train, x_val
</code></pre>
",4555441.0,,,,,2022-03-19 08:54:31,TypeError: Failed to convert object of type Sparsetensor to Tensor,<python><keras>,3,0,0.0,,,CC BY-SA 4.0
67706092,1,67706235.0,,2021-05-26 13:36:23,,4,4522,"<p>I'm testing a basic neural network model. But before go any further I've encountered this error shown in the screenshot.</p>
<p><strong>Here is my code:</strong></p>
<pre><code>import numpy as np

# Training Data
x_train = np.array([[1.0,1.0]])
y_train = np.array([2.0])


for i in range(3,10000,2):
    x_train = np.append(x_train,[[i,i]],axis = 0)
    y_train = np.append(y_train,[i+i],axis = 0)


# Test Data
import numpy as np

x_test = np.array([[2.0,2.0]])
y_test = np.array([4.0])

for i in range(4,8000,4):
    x_test = np.append(x_test,[[i,i]],axis = 0)
    y_test = np.append(y_test,[i+i])

from tensorflow import keras    
from keras.layers import Flatten   # to flatten the input data
from keras.layers import Dense     # for the hidden layer

# We'll follow sequential method i.e. one after the other(input layer ---&gt; hidden layer---&gt; output layer) 

model = keras.Sequential()

# For input layer
model.add(Flatten(input_shape = x_train[0].shape))   # input layer

# For Hidden layer
model.add(Dense(2,activation = 'relu'))    # '2' represents a no. of neurons

# For Output layer
model.add(Dense(1))   # By default, activation = 'linear'

# before training
bf_train = model.get_weights()
bf_train
</code></pre>
<p>The error is :</p>
<p>ValueError: Weights for model sequential have not yet been created. Weights are created when the Model is first called on inputs or <code>build()</code> is called with an <code>input_shape</code>.</p>
",16038099.0,,,,,2021-05-26 13:44:36,ValueError : Weights for model sequential have not yet been created,<python><tensorflow><keras>,1,0,,,,CC BY-SA 4.0
64959524,1,64987854.0,,2020-11-22 21:04:42,,4,826,"<p>I have read a sequence of images (frames) into a numpy array with shape <code>(9135, 200, 200, 4)</code> where 9135 is the sample size, 200 is height and width in 4 channel (R-G-B-Depth) images.</p>
<p>I have a sequential model with an LSTM layer:</p>
<pre><code>  x_train=np.reshape(x_train,(x_train.shape[0],x_train.shape[1],x_train.shape[2],x_train.shape[3],1))
  #(9135, 200, 200, 4, 1)
  x_val=np.reshape(x_val,(x_val.shape[0],x_val.shape[1],x_val.shape[2],x_val.shape[3],1))
  #(3046, 200, 200, 4, 1)

  model = Sequential()
  model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu'), input_shape=(200, 200, 4)))

  model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu')))
  model.add(TimeDistributed(GlobalAveragePooling2D()))
  model.add(LSTM(1024, activation='relu', return_sequences=False))
  model.add(Dense(1024, activation='relu'))
  model.add(Dropout(.5))
  model.add(Dense(10, activation='sigmoid'))
  model.compile('adam', loss='categorical_crossentropy')
  model.summary()

  history = model.fit(x_train, y_train, epochs=epochs,batch_size=batch_size,verbose=verbose, validation_data=(x_val, y_val))
</code></pre>
<p>but there is an error in the result:</p>
<blockquote>
<p>ValueError: Input 0 of layer conv2d is incompatible with the layer: :
expected min_ndim=4, found ndim=3. Full shape received: [None, 200, 4]</p>
</blockquote>
<p>What is the suggested way to input a 4 channel image into an LSTM layer in Keras?</p>
<p>PS: Εach class has different frames so I do not know how to put unstable timestep</p>
",14688283.0,,14688283.0,,2020-11-23 13:21:57,2020-11-24 13:47:26,Input a 4 channel RGB-D Image into LSTM,<python><tensorflow><keras><deep-learning><lstm>,1,4,,,,CC BY-SA 4.0
67684738,1,67690934.0,,2021-05-25 08:53:25,,4,190,"<p>I like to load a ML Model in a React-Native App. <br>
I converted Keras model <code>model.h5</code> to <code>model.json</code> and binary weight files using this command.</p>
<pre><code>tensorflowjs_converter --input_format=keras /tmp/model.h5 /tmp/tfjs_model
</code></pre>
<p>App Code</p>
<pre><code>import * as tf from &quot;@tensorflow/tfjs&quot;
import { bundleResourceIO } from &quot;@tensorflow/tfjs-react-native&quot;

const modelJson = require(&quot;model.json&quot;)
const modelWeights = require(&quot;weights.bin&quot;)

await tf.ready().then(async () =&gt; {
  try {
    const modelBundle = bundleResourceIO(modelJson, modelWeights)
    console.log(&quot;modelBundle&quot;, modelBundle)
    // Output
    /**
     * {&quot;modelJson&quot;: {&quot;convertedBy&quot;: &quot;TensorFlow.js Converter v3.6.0&quot;, &quot;format&quot;: &quot;layers-model&quot;,
     * &quot;generatedBy&quot;: &quot;keras v2.4.0&quot;, &quot;modelTopology&quot;: {&quot;backend&quot;: &quot;tensorflow&quot;,
     * &quot;keras_version&quot;: &quot;2.4.0&quot;, &quot;model_config&quot;: [Object]}, &quot;weightsManifest&quot;: [[Object]]},
     * &quot;modelWeightsId&quot;: 4}
     */
    await tf
      .loadLayersModel(bundleResourceIO(modelJson, modelWeights))
      .then((layersModel) =&gt; console.log(&quot;layersModel&quot;, layersModel))
    // Output
    /**
     * [Error: Unknown activation: swish. This may be due to one of the following reasons: 
     * 1. The activation is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
     * 2. The custom activation is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().]
    */
    await tf
      .loadGraphModel(bundleResourceIO(modelJson, modelWeights))
      .then((graphModel) =&gt; console.log(&quot;graphModel&quot;, graphModel))
    // Output
    /**
     * [TypeError: undefined is not an object (evaluating 'graph.versions.producer')]
     */
  } catch (error) {
    console.log(&quot;error&quot;, error)
  }
})
</code></pre>
<p>I tried changing <code>modelTopology.model_config.class_name</code> in <code>model.json</code> from <code>Functional</code> to <code>Model</code> still the same result.</p>
<p>Packages Versions:</p>
<pre><code>&quot;@tensorflow/tfjs&quot;: &quot;3.4.0&quot;,
&quot;@tensorflow/tfjs-react-native&quot;: &quot;^0.5.0&quot;,
</code></pre>
",7273158.0,,5069957.0,,2021-05-25 15:19:39,2021-05-25 15:19:39,Unknown activation: swish,<react-native><tensorflow><keras><tensorflow.js>,1,0,0.0,,,CC BY-SA 4.0
70973309,1,,,2022-02-03 14:45:32,,4,362,"<p>I'm trying to load a saved Tensorflow ELMO model in a different function than I trained it, because I want to do multiple predictions with the model without having to train it every time. My (simplified) code is as follows:</p>
<pre class=""lang-py prettyprint-override""><code>(builder.py)

from word_classifier import train_word_classifier, predict_labels

def builder(lines):

    train_word_classifier()

    for lst in lines:
        print('PRED_LABELS: ', predict_labels(lst))

</code></pre>
<pre class=""lang-py prettyprint-override""><code>(word_classifier.py)

import pandas as pd
import numpy as np

import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.python.keras import backend as K

from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model, Sequential, model_from_json
from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda, add, Input


def train_word_classifier():

   &quot;&quot;&quot;
   Input data preparation excluded for readability
   &quot;&quot;&quot;

    sess = tf.compat.v1.Session()
    K.set_session(sess)

    elmo_model = hub.Module(&quot;https://tfhub.dev/google/elmo/3&quot;, trainable=True)
    init = tf.compat.v1.global_variables_initializer()

    sess.run(init)

    input_text = Input(shape=(MAX_LEN,), dtype=tf.string)

    def elmo_embedding(inData):
        return \
            elmo_model(inputs={&quot;tokens&quot;: tf.squeeze(tf.cast(inData, tf.string)),
                               &quot;sequence_len&quot;: tf.constant(BATCH_SIZE * [MAX_LEN])},
                       signature=&quot;tokens&quot;, as_dict=True)[&quot;elmo&quot;]

    embedding = Lambda(lambda text, : elmo_embedding(text), output_shape=(MAX_LEN, 1024))(input_text, )

    x = Bidirectional(LSTM(units=LSTM_UNITS, return_sequences=LSTM_RETURN_SEQ,
                           recurrent_dropout=LSTM_RO_DROPOUT, dropout=LSTM_DROPOUT))(embedding)
    x_rnn = Bidirectional(LSTM(units=LSTM_UNITS, return_sequences=LSTM_RETURN_SEQ,
                               recurrent_dropout=LSTM_RO_DROPOUT, dropout=LSTM_DROPOUT))(x)
    x = add([x, x_rnn])  # residual connection to the first biLSTM
    out = TimeDistributed(Dense(n_tags, activation=&quot;softmax&quot;))(x)
    model = Model(input_text, out)
    model.compile(optimizer=&quot;adam&quot;, loss=&quot;sparse_categorical_crossentropy&quot;, metrics=[&quot;accuracy&quot;])

    line_count_training_data = count_lines_in_file(CLASSIFIER_SENTENCE_FILE, 10)
    size_train, size_test = get_count_for_batch_train_test_data(line_count_training_data)
    print(size_train)
    mode_dict = {
            &quot;train&quot;: size_train,
            &quot;test&quot;: size_test,
        }

    x_tr, x_val = x_tr[:mode_dict[&quot;train&quot;] * BATCH_SIZE], x_tr[-mode_dict[&quot;test&quot;] * BATCH_SIZE:]
    y_tr, y_val = y_tr[:mode_dict[&quot;train&quot;] * BATCH_SIZE], y_tr[-mode_dict[&quot;test&quot;] * BATCH_SIZE:]
    y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)
    y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)
    
    history = model.fit(np.array(x_tr),
                        y_tr,
                        validation_data=(np.array(x_val), y_val),
                        batch_size=BATCH_SIZE,
                        epochs=NUM_EPOCHS,
                        verbose=VERBOSE_VALUE)

    model_json = model.to_json()
    with open(&quot;resources/SavedModel/word_classifier/model.json&quot;, &quot;w&quot;) as json_file:
        json_file.write(model_json)
    # serialize weights to HDF5
    model.save_weights(&quot;resources/SavedModel/word_classifier/model.h5&quot;)


def predict_labels(input_data_list):

    with open('resources/SavedModel/word_classifier/model.json', 'r') as json_file:
        loaded_model_json = json_file.read()

    def elmo_embedding(inData):
        return \
            elmo_model(inputs={&quot;tokens&quot;: tf.squeeze(tf.cast(inData, tf.string)),
                               &quot;sequence_len&quot;: tf.constant(BATCH_SIZE * [MAX_LEN])},
                       signature=&quot;tokens&quot;, as_dict=True)[&quot;elmo&quot;]

    loaded_model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={'elmo_embedding': elmo_embedding})

    # load weights into new model
    loaded_model.load_weights(&quot;resources/SavedModel/word_classifier/model.h5&quot;)
    print(&quot;Loaded model from disk&quot;)
</code></pre>
<p>In the end, after training the model, this gives me the error &quot;TypeError: 'str' object is not callable&quot; with the following traceback:</p>
<pre><code>Traceback (most recent call last):
  File &quot;usc_coordinator.py&quot;, line 62, in &lt;module&gt;
    run_usc_coordinator(fIn, fOut, mode)
  File &quot;usc_coordinator.py&quot;, line 32, in run_usc_coordinator
    user_story_builder(fast_mode, file_in)
  File &quot;/home/ubuntu/PA/PA_AI4US/PythonVersion/src/builder.py&quot;, line 45, in builder
    print('PRED_LABELS: ', predict_labels(lst))
  File &quot;/home/ubuntu/PA/PA_AI4US/PythonVersion/src/word_classifier.py&quot;, line 161, in predict_labels
    loaded_model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={'elmo_embedding': elmo_embedding})
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/saving/model_config.py&quot;, line 122, in model_from_json
    return deserialize(config, custom_objects=custom_objects)
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py&quot;, line 171, in deserialize
    return generic_utils.deserialize_keras_object(
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py&quot;, line 354, in deserialize_keras_object
    return cls.from_config(
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py&quot;, line 616, in from_config
    input_tensors, output_tensors, created_layers = reconstruct_from_config(
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py&quot;, line 1214, in reconstruct_from_config
    process_node(layer, node_data)
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py&quot;, line 1162, in process_node
    output_tensors = layer(input_tensors, **kwargs)
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py&quot;, line 776, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File &quot;/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py&quot;, line 903, in call
    result = self.function(inputs, **kwargs)
  File &quot;/home/ubuntu/PA/PA_AI4US/PythonVersion/src/word_classifier.py&quot;, line 101, in &lt;lambda&gt;
    embedding = Lambda(lambda text, : elmo_embedding(text), output_shape=(MAX_LEN, 1024))(input_text, )
TypeError: 'str' object is not callable

</code></pre>
<p>My versions are:</p>
<pre><code>Python 3.8.10
Keras 2.3.0
Tensorflow 2.3.1
Tensorflow-hub 0.10.0
</code></pre>
<p>My guess is that the error is caused by the variable input_text that is set as a dtype tf.string. However, I don't how what to do about that without breaking the training sequence.</p>
<p>I hope that somebody can help!</p>
",16537776.0,,16537776.0,,2022-02-03 14:56:24,2022-09-20 04:21:20,"Trying to load a saved Tensorflow ELMO model but get ""TypeError: 'str' object is not callable"" when loading",<python><tensorflow><keras><lambda><typeerror>,2,1,,,,CC BY-SA 4.0
65302030,1,65303441.0,,2020-12-15 08:01:19,,4,2504,"<p>I read this <a href=""https://www.tensorflow.org/guide/keras/custom_callback"" rel=""nofollow noreferrer"">https://www.tensorflow.org/guide/keras/custom_callback</a>, but I don't know how I could get all the other parameters.</p>
<p>This is my code</p>
<pre><code> (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)
  hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]
  print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]' 
                  % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))
 if hr &gt; best_hr:
     best_hr, best_ndcg, best_iter = hr, ndcg, epoch
 if args.out &gt; 0:
     model.save(model_out_file, overwrite=True)
</code></pre>
<p>As you can see I need <code>model</code>, <code>hist</code> and <code>model.save</code>.
Is there a way to use these three parameters in a custom callback?
So that I can write all of this into a custom callback.</p>
<pre><code>class CustomCallback(keras.callbacks.Callback):

   def on_epoch_end(self, logs=None):
       keys = list(logs.keys())
       print(&quot;Stop training; got log keys: {}&quot;.format(keys))
</code></pre>
",14721684.0,,14721684.0,,2020-12-15 10:03:57,2020-12-15 14:28:56,Access loss and model in a custom callback,<python><tensorflow><keras><callback>,1,0,,,,CC BY-SA 4.0
67703514,1,67751009.0,,2021-05-26 10:57:56,,4,1827,"<p>Tensorflow issue  google colab :  module 'tensorflow._api.v1.compat.v2' has no attribute '<strong>internal</strong>'
I am running a MASK RCNN model on google colab With tensorflow 1.15 and keras 2.1.6 every thing work correctly but Today, I got this error:
<a href=""https://i.stack.imgur.com/tP73l.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
",15951143.0,,,,,2021-05-29 11:56:48,Tensorflow issue google colab ; tensorflow._api.v1.compat.v2' has no attribute '__internal__,<python><tensorflow><keras><google-colaboratory>,1,3,0.0,,,CC BY-SA 4.0
70274978,1,70322298.0,,2021-12-08 12:24:30,,4,469,"<p>I have an input that is a time series of 5 dimensions:</p>
<p><code>a = [[8,3],[2] , [4,5],[1], [9,1],[2]...]</code> <code>#total 100 timestamps. For each element, dims 0,1 are numerical data and dim 2 is a numerical encoding of a category. This is per sample, 3200 samples</code></p>
<p>The category has 3 possible values (0,1,2)</p>
<p>I want to build a NN such that the last dimension (the category) will go through an embedding layer with output size 8, and then will be concatenated back to the first two dims (the numerical data).</p>
<p>So, this will be something like:</p>
<pre><code>input1 = keras.layers.Input(shape=(2,)) #the numerical features
input2 = keras.layers.Input(shape=(1,)) #the encoding of the categories. this part will be embedded to 5 dims
x2 = Embedding(input_dim=1, output_dim = 8)(input2) #apply it to every timestamp and take only dim 3, so [2],[1], [2] 
x = concatenate([input1,x2]) #will get 10 dims at each timepoint, still 100 timepoints
x = LSTM(units=24)(x) #the input has 10 dims/features at each timepoint, total 100 timepoints per sample
x = Dense(1, activation='sigmoid')(x)
model = Model(inputs=[input1, input2] , outputs=[x]) #input1 is 1D vec of the width 2 , input2 is 1D vec with the width 1 and it is going through the embedding
model.compile(
        loss='binary_crossentropy',
        optimizer='adam',
        metrics=['acc']
    )
</code></pre>
<p>How can I do it? (preferably in keras)?
My problem is how to apply the embedding to every time point?
Meaning, if I have 1000 timepoints with 3 dims each, I need to convert it to 1000 timepoints with 8 dims each (The emebedding layer should transform input2 from (1000X1) to (1000X8)</p>
",6057371.0,,6057371.0,,2021-12-12 10:59:29,2021-12-12 11:08:30,Deep Learning how to split 5 dimensions timeseries and pass some dimensions through embedding layer,<python><tensorflow><keras><deep-learning><neural-network>,2,7,,,,CC BY-SA 4.0
67694114,1,,,2021-05-25 19:04:51,,4,2545,"<p>I have running a machine learning model (Matterport's Mask R-CNN) in google colab for a couple of weeks.  All of a sudden today I am unable to run any of my notebooks due to I think some kind of dependency mismatch error.  The full error is as follows:</p>
<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-3-d76d39ae81e5&gt; in &lt;module&gt;()
     11 
     12 import tensorflow as tf
---&gt; 13 import keras
     14 import platform
     15 

8 frames
/usr/local/lib/python3.7/dist-packages/keras/__init__.py in &lt;module&gt;()
      1 from __future__ import absolute_import
      2 
----&gt; 3 from . import utils
      4 from . import activations
      5 from . import applications

/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py in &lt;module&gt;()
     23 from .np_utils import to_categorical
     24 from .np_utils import normalize
---&gt; 25 from .multi_gpu_utils import multi_gpu_model

/usr/local/lib/python3.7/dist-packages/keras/utils/multi_gpu_utils.py in &lt;module&gt;()
      5 from __future__ import print_function
      6 
----&gt; 7 from ..layers.merge import concatenate
      8 from .. import backend as K
      9 from ..layers.core import Lambda

/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py in &lt;module&gt;()
      2 
      3 from ..utils.generic_utils import deserialize_keras_object
----&gt; 4 from ..engine import Layer
      5 from ..engine import Input
      6 from ..engine import InputLayer

/usr/local/lib/python3.7/dist-packages/keras/engine/__init__.py in &lt;module&gt;()
      1 # note: topology.Node is an internal class,
      2 # it isn't meant to be used by Keras users.
----&gt; 3 from .topology import InputSpec
      4 from .topology import Input
      5 from .topology import InputLayer

/usr/local/lib/python3.7/dist-packages/keras/engine/topology.py in &lt;module&gt;()
     16 
     17 from .. import backend as K
---&gt; 18 from .. import initializers
     19 from ..utils.io_utils import ask_to_proceed_with_overwrite
     20 from ..utils.layer_utils import print_summary as print_layer_summary

/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py in &lt;module&gt;()
    122 # from ALL_OBJECTS. We make no guarantees as to whether these objects will
    123 # using their correct version.
--&gt; 124 populate_deserializable_objects()
    125 globals().update(LOCAL.ALL_OBJECTS)
    126 

/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py in populate_deserializable_objects()
     47 
     48   LOCAL.ALL_OBJECTS = {}
---&gt; 49   LOCAL.GENERATED_WITH_V2 = tf.__internal__.tf2.enabled()
     50 
     51   # Compatibility aliases (need to exist in both V1 and V2).

/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/module_wrapper.py in __getattr__(self, name)
    191   def __getattr__(self, name):
    192     try:
--&gt; 193       attr = getattr(self._tfmw_wrapped_module, name)
    194     except AttributeError:
    195       if not self._tfmw_public_apis:

AttributeError: module 'tensorflow._api.v1.compat.v2' has no attribute '__internal__'
</code></pre>
<p>the pip list of my installed dependency versions is:</p>
<pre><code>Package                       Version            
----------------------------- -------------------
absl-py                       0.12.0             
alabaster                     0.7.12             
albumentations                0.1.12             
altair                        4.1.0              
appdirs                       1.4.4              
argon2-cffi                   20.1.0             
arviz                         0.11.2             
astor                         0.8.1              
astropy                       4.2.1              
astunparse                    1.6.3              
async-generator               1.10               
atari-py                      0.2.9              
atomicwrites                  1.4.0              
attrs                         21.2.0             
audioread                     2.1.9              
autograd                      1.3                
Babel                         2.9.1              
backcall                      0.2.0              
backports.tempfile            1.0                
backports.weakref             1.0.post1          
beautifulsoup4                4.6.3              
bleach                        3.3.0              
blis                          0.4.1              
bokeh                         2.3.2              
Bottleneck                    1.3.2              
branca                        0.4.2              
bs4                           0.0.1              
bz2file                       0.98               
CacheControl                  0.12.6             
cached-property               1.5.2              
cachetools                    4.2.2              
catalogue                     1.0.0              
certifi                       2020.12.5          
cffi                          1.14.5             
cftime                        1.5.0              
chainer                       7.4.0              
chardet                       3.0.4              
click                         7.1.2              
cloudpickle                   1.3.0              
cmake                         3.12.0             
cmdstanpy                     0.9.5              
colorcet                      2.0.6              
colorlover                    0.3.0              
community                     1.0.0b1            
contextlib2                   0.5.5              
convertdate                   2.3.2              
coverage                      3.7.1              
coveralls                     0.5                
crcmod                        1.7                
cufflinks                     0.17.3             
cupy-cuda101                  7.4.0              
cvxopt                        1.2.6              
cvxpy                         1.0.31             
cycler                        0.10.0             
cymem                         2.0.5              
Cython                        0.29.23            
daft                          0.0.4              
dask                          2.12.0             
datascience                   0.10.6             
debugpy                       1.0.0              
decorator                     4.4.2              
defusedxml                    0.7.1              
descartes                     1.1.0              
dill                          0.3.3              
distributed                   1.25.3             
dlib                          19.18.0            
dm-sonnet                     1.35               
dm-tree                       0.1.6              
docopt                        0.6.2              
docutils                      0.17.1             
dopamine-rl                   1.0.5              
earthengine-api               0.1.266            
easydict                      1.9                
ecos                          2.0.7.post1        
editdistance                  0.5.3              
en-core-web-sm                2.2.5              
entrypoints                   0.3                
ephem                         3.7.7.1            
et-xmlfile                    1.1.0              
fa2                           0.3.5              
fastai                        1.0.61             
fastdtw                       0.3.4              
fastprogress                  1.0.0              
fastrlock                     0.6                
fbprophet                     0.7.1              
feather-format                0.4.1              
filelock                      3.0.12             
firebase-admin                4.4.0              
fix-yahoo-finance             0.0.22             
Flask                         1.1.4              
flatbuffers                   1.12               
folium                        0.8.3              
future                        0.16.0             
gast                          0.2.2              
GDAL                          2.2.2              
gdown                         3.6.4              
gensim                        3.6.0              
geographiclib                 1.50               
geopy                         1.17.0             
gevent                        1.4.0              
gin-config                    0.4.0              
glob2                         0.7                
google                        2.0.3              
google-api-core               1.26.3             
google-api-python-client      1.12.8             
google-auth                   1.30.0             
google-auth-httplib2          0.0.4              
google-auth-oauthlib          0.4.4              
google-cloud-bigquery         1.21.0             
google-cloud-bigquery-storage 1.1.0              
google-cloud-core             1.0.3              
google-cloud-datastore        1.8.0              
google-cloud-firestore        1.7.0              
google-cloud-language         1.2.0              
google-cloud-storage          1.18.1             
google-cloud-translate        1.5.0              
google-colab                  1.0.0              
google-pasta                  0.2.0              
google-resumable-media        0.4.1              
googleapis-common-protos      1.53.0             
googledrivedownloader         0.4                
graph-nets                    1.0.5              
graphviz                      0.10.1             
greenlet                      0.4.15             
grpcio                        1.34.1             
gspread                       3.0.1              
gspread-dataframe             3.0.8              
gunicorn                      20.0.4             
gym                           0.17.3             
h5py                          3.1.0              
HeapDict                      1.0.1              
hijri-converter               2.1.1              
holidays                      0.10.5.2           
holoviews                     1.14.3             
html5lib                      1.0.1              
httpimport                    0.5.18             
httplib2                      0.17.4             
httplib2shim                  0.0.3              
humanize                      0.5.1              
hyperopt                      0.1.2              
ideep4py                      2.0.0.post3        
idna                          2.10               
imageio                       2.4.1              
imagesize                     1.2.0              
imbalanced-learn              0.4.3              
imblearn                      0.0                
imgaug                        0.2.9              
importlib-metadata            4.0.1              
importlib-resources           5.1.3              
imutils                       0.5.4              
inflect                       2.1.0              
iniconfig                     1.1.1              
install                       1.3.4              
intel-openmp                  2021.2.0           
intervaltree                  2.1.0              
ipykernel                     4.10.1             
ipyparallel                   6.3.0              
ipython                       5.5.0              
ipython-genutils              0.2.0              
ipython-sql                   0.3.9              
ipywidgets                    7.6.3              
itsdangerous                  1.1.0              
jax                           0.2.13             
jaxlib                        0.1.66+cuda110     
jdcal                         1.4.1              
jedi                          0.18.0             
jieba                         0.42.1             
Jinja2                        2.11.3             
joblib                        1.0.1              
jpeg4py                       0.1.4              
jsonschema                    2.6.0              
jupyter                       1.0.0              
jupyter-client                5.3.5              
jupyter-console               5.2.0              
jupyter-core                  4.7.1              
jupyterlab-pygments           0.1.2              
jupyterlab-widgets            1.0.0              
kaggle                        1.5.12             
kapre                         0.3.5              
Keras                         2.1.5              
Keras-Applications            1.0.8              
keras-nightly                 2.5.0.dev2021032900
Keras-Preprocessing           1.1.2              
keras-vis                     0.4.1              
kfac                          0.2.0              
kiwisolver                    1.3.1              
korean-lunar-calendar         0.2.1              
librosa                       0.8.0              
lightgbm                      2.2.3              
llvmlite                      0.34.0             
lmdb                          0.99               
lucid                         0.3.10             
LunarCalendar                 0.0.9              
lxml                          4.2.6              
magenta                       0.3.19             
Markdown                      3.3.4              
MarkupSafe                    2.0.1              
mask-rcnn                     2.1                
matplotlib                    3.2.2              
matplotlib-inline             0.1.2              
matplotlib-venn               0.11.6             
mesh-tensorflow               0.1.12             
mido                          1.2.6              
mir-eval                      0.5                
missingno                     0.4.2              
mistune                       0.8.4              
mizani                        0.6.0              
mkl                           2019.0             
mlxtend                       0.14.0             
more-itertools                8.7.0              
moviepy                       0.2.3.5            
mpi4py                        3.0.3              
mpmath                        1.2.1              
msgpack                       1.0.2              
multiprocess                  0.70.11.1          
multitasking                  0.0.9              
murmurhash                    1.0.5              
music21                       5.5.0              
natsort                       5.5.0              
nbclient                      0.5.3              
nbconvert                     5.6.1              
nbformat                      5.1.3              
nest-asyncio                  1.5.1              
netCDF4                       1.5.6              
networkx                      2.5.1              
nibabel                       3.0.2              
nltk                          3.2.5              
nose                          1.3.7              
notebook                      5.3.1              
numba                         0.51.2             
numexpr                       2.7.3              
numpy                         1.19.5             
nvidia-ml-py3                 7.352.0            
oauth2client                  4.1.3              
oauthlib                      3.1.0              
okgrade                       0.4.3              
opencv-contrib-python         4.1.2.30           
opencv-python                 4.1.2.30           
openpyxl                      2.5.9              
opt-einsum                    3.3.0              
osqp                          0.6.2.post0        
packaging                     20.9               
palettable                    3.3.0              
pandas                        1.1.5              
pandas-datareader             0.9.0              
pandas-gbq                    0.13.3             
pandas-profiling              1.4.1              
pandocfilters                 1.4.3              
panel                         0.11.3             
param                         1.10.1             
parso                         0.8.2              
pathlib                       1.0.1              
patsy                         0.5.1              
pexpect                       4.8.0              
pickleshare                   0.7.5              
Pillow                        7.1.2              
pip                           19.3.1             
pip-tools                     4.5.1              
plac                          1.1.3              
plotly                        4.4.1              
plotnine                      0.6.0              
pluggy                        0.7.1              
pooch                         1.3.0              
portpicker                    1.3.9              
prefetch-generator            1.0.1              
preshed                       3.0.5              
pretty-midi                   0.2.8              
prettytable                   2.1.0              
progressbar2                  3.38.0             
prometheus-client             0.10.1             
promise                       2.3                
prompt-toolkit                1.0.18             
protobuf                      3.12.4             
psutil                        5.4.8              
psycopg2                      2.7.6.1            
ptyprocess                    0.7.0              
py                            1.10.0             
pyarrow                       3.0.0              
pyasn1                        0.4.8              
pyasn1-modules                0.2.8              
pycocotools                   2.0.2              
pycparser                     2.20               
pyct                          0.4.8              
pydata-google-auth            1.2.0              
pydot                         1.3.0              
pydot-ng                      2.0.0              
pydotplus                     2.0.2              
PyDrive                       1.3.1              
pyemd                         0.5.1              
pyerfa                        2.0.0              
pyglet                        1.5.0              
Pygments                      2.6.1              
pygobject                     3.26.1             
pymc3                         3.11.2             
PyMeeus                       0.5.11             
pymongo                       3.11.4             
pymystem3                     0.2.0              
PyOpenGL                      3.1.5              
pyparsing                     2.4.7              
pypng                         0.0.20             
pyrsistent                    0.17.3             
pysndfile                     1.3.8              
PySocks                       1.7.1              
pystan                        2.19.1.1           
pytest                        3.6.4              
python-apt                    0.0.0              
python-chess                  0.23.11            
python-dateutil               2.8.1              
python-louvain                0.15               
python-rtmidi                 1.4.0              
python-slugify                5.0.2              
python-utils                  2.5.6              
pytz                          2018.9             
pyviz-comms                   2.0.1              
PyWavelets                    1.1.1              
PyYAML                        3.13               
pyzmq                         22.0.3             
qdldl                         0.1.5.post0        
qtconsole                     5.1.0              
QtPy                          1.9.0              
regex                         2019.12.20         
requests                      2.23.0             
requests-oauthlib             1.3.0              
resampy                       0.2.2              
retrying                      1.3.3              
rpy2                          3.4.4              
rsa                           4.7.2              
scikit-image                  0.16.2             
scikit-learn                  0.22.2.post1       
scipy                         1.4.1              
screen-resolution-extra       0.0.0              
scs                           2.1.3              
seaborn                       0.11.1             
semantic-version              2.8.4              
semver                        2.13.0             
Send2Trash                    1.5.0              
setuptools                    56.1.0             
setuptools-git                1.2                
Shapely                       1.7.1              
simplegeneric                 0.8.1              
six                           1.15.0             
sklearn                       0.0                
sklearn-pandas                1.8.0              
smart-open                    5.0.0              
snowballstemmer               2.1.0              
sortedcontainers              2.4.0              
SoundFile                     0.10.3.post1       
spacy                         2.2.4              
Sphinx                        1.8.5              
sphinxcontrib-serializinghtml 1.1.4              
sphinxcontrib-websupport      1.2.4              
SQLAlchemy                    1.4.15             
sqlparse                      0.4.1              
srsly                         1.0.5              
stable-baselines              2.2.1              
statsmodels                   0.10.2             
sympy                         1.7.1              
tables                        3.4.4              
tabulate                      0.8.9              
tblib                         1.7.0              
tensor2tensor                 1.14.1             
tensorboard                   1.15.0             
tensorboard-data-server       0.6.1              
tensorboard-plugin-wit        1.8.0              
tensorflow                    1.15.2             
tensorflow-datasets           4.0.1              
tensorflow-estimator          1.15.1             
tensorflow-gan                2.0.0              
tensorflow-gcs-config         2.5.0              
tensorflow-hub                0.12.0             
tensorflow-metadata           1.0.0              
tensorflow-probability        0.7.0              
termcolor                     1.1.0              
terminado                     0.10.0             
testpath                      0.5.0              
text-unidecode                1.3                
textblob                      0.15.3             
tflearn                       0.3.2              
Theano-PyMC                   1.1.2              
thinc                         7.4.0              
tifffile                      2021.4.8           
toml                          0.10.2             
toolz                         0.11.1             
torch                         1.8.1+cu101        
torchsummary                  1.5.1              
torchtext                     0.9.1              
torchvision                   0.9.1+cu101        
tornado                       5.1.1              
tqdm                          4.41.1             
traitlets                     5.0.5              
tweepy                        3.10.0             
typeguard                     2.7.1              
typing-extensions             3.7.4.3            
tzlocal                       1.5.1              
uritemplate                   3.0.1              
urllib3                       1.24.3             
vega-datasets                 0.9.0              
wasabi                        0.8.2              
wcwidth                       0.2.5              
webencodings                  0.5.1              
Werkzeug                      1.0.1              
wheel                         0.36.2             
widgetsnbextension            3.5.1              
wordcloud                     1.5.0              
wrapt                         1.12.1             
xarray                        0.18.2             
xgboost                       0.90               
xkit                          0.0.0              
xlrd                          1.1.0              
xlwt                          1.3.0              
yellowbrick                   0.9.1              
zict                          2.0.0              
zipp                          3.4.1              
zmq                           0.0.0
</code></pre>
<p>How can I get my environment working again?</p>
",11269041.0,,,,,2021-05-28 16:25:11,Sudden Tensorflow / Keras Google Colab dependency problems `AttributeError: module 'tensorflow._api.v1.compat.v2' has no attribute '__internal__'`,<python><tensorflow><machine-learning><keras><google-colaboratory>,3,1,0.0,,,CC BY-SA 4.0
63104255,1,63339516.0,,2020-07-26 18:44:55,,4,7428,"<p>I am trying to run a code using keras. The program uses <code>from keras.backend.tensorflow_backend import set_session</code> and i am getting an underhanded Exception thats says No module named 'keras.backend.tensorflow_backend'; 'keras.backend' is not a package with the following error code<code> File &quot;c:/Users/phili/Desktop/python-projects/test.py&quot;, line 15, in &lt;module&gt; from keras.backend.tensorflow_backend import set_session ModuleNotFoundError: No module named 'keras.backend.tensorflow_backend'; 'keras.backend' is not a package</code></p>
<p>I  am using python 3.7 Keras 2.4.3 and tensorflow 2.2.0, is there any solution to the problem i can provide the whole code if needed
Thanks in advance</p>
",13999186.0,,,,,2020-08-10 11:44:35,from keras.backend.tensorflow_backend import set_session,<python><tensorflow><keras>,1,0,,,,CC BY-SA 4.0
63074971,1,63076252.0,,2020-07-24 13:51:11,,4,1387,"<p>I have a keras NN that I want to train and validate using two sets of data, and then test the ultimate performance of using a third set. In order to avoid having to rerun the training every time I restart my google colab runtime or want to change my test data, I want to save the final state of the model after training in one script and then load it again in another script.</p>
<p>I've looked everywhere and it seems that <code>model.save(&quot;content/drive/My Drive/Directory/ModelName&quot;, save_format='tf')</code> should do the trick, but even though it outputs <code>INFO:tensorflow:Assets written to: content/drive/My Drive/Directory/ModelName/assets</code> nothing appears in my Google Drive, so I assume it isn't actually saving.</p>
<p>Please can someone help me solve this issue?</p>
<p>Thanks in advance!</p>
",12820223.0,,,,,2020-07-24 15:00:38,keras model.save() isn't saving,<python><tensorflow><keras><neural-network>,1,3,,,,CC BY-SA 4.0
67037067,1,67038068.0,,2021-04-10 17:04:14,,4,5987,"<p>I need to add <a href=""https://www.tensorflow.org/guide/mixed_precision"" rel=""nofollow noreferrer"">mixed precision</a> to my code in order to save some memory. Specifically, I have tried adding mixed precision policy near line 27 in <a href=""https://github.com/nimRobotics/google-research/blob/master/ravens/train.py"" rel=""nofollow noreferrer"">https://github.com/nimRobotics/google-research/blob/master/ravens/train.py</a>, below is the code excerpt</p>
<pre><code>import argparse
import datetime
import os

import numpy as np
from ravens import agents
from ravens import Dataset
import tensorflow as tf

# tf.keras.mixed_precision.set_global_policy('mixed_float16')

# OR

# policy = tf.keras.mixed_precision.Policy('mixed_float16')
# mixed_precision.set_global_policy(policy)
</code></pre>
<p>Both the methods result in attribute error as shown below, I'm using Google Colab with TF 2.3.0</p>
<p>Using <code>tf.keras.mixed_precision.set_global_policy('mixed_float16')</code> results in</p>
<pre><code>Traceback (most recent call last):
  File &quot;train.py&quot;, line 28, in &lt;module&gt;
    tf.keras.mixed_precision.set_global_policy('mixed_float16')
AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'set_global_policy'

</code></pre>
<p>Using</p>
<pre><code>policy = tf.keras.mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)
</code></pre>
<p>results in</p>
<pre><code>Traceback (most recent call last):
  File &quot;train.py&quot;, line 29, in &lt;module&gt;
    policy = tf.keras.mixed_precision.Policy('mixed_float16')
AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'Policy'
</code></pre>
<p>Any help or hints will be highly appreciated!</p>
",8013752.0,,,,,2021-04-10 18:48:02,AttributeError: module 'tensorflow.keras.mixed_precision' has no attribute 'set_global_policy',<python><python-3.x><tensorflow><keras><google-colaboratory>,1,0,0.0,,,CC BY-SA 4.0
63097533,1,63100139.0,,2020-07-26 07:53:58,,4,1314,"<p>how to obtain the number of files in tf.keras.preprocessing.image_dataset_from_directory?</p>
<pre><code>train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset=&quot;training&quot;,
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size)
</code></pre>
<p>Found 3670 files belonging to 5 classes.
Using 2936 files for training.</p>
",13333200.0,,,,,2023-03-08 10:10:59,how to obtain the number of files in tf.keras.preprocessing.image_dataset_from_directory,<tensorflow><keras>,3,2,,,,CC BY-SA 4.0
67069600,1,67073653.0,,2021-04-13 06:15:25,,4,9353,"<p>I just learn tensorflow and keras. Here is a code example:</p>
<pre><code># Create a symbolic input
input = tf.keras.Input(shape=(2,), dtype=tf.float32)

# Do a calculation using is
result = 2*input + 1

# the result doesn't have a value
result

calc = tf.keras.Model(inputs=input, outputs=result)
print(calc(np.array([1,2,3,4])).numpy())
print(calc(2).numpy())
</code></pre>
<p>The document says shape: A shape tuple (integers), not including the batch size.
For instance, <code>shape=(32,)</code> indicates that the expected input will be batches of 32-dimensional vectors. Elements of this tuple can be <code>None</code>; <code>None</code> elements represent dimensions where the shape is not known.</p>
<p>But in the above code, two print lines both work. But for me, they are <code>1D</code> dimensions and 1 scalar. So how do understand the shape?</p>
",4827407.0,,9215780.0,,2021-04-13 09:07:30,2021-04-13 11:04:32,Understand the shape in tf.keras.Input?,<tensorflow><keras><input><shapes><dimension>,2,0,,,,CC BY-SA 4.0
66887785,1,,,2021-03-31 12:20:39,,4,1515,"<p>Models implemented as subclasses of <code>keras. Model</code> can generally not be visualized with <code>plot_model</code>. There is a workaround as described <a href=""https://stackoverflow.com/questions/61427583/how-do-i-plot-a-keras-tensorflow-subclassing-api-model"">here</a>. However, it only applies to simple models. As soon as a model is enclosed by another model, the nestings will not be resolved.</p>
<p>I am looking for a way to resolve nested models implemented as subclasses of the <code>keras. Model</code>. As an example, I have created a minimal GAN model:</p>
<pre class=""lang-py prettyprint-override""><code>import keras
from keras import layers
from tensorflow.python.keras.utils.vis_utils import plot_model


class BaseModel(keras.Model):
    def __init__(self, *args, **kwargs):
        super(BaseModel, self).__init__(*args, **kwargs)

    def call(self, inputs, training=None, mask=None):
        super(BaseModel, self).call(inputs=inputs, training=training, mask=mask)

    def get_config(self):
        super(BaseModel, self).get_config()

    def build_graph(self, raw_shape):
        &quot;&quot;&quot; Plot models that subclass `keras.Model`

        Adapted from https://stackoverflow.com/questions/61427583/how-do-i-plot-a-keras-tensorflow-subclassing-api-model

        :param raw_shape: Shape tuple not containing the batch_size
        :return:
        &quot;&quot;&quot;
        x = keras.Input(shape=raw_shape)
        return keras.Model(inputs=[x], outputs=self.call(x))


class GANModel(BaseModel):
    def __init__(self, generator, discriminator):
        super(GANModel, self).__init__()
        self.generator = generator
        self.discriminator = discriminator

    def call(self, input_tensor, training=False, mask=None):
        x = self.generator(input_tensor)
        x = self.discriminator(x)
        return x


class DiscriminatorModel(BaseModel):
    def __init__(self, name=&quot;Critic&quot;):
        super(DiscriminatorModel, self).__init__(name=name)
        self.l1 = layers.Conv2D(64, 2, activation=layers.ReLU())
        self.flat = layers.Flatten()
        self.dense = layers.Dense(1)

    def call(self, inputs, training=False, mask=None):
        x = self.l1(inputs, training=training)
        x = self.flat(x)
        x = self.dense(x, training=training)
        return x


class GeneratorModel(BaseModel):
    def __init__(self, name=&quot;Generator&quot;):
        super(GeneratorModel, self).__init__(name=name)
        self.dense = layers.Dense(128, activation=layers.ReLU())
        self.reshape = layers.Reshape((7, 7, 128))
        self.out = layers.Conv2D(1, (7, 7), activation='tanh', padding=&quot;same&quot;)

    def call(self, inputs, training=False, mask=None):
        x = self.dense(inputs, training=training)
        x = self.reshape(x)
        x = self.out(x, training=training)
        return x


g = GeneratorModel()
d = DiscriminatorModel()

plot_model(g.build_graph((7, 7, 1)), to_file=&quot;generator_model.png&quot;,
           expand_nested=True, show_shapes=True)

gan = GANModel(generator=g, discriminator=d)
plot_model(gan.build_graph((7, 7, 1)), to_file=&quot;gan_model.png&quot;, 
           expand_nested=True, show_shapes=True)
</code></pre>
<hr />
<h1>Edit</h1>
<p>Using the functional keras API I get the desired result (see <a href=""https://imgur.com/a/6ECLRCy"" rel=""nofollow noreferrer"">here</a>). The nested models are correctly resolved within the GAN model.</p>
<pre class=""lang-py prettyprint-override""><code>from keras import Model, layers, optimizers
from tensorflow.python.keras.utils.vis_utils import plot_model


def get_generator(input_dim):
    initial = layers.Input(shape=input_dim)

    x = layers.Dense(128, activation=layers.ReLU())(initial)
    x = layers.Reshape((7, 7, 128))(x)
    x = layers.Conv2D(1, (7, 7), activation='tanh', padding=&quot;same&quot;)(x)

    return Model(inputs=initial, outputs=x, name=&quot;Generator&quot;)


def get_discriminator(input_dim):
    initial = layers.Input(shape=input_dim)

    x = layers.Conv2D(64, 2, activation=layers.ReLU())(initial)
    x = layers.Flatten()(x)
    x = layers.Dense(1)(x)

    return Model(inputs=initial, outputs=x, name=&quot;Discriminator&quot;)

def get_gan(input_dim, latent_dim):
    initial = layers.Input(shape=input_dim)

    x = get_generator(input_dim)(initial)
    x = get_discriminator(latent_dim)(x)

    return Model(inputs=initial, outputs=x, name=&quot;GAN&quot;)



m = get_generator((7, 7, 1))
m.compile(optimizer=optimizers.Adam())

plot_model(m, expand_nested=True, show_shapes=True, to_file=&quot;generator_model_functional.png&quot;)

gan = get_gan((7, 7, 1), (7, 7, 1))
plot_model(gan, expand_nested=True, show_shapes=True, to_file=&quot;gan_model_functional.png&quot;)
</code></pre>
",1702527.0,,1702527.0,,2022-03-08 06:16:26,2022-03-08 06:16:26,How to visualize nested `tf.keras.Model (SubClassed API)` GAN model with plot_model?,<python><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0
70294280,1,70301255.0,,2021-12-09 17:36:52,,4,1434,"<p>I have pre-trained a model (my own saved model) with two classes, which I want to use for transfer learning to train a model with six classes.
I have loaded the pre-trained model into the new training script:</p>
<p><code>base_model = tf.keras.models.load_model(&quot;base_model_path&quot;)</code></p>
<p>How can I remove the top/head layer (a conv1D layer) ?</p>
<p>I see that in keras one can use base_model.pop(), and for tf.keras.applications one can simply use <code>include_top=false</code>
but is there something similar when using tf.keras and load_model?</p>
<p>(I have tried something like this:</p>
<pre><code>for layer in base_model.layers[:-1]:
    layer.trainable = False`
</code></pre>
<p>and then add it to a new model (?) but I am not sure on how to continue)</p>
<p>Thanks for any help!</p>
",15768051.0,,,,,2021-12-10 07:48:50,"Remove top layer from pre-trained model, transfer learning, tensorflow (load_model)",<python><tensorflow><keras><tf.keras><transfer-learning>,1,0,,,,CC BY-SA 4.0
70996574,1,,,2022-02-05 09:04:00,,4,6497,"<p>I have a script that runs well on google collab and kaggle, but regarding their memory limitation, I'm now trying to run it on my jupyter notebook in my laptop but then the error message shows.</p>
<pre><code>ImportError: cannot import name 'BatchNormalization' from 'tensorflow.python.keras.layers' 
</code></pre>
<p>It called from the line:</p>
<pre><code>from pixellib.tune_bg import alter_bg
</code></pre>
<p>I alreaddy imported what seems to be required:</p>
<pre><code>from tensorflow.keras.layers import (Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Concatenate, LeakyReLU, BatchNormalization, concatenate)
</code></pre>
<p>And also installed:</p>
<pre><code>!pip install pixellib
</code></pre>
<p>My Specification: <br>
No GPU <br>
keras version 2.8.0 <br>
tensorflow version 2.8.0 <br>
Python version '3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]'<br></p>
<p>IPython          : not installed <br>
ipykernel        : 6.8.0 <br>
ipywidgets       : not installed <br></p>
<p>jupyter_client   : 7.1.2 <br>
jupyter_core     : 4.9.1 <br>
jupyter_server   : not installed <br>
jupyterlab       : not installed <br>
nbclient         : 0.5.10 <br></p>
<p>Any suggestion please?</p>
",9218544.0,,,,,2022-02-24 09:44:13,ImportError: cannot import name 'BatchNormalization' from 'tensorflow.python.keras.layers',<python><keras><jupyter>,2,3,,,,CC BY-SA 4.0
70988847,1,70990030.0,,2022-02-04 15:25:11,,4,2048,"<p>I'm having some issues saving a trained TensorFlow model, where I have a StringLookup layer and I'm required to use TFRecods as input for training. A minimal example to reproduce the issue:</p>
<p>First I define the training data</p>
<pre><code>vocabulary = [str(i) for i in range(100, 200)]
X_train = np.random.choice(vocabulary, size=(100,))
y_train = np.random.choice([0,1], size=(100,))
</code></pre>
<p>I save it in a file as tfrecords</p>
<pre><code>def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))
def _string_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[str(value).encode('utf-8')]))

with tf.io.TFRecordWriter('train.tfrecords') as writer:
    for i in range(len(X_train)):
        example = tf.train.Example(features=tf.train.Features(feature={
            'user_id': _string_feature(X_train[i]),
            'label': _int64_feature(y_train[i])
        }))
        writer.write(example.SerializeToString())
</code></pre>
<p>Then I use the tf.data API to be able to stream the data into training (the original data doesn't fit into memory)</p>
<pre><code>data = tf.data.TFRecordDataset(['train.tfrecords'])
features = {
    'user_id': tf.io.FixedLenFeature([], tf.string),
    'label': tf.io.FixedLenFeature([], tf.int64)
} 
def parse(record):
    parsed = tf.io.parse_single_example(record, features)
    return (parsed['user_id'], parsed['label'])
data = data.map(parse)
</code></pre>
<p>The data looks like this:</p>
<pre><code>print(list(data.take(5).as_numpy_iterator()))
[(b'166', 1), (b'144', 0), (b'148', 1), (b'180', 0), (b'192', 0)]
</code></pre>
<p>The strings of the original dataset were converted to bytes in the process. I have to pass this new vocabulary to the StringLookup contructor, as passing strings and training with bytes will throw an error</p>
<pre><code>new_vocab = [w.encode('utf-8') for w in vocabulary]

inp = tf.keras.Input(shape=(1,), dtype=tf.string)
x = tf.keras.layers.StringLookup(vocabulary=new_vocab)(inp)
x = tf.keras.layers.Embedding(len(new_vocab)+1, 32)(x)
out = tf.keras.layers.Dense(1, activation='sigmoid')(x)
model = tf.keras.Model(inputs=[inp], outputs=[out])

model.compile(optimizer='adam', loss='BinaryCrossentropy')
model.fit(data.batch(10), epochs=5)
</code></pre>
<p>But when I try to save the model, I get an error because the vocabulary input to the StringLookup layer is encoded as bytes and can't be dumped into json</p>
<pre><code>model.save('model/')
TypeError: ('Not JSON Serializable:', b'100')
</code></pre>
<p>I really don't know what to do, I read that TensorFlow recommends using encoded strings instead of normal strings but that doesn't allow to save the model. I also tried to preprocess the data decoding the strings before thay are fed to the model, but I wasn't able to do it without loading all the data into memory (using just tf.data operations)</p>
",13630890.0,,,,,2022-02-04 17:07:46,Save tensorflow model with StringLookup layer with encoded vocabulary,<python><tensorflow><keras><deep-learning><tfrecord>,1,0,0.0,,,CC BY-SA 4.0
62786227,1,,,2020-07-08 01:32:25,,4,442,"<p>I have defined the following custom model and training loop in Keras:</p>
<pre><code>class CustomModel(keras.Model):
    def train_step(self, data):
        x, y = data

        with tf.GradientTape() as tape:
            y_pred = self(x, training=True)  # Forward pass
            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)

        trainable_vars = self.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))
        self.compiled_metrics.update_state(y, y_pred)
        return {m.name: m.result() for m in self.metrics}
</code></pre>
<p>And I am using the following code to train the model on a simple toy data set:</p>
<pre><code>inputs = keras.layers.Input(shape=(1,))
hidden = keras.layers.Dense(1, activation='tanh')(inputs)
outputs = keras.layers.Dense(1)(hidden)

x = np.arange(0, 2*np.pi, 2*np.pi/100)
y = np.sin(x)

nnmodel = CustomModel(inputs, outputs)
nnmodel.compile(optimizer=keras.optimizers.SGD(lr=0.1), loss=&quot;mse&quot;, metrics=[&quot;mae&quot;])
nnmodel.fit(x, y, batch_size=100, epochs=2000)
</code></pre>
<p>I want to be able to see the values of the <code>gradient</code> and the <code>trainable_vars</code> variables in the <code>train_step</code> function for each training loop, and I am not sure how to do this.</p>
<p>I have tried to set a break point inside the <code>train_step</code> function in my python IDE and expecting it to stop at the break point for each epoch of the training after I call <code>model.fit()</code> but this didn't happen. I also tried to have them print out the values in the log after each epoch but I am not sure how to achieve this.</p>
",10253383.0,,,,,2020-07-08 01:32:25,How to track weights and gradients in a Keras custom training loop,<python-3.x><tensorflow><machine-learning><keras><neural-network>,0,0,,,,CC BY-SA 4.0
65657277,1,65657471.0,,2021-01-10 18:59:13,,4,15009,"<p>Following this example to start <a href=""https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"" rel=""nofollow noreferrer"">https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/</a></p>
<pre><code># first neural network with keras tutorial
from numpy import loadtxt
from keras.models import Sequential
from keras.layers import Dense
</code></pre>
<p>Installed numpy and keras, numpy is ok, but there are red lines under &quot;Sequential&quot; and &quot;Dense&quot;.</p>
<p><a href=""https://i.stack.imgur.com/Y02Nt.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y02Nt.gif"" alt=""enter image description here"" /></a></p>
<p>Here's the Error messages:</p>
<p>Cannot find reference 'Sequential' in 'models.py'</p>
<p>Cannot find reference 'Dense' in '<strong>init</strong>.py'</p>
<p><a href=""https://i.stack.imgur.com/rdO2s.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rdO2s.gif"" alt=""enter image description here"" /></a></p>
<p>Wonder how I can fix this? I had a look <a href=""https://stackoverflow.com/questions/23248017/cannot-find-reference-xxx-in-init-py-python-pycharm"">here</a> but think it might be a different problem?</p>
<p>Also, on a completely different note, I can not install tensorflow for some reason? ...</p>
<p><a href=""https://i.stack.imgur.com/yWFBa.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yWFBa.gif"" alt=""enter image description here"" /></a></p>
",1729452.0,,13860.0,,2021-01-10 19:01:05,2021-01-10 19:16:54,"""Cannot find reference"" when import from Keras",<python><keras><pycharm>,1,1,0.0,,,CC BY-SA 4.0
63468244,1,,,2020-08-18 12:05:05,,4,472,"<p>I have an AMD GPU and I'm running on Windows 10 with Python 3.8. Tensorflow didn't provide any support for AMD users in terms of GPU acceleration.
I've found a way on StackOverflow describing how to run Keras on AMD GPU using plaid-ml that works perfectly on my machine (link below) but does not make the trick since Keras only take numpy array as input of models and not Tensors, particularly tf.data.Dataset as input.</p>
<p><a href=""https://stackoverflow.com/questions/60016868/anyway-to-work-with-keras-in-mac-with-amd-gpu"">Anyway to work with Keras in Mac with AMD GPU?</a></p>
<p>How can we feed a tf.data.Dataset as input of a Keras model with plaid-ml backend ?
Or is there any way to build Tensorflow 2.x so that it uses AMD GPU on Windows 10 (and then no need to use Keras as a stand-alone) ? I have seen people forking Tensorflow repository for AMD users but the version was always Tensorflow 1.x.</p>
<p>Has someone ever overcome this issue ? Deep learning on CPU is pain !</p>
",11779147.0,,,,,2020-08-18 12:05:05,Is there any way to connect Tensorflow Dataset to plaidML-keras for deep learning with GPU?,<python><tensorflow><keras><gpu><amd>,0,0,,,,CC BY-SA 4.0
70573362,1,70578053.0,,2022-01-04 02:02:58,,4,1296,"<p>If you have a MultiHeadAttention layer in Keras, then it can return attention scores like so:</p>
<pre><code>    x, attention_scores = MultiHeadAttention(1, 10, 10)(x, return_attention_scores=True)
</code></pre>
<p>How do you extract the attention scores from the network graph? I would like to graph them.</p>
",6739010.0,,9657861.0,,2022-04-10 20:17:03,2022-04-10 20:17:03,Tensorflow: How to extract attention_scores for graphing?,<python><tensorflow><machine-learning><keras><tensorflow2.0>,1,0,,,,CC BY-SA 4.0
67885869,1,,,2021-06-08 11:10:00,,4,4656,"<p>I am following the <a href=""https://www.tensorflow.org/guide/keras/transfer_learning"" rel=""nofollow noreferrer"">Transfer learning and fine-tuning guide</a> on the official TensorFlow website. It points out that during fine-tuning, batch normalization layers should be in inference mode:</p>
<blockquote>
<h3>Important notes about <code>BatchNormalization</code> layer</h3>
<p>Many image models contain <code>BatchNormalization</code> layers. That layer is a
special case on every imaginable count. Here are a few things to keep
in mind.</p>
<ul>
<li><code>BatchNormalization</code> contains 2 non-trainable weights that get updated during training. These are the variables tracking the mean and variance of the inputs.</li>
<li>When you set <code>bn_layer.trainable = False</code>, the <code>BatchNormalization</code> layer will run in inference mode, and will not update its mean &amp; variance statistics. This is not the case for other layers in general, <a href=""https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute"" rel=""nofollow noreferrer"">as weight trainability &amp; inference/training modes are two orthogonal concepts</a>. But the two are tied in the case of the <code>BatchNormalization</code> layer.</li>
<li>When you unfreeze a model that contains <code>BatchNormalization</code> layers in order to do fine-tuning, you should keep the <code>BatchNormalization</code> layers in inference mode by passing <code>training=False</code> when calling the base model. Otherwise the updates applied to the non-trainable weights will suddenly destroy what the model has learned.</li>
</ul>
<p>You'll see this pattern in action in the end-to-end example at the end
of this guide.</p>
</blockquote>
<p>Even tho, some other sources, for example <a href=""https://balajikulkarni.medium.com/transfer-learning-using-resnet-e20598314427"" rel=""nofollow noreferrer"">this</a> article (titled <em>Transfer Learning with ResNet</em>), says something completely different:</p>
<blockquote>
<pre><code>for layer in resnet_model.layers:
    if isinstance(layer, BatchNormalization):
        layer.trainable = True
    else:
        layer.trainable = False
</code></pre>
</blockquote>
<p>ANYWAY, I know that there is a difference between <code>training</code> and <code>trainable</code> parameters in TensorFlow.</p>
<p>I am loading my model from file, as so:</p>
<pre><code>model = tf.keras.models.load_model(path)
</code></pre>
<p>And I am unfreezing (or actually freezing the rest) some of the top layers in this way:</p>
<pre><code>model.trainable = True

for layer in model.layers:
    if layer not in model.layers[idx:]:
        layer.trainable = False

</code></pre>
<p>NOW about batch normalization layers: I can either do:</p>
<pre><code>for layer in model.layers:
    if isinstance(layer, keras.layers.BatchNormalization):
      layer.trainable = False
</code></pre>
<p>or</p>
<pre><code>  for layer in model.layers:
    if layer.name.startswith('bn'):
      layer.call(layer.input, training=False)
</code></pre>
<p><strong>Which one should I do? And whether finally it is better to freeze batch norm layer or not?</strong></p>
",11480186.0,,7370153.0,,2021-06-08 12:02:12,2022-06-02 12:14:27,How to freeze batch-norm layers during Transfer-learning,<tensorflow><keras><neural-network><tensorflow2.0><batch-normalization>,3,0,0.0,,,CC BY-SA 4.0
69875073,1,69875281.0,,2021-11-07 17:49:17,,4,9886,"<p>I'm currently trying to make a confusion matrix for my neural network model, but keep getting this error:</p>
<pre><code>ValueError: Classification metrics can't handle a mix of binary and continuous targets.
</code></pre>
<p>I have a peptide dataset that I'm using with 100 positive and 100 negative examples, and the labels are 1s and 0s. I've converted each peptide into a Word2Vec embedding that was put into a ML model and trained.</p>
<p>This is my code:</p>
<pre><code>pos = &quot;/content/drive/MyDrive/pepfun/Training_format_pos (1).txt&quot;
neg = &quot;/content/drive/MyDrive/pepfun/Training_format_neg.txt&quot;

# pos sequences extract into list
f = open(pos, 'r')
file_contents = f.read()
data = file_contents
f.close()

newdatapos = data.splitlines()
print(newdatapos)

# neg sequences extract into list
f2 = open(neg, 'r')
file_contents2 = f2.read()
data2 = file_contents2
f2.close()

newdataneg = data2.splitlines()
print(newdataneg)

!pip install rdkit-pypi
import rdkit
from rdkit import Chem

# set up embeddings
import nltk
from gensim.models import Word2Vec
import multiprocessing
EMB_DIM = 4

# embeddings pos
w2vpos = Word2Vec([newdatapos], size=EMB_DIM, min_count=1)
sequez = &quot;VVYPWTQRF&quot;
w2vpos[sequez].shape
words=list(w2vpos.wv.vocab)
vectors = []
for word in words:
  vectors.append(w2vpos[word].tolist())
print(len(vectors))
print(vectors[1])
data = np.array(vectors)

# embeddings neg
w2vneg = Word2Vec([newdataneg], size=EMB_DIM, min_count=1)
sequen = &quot;GIGKFLHSAGKFGKAFLGEVMKS&quot;
w2vneg[sequen].shape
wordsneg = list(w2vneg.wv.vocab)
vectorsneg = []
for word in wordsneg:
  vectorsneg.append(w2vneg[word].tolist())
allvectors = vectorsneg + vectors
print(len(allvectors))
arrayvectors = np.array(allvectors)

labels = []
for i in range (100):
  labels.append(1)
print(labels)
for i in range (100):
  labels.append(0)
print(labels)
print(len(labels))


import seaborn as sns
!pip install keras
import keras
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils import shuffle
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
!pip install tensorflow==2.7.0
import tensorflow as tf
from keras import metrics  
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv3D, Flatten, Dropout


import sklearn
a = sklearn.utils.shuffle(arrayvectors, random_state=1)
b = sklearn.utils.shuffle(labels, random_state=1)
dfa = pd.DataFrame(a, columns=None)
dfb = pd.DataFrame(b, columns=None)
X = dfa.iloc[:]
y = dfb.iloc[:]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=300)
X_train = np.asarray(X_train)
X_test = np.asarray(X_test)
y_train = np.asarray(y_train)
y_test = np.asarray(y_test)
y_train = y_train.astype(np.float32)
y_test = y_test.astype(np.float32)

# train data &amp; test data tensor conversion

class trainData(Dataset):
    
    def __init__(self, X_data, y_data):
        self.X_data = X_data
        self.y_data = y_data
        
    def __getitem__(self, index):
        return self.X_data[index], self.y_data[index]
        
    def __len__ (self):
        return len(self.X_data)


train_data = trainData(torch.FloatTensor(X_train), 
                       torch.FloatTensor(y_train))
## test data    
class testData(Dataset):
    
    def __init__(self, X_data):
        self.X_data = X_data
        
    def __getitem__(self, index):
        return self.X_data[index]
        
    def __len__ (self):
        return len(self.X_data)
    

test_data = testData(torch.FloatTensor(X_test))

train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_data, batch_size=1)

# make model
model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(4,)))
model.add(Dropout(0.1))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(16, input_dim=1, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(12,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1,activation='sigmoid'))
model.summary()

model.compile(loss='binary_crossentropy',optimizer='RMSprop', metrics=['accuracy','AUC'])

history = model.fit(X_train, y_train, epochs=2000,batch_size=64, validation_data = (X_test, y_test), validation_batch_size=64)


from sklearn.metrics import confusion_matrix, classification_report
print(y_pred.round)
print(classification_report(y_test,y_pred))
</code></pre>
<p>I've tried printing my y_pred value to see the problem. This is what I get:</p>
<pre><code>[[6.0671896e-01]
 [9.9999785e-01]
 [1.6576621e-01]
 [9.9999899e-01]
 [5.6016445e-04]
 [2.4935007e-02]
 [4.4204036e-11]
 [2.8884350e-11]
 [6.3217885e-05]
 [4.7181606e-02]
 [9.9742711e-03]
 [1.0780278e-01]
 [7.0868194e-01]
 [2.0298421e-02]
 [9.5819527e-01]
 [1.4784497e-01]
 [1.7605269e-01]
 [9.9643111e-01]
 [4.7657710e-01]
 [9.9991858e-01]
 [4.5830309e-03]
 [6.5091753e-01]
 [3.8710403e-01]
 [2.4756461e-02]
 [1.1719930e-01]
 [6.4381957e-03]
 [7.1598434e-01]
 [1.5749395e-02]
 [6.8473631e-01]
 [9.5499575e-01]
 [2.2420317e-02]
 [9.9999177e-01]
 [6.9633877e-01]
 [9.2811453e-01]
 [1.8373668e-01]
 [2.9298562e-07]
 [1.1250973e-03]
 [4.3785056e-01]
 [9.6832716e-01]
 [8.6754566e-01]]
</code></pre>
<p>It's not 1s and 0s. I believe there's a problem there as well, but I'm not sure.</p>
",13985387.0,,11989081.0,,2022-08-12 19:18:40,2022-08-12 19:18:40,Confusion Matrix ValueError: Classification metrics can't handle a mix of binary and continuous targets,<python><tensorflow><machine-learning><keras><neural-network>,1,0,,,,CC BY-SA 4.0
63687295,1,63687640.0,,2020-09-01 12:04:28,,4,3047,"<p>I am relatively new to Machine Learning and Tensorflow, and I want to try and implement mini-batch gradient descent on the MNIST dataset. However, I am not sure how I should implement it.</p>
<p>(Side note: the training images (28px by 28px) and labels are stored in Numpy arrays)</p>
<p>At the moment, I can see 2 different ways to implement it:</p>
<ol>
<li><p>My training images are in a Numpy array of [60000,28,28]. Reshape this into a [25 (num batches), 2400 (num images in batch), 28,28] and then use a for loop to call each batch and pass it the model.compile() method. The only thing that I am worried about with this method is that for loops are inherently slow, and a vectorised implementation would be much quicker.</p>
</li>
<li><p>Combine the images and labels into a tensorflow dataset object, and then call the Dataset.batch() method and Dataset.prefetch() method, and then pass the data to the model.compile() method. The only problem with this is that my data doesn't remain as a Numpy array, which I feel have more flexibility than tensorflow dataset objects.</p>
</li>
</ol>
<p>Which of these 2 methods would be best to implement, or is there a third way that is best that I am not aware of?</p>
",13251570.0,,,,,2020-09-01 12:25:30,How to implement mini-batch gradient descent in Tensorflow 2?,<python><numpy><tensorflow><keras><tensorflow-datasets>,1,0,,,,CC BY-SA 4.0
67819062,1,,,2021-06-03 09:40:05,,4,19791,"<p>I am following this <a href=""https://thebinarynotes.com/how-to-train-mask-r-cnn-on-the-custom-dataset/"" rel=""nofollow noreferrer"">https://thebinarynotes.com/how-to-train-mask-r-cnn-on-the-custom-dataset/</a> tutorial of Mask RCNN, and trying execute it on Google Colab.</p>
<p>Versions of Tensorflow and Keras are mentioned below: tensorflow==1.13.1 keras==2.1.0</p>
<p>3 weeks ago I have already used this code and trained the model on my custom dataset successfully, and predicted the results as well.</p>
<p>But now, when I try to execute the same code in same environment I got the following error. Tried multiple solutions, like updating Tensorflow to 2.x, but the code is not compatible with it, and creates other issues.<a href=""https://i.stack.imgur.com/NP5KV.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
",9185140.0,,9185140.0,,2021-06-03 10:54:27,2023-04-06 20:03:20,No modules named 'tensorflow.compat.v2' on Colab,<python><tensorflow><keras>,2,2,,,,CC BY-SA 4.0
63414587,1,,,2020-08-14 14:20:13,,4,3775,"<p>I am trying to create a variational autoencoder with tensorflow. I have followed all the steps according to the keras website (<a href=""https://keras.io/guides/making_new_layers_and_models_via_subclassing/"" rel=""nofollow noreferrer"">https://keras.io/guides/making_new_layers_and_models_via_subclassing/</a>)
However I made minor changes.</p>
<pre><code>annealing_weight = tf.keras.backend.variable(0.01)

test = VariationalAutoEncoder(annealing_weight,
                              [8, 8, 128],
                              input_shape=(None, 256, 256, 1))
test.compile('adam', loss=None)
test.summary()
test.train_on_batch(np.random.randn(32, 256, 256, 1),None)
</code></pre>
<p>I am able to compile the network and obtain a summary. Everything seems normal.
However, when I try to train on a batch to see if the network works properly, I get the following error message. The problem seems to be with the error-function.</p>
<p>I hope someone can help me. Thanks!</p>
<pre><code>WARNING:tensorflow:AutoGraph could not transform &lt;bound method ConvolutionalBlock.call of &lt;__main__.ConvolutionalBlock object at 0x000000001D5DC408&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unable to locate the source code of &lt;bound method ConvolutionalBlock.call of &lt;__main__.ConvolutionalBlock object at 0x000000001D5DC408&gt;&gt;. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
WARNING:tensorflow:Output output_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to output_1.
Traceback (most recent call last):
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\framework\ops.py&quot;, line 1619, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 1 and 0
    From merging shape 1 with other shapes. for 'loss_1/AddN' (op: 'AddN') with input shapes: [?], [?], [], [], [], [], [], [], [], [], [], [], [], [].
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;&lt;input&gt;&quot;, line 10, in &lt;module&gt;
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\keras\engine\training.py&quot;, line 1078, in train_on_batch
    standalone=True)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py&quot;, line 416, in train_on_batch
    extract_tensors_from_dataset=True)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\keras\engine\training.py&quot;, line 2360, in _standardize_user_data
    self._compile_from_inputs(all_inputs, y_input, x, y)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\keras\engine\training.py&quot;, line 2618, in _compile_from_inputs
    experimental_run_tf_function=self._experimental_run_tf_function)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\training\tracking\base.py&quot;, line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\keras\engine\training.py&quot;, line 446, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\training\tracking\base.py&quot;, line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\keras\engine\training.py&quot;, line 1592, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\keras\engine\training.py&quot;, line 1701, in _prepare_total_loss
    math_ops.add_n(custom_losses))
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\util\dispatch.py&quot;, line 180, in wrapper
    return target(*args, **kwargs)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\ops\math_ops.py&quot;, line 3053, in add_n
    return gen_math_ops.add_n(inputs, name=name)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py&quot;, line 420, in add_n
    &quot;AddN&quot;, inputs=inputs, name=name)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\framework\op_def_library.py&quot;, line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\framework\func_graph.py&quot;, line 595, in _create_op_internal
    compute_device)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\framework\ops.py&quot;, line 3322, in _create_op_internal
    op_def=op_def)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\framework\ops.py&quot;, line 1786, in __init__
    control_input_ops)
  File &quot;C:\Users\user\.conda\envs\Thesis\lib\site-packages\tensorflow_core\python\framework\ops.py&quot;, line 1622, in _create_c_op
    raise ValueError(str(e))
ValueError: Shapes must be equal rank, but are 1 and 0
    From merging shape 1 with other shapes. for 'loss_1/AddN' (op: 'AddN') with input shapes: [?], [?], [], [], [], [], [], [], [], [], [], [], [], [].
</code></pre>
<p>The code is shown below.</p>
<pre><code>import numpy as np
import tensorflow as tf

from tensorflow.keras import layers as tfl

class ConvolutionalBlock(tfl.Layer):

    def __init__(self, filters, name, deconv=False, **kwargs):

        self.conv_layer = tfl.Conv2DTranspose if deconv else tfl.Conv2D
        self.conv_layer = self.conv_layer(filters,
                                          kernel_size=3,
                                          padding='same',
                                          kernel_initializer='he_normal',
                                          kernel_regularizer=tf.keras.regularizers.l2(0.0001),
                                          strides=2,
                                          name='conv')

        self.batch_norm = tfl.BatchNormalization(name='de_ennorm')
        self.relu = tfl.ReLU(name='en_relu')# + str(index))

        super(ConvolutionalBlock, self).__init__(name=name, **kwargs)

    def call(self, inputs, **kwargs):
        outputs = self.conv_layer(inputs)
        outputs = self.batch_norm(outputs)
        outputs = self.relu(outputs)
        return outputs

class Sampling(tfl.Layer):

    def __init__(self, **kwargs):
        super(Sampling, self).__init__(name='reparameterization_trick', **kwargs)

    def call(self, inputs, training=None, mask=None, **kwargs):
        x_mean, x_variance = inputs

        return x_mean + tf.keras.backend.exp(0.5 * x_variance) * \
                   tf.keras.backend.random_normal(shape=(32, 128), mean=0., stddev=1.0)


class Encoder(tfl.Layer):

    def __init__(self, **kwargs):
        super(Encoder, self).__init__(name='Encoder', **kwargs)

        self.convs = [
            ConvolutionalBlock(8, 'conv1'),
            ConvolutionalBlock(16, 'conv2'),
            ConvolutionalBlock(32, 'conv3'),
            ConvolutionalBlock(64, 'conv4'),
            ConvolutionalBlock(128, 'conv5')
        ]

        self.features = tfl.GlobalAveragePooling2D(name='globaverpool')
        self.denserepresentation = tfl.Dense(128, activation='relu', name='Dense1')

        self.x_mean = tfl.Dense(128, name='meanvector')
        self.x_variance = tfl.Dense(128, name='variancevector')

        self.sampling = Sampling()


    def call(self, inputs, training=None, mask=None, **kwargs):
        outputs = inputs
        print(outputs)

        for layer in self.convs:
            outputs = layer(outputs)
            print(outputs)

        outputs = self.features(outputs)
        print(outputs)
        dense_output = self.denserepresentation(outputs)
        print(dense_output)
        x_mean = self.x_mean(dense_output)
        x_variance = self.x_variance(dense_output)
        output = self.sampling((x_mean,x_variance))

        return output, x_mean, x_variance


class Decoder(tfl.Layer):

    def __init__(self,
                 dense_reshape,
                 **kwargs):

        super(Decoder, self).__init__(name='Decoder', **kwargs)

        self.denserepresentation = tfl.Dense(np.prod(dense_reshape),
                                             activation='relu',
                                             kernel_regularizer=tf.keras.regularizers.l2(0.0001),
                                             name='dense2')
        self.reshaped = tfl.Reshape(dense_reshape,
                                    name='reshape')

        self.deconvs=[
            ConvolutionalBlock(128, 'conv1', deconv=True),
            ConvolutionalBlock(64, 'conv2', deconv=True),
            ConvolutionalBlock(32, 'conv3', deconv=True),
            ConvolutionalBlock(16, 'conv4', deconv=True),
            ConvolutionalBlock(8, 'conv5', deconv=True)
        ]

        self.output_layer = tfl.Conv2D(filters=1,
                                       kernel_size=3,
                                       activation='sigmoid', # check this
                                       padding='same',
                                       name='decodedconv',
                                       kernel_regularizer=tf.keras.regularizers.l2(0.0001),
                                       kernel_initializer='he_normal')

    def call(self, inputs, training=None, mask=None):
        outputs = inputs
        outputs = self.denserepresentation(outputs)
        outputs = self.reshaped(outputs)

        for layer in self.deconvs:
            outputs = layer(outputs)

        outputs = self.output_layer(outputs)

        return outputs


class VariationalAutoEncoder(tf.keras.Model):

    def __init__(self,
                 annealing_weight,
                 dense_reshape,
                 input_shape,
                 **kwargs):
        super(VariationalAutoEncoder, self).__init__(**kwargs)

        self.annealing_weight = annealing_weight  # for KL-loss

        self.encoder = Encoder()
        self.decoder = Decoder(dense_reshape)

        self.build(input_shape)



    def call(self, inputs, training=None, mask=None):
        dense_output, x_mean, x_variance = self.encoder(inputs)
        output = self.decoder(dense_output)

        kl_loss = - self.annealing_weight * tf.reduce_mean(
            x_variance - tf.keras.backend.square(x_mean)
            - tf.keras.backend.exp(x_variance) + 1,
            axis=-1)
        self.add_loss(lambda: kl_loss)
        return output
</code></pre>
",14105715.0,,,,,2020-10-23 10:31:30,"ValueError: Shapes must be equal rank, but are 1 and 0 From merging shape 1 with other shapes. for 'loss/AddN'",<python><tensorflow><keras><autoencoder><loss-function>,1,0,,,,CC BY-SA 4.0
69933345,1,69933594.0,,2021-11-11 18:41:37,,4,14425,"<p>In my model, I have a normalizing layer for a 1 column feature array. I assume this gives a 1 ndim output:</p>
<pre><code>single_feature_model = keras.models.Sequential([
    single_feature_normalizer,
    layers.Dense(1)
])
</code></pre>
<p>Normailaztion step:</p>
<pre><code>single_feature_normalizer = preprocessing.Normalization(axis=None)
single_feature_normalizer.adapt(single_feature)
</code></pre>
<p>The error I'm getting is:</p>
<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-98-22191285d676&gt; in &lt;module&gt;()
      2 single_feature_model = keras.models.Sequential([
      3     single_feature_normalizer,
----&gt; 4     layers.Dense(1) # Linear Model
      5 ])

/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py in assert_input_compatibility(input_spec, inputs, layer_name)
    225       ndim = x.shape.rank
    226       if ndim is not None and ndim &lt; spec.min_ndim:
--&gt; 227         raise ValueError(f'Input {input_index} of layer &quot;{layer_name}&quot; '
    228                          'is incompatible with the layer: '
    229                          f'expected min_ndim={spec.min_ndim}, '

ValueError: Input 0 of layer &quot;dense_27&quot; is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)
</code></pre>
<p>I seems that the dense layer is looking for a 2 ndim array while the normalization layer outputs a 1 ndim array.
Is there anyway to solve this and getting the model working?</p>
",16939860.0,,,,,2022-08-13 21:40:25,"Expected min_ndim=2, found ndim=1. Full shape received: (None,)",<python><tensorflow><keras><neural-network>,2,2,,,,CC BY-SA 4.0
64241645,1,64510890.0,,2020-10-07 09:58:07,,4,2424,"<p>I've created a model using Keras Sequential API, and using <a href=""https://nlp.stanford.edu/projects/glove/"" rel=""nofollow noreferrer"">Glove pretraining embeddings</a></p>
<pre><code>def create_model(
        input_length=20,
        output_length=20):

    encoder_input = tf.keras.Input(shape=(input_length,))
    decoder_input = tf.keras.Input(shape=(output_length,))

    encoder = tf.keras.layers.Embedding(original_embedding_matrix.shape[0], original_embedding_dim, weights=[original_embedding_matrix], mask_zero=True)(encoder_input)
    encoder, h_encoder, u_encoder = tf.keras.layers.LSTM(64, return_state=True)(encoder)

    decoder = tf.keras.layers.Embedding(clone_embedding_matrix.shape[0], clone_embedding_dim, weights=[clone_embedding_matrix], mask_zero=True)(decoder_input)
    decoder = tf.keras.layers.LSTM(64, return_sequences=True)(decoder, initial_state=[h_encoder, u_encoder])
    decoder = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(clone_vocab_size+1))(decoder)

    model = tf.keras.Model(inputs=[encoder_input, decoder_input], outputs=[decoder])
    model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])

    return model

model = create_model()
</code></pre>
<p>Here are my encoder/decoder shapes:</p>
<pre><code>training_encoder_input.shape --&gt; (2500, 20) 
training_decoder_input.shape --&gt; (2500, 20) 
training_decoder_output.shape ---&gt; (2500, 20, 11272) 
clone_vocab_size ---&gt; 11271
</code></pre>
<p>Ouput of <code>model.summary()</code>:</p>
<pre><code>Model: &quot;functional_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 20)]         0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 20)]         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 20, 50)       564800      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 20, 50)       563600      input_2[0][0]                    
__________________________________________________________________________________________________
lstm (LSTM)                     [(None, 64), (None,  29440       embedding[0][0]                  
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 20, 64)       29440       embedding_1[0][0]                
                                                                 lstm[0][1]                       
                                                                 lstm[0][2]                       
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 20, 11272)    732680      lstm_1[0][0]                     
==================================================================================================
Total params: 1,919,960
Trainable params: 1,919,960
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre>
<p>But when I try to train the model:</p>
<pre><code>model.fit(x=[training_encoder_input, training_decoder_input],
          y=training_decoder_output,
          verbose=2,
          batch_size=128,
          epochs=10)
</code></pre>
<p>I get this error:</p>
<pre><code>InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  indices[28,0] = 11292 is not in [0, 11272)
     [[node functional_1/embedding_1/embedding_lookup (defined at &lt;ipython-input-11-967d0351a90e&gt;:31) ]]
  (1) Invalid argument:  indices[28,0] = 11292 is not in [0, 11272)
     [[node functional_1/embedding_1/embedding_lookup (defined at &lt;ipython-input-11-967d0351a90e&gt;:31) ]]
     [[broadcast_weights_1/assert_broadcastable/AssertGuard/else/_13/broadcast_weights_1/assert_broadcastable/AssertGuard/Assert/data_7/_78]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_13975]

Errors may have originated from an input operation.
Input Source operations connected to node functional_1/embedding_1/embedding_lookup:
 functional_1/embedding_1/embedding_lookup/8859 (defined at /usr/lib/python3.6/contextlib.py:81)

Input Source operations connected to node functional_1/embedding_1/embedding_lookup:
 functional_1/embedding_1/embedding_lookup/8859 (defined at /usr/lib/python3.6/contextlib.py:81)

Function call stack:
train_function -&gt; train_function
</code></pre>
<p>Someone already asked <a href=""https://stackoverflow.com/questions/61054359/invalidargumenterror-2-root-errors-found-0-invalid-argument-incompatible"">this question</a> but none of the reponses worked for me, probably the error is within the loss function or within the vocabulary of the embedding layer, but I can't figure out what's exactly the problem.</p>
",13071340.0,,,,,2021-02-22 09:58:47,"Tensorflow InvalidArgumentError: 2 root error(s) found. indices[28,0] = 11292 is not in [0, 11272)",<python><tensorflow><keras><loss-function>,1,4,,,,CC BY-SA 4.0
63495532,1,63594460.0,,2020-08-19 22:01:18,,4,381,"<p>I try to create a very simple neural network: one hidden layer, with 2 neurons. For some very simple data: only one feature.</p>
<pre><code>import numpy as np
X=np.concatenate([np.linspace(0,10,100),np.linspace(11,20,100),np.linspace(21,30,100)])
y=np.concatenate([np.repeat(0,100),np.repeat(1,100),np.repeat(0,100)])
</code></pre>
<p><a href=""https://i.stack.imgur.com/gAgvq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gAgvq.png"" alt=""enter image description here"" /></a></p>
<p>Here is the model</p>
<pre><code>from keras.models import Sequential
from keras.layers import Dense
model = Sequential()
model.add(Dense(2, activation='sigmoid'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])
model.fit(X, y, epochs=200)
</code></pre>
<p>In theory, this model should work. But even after 1000 epochs, the accuracy is still 0.667.</p>
<pre><code>Epoch 999/1000
10/10 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.6667
Epoch 1000/1000
10/10 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.6667
</code></pre>
<p>I think that I did something wrong. Could you suggest some modification?</p>
<p>It seems that there are a lot of <strong>local minimums</strong> and the <strong>initialization</strong> can change the final model. It is the case when testing with the package <code>nnet</code> in R. I had to test lots of seeds, I found this model (among others).</p>
<p><a href=""https://i.stack.imgur.com/hFcvL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hFcvL.png"" alt=""enter image description here"" /></a></p>
<p>And this is the structure that I wanted to create with keras: one hidden layer with 2 neurons. The activation function is sigmoid.</p>
<p>So I am wondering if keras has the same problem with initialization. With this package <code>nnet</code> in R, I thought that it is not a &quot;perfect&quot; package. And I thought keras would be more performant. If the initialization is important, does keras test different initialization? If not why ? Maybe because in general, with more data (and more features), it works better (without testing many initializations)?</p>
<p>For example, with kmeans, it seems that different initializations are tested.</p>
",4822772.0,,4822772.0,,2020-08-23 14:35:18,2020-08-26 13:21:48,Keras: simple neural network with simple data not working,<python><tensorflow><keras><neural-network>,1,0,0.0,,,CC BY-SA 4.0
66501770,1,66533191.0,,2021-03-06 02:23:19,,4,3187,"<p>I have TensorFlow, NVIDIA GPU (CUDA)/CPU, Keras, &amp; Python 3.7 in Linux Ubuntu.
I followed all the steps according to this tutorial:
<a href=""https://www.youtube.com/watch?v=dj-Jntz-74g"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=dj-Jntz-74g</a></p>
<p>when I run the following code of:</p>
<pre><code># What version of Python do you have?
import sys

import tensorflow.keras
import pandas as pd
import sklearn as sk
import tensorflow as tf

print(f&quot;Tensor Flow Version: {tf.__version__}&quot;)
print(f&quot;Keras Version: {tensorflow.keras.__version__}&quot;)
print()
print(f&quot;Python {sys.version}&quot;)
print(f&quot;Pandas {pd.__version__}&quot;)
print(f&quot;Scikit-Learn {sk.__version__}&quot;)
gpu = len(tf.config.list_physical_devices('GPU'))&gt;0
print(&quot;GPU is&quot;, &quot;available&quot; if gpu else &quot;NOT AVAILABLE&quot;)
</code></pre>
<p>I get the these results:</p>
<pre><code>Tensor Flow Version: 2.4.1
Keras Version: 2.4.0

Python 3.7.10 (default, Feb 26 2021, 18:47:35) 
[GCC 7.3.0]
Pandas 1.2.3
Scikit-Learn 0.24.1
GPU is available
</code></pre>
<p>However; I don't know how to run my Keras model on GPU. When I run my model, and I get <code>$ nvidia-smi -l 1</code>, GPU usage is almost %0 during the run.</p>
<pre><code>from keras import layers
from keras.models import Sequential
from keras.layers import Dense, Conv1D, Flatten
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score
from keras.callbacks import EarlyStopping
 
model = Sequential()
model.add(Conv1D(100, 3, activation=&quot;relu&quot;, input_shape=(32, 1)))
model.add(Flatten())
model.add(Dense(64, activation=&quot;relu&quot;))
model.add(Dense(1, activation=&quot;linear&quot;))
model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=['mean_squared_error'])
model.summary()

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=70)

history = model.fit(partial_xtrain_CNN, partial_ytrain_CNN, batch_size=100, epochs=1000,\
                    verbose=0, validation_data=(xval_CNN, yval_CNN), callbacks = [es])
</code></pre>
<p>Do I need to change any parts of my code or add a part to force it run on GPU??</p>
",,user14655550,,user14655550,2021-03-06 03:00:08,2021-03-08 16:06:24,How to force tensorflow and Keras run on GPU?,<python><tensorflow><keras><deep-learning><gpu>,2,2,0.0,,,CC BY-SA 4.0
64226155,1,,,2020-10-06 12:48:32,,4,2115,"<p>I am getting the following error when using the DeepExplainer for the Keras sequential model for Multiclass text classification. Please find the details below:</p>
<p>##KERAS VERSION: 2.4.3.</p>
<p>##MODEL</p>
<pre><code>model = Sequential()
model.add(InputLayer (input_shape= (max_len ,)))
model.add(Embedding (vocab_size +1 , embed_dim , input_length= max_len, weights[embed_matrix]))
model.add(LSTM (LSTM_unit , dropout= dropouts, recurrent_dropout=dropouts,return_sequences=False))
model.add(Dense (6 , activation=&quot;softmax&quot;))
##DEEPEXPLAINER

explainer = shap.DeepExplainer(model, X_train[:100], learning_phase_flags = None)
shap_values = explainer.shap_values(X_test[:10])
</code></pre>
<p>ERROR</p>
<pre><code>LookupError: gradient registry has no entry for: shap_TensorListStack
</code></pre>
<p>Please help me with the solution to this issue. I have tried all the possible solutions provided in the issues mentioned in the repository but couldn't able to solve this error.</p>
<p>Best Regards,
Meghna Goyal</p>
",14400807.0,,10227958.0,,2020-10-07 02:26:45,2022-12-31 08:48:27,"""LookupError: gradient registry has no entry for: shap_TensorListStack"" using DeepExplainer for Keras Model",<tensorflow><keras><shap>,1,0,0.0,,,CC BY-SA 4.0
63515917,1,,,2020-08-21 03:03:52,,4,3027,"<p>I am following along this tutorial on youtube for DeepQlearning.  However, I am having difficulty getting it to run. It says I don't have the attribute '_train_dir'.  When I am not even calling that code. Here is the code:</p>
<pre><code>class ModifiedTensorBoard(TensorBoard):

    # Overriding init to set initial step and writer (we want one log file for all .fit() calls)
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.step = 1
        self.writer = tf.summary.create_file_writer(self.log_dir)
        self._log_write_dir= self.log_dir

    def _write_logs(self, logs, index):
        with self.writer.as_default():
            for name, value in logs.items():
                tf.summary.scalar(name, value, step=index)
                self.step += 1
                self.writer.flush()
                
    # Overriding this method to stop creating default log writer
    def set_model(self, model):
        pass

    # Overrided, saves logs with our step number
    # (otherwise every .fit() will start writing from 0th step)
    def on_epoch_end(self, epoch, logs=None):
        self.update_stats(**logs)

    # Overrided
    # We train for one batch only, no need to save anything at epoch end
    def on_batch_end(self, batch, logs=None):
        pass

    # Overrided, so won't close writer
    def on_train_end(self, _):
        pass

    # Custom method for saving own metrics
    # Creates writer, writes custom metrics and closes writer
    def update_stats(self, **stats):
        self._write_logs(stats, self.step)

</code></pre>
<p>It compiles up until this point:</p>
<pre><code>Traceback (most recent call last):
  File &quot;dqn-1.py&quot;, line 387, in &lt;module&gt;
    agent.train(done, step)
  File &quot;dqn-1.py&quot;, line 334, in train
    verbose=0, shuffle=False, callbacks=[self.tensorboard] if terminal_state else None)
  File &quot;C:\Users\Anthony\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File &quot;C:\Users\Anthony\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\engine\training.py&quot;, line 1079, in fit
    callbacks.on_train_begin()
  File &quot;C:\Users\Anthony\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\callbacks.py&quot;, line 497, in on_train_begin
    callback.on_train_begin(logs)
  File &quot;C:\Users\Anthony\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\callbacks.py&quot;, line 2141, in on_train_begin
    self._push_writer(self._train_writer, self._train_step)
  File &quot;C:\Users\Anthony\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\keras\callbacks.py&quot;, line 1988, in _train_writer
    self._train_dir)
</code></pre>
<p>What am I doing wrong?</p>
",14140860.0,,,,,2021-04-12 19:56:25,AttributeError: 'ModifiedTensorBoard' object has no attribute '_train_dir',<python><python-3.x><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0
63522465,1,,,2020-08-21 11:54:25,,4,3098,"<p><strong>System information</strong></p>
<ul>
<li>OS Platform and Distribution :CentOS Linux release 7.7.1908
-TensorFlow version:2.3.0</li>
</ul>
<p>I am following this example:<a href=""https://www.tensorflow.org/tutorials/text/image_captioning?hl=en"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/text/image_captioning?hl=en</a></p>
<p>It is working as it should be and saving checkpoints and I want to now convert this to a TF Lite model.</p>
<p>Here is the Link of full convert code:<a href=""https://colab.research.google.com/drive/1GJkGcwWvDAWMooTsECzuSRUSPbirADhb?usp=sharing"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/1GJkGcwWvDAWMooTsECzuSRUSPbirADhb?usp=sharing</a></p>
<p>Here is the Link of full train code:
<a href=""https://colab.research.google.com/drive/1X2d9WW1EMEzN8Rgva3rtjevP0T_jFccj?usp=sharing"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/1X2d9WW1EMEzN8Rgva3rtjevP0T_jFccj?usp=sharing</a></p>
<p>I also following the <a href=""https://github.com/tensorflow/tensorflow/issues/32999"" rel=""nofollow noreferrer"">isssue#32999</a></p>
<p>Here is what I am running to save and them convert the inference graph:</p>
<pre><code>@tf.function
def evaluate(image):
    hidden = decoder.reset_states(batch_size=1)

    temp_input = tf.expand_dims(load_image(image)[0], 0)
    img_tensor_val = image_features_extract_model(temp_input)
    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))

    features = encoder(img_tensor_val)

    dec_input = tf.expand_dims([tokenizer.word_index['&lt;start&gt;']], 0)
    result = []

    for i in range(max_length):
        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)

        predicted_id = tf.random.categorical(predictions, 1)[0][0]
        # print(tokenizer.index_word)
        print(predicted_id,predicted_id.dtype)

        # for key,value in tokenizer.index_word.items():
        #     key = tf.convert_to_tensor(key)
        #     tf.dtypes.cast(key,tf.int64)
        #     print(key)

        # print(tokenizer.index_word)

        result.append(predicted_id)

        # if tokenizer.index_word[predicted_id] == '&lt;end&gt;':
        #     return result

        dec_input = tf.expand_dims([predicted_id], 0)

    return result

export_dir = &quot;./&quot;
tflite_enc_input = ''
ckpt.f = evaluate
to_save = evaluate.get_concrete_function('')

converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
tflite_model = converter.convert()
</code></pre>
<p>but I get this error</p>
<pre><code>ValueError: in user code:

    convert2savedmodel.py:310 evaluate  *
        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__  **
        outputs = call_fn(inputs, *args, **kwargs)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:780 __call__
        result = self._call(*args, **kwds)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:840 _call
        return self._stateless_fn(*args, **kwds)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2828 __call__
        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3171 _maybe_define_function
        *args, **kwargs)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2622 canonicalize_function_inputs
        self._flat_input_signature)
    /share/nishome/19930072_0/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2713 _convert_inputs_to_signature
        format_error_message(inputs, input_signature))

    ValueError: Python inputs incompatible with input_signature:
      inputs: (
        Tensor(&quot;ExpandDims_1:0&quot;, shape=(1, 1), dtype=int32),
        Tensor(&quot;cnn__encoder/StatefulPartitionedCall:0&quot;, shape=(1, 64, 256), dtype=float32),
        Tensor(&quot;zeros:0&quot;, shape=(1, 512), dtype=float32))
      input_signature: (
        TensorSpec(shape=(1, 1), dtype=tf.int64, name=None),
        TensorSpec(shape=(1, 64, 256), dtype=tf.float32, name=None),
        TensorSpec(shape=(1, 512), dtype=tf.float32, name=None))

</code></pre>
<p>Encoder Model:</p>
<pre><code>class CNN_Encoder(tf.keras.Model):
    def __init__(self, embedding):
        super(CNN_Encoder, self).__init__()
        # shape after fc == (batch_size, 64, embedding_dim)
        self.fc = tf.keras.layers.Dense(embedding_dim)

    @tf.function(input_signature=[tf.TensorSpec(shape=(1, 64, features_shape),dtype=tf.dtypes.float32)])
    def call(self, x):
        x = self.fc(x)
        x = tf.nn.relu(x)
        return x
</code></pre>
<p>Decoder model:</p>
<pre><code>class RNN_Decoder(tf.keras.Model):
    def __init__(self, embedding_dim, units, vocab_size):
        super(RNN_Decoder, self).__init__()
        self.units = units

        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.gru = tf.keras.layers.GRU(self.units,
                                       return_sequences=True,
                                       return_state=True,
                                       recurrent_initializer='glorot_uniform',
                                       unroll = True)
        self.fc1 = tf.keras.layers.Dense(self.units)
        self.fc2 = tf.keras.layers.Dense(vocab_size)

        self.attention = BahdanauAttention(self.units)


    @tf.function(input_signature=[tf.TensorSpec(shape=[1, 1], dtype=tf.int64),
                                  tf.TensorSpec(shape=[1, 64, 256], dtype=tf.float32),
                                  tf.TensorSpec(shape=[1, 512], dtype=tf.float32)])
    def call(self, x , features, hidden):

        context_vector, attention_weights = self.attention(features, hidden)

        #x shape after passing through embedding == (batch_size, 1, embedding_dim)
        x = self.embedding(x)

        #x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)


        output, state = self.gru(x)

        #shape == (batch_size, max_length, hidden_size)
        x = self.fc1(output)

        #x shape == (batch_size, max_length, hidden_size)
        x = tf.reshape(x, (-1, x.shape[2]))

        # output shape == (batch_size * max_length, vocab)
        x = self.fc2(x)

        return x, state, attention_weights

    def reset_states(self, batch_size):
        return tf.zeros((batch_size, self.units))
</code></pre>
<p>I just change the tf.function to int32 as below:</p>
<p><code>@tf.function(input_signature=[tf.TensorSpec(shape=[1, 1], dtype=tf.int32), tf.TensorSpec(shape=[1, 64,256], dtype=tf.float32), tf.TensorSpec(shape=[1, 512], dtype=tf.float32)])</code></p>
<p>but another error came:</p>
<p>ValueError: Python inputs incompatible with input_signature:</p>
<pre><code>Tensor(&quot;ExpandDims_2:0&quot;, shape=(1, 1), dtype=int64),
Tensor(&quot;cnn__encoder/StatefulPartitionedCall:0&quot;, shape=(1, 64, 256), dtype=float32),
Tensor(&quot;rnn__decoder/StatefulPartitionedCall:1&quot;, shape=(1, 512), dtype=float32))
input_signature: (
TensorSpec(shape=(1, 1), dtype=tf.int32, name=None),
TensorSpec(shape=(1, 64, 256), dtype=tf.float32, name=None),
TensorSpec(shape=(1, 512), dtype=tf.float32, name=None))```
Why the dtypes of inputs change from int64 to int32?
</code></pre>
",12318017.0,,,,,2020-08-21 11:54:25,ValueError: Python inputs incompatible with input_signature:,<python><tensorflow><keras><tensorflow2.0><tensorflow-lite>,0,0,,,,CC BY-SA 4.0
71928740,1,,,2022-04-19 17:09:04,,4,437,"<p>I have been getting this warning when using <code>model.fit()</code> or even <code>model.summary()</code>. Using (on Windows 10):</p>
<ul>
<li>Tensorflow 2.6.2</li>
<li>Tensorflow Probability 0.14</li>
<li>Keras 2.6</li>
</ul>
<p>Also tested on Google Colab with <code>tf==2.8, tfp==0.16, keras==2.8</code>, without any change.</p>
<p>Tried to downgrade Tensorflow and TF-probability as suggusted <a href=""https://github.com/theislab/scCODA/issues/40"" rel=""nofollow noreferrer"">here (for a different implementation)</a> but did not work. My model is this, however I've had the same issue with different hidden layers and also when used a functional API:</p>
<pre><code>model = Sequential()
model.add(keras.Input(shape=(dataset.shape[1],1)))
model.add(tfkl.Conv1D(128, kernel_size = dataset.shape[1], activation='relu'))
model.add(tfkl.Conv1D(16, kernel_size = 1, activation='softplus'))
model.add( tfkl.Flatten())
model.add(tfkl.Dense(16, activation='softplus'))
model.add(tfkl.Dense(1, use_bias = 1))
model.add(tfpl.DistributionLambda(
    lambda t: tfd.Chi2(df= abs(t[..., :1])
                        )))
</code></pre>
<p>Note that I'm not having the same issue when using <code>tfd.Normal</code> (only <code>tfd.Chi2</code> and <code>tfd.Gamma</code> don't work). Anyone faced the same issue?</p>
",17832660.0,,17832660.0,,2022-04-20 11:55:07,2022-04-20 11:55:07,"How to fix ""WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass""?",<python><tensorflow><keras><neural-network><tensorflow-probability>,0,0,0.0,,,CC BY-SA 4.0
66370887,1,66417795.0,,2021-02-25 14:51:22,,4,801,"<p>Please add a minimum comment on your thoughts so that I can improve my query. Thank you.  -)</p>
<hr />
<p>I'm trying to understand and implement a research work on <a href=""https://www.sciencedirect.com/science/article/abs/pii/S1361841520302103"" rel=""nofollow noreferrer"">Triple Attention Learning</a>, which consists on</p>
<pre><code>- channel-wise attention  (a)
- element-wise attention  (b)
- scale-wise attention    (c)
</code></pre>
<p>The mechanism is integrated experimentally inside the <code>DenseNet</code> model. The arch of the whole model's diagram is <a href=""https://i.stack.imgur.com/Zu8Yy.png"" rel=""nofollow noreferrer"">here</a>. The <strong>channel-wise</strong> attention module is simply nothing but the <strong>squeeze and excitation</strong> block. That gives a <code>sigmoid</code> output further to the <strong>element-wise</strong> attention module. Below is the more precise feature flow diagram of these modules (<code>a</code>, <code>b</code>, and <code>c</code>).</p>
<img src=""https://i.stack.imgur.com/nHnxL.png"" width=""600""/> 
<hr />
<h3>Theory</h3>
<p>For the most part, I was able to understand and implement it but was a bit lost in the <code>Element-Wise</code> attention section (part <code>b</code> from the above diagram). This is where I need your assistance. -)</p>
<p>Here is a little theory on this topic to give you a rough idea of what all this is about. Please note, The paper is not openly accessible <strong>now</strong> but at its early stage of release on the publisher page <strong>it was</strong> free to get and I saved it at that time. And to be fair to all, I'm sharing it with you, <a href=""https://drive.google.com/file/d/1BtH2qnAxWzGVScJ9tW4nGlZI0MI5IGGu/view?usp=sharing"" rel=""nofollow noreferrer"">Link</a>. Anyway, from the paper (Section <strong>4.3</strong>) it shows:</p>
<img src=""https://i.stack.imgur.com/wjPTL.jpg"" width=""400""/> 
<p>So <strong>first</strong> of all, <code>f(att)</code> function (which is in the first inplace diagram, left-middle part or <code>b</code>) consists of three convolution layers with <strong>512</strong> kernels with <code>1 x 1</code>, <strong>512</strong> kernels with <code>3 x 3</code> and <code>C</code> kernels with <code>1 x 1</code>. Here <code>C</code> is the number of the classifier. And with <code>Softmax</code> activation!</p>
<p>Next, it applies to the <code>Channel-Wise</code> attention module which we mentioned that simply a <code>SENet</code> module and gave a <code>sigmoid</code> probability score i.e <code>X(CA)</code>. So, from the function of <code>f(att)</code>, we're getting <code>C</code> times <code>softmax</code> probability scores and each of these scores get multiplied with <code>sigmoid</code> output and finally produces feature maps <code>A</code> (according to the equation <strong>4</strong> of the above diagram).</p>
<p><strong>Second</strong>, there is a <code>C</code> linear classifier that implemented as a <code>1 x 1</code> - <code>C</code> kernels convolution layer. This layer also applied to the <code>SENet</code> module's output i.e. <code>X(CA)</code>, to each feature vector pixel-wise. And in the end, it gives an output of feature maps <code>S</code> (equation <strong>5</strong> shown below diagram).</p>
<p>And <strong>Third</strong>, they element-wise multiply each confidence score (of <code>S</code>) with the corresponding attention element <code>A</code>. This multiplication is on purpose. They did it for preventing unnecessary attention on the feature maps.  To make it effective, they also use the <code>weighted cross-entropy</code> loss function to minimize it here between the classification <strong>ground truth</strong> and the <strong>score vector</strong>.</p>
<img src=""https://i.stack.imgur.com/upUs2.jpg"" width=""400""/> 
<p><strong>My Query</strong></p>
<p>Mostly I don't get properly the minimization strategies in the middle of the network. I want someone who can give me a proper understanding and implementation of this `element-wise attention mechanism in detail that proposed in the mentioned paperwork (section <strong>4.3</strong>).</p>
<hr />
<h2>Implement</h2>
<p>Here is a minimum code to get started. It should enough I guess. This is shallow implementation but too much away from the original element-wise module. I'm not sure how to implement it properly. For now, I want it as a layer that supposed to plug and play to any model. I was trying with MNIST and a simple <code>Conv</code> net.</p>
<p>In a summary, for MNIST, we should have a network that contains both the <code>channel-wise</code> and <code>element-wise</code> attention model followed by the last <strong>10</strong> unit <code>softmax</code> layer. So for example:</p>
<pre><code>Net: Conv2D - Attentions-Module - GAP - Softmax(10)
</code></pre>
<p>The <code>Attention-Module</code> consists of those two-part: <code>Channel-wise</code> and <code>Element-wise</code>, and the <code>Element-wise</code>supposed to have <code>Softmax</code> too that minimizes weighted <code>CE</code> loss function to <code>ground-truth</code> and <code>score vector</code> coming from this module (according to the paperwork, already described above too). The module also passes <strong>weighted feature maps</strong> to the consecutive layers. For more clarity here is a simple schematic diagram of what we're looking for</p>
<img src=""https://i.stack.imgur.com/2hP39.png"" width=""500""/> 
<p>Ok, for the <code>channel-wise</code> attention which should give us a single probability score (<code>sigmoid</code>), let's use a fake layer for now for simplicity:</p>
<pre><code>class FakeSE(tf.keras.layers.Layer):
    def __init__(self):
        super(Block, self).__init__()
        # conv layer
        self.conv = tf.keras.layers.Conv2D(10, padding='same',
                                           kernel_size=3)
    def call(self, input_tensor, training=False):
        x = self.conv(input_tensor)
        return tf.math.sigmoid(x)
</code></pre>
<p>And for the <code>element-wise</code> attention part, following is the failed attempt so far:</p>
<pre><code>class ElementWiseAttention(tf.keras.layers.Layer):
    def __init__(self):
        # for simplicity the f(attn) function here has 2 convolution instead of 3
        # self.conv1, and self.conv2
        self.conv1 = tf.keras.layers.Conv2D(16, 
                                            kernel_size=1, 
                                            strides=1, padding='same',
                                            use_bias=True, activation=tf.nn.silu)

        self.conv2 = tf.keras.layers.Conv2D(10, 
                                            kernel_size=1, 
                                            strides=1, padding='same',
                                            use_bias=False, activation=tf.keras.activations.softmax)
        
        # fake SENet or channel-wise attention module 
        self.cam = FakeSE()
        
        # a linear layer 
        self.linear = tf.keras.layers.Conv2D(10,
                                           kernel_size=1,
                                           strides=1, padding='same',
                                           use_bias=True, activation=None)
        
        super(ElementWiseAttention, self).__init__()
    
    def call(self, inputs):
        # 2 stacked conv layer (in paper, it's 3. we set 2 for simplicity)
        # this is the f(att)
        x = self.conv1(inputs)
        x = self.conv2(x)
        
        # this is the A = f(att)*X(CA)
        camx = self.cam(x)*x
        
        # this is S = X(CA)*Linear_Classifier
        linx = self.cam(self.linear(inputs))

        # element-wise multiply to prevent unnecessary attention
        # suppose to minimize with weighted cross entorpy loss 
        out = tf.multiply(camx, linx)
        
        return out
</code></pre>
<p>The above one is the <strong>Layer of Interest</strong>. If I understand the paper words correctly, this layer should not only minimize the weighted loss function to <code>gt</code> and <code>score_vector</code> but also produce some weighted feature maps (<code>2D</code>).</p>
<h2>Run</h2>
<p>Here is the toy data</p>
<pre><code>
(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()
x_train = np.expand_dims(x_train, axis=-1)
x_train = x_train.astype('float32') / 255
x_train = tf.image.resize(x_train, [32,32]) # if we want to resize 
y_train = tf.keras.utils.to_categorical(y_train , num_classes=10) 

# Model 
input = tf.keras.Input(shape=(32,32,1))
efnet = tf.keras.applications.DenseNet121(weights=None,
                                             include_top = False, 
                                             input_tensor = input)
em =  ElementWiseAttention()(efnet.output)
# Now that we apply global max pooling.
gap = tf.keras.layers.GlobalMaxPooling2D()(em)

# classification layer.
output = tf.keras.layers.Dense(10, activation='softmax')(gap)

# bind all
func_model = tf.keras.Model(efnet.input, output)
func_model.compile(
          loss      = tf.keras.losses.CategoricalCrossentropy(),
          metrics   = tf.keras.metrics.CategoricalAccuracy(),
          optimizer = tf.keras.optimizers.Adam())
# fit 
func_model.fit(x_train, y_train, batch_size=32, epochs=3, verbose = 1)
</code></pre>
",9215780.0,,9215780.0,,2022-02-24 10:56:09,2022-02-24 10:56:09,Understand and Implement Element-Wise Attention Module,<python><tensorflow><machine-learning><keras><deep-learning>,1,0,0.0,,,CC BY-SA 4.0
63721915,1,63723321.0,,2020-09-03 10:39:08,,4,1035,"<p>I have a Keras model for which I would like to save the normalization values in the <code>model</code> object itself for easier portability.</p>
<p>I'm using sklearn's <code>StandardScaler()</code> to normalize my data, so I simply want to save the <code>mean_</code> and <code>var_</code> attributes from the <code>scaler</code> to the <code>model</code>, save the model, and when I reload the model have access to these attributes.</p>
<p>Currently when I reload the model the attributes I added are not there. What is the correct way of doing this ?</p>
<p>Code:</p>
<pre><code># Normalize data
scaler = StandardScaler()
scaler.fit(X_train)
...

# Create model
model = Sequential(...)

# Compile and train
...

# Save model with normalization mean and var
model.normalization_mean = scaler.mean_
model.normalization_var  = scaler.var_

keras.models.save_model(model = model, 
                        filepath = ...)

# Reload model
model = keras.models.load_model(filepath = ...)

hasattr(model, 'normalization_mean') # False
hasattr(model, 'normalization_var')  # False
</code></pre>
",12397370.0,,10375049.0,,2022-01-16 20:42:09,2022-01-16 20:42:09,Saving normalization values in Keras model,<python><tensorflow><machine-learning><keras><deep-learning>,2,0,0.0,,,CC BY-SA 4.0
70017229,1,70059354.0,,2021-11-18 09:17:10,,4,405,"<p>I have defined a callback that runs on the epoch end and calculate the metrics. It is working fine in terms of calculating the desired metrics. Below is the function for reference</p>
<h2>callback to find metrics at epoch end</h2>
<pre><code>class Metrics(tf.keras.callbacks.Callback):
    def __init__(self, train_tf_data, val_tf_data, model, CLASSES, logs={}, **kwargs):
        super().__init__(**kwargs)
        self.train_tf_data = train_tf_data
        self.val_tf_data = val_tf_data
        self.model = model
        self.CLASSES = CLASSES
        # for train data
        self.train_f1_after_epoch = 0
        self.train_prec_after_epoch = 0
        self.train_recall_after_epoch = 0
        # for val data
        self.val_f1_after_epoch = 0
        self.val_prec_after_epoch = 0
        self.val_recall_after_epoch = 0

    def on_train_begin(self, logs={}):
        self.train_reports = None
        self.val_reports = None
        self.val_f1_after_epoch = 0

    def on_epoch_end(self, epoch, logs={}):
        # for train data
        self.train_reports = test_model(model=self.model, data=self.train_tf_data, 
                                        CLASSES=self.CLASSES)
        self.train_f1_after_epoch = self.train_reports['f1_score']
        self.train_recall_after_epoch = self.train_reports['recall']
        self.train_prec_after_epoch = self.train_reports['precision']

        # for val data
        self.val_reports = test_model(model=self.model, data=self.val_tf_data, 
                                      CLASSES=self.CLASSES)
        self.val_f1_after_epoch = self.val_reports['f1_score']
        self.val_recall_after_epoch = self.val_reports['recall']
        self.val_prec_after_epoch = self.val_reports['precision']

        # saving train results to log dir
        logs[&quot;train_f1_after_epoch&quot;]=self.train_f1_after_epoch
        logs['train_precision_after_epoch'] = self.train_prec_after_epoch
        logs['train_recall_after_epoch'] = self.train_recall_after_epoch
        
        # saving val results to log dir
        logs['val_f1_after_epoch'] = self.val_f1_after_epoch
        logs['val_precision_after_epoch'] = self.val_prec_after_epoch
        logs['val_recall_after_epoch'] = self.val_recall_after_epoch


        print('train_reports_after_epoch', self.train_reports)
        print('val_reports_after_epoch', self.val_reports)
</code></pre>
<h1>Code for test_model</h1>
<pre><code>def test_model(model, data, CLASSES, label_one_hot=True, average=&quot;micro&quot;):
    images_ds = data.map(lambda image, label: image)
    labels_ds = data.map(lambda image, label: label).unbatch()
    NUM_VALIDATION_IMAGES = count_data_items(tf_records_filenames=data)
    cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy() # get everything as one batch
    if label_one_hot is True:
        cm_correct_labels = np.argmax(cm_correct_labels, axis=-1)
    cm_probabilities = model.predict(images_ds)
    cm_predictions = np.argmax(cm_probabilities, axis=-1)
    
    # cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))

    warnings.filterwarnings('ignore')
    score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average=average)
    precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average=average)
    recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average=average)
    # cmat = (cmat.T / cmat.sum(axis=1)).T # normalized
    # print('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))
    test_results = {'f1_score': score, 'precision':precision, 'recall':recall}
    warnings.filterwarnings('always')
    return test_results
</code></pre>
<h1>Some model code.....</h1>
<h1>Model code</h1>
<pre><code>m1 = tf.keras.metrics.CategoricalAccuracy()
m2 = tf.keras.metrics.Recall()
m3 = tf.keras.metrics.Precision()
m4 = Metrics(train_tf_data=train_data, 
             val_tf_data=test_data, model=model, 
             CLASSES=CLASS_NAMES)
optimizers = [
        tfa.optimizers.AdamW(learning_rate=lr * .001 , weight_decay=wd),
        tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)

           ]
optimizers_and_layers = [(optimizers[0], model.layers[0]), (optimizers[1], model.layers[1:])]
    
optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)


model.compile(
    optimizer= optimizer,
    loss = 'categorical_crossentropy',
    metrics=[m1, m2, m3],
    )
</code></pre>
<h1>Using this in the callback</h1>
<pre><code>checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, 
                                                    monitor = 'val_f1_after_epoch',
                                                    save_best_only=True,
                                                    save_weights_only=True,
                                                    mode='max',
                                                    save_freq='epoch',
                                                    verbose=1)
                                                    
checkpoint_cb._supports_tf_logs = False
</code></pre>
<p>The issue that I am facing is that it is giving me a warning that say</p>
<p><strong>WARNING:tensorflow:Can save best model only with val_f1_after_epoch available, skipping</strong></p>
<p>Upon investigating history I found that metrics is available in the history</p>
<pre><code>print(list(history.history.keys()))
['loss',
'categorical_accuracy',
'recall',
'precision',
'val_loss',
'val_categorical_accuracy',
'val_recall',
'val_precision',
'train_f1_after_epoch',
'train_precision_after_epoch',
'train_recall_after_epoch',
'val_f1_after_epoch', #this is the metrics
'val_precision_after_epoch',
'val_recall_after_epoch']
</code></pre>
<p>Please let me know what I am missing here, I want to save the best model based on my custom metrics?</p>
",6244166.0,,6244166.0,,2021-11-24 06:03:24,2021-11-28 21:09:45,"Saving best metrics based on Custom metrics failing (WARNING:tensorflow:Can save best model only with CUSTOM METRICS available, skipping)",<python><tensorflow><keras><tf.keras>,1,0,,,,CC BY-SA 4.0
63732504,1,63734057.0,,2020-09-03 22:33:23,,4,1569,"<p>I am trying to implement a regression Sequential model with Keras and I am getting very weird results. My code is below. I am using a tf.data dataset as my input dataset. My loss goes down initially but then starts oscillating. Would there be a reason this is happening?</p>
<pre><code>    #initialize model
    model = keras.models.Sequential()
    
    model.add(Dense(1+(len(feature_names)-1), input_shape=((len(feature_names)-1),)))
    model.add(LeakyReLU())
    model.add(Dropout(0.5))
    
    model.add(Dense(10))
    model.add(LeakyReLU())
    
    #output layer, 1 unit
    model.add(Dense(1))
    
    loss = 'mean_squared_error'
    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.0001)
    
    #compile the model
    m = tf.keras.metrics.RootMeanSquaredError()
    model.compile(optimizer=optimizer, loss=loss, metrics=[m,'mae'])
    
#    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)
    tb = TensorBoard(histogram_freq=1)
    
    ##try learning rates, different noise, dropout, using only nasadem
    
    #run the model
    history = model.fit(x=final_train_dataset,epochs=count,steps_per_epoch=steps_per_epoch,validation_data=final_valid_dataset,callbacks=[tb])
</code></pre>
<pre><code>5468/5468 [==============================] - 19s 4ms/step - loss: 19.8461 - root_mean_squared_error: 4.4549 - mae: 3.1814 - val_loss: 13.2963 - val_root_mean_squared_error: 3.6464 - val_mae: 3.0513
Epoch 2/25
   1/5468 [..............................] - ETA: 0s - loss: 12.9226 - root_mean_squared_error: 3.5948 - mae: 2.63732020-09-03 17:02:51.641109: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 216632 of 1000000
2020-09-03 17:03:01.641093: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 432841 of 1000000
2020-09-03 17:03:11.641090: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 644957 of 1000000
2020-09-03 17:03:14.202555: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 9ms/step - loss: 4.5396 - root_mean_squared_error: 2.1306 - mae: 1.5395 - val_loss: 9.2400 - val_root_mean_squared_error: 3.0397 - val_mae: 2.3317
Epoch 3/25
   1/5468 [..............................] - ETA: 0s - loss: 2.1542 - root_mean_squared_error: 1.4677 - mae: 1.14152020-09-03 17:03:43.456237: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 209810 of 1000000
2020-09-03 17:03:53.456238: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 430811 of 1000000
2020-09-03 17:04:03.456243: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 649754 of 1000000
2020-09-03 17:04:05.717317: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 51s 9ms/step - loss: 3.5548 - root_mean_squared_error: 1.8854 - mae: 1.3483 - val_loss: 12.9111 - val_root_mean_squared_error: 3.5932 - val_mae: 3.1018
Epoch 4/25
   1/5468 [..............................] - ETA: 0s - loss: 3.0977 - root_mean_squared_error: 1.7600 - mae: 1.38832020-09-03 17:04:34.262132: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 220010 of 1000000
2020-09-03 17:04:44.262123: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 440231 of 1000000
2020-09-03 17:04:54.262103: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 658897 of 1000000
2020-09-03 17:04:56.431462: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 9ms/step - loss: 1.9917 - root_mean_squared_error: 1.4113 - mae: 1.0305 - val_loss: 18.9676 - val_root_mean_squared_error: 4.3552 - val_mae: 3.4140
Epoch 5/25
   1/5468 [..............................] - ETA: 0s - loss: 2.0044 - root_mean_squared_error: 1.4158 - mae: 0.98262020-09-03 17:05:25.768521: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 209530 of 1000000
2020-09-03 17:05:35.768491: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 415149 of 1000000
2020-09-03 17:05:45.768498: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 619178 of 1000000
2020-09-03 17:05:49.626056: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 10ms/step - loss: 3.1466 - root_mean_squared_error: 1.7739 - mae: 1.2621 - val_loss: 9.5821 - val_root_mean_squared_error: 3.0955 - val_mae: 2.3618
Epoch 6/25
   1/5468 [..............................] - ETA: 0s - loss: 2.2696 - root_mean_squared_error: 1.5065 - mae: 1.13252020-09-03 17:06:18.050735: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 216085 of 1000000
2020-09-03 17:06:28.050765: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 433756 of 1000000
2020-09-03 17:06:38.050744: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 647129 of 1000000
2020-09-03 17:06:40.516620: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 51s 9ms/step - loss: 6.5886 - root_mean_squared_error: 2.5668 - mae: 1.9638 - val_loss: 12.8445 - val_root_mean_squared_error: 3.5839 - val_mae: 2.6729
Epoch 7/25
   1/5468 [..............................] - ETA: 0s - loss: 6.2392 - root_mean_squared_error: 2.4978 - mae: 1.95852020-09-03 17:07:08.786525: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 211271 of 1000000
2020-09-03 17:07:18.786501: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 413948 of 1000000
2020-09-03 17:07:28.786525: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 628456 of 1000000
2020-09-03 17:07:32.091402: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 51s 9ms/step - loss: 8.6716 - root_mean_squared_error: 2.9448 - mae: 2.2906 - val_loss: 8.4462 - val_root_mean_squared_error: 2.9062 - val_mae: 2.0556
Epoch 8/25
   1/5468 [..............................] - ETA: 0s - loss: 7.3663 - root_mean_squared_error: 2.7141 - mae: 2.09252020-09-03 17:07:59.862839: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 196030 of 1000000
2020-09-03 17:08:09.862769: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 396211 of 1000000
2020-09-03 17:08:19.862786: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 596521 of 1000000
2020-09-03 17:08:24.550654: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 53s 10ms/step - loss: 4.6825 - root_mean_squared_error: 2.1639 - mae: 1.5158 - val_loss: 3.3543 - val_root_mean_squared_error: 1.8315 - val_mae: 1.4609
Epoch 9/25
   1/5468 [..............................] - ETA: 0s - loss: 3.3096 - root_mean_squared_error: 1.8192 - mae: 1.34092020-09-03 17:08:52.847230: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 213665 of 1000000
2020-09-03 17:09:02.847221: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 420633 of 1000000
2020-09-03 17:09:12.847262: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 625401 of 1000000
2020-09-03 17:09:16.325973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 53s 10ms/step - loss: 7.0318 - root_mean_squared_error: 2.6518 - mae: 2.0913 - val_loss: 5.9001 - val_root_mean_squared_error: 2.4290 - val_mae: 1.7496
Epoch 10/25
   1/5468 [..............................] - ETA: 0s - loss: 5.4777 - root_mean_squared_error: 2.3405 - mae: 1.84602020-09-03 17:09:45.541587: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 211860 of 1000000
2020-09-03 17:09:55.541592: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 425901 of 1000000
2020-09-03 17:10:05.541639: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 638506 of 1000000
2020-09-03 17:10:08.444475: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 51s 9ms/step - loss: 5.5155 - root_mean_squared_error: 2.3485 - mae: 1.6887 - val_loss: 7.0059 - val_root_mean_squared_error: 2.6469 - val_mae: 1.9491
Epoch 11/25
   1/5468 [..............................] - ETA: 0s - loss: 4.7595 - root_mean_squared_error: 2.1816 - mae: 1.60422020-09-03 17:10:36.978236: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 220628 of 1000000
2020-09-03 17:10:46.978223: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 439429 of 1000000
2020-09-03 17:10:56.978219: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 658497 of 1000000
2020-09-03 17:10:58.887525: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 50s 9ms/step - loss: 7.7528 - root_mean_squared_error: 2.7844 - mae: 2.1798 - val_loss: 7.4304 - val_root_mean_squared_error: 2.7259 - val_mae: 2.1477
Epoch 12/25
   1/5468 [..............................] - ETA: 0s - loss: 5.9227 - root_mean_squared_error: 2.4337 - mae: 1.86982020-09-03 17:11:26.748628: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 215455 of 1000000
2020-09-03 17:11:36.748645: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 432008 of 1000000
2020-09-03 17:11:46.748652: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 648981 of 1000000
2020-09-03 17:11:49.102683: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 9ms/step - loss: 5.3337 - root_mean_squared_error: 2.3095 - mae: 1.7406 - val_loss: 16.7965 - val_root_mean_squared_error: 4.0984 - val_mae: 2.9269
Epoch 13/25
   1/5468 [..............................] - ETA: 0s - loss: 3.7040 - root_mean_squared_error: 1.9246 - mae: 1.49812020-09-03 17:12:18.282279: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 220812 of 1000000
2020-09-03 17:12:28.282279: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 446392 of 1000000
2020-09-03 17:12:38.282271: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 665649 of 1000000
2020-09-03 17:12:39.861825: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 9ms/step - loss: 8.0562 - root_mean_squared_error: 2.8384 - mae: 2.1867 - val_loss: 16.5570 - val_root_mean_squared_error: 4.0690 - val_mae: 3.2326
Epoch 14/25
   1/5468 [..............................] - ETA: 0s - loss: 7.7569 - root_mean_squared_error: 2.7851 - mae: 2.19592020-09-03 17:13:10.059481: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 218698 of 1000000
2020-09-03 17:13:20.059483: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 442427 of 1000000
2020-09-03 17:13:30.059488: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 667466 of 1000000
2020-09-03 17:13:31.590296: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 50s 9ms/step - loss: 5.5334 - root_mean_squared_error: 2.3523 - mae: 1.7780 - val_loss: 2.7601 - val_root_mean_squared_error: 1.6614 - val_mae: 1.3854
Epoch 15/25
   1/5468 [..............................] - ETA: 0s - loss: 5.4189 - root_mean_squared_error: 2.3279 - mae: 1.71692020-09-03 17:14:00.199430: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 221723 of 1000000
2020-09-03 17:14:10.199432: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 439283 of 1000000
2020-09-03 17:14:20.199441: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 656318 of 1000000
2020-09-03 17:14:22.153380: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 50s 9ms/step - loss: 7.9082 - root_mean_squared_error: 2.8121 - mae: 2.2185 - val_loss: 5.2582 - val_root_mean_squared_error: 2.2931 - val_mae: 1.8866
Epoch 16/25
   1/5468 [..............................] - ETA: 0s - loss: 8.4431 - root_mean_squared_error: 2.9057 - mae: 2.26912020-09-03 17:14:49.720142: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 206675 of 1000000
2020-09-03 17:14:59.720147: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 421484 of 1000000
2020-09-03 17:15:09.720163: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 621983 of 1000000
2020-09-03 17:15:13.378677: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 53s 10ms/step - loss: 8.1283 - root_mean_squared_error: 2.8510 - mae: 2.2215 - val_loss: 5.8047 - val_root_mean_squared_error: 2.4093 - val_mae: 1.7678
Epoch 17/25
   1/5468 [..............................] - ETA: 0s - loss: 6.9673 - root_mean_squared_error: 2.6396 - mae: 2.06012020-09-03 17:15:42.974799: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 216994 of 1000000
2020-09-03 17:15:52.974823: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 431703 of 1000000
2020-09-03 17:16:02.974787: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 647963 of 1000000
2020-09-03 17:16:05.286592: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 10ms/step - loss: 5.6694 - root_mean_squared_error: 2.3811 - mae: 1.8346 - val_loss: 4.0211 - val_root_mean_squared_error: 2.0053 - val_mae: 1.4926
Epoch 18/25
   1/5468 [..............................] - ETA: 0s - loss: 4.3882 - root_mean_squared_error: 2.0948 - mae: 1.69472020-09-03 17:16:35.245666: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 219541 of 1000000
2020-09-03 17:16:45.245695: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 434849 of 1000000
2020-09-03 17:16:55.245697: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 657326 of 1000000
2020-09-03 17:16:57.154813: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 51s 9ms/step - loss: 7.6286 - root_mean_squared_error: 2.7620 - mae: 2.1647 - val_loss: 8.8990 - val_root_mean_squared_error: 2.9831 - val_mae: 2.1807
Epoch 19/25
   1/5468 [..............................] - ETA: 0s - loss: 6.3365 - root_mean_squared_error: 2.5172 - mae: 1.98792020-09-03 17:17:25.767055: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 210541 of 1000000
2020-09-03 17:17:35.767069: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 428168 of 1000000
2020-09-03 17:17:45.767050: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 648394 of 1000000
2020-09-03 17:17:48.163076: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 9ms/step - loss: 5.6925 - root_mean_squared_error: 2.3859 - mae: 1.8557 - val_loss: 7.0036 - val_root_mean_squared_error: 2.6464 - val_mae: 2.0192
Epoch 20/25
   1/5468 [..............................] - ETA: 0s - loss: 5.9111 - root_mean_squared_error: 2.4313 - mae: 1.86942020-09-03 17:18:17.564046: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 218969 of 1000000
2020-09-03 17:18:27.564032: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 438295 of 1000000
2020-09-03 17:18:37.564054: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 655413 of 1000000
2020-09-03 17:18:39.599428: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 10ms/step - loss: 6.8373 - root_mean_squared_error: 2.6148 - mae: 1.9742 - val_loss: 4.4934 - val_root_mean_squared_error: 2.1198 - val_mae: 1.5544
Epoch 21/25
  20/5468 [..............................] - ETA: 16s - loss: 6.7229 - root_mean_squared_error: 2.5929 - mae: 1.95182020-09-03 17:19:09.851911: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 210717 of 1000000
2020-09-03 17:19:19.851916: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 414573 of 1000000
2020-09-03 17:19:29.851935: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 631533 of 1000000
2020-09-03 17:19:33.007503: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 9ms/step - loss: 5.7252 - root_mean_squared_error: 2.3927 - mae: 1.7921 - val_loss: 19.9770 - val_root_mean_squared_error: 4.4696 - val_mae: 3.9483
Epoch 22/25
  20/5468 [..............................] - ETA: 14s - loss: 5.5166 - root_mean_squared_error: 2.3488 - mae: 1.75092020-09-03 17:20:01.793350: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 206965 of 1000000
2020-09-03 17:20:11.793374: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 417262 of 1000000
2020-09-03 17:20:21.793379: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 618303 of 1000000
2020-09-03 17:20:25.882237: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 53s 10ms/step - loss: 7.3727 - root_mean_squared_error: 2.7153 - mae: 2.1631 - val_loss: 3.7680 - val_root_mean_squared_error: 1.9411 - val_mae: 1.4858
Epoch 23/25
  22/5468 [..............................] - ETA: 13s - loss: 6.6480 - root_mean_squared_error: 2.5784 - mae: 2.03622020-09-03 17:20:55.131738: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 197145 of 1000000
2020-09-03 17:21:05.131721: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 411294 of 1000000
2020-09-03 17:21:15.131712: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 624435 of 1000000
2020-09-03 17:21:18.642404: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 52s 9ms/step - loss: 5.5347 - root_mean_squared_error: 2.3526 - mae: 1.7962 - val_loss: 8.6975 - val_root_mean_squared_error: 2.9492 - val_mae: 2.3858
Epoch 24/25
  23/5468 [..............................] - ETA: 13s - loss: 5.2042 - root_mean_squared_error: 2.2813 - mae: 1.72872020-09-03 17:21:46.952287: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 217458 of 1000000
2020-09-03 17:21:56.952289: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 421999 of 1000000
2020-09-03 17:22:06.952280: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 614871 of 1000000
2020-09-03 17:22:11.265809: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 53s 10ms/step - loss: 2.9234 - root_mean_squared_error: 1.7098 - mae: 1.2129 - val_loss: 8.1747 - val_root_mean_squared_error: 2.8591 - val_mae: 2.3386
Epoch 25/25
  23/5468 [..............................] - ETA: 12s - loss: 2.7464 - root_mean_squared_error: 1.6572 - mae: 1.18782020-09-03 17:22:39.998529: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 210233 of 1000000
2020-09-03 17:22:49.998541: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 420717 of 1000000
2020-09-03 17:22:59.998540: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:184] Filling up shuffle buffer (this may take a while): 631855 of 1000000
2020-09-03 17:23:03.105398: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:233] Shuffle buffer filled.
5468/5468 [==============================] - 51s 9ms/step - loss: 3.2256 - root_mean_squared_error: 1.7960 - mae: 1.2697 - val_loss: 8.8438 - val_root_mean_squared_error: 2.9738 - val_mae: 2.2013
</code></pre>
<p>I took a look at the Tensorboard histograms and I got a weird histogram for one of the layers but I don't know how to interpret it.
<a href=""https://i.stack.imgur.com/1Cvme.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Cvme.png"" alt=""Tensorboard histograms"" /></a></p>
<p>Any help deciphering what is going on would be greatly appreciated!</p>
",11229510.0,,,,,2020-09-04 02:38:06,What does this peculiar Tensorboard histogram mean?,<python><keras><tensorflow2.0>,1,0,,,,CC BY-SA 4.0
63406138,1,63406418.0,,2020-08-14 03:35:18,,4,6807,"<p>I have made a CNN model in Keras and saved it as 'model.h5'. It takes an input shape of 128x128. Now, I am in a new file and am trying to make predictions with this model.Here is what I have done so far:</p>
<pre><code>import keras
from keras.preprocessing.image import load_img, img_to_array 
from keras.models import load_model
import PIL

img = load_img(&quot;img.jpg&quot;)

img = img_to_array(img) 

img = img.resize((128, 128))

model = load_model('model.h5')

model.summary()

abc = model.predict(img)

print(abc)
</code></pre>
<p>Here is my error:</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-3-e23dbdb3fe22&gt; in &lt;module&gt;()
     14 model.summary()
     15 
---&gt; 16 abc = model.predict(img)
     17 
     18 print(abc)

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in select_data_adapter(x, y)
    969         &quot;Failed to find data adapter that can handle &quot;
    970         &quot;input: {}, {}&quot;.format(
--&gt; 971             _type_name(x), _type_name(y)))
    972   elif len(adapter_cls) &gt; 1:
    973     raise RuntimeError(

ValueError: Failed to find data adapter that can handle input: &lt;class 'NoneType'&gt;, &lt;class 'NoneType'&gt;
</code></pre>
<p>Any help would be appreciated.</p>
<p>Thanks in advance</p>
",13298841.0,,,,,2021-06-02 17:11:08,"ValueError: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'> in keras model.predict",<python><tensorflow><keras>,2,2,,,,CC BY-SA 4.0
63675602,1,,,2020-08-31 17:39:30,,4,1892,"<p>I would like to implement a neural network with an input layer, two dense hidden layer and a non-dense output layer. A toy example is shown in the figure below. The first hidden layer has three neurons, the second two and the final four neurons but between the second and third there are only four connections.</p>
<p><a href=""https://i.stack.imgur.com/Gdpz7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gdpz7.png"" alt=""Network architecture"" /></a></p>
<p>I would like to use Keras functional API. How can I implement it? Should I set the missing weight manually to 0? I would start as follows:</p>
<pre><code>input=keras.layers.Input(...)
hidden1=keras.layers.Dense(3, activation=&quot;..&quot;)(input)
hidden2=keras.layers.Dense(3, activation=&quot;..&quot;)(hidden1)
</code></pre>
<p>but then I do not know how to proceed.</p>
",7904479.0,,2099607.0,,2020-09-01 15:37:05,2020-09-01 15:37:05,How to implement a neural network with a not-fully-connected layer as the final layer?,<python><tensorflow><keras><neural-network><tf.keras>,1,0,0.0,,,CC BY-SA 4.0
65314638,1,65317863.0,,2020-12-15 22:31:26,,4,2159,"<p>I would like to add a custom metric to model with Keras, I'm debugging my working code and I don't find a method to do the operations I need.</p>
<p>The problem could be described as a multi classification trough logistic multinomial regression.
The custom metric I would like to implement is this:</p>
<pre><code>(1/Number_of_Classes)*(TruePositivesClass1/TotalElementsClass1 + TruePositivesClass2/TotalElementsClass2 + ... + TruePositivesClassN/TotalElementsClassN)
</code></pre>
<p>Where Number_of_Classes must be calculate from batch, i.e something like <code>np.unique(y_true).count()</code> and
and every summation item would be something like</p>
<pre><code>len(np.where(y_true==class_i,1,0) == np.where(y_pred==class_i,1,0) )/np.where(y_true==class_i,1,0).sum()
</code></pre>
<p>In terms of confusion matrix (in the minimal form of 2 variables)</p>
<pre><code>        True    False
True     15      3
False    12      1
</code></pre>
<p>The formula would be <code>0.5*(15)/(15+12) + 0.5*(1/(1+3))=0.4027</code></p>
<p>The code could be something like</p>
<pre><code>def custom_metric(y_true,y_pred):

    total_classes = Unique(y_true) #How calculate total unique elements?
    summation = 0
    for _ in unique_value_on_target:

        # calculates Number of y_predict that are _
        true_predics_of_class = Count(y_predict,_) 

        # calculates total number of items of class _ in batch y_true
        true_values = Count(y_true,_) 

        value = true_predicts/true_values
       summation + = value
    return summation
</code></pre>
<p>My preprocessed data is a numpy array  like <code>x=[v1,v2,v3,v4,...,vn]</code>, and my
objetive column is a nompy array <code>y=[1, 0, 1, 0, 1, 0, 0, 1 ,..., 0, 1]</code></p>
<p>then, they are converted to tensors:</p>
<pre><code>x_train = tf.convert_to_tensor(x)
y_train = tf.convert_to_tensor(tf.keras.utils.to_categorical(y))
</code></pre>
<p>Then, they are converted to tensorflow dataset objects:</p>
<pre><code>train_ds = tf.data.Dataset.zip((tf.data.Dataset.from_tensor_slices(x_train),
                                tf.data.Dataset.from_tensor_slices(y_train)))
</code></pre>
<p>Later, I take a iterator:</p>
<pre><code> train_itr = iter(
          train_ds.shuffle(len(y_train) * 5, reshuffle_each_iteration=True).batch(len(y_train)))
</code></pre>
<p>and last, I take one element of iterator and train</p>
<pre><code>x_train, y_train = train_itr.get_next()
model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs,
          callbacks=[custom_callback], validation_data=test_itr.get_next())
</code></pre>
<p>So, since objects are dataset iterators, I can't find functions to operate them as I would like, in order to get the custom metric described.</p>
<p><a href=""https://i.stack.imgur.com/fdtwA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fdtwA.png"" alt=""type(y_pred)"" /></a></p>
",4959345.0,,4959345.0,,2020-12-16 15:43:00,2020-12-17 03:27:23,"Custom metric for Keras model, using Tensorflow 2.1",<python><keras><tensorflow2.x><keras-metrics>,1,0,0.0,,,CC BY-SA 4.0
64275353,1,64275957.0,,2020-10-09 07:01:55,,4,12030,"<p>I'm training a model with a generator and I'm getting this Warning from Tensorflow, although I can train the model without errors, I want to fix this or at least understand why it happens.</p>
<p>My data from the generator have this shapes:</p>
<pre><code>for x, y in model_generator(): # x[0] and x[1] are the inputs, y is the output
    print(x[0].shape, x[1].shape, y.shape)

# (20,)(20,)(20,17772) 
# 17772 --&gt; Number of unique words in my datatset
# 20 --&gt; Number of words per example (per sentence)
</code></pre>
<p>This is my model:</p>
<pre><code>Model: &quot;functional_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 20)]         0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 20)]         0                                            
__________________________________________________________________________________________________
embedding (Embedding)           (None, 20, 50)       890850      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 20, 50)       890850      input_2[0][0]                    
__________________________________________________________________________________________________
lstm (LSTM)                     [(None, 64), (None,  29440       embedding[0][0]                  
__________________________________________________________________________________________________
lstm_1 (LSTM)                   (None, 20, 64)       29440       embedding_1[0][0]                
                                                                 lstm[0][1]                       
                                                                 lstm[0][2]                       
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 20, 17772)    1155180     lstm_1[0][0]                     
==================================================================================================
Total params: 2,995,760
Trainable params: 1,214,060
Non-trainable params: 1,781,700
__________________________________________________________________________________________________
None
</code></pre>
<p>And this are the warnings I'm getting when running the model:</p>
<pre><code>WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(&quot;input_1:0&quot;, shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1).
WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(&quot;input_2:0&quot;, shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1).
WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(&quot;input_1:0&quot;, shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1).
WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(&quot;input_2:0&quot;, shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 1).
</code></pre>
<p>I don't understand why I get this, the shape of the input is (20,) so should be correct, any suggestions?</p>
<p><strong>EDIT</strong></p>
<p>Generator:</p>
<pre><code>def model_generator():
    for index, output in enumerate(training_decoder_output):
        for i in range(size):
            yield ([training_encoder_input[size*index+i], training_decoder_input[size*index+i]], output[i])

# Generator, returns inputs and ouput one by one when calling 
# (I saved the outputs in chunks on disk so that's why I iterate over it in that way)
</code></pre>
<p>Call to <code>model.fit()</code>:</p>
<pre><code>model.fit(model_generator(), epochs=5)
</code></pre>
<p>Sample of <code>training_encoder_input</code>:</p>
<pre><code>print(training_encoder_input[:5])

[[   3 1516   10 3355 2798    1 9105    1 9106    4  162    1  411    1
  9107 3356  612    1 9108    1]
 [   0    0    0    0    0    0    0    0    0    0    0    2 9109 2799
  5632   29 1187    2  157  275]
 [   0   54 5633 5634    1  412 4199   12 9110 5633 5634   27  443  134
  1516    7    6 4200 1280    1]
 [  23 9112  816   11 9113   33  184 9114  816    1 9115   42    3    2
    57    5 2120    3  185    1]
 [   0    0    0    0    0    0   15  301 9116    3 3357    1 9117    1
    67 5635    4  110 5635    1]]
</code></pre>
",13071340.0,,13071340.0,,2020-10-09 07:39:41,2020-10-09 07:46:28,WARNING:tensorflow:Model was constructed with shape for input Tensor(). but it was called on an input with incompatible shape,<python><tensorflow><keras>,1,4,0.0,,,CC BY-SA 4.0
67737951,1,67740456.0,,2021-05-28 11:25:47,,4,1989,"<p>I just wanted to set up a learning rate schedule for my first CNN and I found there are various ways of doing so:</p>
<ol>
<li><a href=""https://keras.io/api/callbacks/learning_rate_scheduler/"" rel=""nofollow noreferrer"">One can include the schedule in callbacks</a> using <code>tf.keras.callbacks.LearningRateScheduler()</code></li>
<li><a href=""https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule"" rel=""nofollow noreferrer"">One can pass it to an optimizer</a> using <code>tf.keras.optimizers.schedules.LearningRateSchedule()</code></li>
</ol>
<p>Now I wondered if there are any differences and if so, what are they? In case it makes no difference, why do those alternatives exist then? Is there a historical reason (and which method should be preferred)?</p>
<p>Can someone elaborate?</p>
",11611246.0,,,,,2021-05-29 03:38:05,tf.Keras learning rate schedules—pass to optimizer or callbacks?,<python><tensorflow><keras><conv-neural-network><learning-rate>,1,0,0.0,,,CC BY-SA 4.0
75164850,1,,,2023-01-18 20:17:30,,4,230,"<p>I want to create a model signature that returns named tensors (using Keras). This is what I mean by that. When the model is deployed to TF-Serving, I want it to return a JSON like this:</p>
<pre class=""lang-json prettyprint-override""><code>{
    &quot;predictions&quot;: [
        {
            &quot;t3&quot;: 19,
            &quot;t1&quot;: 76.975174,
            &quot;t2&quot;: &quot;cat3&quot;
        },
        {
            &quot;t3&quot;: 17,
            &quot;t1&quot;: 77.7983246,
            &quot;t2&quot;: &quot;cat3&quot;
        }
    ]
}
</code></pre>
<p>The important part is <code>t1</code>, <code>t2</code>, and <code>t3</code>. These are named by me. If I hadn't named them, the returned JSON would have been this:</p>
<pre class=""lang-json prettyprint-override""><code>{
    &quot;predictions&quot;: [
        {
            &quot;output_0&quot;: 77.5714188,
            &quot;output_1&quot;: &quot;cat3&quot;,
            &quot;output_2&quot;: 17
        },
        {
            &quot;output_0&quot;: 80.7243729,
            &quot;output_1&quot;: &quot;cat4&quot;,
            &quot;output_2&quot;: 17
        }
    ]
}
</code></pre>
<p>The <code>output_0</code>, <code>output_1</code>, and <code>output_2</code> are automatically generated by some component (not sure which one but I guess TF or Keras). I kinda managed to pull this off but only in specific scenarios.</p>
<p>This is what I have so far:</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras import layers


class OutputWithNames(layers.Layer):
    def __init__(self):
        super(OutputWithNames, self).__init__()

    def call(self, x):
        return {&quot;t1&quot;: x[0], &quot;t2&quot;: x[1], &quot;t3&quot;: x[2]}
</code></pre>
<p>Adding this custom layer as the last one in my model's signature, I get exactly what I mentioned. A JSON object with desired property names <code>t1</code>, <code>t2</code>, and <code>t3</code>.</p>
<p>Inspecting the saved model using the <code>saved_model_cli</code> tool, this is what I get as my output signature when the resulting model works as expected:</p>
<pre><code>The given SavedModel SignatureDef contains the following output(s):
  outputs['t1'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1)
      name: StatefulPartitionedCall_1:0
  outputs['t2'] tensor_info:
      dtype: DT_STRING
      shape: (-1)
      name: StatefulPartitionedCall_1:1
  outputs['t3'] tensor_info:
      dtype: DT_INT32
      shape: (-1)
      name: StatefulPartitionedCall_1:2
</code></pre>
<p>And again, so far everything's fine. But when I have only one single output:</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras import layers


class OutputWithNames(layers.Layer):
    def __init__(self):
        super(OutputWithNames, self).__init__()

    def call(self, x):
        return {&quot;t1&quot;: x}
</code></pre>
<p>Note: In the first code block, <code>x</code> is a list of Tensors since I have multiple outputs. That's why I can/have to use <code>x[0]</code>. But in the second code block, <code>x</code> is just simply a Tensor since there's only one output. That's why there's no <code>[]</code> in front of the <code>x</code>.</p>
<p>This time, TF-Serving will generate this JSON for me:</p>
<pre class=""lang-json prettyprint-override""><code>{
    &quot;predictions&quot;: [
        67.2723083,
        68.9468231
    ]
}
</code></pre>
<p>While this is what I was expecting to see:</p>
<pre class=""lang-json prettyprint-override""><code>{
    &quot;predictions&quot;: [
        {
            &quot;t1&quot;: 67.2723083
        },
        {
            &quot;t1&quot;: 68.9468231
        }
    ]
}
</code></pre>
<p>And this is what <code>saved_model_cli</code> tool returns for it:</p>
<pre><code>The given SavedModel SignatureDef contains the following output(s):
  outputs['t1'] tensor_info:
      dtype: DT_INT64
      shape: (-1)
      name: StatefulPartitionedCall:0
</code></pre>
<p>Basically, the saved model has the name for the output correctly set. But for some reason, TF-Serving strips it. And instead of returning an array of objects, it returns only the values.</p>
<p>My question is how can I force the TF-Serving to return a list of objects when there's only a single output?</p>
",866082.0,,866082.0,,2023-02-11 19:29:57,2023-02-14 01:42:43,How to tell Tensorflow Serving to leave my named output untouched?,<tensorflow><keras><tensorflow-serving>,1,0,,,,CC BY-SA 4.0
65327655,1,65327723.0,,2020-12-16 16:52:15,,4,8351,"<p>How do I add Keras dropout layer? Unfortunately, I don't know where exactly I would have to add this layer. I looked at 2 links:</p>
<ul>
<li><a href=""https://keras.io/api/layers/regularization_layers/dropout/"" rel=""nofollow noreferrer"">https://keras.io/api/layers/regularization_layers/dropout/</a></li>
<li><a href=""https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/"" rel=""nofollow noreferrer"">https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/</a></li>
</ul>
<p>For example, I've seen this</p>
<pre><code>model.add(Dense(60, input_dim=60, activation='relu', kernel_constraint=maxnorm(3)))
model.add(Dropout(0.2))
model.add(Dense(30, activation='relu', kernel_constraint=maxnorm(3)))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))
</code></pre>
<p>The dense layers are created with a loop as I understand it so I'm not sure how to add this.</p>
<pre><code>def get_Model(...):
   
    # build dense layer for model
    for i in range(1, len(dense_layers)):
       
        layer = Dense(dense_layers[i],
                      activity_regularizer=l2(reg_layers[i]),
                      activation='relu',
                      name='layer%d' % i)
        mlp_vector = layer(mlp_vector)

    predict_layer = Concatenate()([mf_cat_latent, mlp_vector])
    result = Dense(1, activation='sigmoid',
                   kernel_initializer='lecun_uniform', name='result')

    model = Model(inputs=[input_user, input_item], outputs=result(predict_layer))

    return model
</code></pre>
",14721684.0,,14721684.0,,2021-01-19 07:58:50,2021-01-19 07:58:50,How do I add keras dropout layers?,<python><tensorflow><machine-learning><keras><neural-network>,1,0,,,,CC BY-SA 4.0
66855867,1,,,2021-03-29 14:15:51,,4,1019,"<p>Is there any way to get the compiled model loss/metrics functions from the model object?</p>
<p>I need this to access the loss function from within a callback, where I have access to self.model, but I can't find a way to access the compiled loss.</p>
",1490721.0,,,,,2022-01-24 18:45:31,Getting keras compiled model loss function,<keras><tf.keras>,2,1,,,,CC BY-SA 4.0
70916804,1,,,2022-01-30 16:49:51,,4,555,"<p>I am implementing a model in Tensorflow 2, and I want to apply a penalization on a tensor (multiplication from two layers' outputs) in my model.
I am used to use regularization on layers (kernel, bias or activity regularization).</p>
<p>I could build a custom layer that only has an activity regularization, but I am hopping that there is a simpler solution to add regularization to a tensor.</p>
<p>I saw this code in <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/Regularizer"" rel=""nofollow noreferrer"">Tensorflow</a>:</p>
<pre><code>regularizer = tf.keras.regularizers.L2(2.)
tensor = tf.ones(shape=(5, 5))
regularizer(tensor)
</code></pre>
<p>Which outputs:</p>
<pre><code>&lt;tf.Tensor: shape=(), dtype=float32, numpy=50.0&gt;
</code></pre>
<p>But does this only compute the regularization value or it also add it to my model's loss?</p>
<p>Or would adding <code>self.add_loss(tf.keras.regularizers.L2(2.)(tensor))</code> in my call function work?</p>
<p>How would you add a penalty on a tensor?</p>
<p>It is my first question on stackoverflow so sorry if I didn't ask in the good place.</p>
",17142635.0,,17142635.0,,2022-02-10 14:26:59,2022-02-10 14:26:59,Tensorflow: How to apply a regularizer on a tensor?,<tensorflow><keras><tensor><regularized>,1,0,0.0,,,CC BY-SA 4.0
64938970,1,,,2020-11-21 01:31:33,,4,2214,"<p>I was running some code in Google Colab. I defined my own model &quot;MyModel()&quot; and some functions (not shown because it's too long), which is inherited from 'tf.keras.Model'.</p>
<p>'''</p>
<pre><code>save_model_path='./models' # path to save trained model
save_mat_folder='./results' # path to save reconstruction examples
log_path='./tensorboard_log' # path to log training process
load_model_path = save_model_path

model = MyModel()

summary_writer = tf.summary.create_file_writer(log_path)
tf.summary.trace_on(graph = True,profiler = False)

variables = [model.phi1,model.phi2] # write variables in a list

# define optimizer
optimizer =  tf.keras.optimizers.Adam(learning_rate= 1e-3)
for i in tf.range(50):
    # print(i)
    # below for TF 1.x:
    # loss,summary,_=sess.run([L,merged,train_op],feed_dict) #run(fetches, feed_dict=None, options=None, run_metadata=None)
    # model1_writer.add_summary(summary,global_step = i)
    # below for TF2.x:
    with tf.GradientTape() as tape:
        # loss function
        loss = model.call(Ein)
    # The tape is automatically erased immediately after you call its gradient() method
    grads = tape.gradient(loss, variables) ## auto-differentiation，powerful !!
    # TensorFlow will update parameters automatically
    optimizer.apply_gradients(grads_and_vars=zip(grads, variables))
    # train_op = optimizer.minimize(L) # calculates gradients automatically
    with summary_writer.as_default():
        tf.summary.scalar('loss', loss, step = tf.cast(i,tf.int64))
    if i % 10 == 0:
        print(loss)
# export trace 
with summary_writer.as_default():
    tf.summary.trace_export(name ='model_trace',step=0 ) #, profiler_outdir = log_path) 
    tf.saved_model.save(model, save_model_path)
# save_path=saver.save(sess,save_model_path)
</code></pre>
<p>'''</p>
<p>The code looks worked, but got unexpected warnings. Can anyone tell me source of the warning?</p>
<p>Below are the running outputs:
**</p>
<pre><code>tf.Tensor(-8.2480165e-06, shape=(), dtype=float32)
tf.Tensor(-8.653108e-06, shape=(), dtype=float32)
tf.Tensor(-9.343687e-06, shape=(), dtype=float32)
tf.Tensor(-1.0216764e-05, shape=(), dtype=float32)
tf.Tensor(-1.1233077e-05, shape=(), dtype=float32)
WARNING:tensorflow:Skipping full serialization of Keras layer &lt;__main__.MyModel object at 0x7fea4a9e9e48&gt;, because it is not built.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: ./models/assets
</code></pre>
<p>**</p>
",14230467.0,,,,,2022-03-17 10:16:53,"WARNING: This property should not be used in TensorFlow 2.0, as updates are applied automatically",<python><tensorflow><keras><low-level-api>,1,1,,,,CC BY-SA 4.0
70489738,1,,,2021-12-26 20:45:39,,4,291,"<p>I am working with Tensorflow input data pipeline on a classification problem with 3 classes. I am trying to create balanced batch and n0=100,n1=10 and n2=20 are selected based on relative size of each class in dataset. However, I get this error:</p>
<pre><code> 2021-12-26 14:14:24.168439: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. 
In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. 
This can happen if you have an input pipeline similar to`dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
</code></pre>
<p>This is my code:</p>
<pre><code>Train_dataset = tf.data.Dataset.list_files(file_list)
Train_dataset= Train_dataset.interleave(lambda filename: tf.data.TextLineDataset(filename))
Train_dataset= Train_dataset.map(separate_input_output)
class0 = Train_dataset.filter(lambda x,y: y==0).cache().repeat(n0*nepocs)
class1 = Train_dataset.filter(lambda x,y: y == 1).cache().repeat(n1*nepocs)
class2 = Train_dataset.filter(lambda x,y: y == 2).cache().repeat(n2*nepocs)
Train_dataset = tf.data.Dataset.zip((class0, class1, class2))
Train_dataset=Train_dataset.flat_map(lambda c0, c1, c2:tf.data.Dataset.from_tensors(c0).concatenate(tf.data.Dataset.from_tensors(c1).concatenate(tf.data.Dataset.from_tensors(c2))))
Train_dataset= Train_dataset.batch(64,drop_remainder=True).prefetch(buffer_size=1)
</code></pre>
<p>Does anyone know why I can not fully read the dataset being cached?</p>
",8155727.0,,8155727.0,,2021-12-26 20:50:54,2021-12-26 20:50:54,TF data pipeline can not fully read the dataset being cached,<python><tensorflow><keras><tensorflow-datasets>,0,0,,,,CC BY-SA 4.0
63572451,1,63573058.0,,2020-08-25 05:16:46,,4,5370,"<p>I'm using <code>tf.keras.preprocessing.image_dataset_from_directory</code> from TF 2.3 to load images from directories (train/test split). What I get is a tf.data.Dataset (<code>tensorflow.python.data.ops.dataset_ops.BatchDataset</code>actually) object with shapes:</p>
<pre class=""lang-py prettyprint-override""><code>train_ds.take(1)
# &lt;TakeDataset shapes: ((None, 256, 256, 3), (None, 6)), types: (tf.float32, tf.float32)&gt;
</code></pre>
<pre class=""lang-py prettyprint-override""><code>for images, labels in train_ds.take(1):
    print(images.shape)
    print(images[0])
# (32, 256, 256, 3)
# tf.Tensor(
# [[[225.75  225.75  225.75 ]
#   [225.75  225.75  225.75 ]
#   [225.75  225.75  225.75 ]
#   ...
#   [215.    214.    209.   ]
#   [215.    214.    209.   ]
#   [215.    214.    209.   ]]
#
#  ...], shape=(256, 256, 3), dtype=float32)
</code></pre>
<p>I cannot figure out how to normalize images (<code>/= 255</code>) with that Dataset object. I tried playing with <code>/=</code> operator itself, <code>map</code> and <code>apply</code> methods and even casting that object to list as mentioned <a href=""https://stackoverflow.com/questions/57791851/cast-tensorflow-2-0-batchdataset-to-numpy-array"">here</a>. Nothing seems to work and I would really like to solve this problem at Dataset level instead of adding normalization layer to my network.</p>
<p>Any ideas?</p>
",5208760.0,,,,,2020-08-25 06:20:36,Normalizing BatchDataset in Tensorflow 2.3,<python><tensorflow><keras><deep-learning><tensorflow-datasets>,1,1,0.0,,,CC BY-SA 4.0
70501300,1,,,2021-12-27 23:08:48,,4,373,"<p>I have a keras model and I use <code>sklearn.model_selection.GridSearchCV</code> for tuning the hyperparameters, but it gets stuck in an infinite loop.</p>
<p>This is my model:</p>
<pre><code>from keras import Sequential
from keras.layers import Dense, Activation

def make_model(optimizer='rmsprop'):
  model = Sequential()
  model.add(Dense(9, activation='relu', input_dim=28 * 28))
  model.add(Dense(27 , activation='relu'))
  model.add(Dense(27 , activation='relu'))
  model.add(Dense(81 , activation='relu'))
  model.add(Dense(10, activation='softmax'))
  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics='acc')
  return model
</code></pre>
<pre><code>from sklearn.model_selection import GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier

model = KerasClassifier(build_fn=make_model)

param_grid=dict(
    optimizer=['rmsprop'], 
    epochs=[25, 40], 
    batch_size=[45],
    validation_split=[.2])

grid_model = GridSearchCV(estimator=model, param_grid=param_grid)
</code></pre>
<p>And when I call <code>fit</code> on the model, instead of running with 25 and 40 epochs it will get stuck in an infinite loop.</p>
<p>I used <code>keras.datasets.fashion_mnist</code> as my dataset as below:</p>
<pre><code>from keras.utils.np_utils import to_categorical


(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

y_train = to_categorical(train_labels, num_classes=10)
y_test = to_categorical(test_labels, num_classes=10)

x_train = train_images / 255.0
x_test  = test_images / 255.0

x_train = x_train.reshape(60000, -1)
x_test = x_test.reshape(10000, -1)
</code></pre>
<p>I have used <code>epochs=[2, 3]</code> to representing the loop, and rest of the code as the same as before.</p>
<p>It's the result:
<a href=""https://i.stack.imgur.com/gkkn7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gkkn7.png"" alt=""enter image description here"" /></a></p>
",17121235.0,,17121235.0,,2021-12-28 18:18:23,2021-12-28 18:18:23,Keras model using GridSearchCV stuck in infinite loop,<python><tensorflow><keras><scikit-learn><infinite>,0,7,0.0,,,CC BY-SA 4.0
70884608,1,70939329.0,,2022-01-27 19:28:33,,4,368,"<p>I'm trying to use <code>GridSearchCV</code> to find the best hyperparameters for an LSTM model, including the best parameters for vocab size and the word embeddings dimension. First, I prepared my testing and training data.</p>
<pre><code>x = df['tweet_text']
y = df['potentially_harmful']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=0)

x_train= x_train.to_numpy().reshape(-1, 1)
y_train= y_train.to_numpy().reshape(-1, 1)
x_test = x_test.to_numpy().reshape(-1, 1)
y_test = y_test.to_numpy().reshape(-1,1)
</code></pre>
<p>And then I tried to create a model that I could use for my <code>GridSearchCV</code>. I know to use a Keras model for the grid search, you need to use <code>KerasClassifier</code> or <code>KerasRegressor</code>. I also make sure to adapt <code>x</code>, not <code>x_train</code> or anything, as <code>x</code> is the full <code>x_data</code> and I assume it needs to vectorize all of <code>x</code> so that all input docs have a consistent vectorized form.</p>
<pre><code>from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.models import Sequential
from tensorflow.keras import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Embedding
from scikeras.wrappers import KerasClassifier, KerasRegressor
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from sklearn.model_selection import StratifiedKFold

def build_model(max_tokens, max_len, dropout):
    
    model = Sequential()
    vectorize_layer = TextVectorization(

    max_tokens=max_tokens,
    output_mode=&quot;int&quot;,
    output_sequence_length=max_len,
    )
    vectorize_layer.adapt(x)
    model.add(tf.keras.Input(shape=(1,), dtype=tf.string))
    model.add(vectorize_layer)
    model.add(Embedding(max_tokens + 1, 128))
    model.add(LSTM(64, dropout = dropout, recurrent_dropout = dropout))
    model.add(Dense(64, activation=&quot;relu&quot;))
    model.add(Dense(1, activation=&quot;sigmoid&quot;))
    model.compile(
    optimizer='adam', 
    loss='binary_crossentropy',
    metrics=['accuracy'],
    )
    return model
</code></pre>
<p>Here I try to instantiate the model with the params. The classifier complained that I should add the <code>dropout = 0.2, max_len = 5, max_tokens=25</code> part.</p>
<pre><code>model = KerasClassifier(build_fn=build_model, dropout = 0.2, max_len = 5, max_tokens=25)
params = {
    &quot;max_tokens&quot; : [25, 50, 500, 5000],
    &quot;max_len&quot; : [5, 50, 500, 1000],
    &quot;dropout&quot; : [0.1, 0.2, 0.3, 0.4, 0.5],
}

grid = GridSearchCV(estimator = model, scoring = 'accuracy', param_grid = params,  cv = 3, verbose = 2, error_score = 'raise')

grid.fit(x_train, y_train)
</code></pre>
<p>Then, I get this error:</p>
<pre><code>Fitting 3 folds for each of 80 candidates, totalling 240 fits
ValueError: could not convert string to float: 'promo looks promising pls say absence means fauxfoodies r couple eliminated next round ugh cantstandthem mkr'
</code></pre>
<p>Which confuses me. This model works if I just try to instantiate a model with something like <code>model = build_model(...)</code> and try <code>model.fit(x_train, y_train)</code>, for example, and it doesn't have trouble converting strings to floats then. Why is it unable to do so now?</p>
",8825740.0,,10375049.0,,2022-02-06 09:13:14,2022-02-06 09:13:14,Getting optimal vocab size and embedding dimensionality using GridSearchCV,<python><tensorflow><machine-learning><keras><hyperparameters>,1,0,0.0,,,CC BY-SA 4.0
66592506,1,66592793.0,,2021-03-12 00:28:49,,4,4758,"<p>I'm getting a warning which I cannot find a solution to.
Apparently this:</p>
<pre class=""lang-py prettyprint-override""><code>import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}
import tensorflow as tf
os.environ['AUTOGRAPH_VERBOSITY'] = '1'
</code></pre>
<p>is not enough to stop this annoying message:</p>
<pre class=""lang-py prettyprint-override""><code>WARNING:tensorflow:AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000281A55264C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 4, expecting 3
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
</code></pre>
<p>which pops up after every single epoch.</p>
<p>And yes, I've decorated every function I have with <code>@tf.autograph.experimental.do_not_convert</code> and the message still pops up. I am currently using Tensorflow 2.2.0</p>
<p>If you know the reason why this is happening, that would be great. I have no clue what &quot;Name&quot; is, as nothing is called that anywhere in any of my files.</p>
",9064615.0,,,,,2023-02-03 02:47:44,How to suppress all autograph warnings from Tensorflow?,<python><python-3.x><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0
