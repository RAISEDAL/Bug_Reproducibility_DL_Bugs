Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense,Link
44747343,1,44748370,,2017-06-25 14:29:03,,409,316882,"<p>For any Keras layer (<code>Layer</code> class), can someone explain how to understand the difference between <code>input_shape</code>, <code>units</code>, <code>dim</code>, etc.?  </p>

<p>For example the doc says <code>units</code> specify the output shape of a layer. </p>

<p>In the image of the neural net below <code>hidden layer1</code> has 4 units. Does this directly translate to the <code>units</code> attribute of the <code>Layer</code> object? Or does <code>units</code> in Keras equal the shape of every weight in the hidden layer times the number of units? </p>

<p>In short how does one understand/visualize the attributes of the model -  in particular the layers - with the image below? 
<a href=""https://i.stack.imgur.com/iHW2o.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/iHW2o.jpg"" alt=""enter image description here""></a></p>
",1849998.0,,4590385.0,,2018-09-12 15:50:24,2022-11-29 14:04:02,"Keras input explanation: input_shape, units, batch_size, dim, etc",<neural-network><deep-learning><keras><keras-layer><tensor>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44747343
38714959,1,38737941,,2016-08-02 08:04:13,,404,79434,"<p>I am trying to reconcile my understand of LSTMs and pointed out here in <a href=""http://colah.github.io/posts/2015-08-Understanding-LSTMs/"" rel=""noreferrer"">this post by Christopher Olah</a> implemented in Keras. I am following the <a href=""http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">blog written by Jason Brownlee</a> for the Keras tutorial. What I am mainly confused about is,</p>
<ol>
<li>The reshaping of the data series into <code>[samples, time steps, features]</code> and,</li>
<li>The stateful LSTMs</li>
</ol>
<p>Lets concentrate on the above two questions with reference to the code pasted below:</p>
<pre><code># reshape into X=t and Y=t+1
look_back = 3
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

# reshape input to be [samples, time steps, features]
trainX = numpy.reshape(trainX, (trainX.shape[0], look_back, 1))
testX = numpy.reshape(testX, (testX.shape[0], look_back, 1))
########################
# The IMPORTANT BIT
##########################
# create and fit the LSTM network
batch_size = 1
model = Sequential()
model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
for i in range(100):
    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=2, shuffle=False)
    model.reset_states()
</code></pre>
<p>Note: create_dataset takes a sequence of length N and returns a <code>N-look_back</code> array of which each element is a <code>look_back</code> length sequence.</p>
<h1>What is Time Steps and Features?</h1>
<p>As can be seen TrainX is a 3-D array with Time_steps and Feature being the last two dimensions respectively (3 and 1 in this particular code). With respect to the image below, does this mean that we are considering the <code>many to one</code> case, where the number of pink boxes are 3? Or does it literally mean the chain length is 3 (i.e. only 3 green boxes considered). <a href=""https://i.stack.imgur.com/kwhAP.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/kwhAP.jpg"" alt=""enter image description here"" /></a></p>
<p>Does the features argument become relevant when we consider multivariate series? e.g. modelling two financial stocks simultaneously?</p>
<h1>Stateful LSTMs</h1>
<p>Does stateful LSTMs mean that we save the cell memory values between runs of batches? If this is the case, <code>batch_size</code> is one, and the memory is reset between the training runs so what was the point of saying that it was stateful. I'm guessing this is related to the fact that training data is not shuffled, but I'm not sure how.</p>
<p>Any thoughts?
Image reference: <a href=""http://karpathy.github.io/2015/05/21/rnn-effectiveness/"" rel=""noreferrer"">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></p>
<h2>Edit 1:</h2>
<p>A bit confused about @van's comment about the red and green boxes being equal. So just to confirm, does the following API calls correspond to the unrolled diagrams? Especially noting the second diagram (<code>batch_size</code> was arbitrarily chosen.):
<a href=""https://i.stack.imgur.com/sW207.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/sW207.jpg"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/15V2C.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/15V2C.jpg"" alt=""enter image description here"" /></a></p>
<h2>Edit 2:</h2>
<p>For people who have done Udacity's deep learning course and still confused about the time_step argument, look at the following discussion: <a href=""https://discussions.udacity.com/t/rnn-lstm-use-implementation/163169"" rel=""noreferrer"">https://discussions.udacity.com/t/rnn-lstm-use-implementation/163169</a></p>
<h2>Update:</h2>
<p>It turns out <code>model.add(TimeDistributed(Dense(vocab_len)))</code> was what I was looking for. Here is an example: <a href=""https://github.com/sachinruk/ShakespeareBot"" rel=""noreferrer"">https://github.com/sachinruk/ShakespeareBot</a></p>
<h2>Update2:</h2>
<p>I have summarised most of my understanding of LSTMs here: <a href=""https://www.youtube.com/watch?v=ywinX5wgdEU"" rel=""noreferrer"">https://www.youtube.com/watch?v=ywinX5wgdEU</a></p>
",2530674.0,,-1.0,,2020-06-20 09:12:55,2021-08-20 15:28:35,Understanding Keras LSTMs,<python><deep-learning><keras><lstm>,4,9,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38714959
41711190,1,41712013,,2017-01-18 04:07:16,,226,300123,"<p>I have trained a binary classification model with CNN, and here is my code</p>

<pre><code>model = Sequential()
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],
                        border_mode='valid',
                        input_shape=input_shape))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=pool_size))
# (16, 16, 32)
model.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=pool_size))
# (8, 8, 64) = (2048)
model.add(Flatten())
model.add(Dense(1024))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(2))  # define a binary classification problem
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adadelta',
              metrics=['accuracy'])
model.fit(x_train, y_train,
          batch_size=batch_size,
          nb_epoch=nb_epoch,
          verbose=1,
          validation_data=(x_test, y_test))
</code></pre>

<p>And here, I wanna get the output of each layer just like TensorFlow, how can I do that?</p>
",5046896.0,,,,,2023-01-21 20:37:24,"Keras, How to get the output of each layer?",<python><tensorflow><deep-learning><keras>,13,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41711190
55142951,1,55143329,,2019-03-13 13:23:19,,220,452456,"<p>When I am executing the command <code>sess = tf.Session()</code> in Tensorflow 2.0 environment, I am getting an error message as below:</p>
<pre><code>Traceback (most recent call last):
File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
AttributeError: module 'tensorflow' has no attribute 'Session'
</code></pre>
<blockquote>
<p>System Information:</p>
</blockquote>
<ul>
<li>OS Platform and Distribution: Windows 10</li>
<li>Python Version: 3.7.1</li>
<li>Tensorflow Version: 2.0.0-alpha0 (installed with pip)</li>
</ul>
<blockquote>
<p>Steps to reproduce:</p>
<p>Installation:</p>
</blockquote>
<ol>
<li>pip install --upgrade pip</li>
<li><strong>pip install tensorflow==2.0.0-alpha0</strong></li>
<li>pip install keras</li>
<li>pip install numpy==1.16.2</li>
</ol>
<blockquote>
<p>Execution:</p>
</blockquote>
<ol>
<li>Execute command: import tensorflow as tf</li>
<li>Execute command: sess = tf.Session()</li>
</ol>
",8531952.0,,-1.0,,2020-06-20 09:12:55,2023-03-26 15:13:58,Tensorflow 2.0 - AttributeError: module 'tensorflow' has no attribute 'Session',<python><tensorflow><keras><tensorflow2.0>,17,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55142951
42081257,1,46038271,,2017-02-07 03:34:55,,215,239336,"<p>I'm trying to train a CNN to categorize text by topic. When I use binary cross-entropy I get ~80% accuracy, with categorical cross-entropy I get ~50% accuracy.</p>

<p>I don't understand why this is. It's a multiclass problem, doesn't that mean that I have to use categorical cross-entropy and that the results with binary cross-entropy are meaningless?</p>



<pre class=""lang-python prettyprint-override""><code>model.add(embedding_layer)
model.add(Dropout(0.25))
# convolution layers
model.add(Conv1D(nb_filter=32,
                    filter_length=4,
                    border_mode='valid',
                    activation='relu'))
model.add(MaxPooling1D(pool_length=2))
# dense layers
model.add(Flatten())
model.add(Dense(256))
model.add(Dropout(0.25))
model.add(Activation('relu'))
# output layer
model.add(Dense(len(class_id_index)))
model.add(Activation('softmax'))
</code></pre>

<p>Then I compile it either it like this using <code>categorical_crossentropy</code> as the loss function:</p>

<pre class=""lang-python prettyprint-override""><code>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>or </p>

<pre class=""lang-python prettyprint-override""><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>Intuitively it makes sense why I'd want to use categorical cross-entropy, I don't understand why I get good results with binary, and poor results with categorical.</p>
",1291820.0,,4685471.0,,2020-01-20 13:13:30,2022-05-15 15:47:31,Why binary_crossentropy and categorical_crossentropy give different performances for the same problem?,<machine-learning><keras><neural-network><deep-learning><conv-neural-network>,12,10,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42081257
34716454,1,37979391,,2016-01-11 07:47:53,,208,240702,"<p>If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?</p>

<p>I read this documentation for it: <a href=""http://keras.io/layers/normalization/"">http://keras.io/layers/normalization/</a></p>

<p>I don't see where I'm supposed to call it. Below is my code attempting to use it:</p>

<pre><code>model = Sequential()
keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)
model.add(Dense(64, input_dim=14, init='uniform'))
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(64, init='uniform'))
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(2, init='uniform'))
model.add(Activation('softmax'))

sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='binary_crossentropy', optimizer=sgd)
model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)
</code></pre>

<p>I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.</p>
",4984897.0,,8927035.0,,2019-06-04 18:55:02,2021-01-15 18:08:24,Where do I call the BatchNormalization function in Keras?,<python><keras><neural-network><data-science><batch-normalization>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34716454
58441514,1,58653632,,2019-10-17 22:28:33,,198,39355,"<p>It's been cited by many users as the reason for switching to Pytorch, but I've yet to find a justification/explanation for sacrificing the most important practical quality, speed, for eager execution.</p>
<p>Below is code benchmarking performance, TF1 vs. TF2 - with TF1 running anywhere from <strong>47% to 276% faster</strong>.</p>
<p>My question is: <em>what is it, at the graph or hardware level, that yields such a significant slowdown?</em></p>
<hr>
<p>Looking for a detailed answer - am already familiar with broad concepts. <a href=""https://github.com/tensorflow/tensorflow/issues/33487"" rel=""noreferrer"">Relevant Git</a></p>
<p><strong>Specs</strong>: CUDA 10.0.130, cuDNN 7.4.2, Python 3.7.4, Windows 10, GTX 1070</p>
<hr>
<p><strong>Benchmark results</strong>:</p>
<img src=""https://i.stack.imgur.com/ayBCS.png"" width=""530"">
<hr>
<p><strong>UPDATE</strong>: Disabling Eager Execution per below code does <em>not</em> help. The behavior, however, is inconsistent: sometimes running in graph mode helps considerably, other times it runs <em>slower</em> relative to Eager.</p>
<hr>
<p><strong>Benchmark code</strong>:</p>
<pre class=""lang-py prettyprint-override""><code># use tensorflow.keras... to benchmark tf.keras; used GPU for all above benchmarks
from keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D
from keras.layers import Flatten, Dropout
from keras.models import Model
from keras.optimizers import Adam
import keras.backend as K
import numpy as np
from time import time

batch_shape = (32, 400, 16)
X, y = make_data(batch_shape)

model_small = make_small_model(batch_shape)
model_small.train_on_batch(X, y)  # skip first iteration which builds graph
timeit(model_small.train_on_batch, 200, X, y)

K.clear_session()  # in my testing, kernel was restarted instead

model_medium = make_medium_model(batch_shape)
model_medium.train_on_batch(X, y)  # skip first iteration which builds graph
timeit(model_medium.train_on_batch, 10, X, y)
</code></pre>
<hr>
<p><strong>Functions used</strong>:</p>
<pre class=""lang-py prettyprint-override""><code>def timeit(func, iterations, *args):
    t0 = time()
    for _ in range(iterations):
        func(*args)
    print(&quot;Time/iter: %.4f sec&quot; % ((time() - t0) / iterations))

def make_small_model(batch_shape):
    ipt   = Input(batch_shape=batch_shape)
    x     = Conv1D(128, 400, strides=4, padding='same')(ipt)
    x     = Flatten()(x)
    x     = Dropout(0.5)(x)
    x     = Dense(64, activation='relu')(x)
    out   = Dense(1,  activation='sigmoid')(x)
    model = Model(ipt, out)
    model.compile(Adam(lr=1e-4), 'binary_crossentropy')
    return model

def make_medium_model(batch_shape):
    ipt   = Input(batch_shape=batch_shape)
    x     = Bidirectional(LSTM(512, activation='relu', return_sequences=True))(ipt)
    x     = LSTM(512, activation='relu', return_sequences=True)(x)
    x     = Conv1D(128, 400, strides=4, padding='same')(x)
    x     = Flatten()(x)
    x     = Dense(256, activation='relu')(x)
    x     = Dropout(0.5)(x)
    x     = Dense(128, activation='relu')(x)
    x     = Dense(64,  activation='relu')(x)
    out   = Dense(1,   activation='sigmoid')(x)
    model = Model(ipt, out)
    model.compile(Adam(lr=1e-4), 'binary_crossentropy')
    return model
    
def make_data(batch_shape):
    return np.random.randn(*batch_shape), np.random.randint(0, 2, (batch_shape[0], 1))
</code></pre>
",10133797.0,,10133797.0,,2021-04-03 18:14:27,2021-12-17 11:59:42,Why is TensorFlow 2 much slower than TensorFlow 1?,<python><tensorflow><keras><performance-testing><tensorflow2.0>,2,6,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58441514
43237124,1,43237727,,2017-04-05 16:48:24,,186,181354,"<p>I am trying to understand the role of the <code>Flatten</code> function in Keras. Below is my code, which is a simple two-layer network. It takes in 2-dimensional data of shape (3, 2), and outputs 1-dimensional data of shape (1, 4):</p>

<pre><code>model = Sequential()
model.add(Dense(16, input_shape=(3, 2)))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(4))
model.compile(loss='mean_squared_error', optimizer='SGD')

x = np.array([[[1, 2], [3, 4], [5, 6]]])

y = model.predict(x)

print y.shape
</code></pre>

<p>This prints out that <code>y</code> has shape (1, 4). However, if I remove the <code>Flatten</code> line, then it prints out that <code>y</code> has shape (1, 3, 4).</p>

<p>I don't understand this. From my understanding of neural networks, the <code>model.add(Dense(16, input_shape=(3, 2)))</code> function is creating a hidden fully-connected layer, with 16 nodes. Each of these nodes is connected to each of the 3x2 input elements. Therefore, the 16 nodes at the output of this first layer are already ""flat"". So, the output shape of the first layer should be (1, 16). Then, the second layer takes this as an input, and outputs data of shape (1, 4).</p>

<p>So if the output of the first layer is already ""flat"" and of shape (1, 16), why do I need to further flatten it?</p>
",3320135.0,,3924118.0,,2019-10-15 16:54:31,2022-09-09 13:07:40,"What is the role of ""Flatten"" in Keras?",<machine-learning><tensorflow><neural-network><deep-learning><keras>,10,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43237124
47902295,1,47905435,,2017-12-20 09:07:17,,170,294105,"<p>I'm running the LSTM model for the first time.
Here is my model:</p>

<pre><code>opt = Adam(0.002)
inp = Input(...)
print(inp)
x = Embedding(....)(inp)
x = LSTM(...)(x)
x = BatchNormalization()(x)
pred = Dense(5,activation='softmax')(x)

model = Model(inp,pred)
model.compile(....)

idx = np.random.permutation(X_train.shape[0])
model.fit(X_train[idx], y_train[idx], nb_epoch=1, batch_size=128, verbose=1)
</code></pre>

<p>What is the use of verbose while training the model?</p>
",3681169.0,,,user10043429,2018-07-06 17:19:41,2021-06-18 17:29:43,What is the use of verbose in Keras while validating the model?,<python><deep-learning><keras><verbose>,6,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47902295
45662253,1,45662992,,2017-08-13 15:58:58,,168,334833,"<p>I'm running a Keras model, with a submission deadline of 36 hours, if I train my model on the cpu it will take approx 50 hours, is there a way to run Keras on gpu?</p>

<p>I'm using Tensorflow backend and running it on my Jupyter notebook, without anaconda installed.</p>
",8176285.0,,472495.0,,2017-08-14 18:48:27,2021-08-09 10:19:12,Can I run Keras model on gpu?,<python><tensorflow><keras><jupyter>,7,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45662253
42112260,1,42112935,,2017-02-08 11:47:12,,160,128331,"<p>I have built a neural network with Keras. I would visualize its data by Tensorboard, therefore I have utilized:</p>

<pre class=""lang-py prettyprint-override""><code>keras.callbacks.TensorBoard(log_dir='/Graph', histogram_freq=0,
                            write_graph=True, write_images=True)
</code></pre>

<p>as explained in <a href=""https://keras.io/callbacks/#tensorboard"" rel=""noreferrer"">keras.io</a>. When I run the callback I get <code>&lt;keras.callbacks.TensorBoard at 0x7f9abb3898&gt;</code>, but I don't get any file in my folder ""Graph"". Is there something wrong in how I have used this callback?</p>
",7387749.0,,2099607.0,,2018-06-19 11:33:55,2022-12-23 06:16:19,How do I use the Tensorboard callback of Keras?,<keras><tensorboard>,10,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42112260
43034960,1,43047615,,2017-03-26 21:47:35,,159,77227,"<p>I try to understand LSTMs and how to build them with Keras. I found out, that there are principally the 4 modes to run a RNN (the 4 right ones in the picture)</p>

<p><a href=""https://i.stack.imgur.com/b4sus.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/b4sus.jpg"" alt=""enter image description here""></a>
Image source: <a href=""http://karpathy.github.io/2015/05/21/rnn-effectiveness/"" rel=""noreferrer"">Andrej Karpathy</a></p>

<p>Now I wonder how a minimalistic code snippet for each of them would look like in Keras.
So something like</p>

<pre><code>model = Sequential()
model.add(LSTM(128, input_shape=(timesteps, data_dim)))
model.add(Dense(1))
</code></pre>

<p>for each of the 4 tasks, maybe with a little bit of explanation.</p>
",3869448.0,,951894.0,,2018-02-27 23:01:51,2020-11-09 06:17:27,Many to one and many to many LSTM examples in Keras,<machine-learning><neural-network><deep-learning><keras><recurrent-neural-network>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43034960
59823283,1,59823284,,2020-01-20 12:26:53,,157,446494,"<p>I just installed the latest version of Tensorflow via <code>pip install tensorflow</code> and whenever I run a program, I get the log message:</p>

<blockquote>
  <p>W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found</p>
</blockquote>

<p>Is this bad? How do I fix the error?</p>
",3214872.0,,10908375.0,,2020-05-27 15:25:47,2022-11-09 05:59:18,Could not load dynamic library 'cudart64_101.dll' on tensorflow CPU-only installation,<python><python-3.x><tensorflow><keras><tensorflow2.0>,19,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59823283
55890813,1,56243777,,2019-04-28 13:39:33,,155,258598,"<p>I'm trying to implement the binary classification example using the IMDb dataset in <strong>Google Colab</strong>. I have implemented this model before. But when I tried to do it again after a few days, it returned a <code>value error: 'Object arrays cannot be loaded when allow_pickle=False'</code> for the load_data() function.</p>
<p>I have already tried solving this, referring to an existing answer for a similar problem: <a href=""https://stackoverflow.com/questions/55824625/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-in-the-sketc?answertab=votes#tab-top"">How to fix &#39;Object arrays cannot be loaded when allow_pickle=False&#39; in the sketch_rnn algorithm</a>.
But it turns out that just adding an allow_pickle argument isn't sufficient.</p>
<p>My code:</p>
<pre><code>from keras.datasets import imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)
</code></pre>
<p>The error:</p>
<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-1-2ab3902db485&gt; in &lt;module&gt;()
      1 from keras.datasets import imdb
----&gt; 2 (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)

2 frames
/usr/local/lib/python3.6/dist-packages/keras/datasets/imdb.py in load_data(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)
     57                     file_hash='599dadb1135973df5b59232a0e9a887c')
     58     with np.load(path) as f:
---&gt; 59         x_train, labels_train = f['x_train'], f['y_train']
     60         x_test, labels_test = f['x_test'], f['y_test']
     61 

/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py in __getitem__(self, key)
    260                 return format.read_array(bytes,
    261                                          allow_pickle=self.allow_pickle,
--&gt; 262                                          pickle_kwargs=self.pickle_kwargs)
    263             else:
    264                 return self.zip.read(key)

/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py in read_array(fp, allow_pickle, pickle_kwargs)
    690         # The array contained Python objects. We need to unpickle the data.
    691         if not allow_pickle:
--&gt; 692             raise ValueError(&quot;Object arrays cannot be loaded when &quot;
    693                              &quot;allow_pickle=False&quot;)
    694         if pickle_kwargs is None:

ValueError: Object arrays cannot be loaded when allow_pickle=False
</code></pre>
",11423025.0,,6073.0,,2020-10-15 16:01:26,2022-07-05 05:00:51,How to fix 'Object arrays cannot be loaded when allow_pickle=False' for imdb.load_data() function?,<python><numpy><keras>,27,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55890813
42666046,1,42670479,,2017-03-08 08:07:57,,145,125837,"<p>I was wondering if it was possible to save a partly trained Keras model and continue the training after loading the model again.</p>
<p>The reason for this is that I will have more training data in the future and I do not want to retrain the whole model again.</p>
<p>The functions which I am using are:</p>
<pre><code>#Partly train model
model.fit(first_training, first_classes, batch_size=32, nb_epoch=20)

#Save partly trained model
model.save('partly_trained.h5')

#Load partly trained model
from keras.models import load_model
model = load_model('partly_trained.h5')

#Continue training
model.fit(second_training, second_classes, batch_size=32, nb_epoch=20)
</code></pre>
<hr />
<p><strong>Edit 1: added fully working example</strong></p>
<p>With the first dataset after 10 epochs the loss of the last epoch will be 0.0748 and the accuracy 0.9863.</p>
<p>After saving, deleting and reloading the model the loss and accuracy of the model trained on the second dataset will be 0.1711 and 0.9504 respectively.</p>
<p>Is this caused by the new training data or by a completely re-trained model?</p>
<pre><code>&quot;&quot;&quot;
Model by: http://machinelearningmastery.com/
&quot;&quot;&quot;
# load (downloaded if needed) the MNIST dataset
import numpy
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from keras.models import load_model
numpy.random.seed(7)

def baseline_model():
    model = Sequential()
    model.add(Dense(num_pixels, input_dim=num_pixels, init='normal', activation='relu'))
    model.add(Dense(num_classes, init='normal', activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

if __name__ == '__main__':
    # load data
    (X_train, y_train), (X_test, y_test) = mnist.load_data()

    # flatten 28*28 images to a 784 vector for each image
    num_pixels = X_train.shape[1] * X_train.shape[2]
    X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')
    X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')
    # normalize inputs from 0-255 to 0-1
    X_train = X_train / 255
    X_test = X_test / 255
    # one hot encode outputs
    y_train = np_utils.to_categorical(y_train)
    y_test = np_utils.to_categorical(y_test)
    num_classes = y_test.shape[1]

    # build the model
    model = baseline_model()

    #Partly train model
    dataset1_x = X_train[:3000]
    dataset1_y = y_train[:3000]
    model.fit(dataset1_x, dataset1_y, nb_epoch=10, batch_size=200, verbose=2)

    # Final evaluation of the model
    scores = model.evaluate(X_test, y_test, verbose=0)
    print(&quot;Baseline Error: %.2f%%&quot; % (100-scores[1]*100))

    #Save partly trained model
    model.save('partly_trained.h5')
    del model

    #Reload model
    model = load_model('partly_trained.h5')

    #Continue training
    dataset2_x = X_train[3000:]
    dataset2_y = y_train[3000:]
    model.fit(dataset2_x, dataset2_y, nb_epoch=10, batch_size=200, verbose=2)
    scores = model.evaluate(X_test, y_test, verbose=0)
    print(&quot;Baseline Error: %.2f%%&quot; % (100-scores[1]*100))
</code></pre>
<hr />
<p><strong>Edit 2: tensorflow.keras remarks</strong></p>
<p>For tensorflow.keras change the parameter nb_epochs to epochs in the model fit. The imports and basemodel function are:</p>
<pre><code>import numpy
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import load_model


numpy.random.seed(7)

def baseline_model():
    model = Sequential()
    model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model
</code></pre>
",5359882.0,,5359882.0,,2021-01-11 14:13:29,2022-06-13 03:47:29,Loading a trained Keras model and continue training,<python><tensorflow><neural-network><keras><resuming-training>,8,8,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42666046
58636087,1,58667409,,2019-10-31 02:18:03,,145,380890,"<p>Continuation from previous question: <a href=""https://stackoverflow.com/questions/58635521/tensorflow-typeerror-int-object-is-not-iterable/58635565#58635583"">Tensorflow - TypeError: &#39;int&#39; object is not iterable</a></p>
<p>My training data is a list of lists each comprised of 1000 floats. For example, <code>x_train[0] =</code></p>
<pre><code>[0.0, 0.0, 0.1, 0.25, 0.5, ...]
</code></pre>
<p>Here is my model:</p>
<pre><code>model = Sequential()

model.add(LSTM(128, activation='relu',
               input_shape=(1000, 1), return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(128, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))
</code></pre>
<p>Here is the error I'm getting:</p>
<pre><code>Traceback (most recent call last):
      File &quot;C:\Users\bencu\Desktop\ProjectFiles\Code\Program.py&quot;, line 88, in FitModel
        model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training.py&quot;, line 728, in fit
        use_multiprocessing=use_multiprocessing)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py&quot;, line 224, in fit
        distribution_strategy=strategy)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py&quot;, line 547, in _process_training_inputs
        use_multiprocessing=use_multiprocessing)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py&quot;, line 606, in _process_inputs
        use_multiprocessing=use_multiprocessing)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\data_adapter.py&quot;, line 479, in __init__
        batch_size=batch_size, shuffle=shuffle, **kwargs)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\keras\engine\data_adapter.py&quot;, line 321, in __init__
        dataset_ops.DatasetV2.from_tensors(inputs).repeat()
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py&quot;, line 414, in from_tensors
        return TensorDataset(tensors)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\data\ops\dataset_ops.py&quot;, line 2335, in __init__
        element = structure.normalize_element(element)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\data\util\structure.py&quot;, line 111, in normalize_element
        ops.convert_to_tensor(t, name=&quot;component_%d&quot; % i))
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py&quot;, line 1184, in convert_to_tensor
        return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py&quot;, line 1242, in convert_to_tensor_v2
        as_ref=False)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py&quot;, line 1296, in internal_convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\tensor_conversion_registry.py&quot;, line 52, in _default_conversion_function
        return constant_op.constant(value, dtype, name=name)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\constant_op.py&quot;, line 227, in constant
        allow_broadcast=True)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\constant_op.py&quot;, line 235, in _constant_impl
        t = convert_to_eager_tensor(value, ctx, dtype)
      File &quot;C:\Users\bencu\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\constant_op.py&quot;, line 96, in convert_to_eager_tensor
        return ops.EagerTensor(value, ctx.device_name, dtype)
    ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).
</code></pre>
<p>I've tried googling the error myself, I found something about using the <code>tf.convert_to_tensor</code> function. I tried passing my training and testing lists through this but the function won't take them.</p>
",6748145.0,,3750257.0,,2021-08-12 17:11:04,2023-02-05 17:01:57,Tensorflow - ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float),<python><tensorflow><keras><lstm>,17,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58636087
40050397,1,40434284,,2016-10-14 19:07:18,,144,221219,"<p>Perhaps too general a question, but can anyone explain what would cause a Convolutional Neural Network to diverge?</p>
<p>Specifics:</p>
<p>I am using Tensorflow's iris_training model with some of my own data and keep getting</p>
<blockquote>
<p>ERROR:tensorflow:Model diverged with loss = NaN.</p>
<p>Traceback...</p>
<p>tensorflow.contrib.learn.python.learn.monitors.NanLossDuringTrainingError: NaN loss during training.</p>
</blockquote>
<p>Traceback originated with line:</p>
<pre><code> tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                        hidden_units=[300, 300, 300],
                                        #optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=0.001, l1_regularization_strength=0.00001),                                                          
                                        n_classes=11,
                                        model_dir=&quot;/tmp/iris_model&quot;)
</code></pre>
<p>I've tried adjusting the optimizer, using a zero for learning rate, and using no optimizer. Any insights into network layers, data size, etc is appreciated.</p>
",5031496.0,,-1.0,,2020-06-20 09:12:55,2022-10-27 21:12:24,Deep-Learning Nan loss reasons,<python><tensorflow><machine-learning><keras><theano>,13,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/40050397
37232782,1,37242531,,2016-05-14 23:04:30,,128,196030,"<p>I have a data matrix in ""one-hot encoding"" (all ones and zeros) with 260,000 rows and 35 columns.  I am using Keras to train a simple neural network to predict a continuous variable.  The code to make the network is the following:</p>

<pre><code>model = Sequential()
model.add(Dense(1024, input_shape=(n_train,)))
model.add(Activation('relu'))
model.add(Dropout(0.1))

model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.1))

model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Dense(1))

sgd = SGD(lr=0.01, nesterov=True);
#rms = RMSprop()
#model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])
model.compile(loss='mean_absolute_error', optimizer=sgd)
model.fit(X_train, Y_train, batch_size=32, nb_epoch=3, verbose=1, validation_data=(X_test,Y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=4)] )
</code></pre>

<p>However, during the training process, I see the loss decrease nicely, but during the middle of the second epoch, it goes to nan:</p>

<pre><code>Train on 260000 samples, validate on 64905 samples
Epoch 1/3
260000/260000 [==============================] - 254s - loss: 16.2775 - val_loss:
 13.4925
Epoch 2/3
 88448/260000 [=========&gt;....................] - ETA: 161s - loss: nan
</code></pre>

<p>I tried using <code>RMSProp</code> instead of <code>SGD</code>, I tried <code>tanh</code> instead of <code>relu</code>, I tried with and without dropout, all to no avail.  I tried with a smaller model, i.e. with only one hidden layer, and same issue (it becomes nan at a different point).  However, it does work with less features, i.e. if there are only 5 columns, and gives quite good predictions. It seems to be there is some kind of overflow, but I can't imagine why--the loss is not unreasonably large at all.  </p>

<p>Python version 2.7.11, running on a linux machine, CPU only.  I tested it with the latest version of Theano, and I also get Nans, so I tried going to Theano 0.8.2 and have the same problem.  With the latest version of Keras has the same problem, and also with the 0.3.2 version.  </p>
",684979.0,,14336011.0,,2020-11-09 07:34:26,2022-11-05 17:06:24,NaN loss when training regression network,<python><keras><neural-network><theano><loss-function>,27,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37232782
35074549,1,35196851,,2016-01-29 00:03:28,,120,287230,"<p>How to load a model from an HDF5 file in Keras?</p>

<p>What I tried:</p>

<pre><code>model = Sequential()

model.add(Dense(64, input_dim=14, init='uniform'))
model.add(LeakyReLU(alpha=0.3))
model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))
model.add(Dropout(0.5))

model.add(Dense(64, init='uniform'))
model.add(LeakyReLU(alpha=0.3))
model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))
model.add(Dropout(0.5))

model.add(Dense(2, init='uniform'))
model.add(Activation('softmax'))


sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='binary_crossentropy', optimizer=sgd)

checkpointer = ModelCheckpoint(filepath=""/weights.hdf5"", verbose=1, save_best_only=True)
model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2, callbacks=[checkpointer])
</code></pre>

<p>The above code successfully saves the best model to a file named weights.hdf5. What I want to do is then load that model. The below code shows how I tried to do so:</p>

<pre><code>model2 = Sequential()
model2.load_weights(""/Users/Desktop/SquareSpace/weights.hdf5"")
</code></pre>

<p>This is the error I get:</p>

<pre><code>IndexError                                Traceback (most recent call last)
&lt;ipython-input-101-ec968f9e95c5&gt; in &lt;module&gt;()
      1 model2 = Sequential()
----&gt; 2 model2.load_weights(""/Users/Desktop/SquareSpace/weights.hdf5"")

/Applications/anaconda/lib/python2.7/site-packages/keras/models.pyc in load_weights(self, filepath)
    582             g = f['layer_{}'.format(k)]
    583             weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]
--&gt; 584             self.layers[k].set_weights(weights)
    585         f.close()
    586 

IndexError: list index out of range
</code></pre>
",4984897.0,,4984897.0,,2016-02-03 20:46:42,2022-03-14 23:14:49,How to load a model from an HDF5 file in Keras?,<python><machine-learning><keras><data-science>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35074549
43196636,1,43196972,,2017-04-04 00:56:54,,119,161434,"<p>I have an example of a neural network with two layers. The first layer takes two arguments and has one output. The second should take one argument as result of the first layer and one additional argument. It should looks like this:</p>

<pre><code>x1  x2  x3
 \  /   /
  y1   /
   \  /
    y2
</code></pre>

<p>So, I'd created a model with two layers and tried to merge them but it returns an error: <code>The first layer in a Sequential model must get an ""input_shape"" or ""batch_input_shape"" argument.</code> on the line <code>result.add(merged)</code>.</p>

<p>Model:</p>

<pre class=""lang-python prettyprint-override""><code>first = Sequential()
first.add(Dense(1, input_shape=(2,), activation='sigmoid'))

second = Sequential()
second.add(Dense(1, input_shape=(1,), activation='sigmoid'))

result = Sequential()
merged = Concatenate([first, second])
ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)
result.add(merged)
result.compile(optimizer=ada_grad, loss=_loss_tensor, metrics=['accuracy'])
</code></pre>
",944000.0,,4565615.0,,2021-07-21 11:37:29,2021-07-21 11:37:29,How to concatenate two layers in keras?,<python><machine-learning><keras><neural-network><hierarchical>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43196636
40690598,1,42750563,,2016-11-19 08:04:53,,118,156758,"<p>I have Keras installed with the Tensorflow backend and CUDA.  I'd like to sometimes on demand force Keras to use CPU.  Can this be done without say installing a separate CPU-only Tensorflow in a virtual environment?  If so how?  If the backend were Theano, the flags could be set, but I have not heard of Tensorflow flags accessible via Keras.  </p>
",3993741.0,,3993741.0,,2016-11-19 08:17:38,2022-10-14 04:34:20,Can Keras with Tensorflow backend be forced to use CPU or GPU at will?,<python><machine-learning><tensorflow><keras>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40690598
36498127,1,36501922,,2016-04-08 11:09:55,,117,96402,"<p>Considering the <a href=""https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/recurrent_network.py"">example code</a>.</p>

<p>I would like to know How to apply gradient clipping on this network on the RNN where there is a possibility of exploding gradients.</p>

<pre><code>tf.clip_by_value(t, clip_value_min, clip_value_max, name=None)
</code></pre>

<p>This is an example that could be used but where do I introduce this ?
In the def of RNN </p>

<pre><code>    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)
    # Split data because rnn cell needs a list of inputs for the RNN inner loop
    _X = tf.split(0, n_steps, _X) # n_steps
tf.clip_by_value(_X, -1, 1, name=None)
</code></pre>

<p>But this doesn't make sense as the tensor _X is the input and not the grad what is to be clipped? </p>

<p>Do I have to define my own Optimizer for this or is there a simpler option?</p>
",2527680.0,,10908375.0,,2020-12-01 14:33:35,2022-07-29 06:13:38,How to apply gradient clipping in TensorFlow?,<python><tensorflow><machine-learning><keras><deep-learning>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36498127
41061457,1,44674337,,2016-12-09 13:20:55,,117,115431,"<p>In Keras, we can return the output of <code>model.fit</code> to a history as follows:</p>

<pre><code> history = model.fit(X_train, y_train, 
                     batch_size=batch_size, 
                     nb_epoch=nb_epoch,
                     validation_data=(X_test, y_test))
</code></pre>

<p>Now, how to save the history attribute of the history object to a file for further uses (e.g. draw plots of acc or loss against epochs)?</p>
",6807211.0,,3731622.0,,2019-10-18 23:53:04,2022-10-13 22:54:54,keras: how to save the training history attribute of the history object,<python><machine-learning><neural-network><deep-learning><keras>,10,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41061457
43906048,1,43906235,,2017-05-11 03:30:20,,117,91906,"<p>I'm training a neural network for my project using Keras. Keras has provided a function for early stopping. May I know what parameters should be observed to avoid my neural network from overfitting by using early stopping?</p>
",7343062.0,,3924118.0,,2020-05-04 15:06:46,2021-07-29 11:35:11,Which parameters should be used for early stopping?,<python><keras><deep-learning><conv-neural-network>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43906048
51956000,1,51956230,,2018-08-21 20:08:48,,115,98678,"<p>On occasion, circumstances require us to do the following:</p>

<pre><code>from keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer(num_words=my_max)
</code></pre>

<p>Then, invariably, we chant this mantra:</p>

<pre><code>tokenizer.fit_on_texts(text) 
sequences = tokenizer.texts_to_sequences(text)
</code></pre>

<p>While I (more or less) understand what the total effect is, I can't figure out what each one does separately, regardless of how much research I do (including, obviously, the documentation). I don't think I've ever seen one without the other. </p>

<p>So what does each do? Are there any circumstances where you would use either one without the other? If not, why aren't they simply combined into something like:</p>

<pre><code>sequences = tokenizer.fit_on_texts_to_sequences(text)
</code></pre>

<p>Apologies if I'm missing something obvious, but I'm pretty new at this.</p>
",9448090.0,,9448090.0,,2018-12-25 11:38:07,2021-10-20 09:25:47,What does Keras Tokenizer method exactly do?,<python><keras><nlp>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51956000
47305618,1,47309453,,2017-11-15 10:57:45,,114,56161,"<p>I am trying to grasp what TimeDistributed wrapper does in Keras.</p>

<p>I get that TimeDistributed ""applies a layer to every temporal slice of an input.""</p>

<p>But I did some experiment and got the results that I cannot understand.</p>

<p>In short, in connection to LSTM layer, TimeDistributed and just Dense layer bear same results.</p>

<pre><code>model = Sequential()
model.add(LSTM(5, input_shape = (10, 20), return_sequences = True))
model.add(TimeDistributed(Dense(1)))
print(model.output_shape)

model = Sequential()
model.add(LSTM(5, input_shape = (10, 20), return_sequences = True))
model.add((Dense(1)))
print(model.output_shape)
</code></pre>

<p>For both models, I got output shape of <strong>(None, 10, 1)</strong>.</p>

<p>Can anyone explain the difference between TimeDistributed and Dense layer after an RNN layer?</p>
",7124707.0,,8708364.0,,2019-01-27 00:33:17,2019-01-27 00:33:17,What is the role of TimeDistributed layer in Keras?,<python><machine-learning><keras><neural-network><deep-learning>,1,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47305618
47995324,1,47996024,,2017-12-27 16:15:21,,108,64005,"<p>When I start training a model, there is no model saved previously. I can use <code>model.compile()</code> safely. I have now saved the model in a <code>h5</code> file for further training using <code>checkpoint</code>.</p>

<p>Say, I want to train the model further. I am confused at this point: can I use <code>model.compile()</code> here? And should it be placed before or after the <code>model = load_model()</code> statement? If <code>model.compile()</code> reinitializes all the weights and biases, I should place it before <code>model = load_model()</code> statement.</p>

<p>After discovering some discussions, it seems to me that <code>model.compile()</code> is only needed when I have no model saved previously. Once I have saved the model, there is no need to use <code>model.compile()</code>. Is it true or false? And when I want to predict using the trained model, should I use <code>model.compile()</code> before predicting? </p>
",5254777.0,,5254777.0,,2017-12-27 16:26:00,2019-10-31 16:15:54,Does model.compile() initialize all the weights and biases in Keras (tensorflow backend)?,<tensorflow><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47995324
42812230,1,42812559,,2017-03-15 14:11:24,,108,234738,"<p>I have this code, copied from a tutorial:</p>
<pre><code>import numpy as np
np.random.seed(123)
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils
from keras.datasets import mnist
(X_train,y_train),(X_test,y_test) = mnist.load_data()
print X_train.shape
from matplotlib import pyplot as plt
plt.imshow(X_train[0])
</code></pre>
<p>No image was displayed. <strong>Why not?</strong></p>
<p>There doesn't appear to be anything wrong with the backend of <code>matplotlib</code> on my computer. I tested that like so:</p>
<pre><code>import matplotlib.pyplot as plt

data = [[0, 0.25], [0.5, 0.75]]

fig, ax = plt.subplots()
im = ax.imshow(data, cmap=plt.get_cmap('hot'), interpolation='nearest',
               vmin=0, vmax=1)
fig.colorbar(im)
plt.show()
</code></pre>
<p>and was able to produce an image:
<img src=""https://i.stack.imgur.com/2r6Lw.png"" alt=""enter image description here"" /></p>
<p>I also tried printing <code>X_train[0]</code> and it looks right.</p>
",5511906.0,,523612.0,,2023-01-10 02:19:21,2023-01-10 02:19:21,Why doesn't plt.imshow() display the image?,<python><matplotlib><keras>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42812230
44495698,1,44496213,,2017-06-12 09:16:34,,100,48148,"<p>I have noticed that <em>weight_regularizer</em> is no more available in Keras and that, in its place, there are <em>activity</em> and <em>kernel</em> regularizer. 
I would like to know:</p>

<ul>
<li>What are the main differences between <em>kernel</em> and <em>activity</em> regularizers?</li>
<li>Could I use <em>activity_regularizer</em> in place of <em>weight_regularizer</em>?</li>
</ul>
",7387749.0,,2314737.0,,2017-12-19 16:13:55,2021-03-17 12:56:23,Keras: Difference between Kernel and Activity regularizers,<machine-learning><keras><keras-layer>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44495698
46308374,1,46308466,,2017-09-19 19:28:00,,99,101811,"<p>My question is simple, <strong>what is the validation data</strong> passed to model.fit in a Sequential model <strong>used for</strong>?</p>

<p>And, does it affect how the model is trained (normally a validation set is used, for example, to choose hyper-parameters in a model, but I think this does not happen here)?</p>

<p>I am talking about the validation set that can be passed like this:</p>

<pre><code># Create model
model = Sequential()
# Add layers
model.add(...)

# Train model (use 10% of training set as validation set)
history = model.fit(X_train, Y_train, validation_split=0.1)

# Train model (use validation data as validation set)
history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test))
</code></pre>

<p>I investigated a bit, and I saw that <code>keras.models.Sequential.fit</code> calls <code>keras.models.training.fit</code>, which creates variables like <code>val_acc</code>and <code>val_loss</code> (which can be accessed from Callbacks). <code>keras.models.training.fit</code> also calls <code>keras.models.training._fit_loop</code>, which adds the validation data to the <code>callbacks.validation_data</code>, and also calls <code>keras.models.training._test_loop</code>, which will loop the validation data in batches on the <code>self.test_function</code> of the model. The result of this function is used to fill the values of the logs, which are the values accessible from the callbacks.</p>

<p>After seeing all this, I feel that the validation set passed to <code>model.fit</code> is not used to validate anything during training, and its only use is to get feedback on how the trained model will perform in every epoch for a completely independent set. Therefore, it would be okey to use the same validation and test set, right?</p>

<p>Could anyone confirm if the validation set in model.fit has any other goal besides being read from the callbacks?</p>
",4864422.0,,,,,2021-07-30 08:05:48,What is validation data used for in a Keras Sequential model?,<python><validation><keras><training-data><keras-2>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46308374
44924690,1,44929759,,2017-07-05 11:13:26,,99,41965,"<p>From the Keras documentation:</p>

<p>dropout: Float between 0 and 1. Fraction of the units to drop for the
 linear transformation of the inputs.</p>

<p>recurrent_dropout: Float between 0 and 1. Fraction of the units to
 drop for the linear transformation of the recurrent state.</p>

<p>Can anyone point to where on the image below each dropout happens?</p>

<p><a href=""https://i.stack.imgur.com/DS97N.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DS97N.png"" alt=""enter image description here""></a></p>
",1998149.0,,2858407.0,,2018-04-03 13:18:34,2022-04-15 19:39:01,Keras: the difference between LSTM dropout and LSTM recurrent dropout,<keras><lstm><dropout>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44924690
58565394,1,58566065,,2019-10-25 20:33:19,,99,68103,"<p>What is the difference between <code>sparse_categorical_crossentropy</code> and <code>categorical_crossentropy</code>? When should one loss be used as opposed to the other? For example, are these losses suitable for linear regression?</p>
",12264499.0,,3924118.0,,2019-12-05 17:08:21,2022-04-05 21:35:43,What is the difference between sparse_categorical_crossentropy and categorical_crossentropy?,<python><tensorflow><machine-learning><keras><deep-learning>,3,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58565394
43035827,1,44082853,,2017-03-26 23:31:47,,98,87426,"<p>Can someone please explain this? I know bidirectional LSTMs have a forward and backward pass but what is the advantage of this over a unidirectional LSTM?</p>

<p>What is each of them better suited for?</p>
",2123328.0,,,,,2020-03-22 12:12:38,What's the difference between a bidirectional LSTM and an LSTM?,<machine-learning><neural-network><keras><lstm><recurrent-neural-network>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43035827
53740577,1,64635871,,2018-12-12 10:07:13,,97,108764,"<p>After Training, I saved Both Keras whole Model and Only Weights using </p>

<pre><code>model.save_weights(MODEL_WEIGHTS) and model.save(MODEL_NAME)
</code></pre>

<p>Models and Weights were saved successfully and there was no error.
I can successfully load the weights simply using model.load_weights and they are good to go, but when i try to load the save model via load_model, i am getting an error.</p>

<pre><code>File ""C:/Users/Rizwan/model_testing/model_performance.py"", line 46, in &lt;module&gt;
Model2 = load_model('nasnet_RS2.h5',custom_objects={'euc_dist_keras': euc_dist_keras})
File ""C:\Users\Rizwan\AppData\Roaming\Python\Python36\site-packages\keras\engine\saving.py"", line 419, in load_model
model = _deserialize_model(f, custom_objects, compile)
File ""C:\Users\Rizwan\AppData\Roaming\Python\Python36\site-packages\keras\engine\saving.py"", line 321, in _deserialize_model
optimizer_weights_group['weight_names']]
File ""C:\Users\Rizwan\AppData\Roaming\Python\Python36\site-packages\keras\engine\saving.py"", line 320, in &lt;listcomp&gt;
n.decode('utf8') for n in
AttributeError: 'str' object has no attribute 'decode'
</code></pre>

<p>I never received this error and i used to load any models successfully. I am using Keras 2.2.4 with tensorflow backend. Python 3.6.
My Code for training is :</p>

<pre><code>from keras_preprocessing.image import ImageDataGenerator
from keras import backend as K
from keras.models import load_model
from keras.callbacks import ReduceLROnPlateau, TensorBoard, 
ModelCheckpoint,EarlyStopping
import pandas as pd

MODEL_NAME = ""nasnet_RS2.h5""
MODEL_WEIGHTS = ""nasnet_RS2_weights.h5""
def euc_dist_keras(y_true, y_pred):
return K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True))
def main():

# Here, we initialize the ""NASNetMobile"" model type and customize the final 
#feature regressor layer.
# NASNet is a neural network architecture developed by Google.
# This architecture is specialized for transfer learning, and was discovered via Neural Architecture Search.
# NASNetMobile is a smaller version of NASNet.
model = NASNetMobile()
model = Model(model.input, Dense(1, activation='linear', kernel_initializer='normal')(model.layers[-2].output))

#    model = load_model('current_best.hdf5', custom_objects={'euc_dist_keras': euc_dist_keras})

# This model will use the ""Adam"" optimizer.
model.compile(""adam"", euc_dist_keras)
lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.003)
# This callback will log model stats to Tensorboard.
tb_callback = TensorBoard()
# This callback will checkpoint the best model at every epoch.
mc_callback = ModelCheckpoint(filepath='current_best_mem3.h5', verbose=1, save_best_only=True)
es_callback=EarlyStopping(monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='auto', baseline=None, restore_best_weights=True)

# This is the train DataSequence.
# These are the callbacks.
#callbacks = [lr_callback, tb_callback,mc_callback]
callbacks = [lr_callback, tb_callback,es_callback]

train_pd = pd.read_csv(""./train3.txt"", delimiter="" "", names=[""id"", ""label""], index_col=None)
test_pd = pd.read_csv(""./val3.txt"", delimiter="" "", names=[""id"", ""label""], index_col=None)

 #    train_pd = pd.read_csv(""./train2.txt"",delimiter="" "",header=None,index_col=None)
 #    test_pd = pd.read_csv(""./val2.txt"",delimiter="" "",header=None,index_col=None)
#model.summary()
batch_size=32
datagen = ImageDataGenerator(rescale=1. / 255)
train_generator = datagen.flow_from_dataframe(dataframe=train_pd, 
directory=""./images"", x_col=""id"", y_col=""label"",
                                              has_ext=True, 
class_mode=""other"", target_size=(224, 224),
                                              batch_size=batch_size)
valid_generator = datagen.flow_from_dataframe(dataframe=test_pd, directory=""./images"", x_col=""id"", y_col=""label"",
                                              has_ext=True, class_mode=""other"", target_size=(224, 224),
                                              batch_size=batch_size)

STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size
STEP_SIZE_VALID = valid_generator.n // valid_generator.batch_size
model.fit_generator(generator=train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=valid_generator,
                    validation_steps=STEP_SIZE_VALID,
                    callbacks=callbacks,
                    epochs=20)

# we save the model.
model.save_weights(MODEL_WEIGHTS)
model.save(MODEL_NAME)
if __name__ == '__main__':
   # freeze_support() here if program needs to be frozen
    main()
</code></pre>
",8857724.0,,8857724.0,,2021-10-17 13:36:00,2023-01-26 10:14:59,"Does Any one got ""AttributeError: 'str' object has no attribute 'decode' "" , while Loading a Keras Saved Model",<python><machine-learning><keras><deep-learning>,10,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53740577
46086030,1,46086039,,2017-09-07 00:14:40,,96,245049,"<p>Question is the same as the title says. </p>

<p>I prefer not to open Python and I use either MacOS or Ubuntu.</p>
",3907250.0,,,,,2021-11-26 22:34:24,How to check which version of Keras is installed?,<keras>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46086030
40331510,1,40336582,,2016-10-30 17:07:19,,95,73586,"<p>I am using deep learning library keras and trying to stack multiple LSTM with no luck.
Below is my code</p>

<pre><code>model = Sequential()
model.add(LSTM(100,input_shape =(time_steps,vector_size)))
model.add(LSTM(100))
</code></pre>

<p>The above code returns error in the third line <code>Exception: Input 0 is incompatible with layer lstm_28: expected ndim=3, found ndim=2
</code></p>

<p>The input X is a tensor of shape (100,250,50). I am running keras on tensorflow backend</p>
",2270136.0,,,,,2022-09-16 17:56:02,How to stack multiple lstm in keras?,<tensorflow><deep-learning><keras><lstm><keras-layer>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40331510
37293642,1,37296168,,2016-05-18 08:02:26,,91,60221,"<p>Currently I use the following code:</p>

<pre><code>callbacks = [
    EarlyStopping(monitor='val_loss', patience=2, verbose=0),
    ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),
]
model.fit(X_train.astype('float32'), Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
      shuffle=True, verbose=1, validation_data=(X_valid, Y_valid),
      callbacks=callbacks)
</code></pre>

<p>It tells Keras to stop training when loss didn't improve for 2 epochs. But I want to stop training after loss became smaller than some constant ""THR"":</p>

<pre><code>if val_loss &lt; THR:
    break
</code></pre>

<p>I've seen in documentation there are possibility to make your own callback:
<a href=""http://keras.io/callbacks/"">http://keras.io/callbacks/</a>
But nothing found how to stop training process. I need an advice.</p>
",2115332.0,,,,,2020-08-17 20:37:51,How to tell Keras stop training based on loss value?,<python><machine-learning><neural-network><conv-neural-network><keras>,7,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37293642
43979449,1,43982656,,2017-05-15 12:22:36,,90,87084,"<p>I'm trying to use deep learning to predict income from 15 self reported attributes from a dating site.</p>

<p>We're getting rather odd results, where our validation data is getting better accuracy and lower loss, than our training data. And this is consistent across different sizes of hidden layers.
This is our model:</p>

<pre class=""lang-py prettyprint-override""><code>for hl1 in [250, 200, 150, 100, 75, 50, 25, 15, 10, 7]:
    def baseline_model():
        model = Sequential()
        model.add(Dense(hl1, input_dim=299, kernel_initializer='normal', activation='relu', kernel_regularizer=regularizers.l1_l2(0.001)))
        model.add(Dropout(0.5, seed=seed))
        model.add(Dense(3, kernel_initializer='normal', activation='sigmoid'))

        model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])
        return model

    history_logs = LossHistory()
    model = baseline_model()
    history = model.fit(X, Y, validation_split=0.3, shuffle=False, epochs=50, batch_size=10, verbose=2, callbacks=[history_logs])
</code></pre>

<p>And this is an example of the accuracy and losses:
<img src=""https://i.stack.imgur.com/0TfSp.png"" alt=""Accuracy with hidden layer of 250 neurons""> and <img src=""https://i.stack.imgur.com/TH6Nr.png"" alt=""the loss"">.</p>

<p>We've tried to remove regularization and dropout, which, as expected, ended in overfitting (training acc: ~85%). We've even tried to decrease the learning rate drastically, with similiar results.</p>

<p>Has anyone seen similar results?</p>
",2200569.0,,11114701.0,,2019-05-07 10:54:36,2023-04-14 07:31:10,"Higher validation accuracy, than training accurracy using Tensorflow and Keras",<tensorflow><machine-learning><neural-network><keras><classification>,10,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43979449
44273249,1,44277785,,2017-05-30 23:05:49,,84,44219,"<p>The first arguments in a normal <code>Dense</code> layer is also <code>units</code>, and is the number of neurons/nodes in that layer. A standard LSTM unit however looks like the following:</p>

<p><a href=""https://i.stack.imgur.com/aTDpS.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/aTDpS.png"" alt=""enter image description here""></a></p>

<p>(This is a reworked version of ""<a href=""http://colah.github.io/posts/2015-08-Understanding-LSTMs/"" rel=""noreferrer"">Understanding LSTM Networks</a>"")</p>

<p>In Keras, when I create an LSTM object like this <code>LSTM(units=N, ...)</code>, am I actually creating <code>N</code> of these LSTM units? Or is it the size of the ""Neural Network"" layers inside the LSTM unit, i.e., the <code>W</code>'s in the formulas? Or is it something else?</p>

<p>For context, I'm working based on <a href=""https://github.com/fchollet/keras/blob/master/examples/stateful_lstm.py"" rel=""noreferrer"">this example code</a>.</p>

<p>The following is the documentation: <a href=""https://keras.io/layers/recurrent/"" rel=""noreferrer"">https://keras.io/layers/recurrent/</a></p>

<p>It says:</p>

<blockquote>
  <p>units: Positive integer, dimensionality of the output space.</p>
</blockquote>

<p>It makes me think it is the number of outputs from the Keras LSTM ""layer"" object. Meaning the next layer will have <code>N</code> inputs. Does that mean there actually exists <code>N</code> of these LSTM units in the LSTM layer, or maybe that that exactly <em>one</em> LSTM unit is run for <code>N</code> iterations outputting <code>N</code> of these <code>h[t]</code> values, from, say, <code>h[t-N]</code> up to <code>h[t]</code>?</p>

<p>If it only defines the number of outputs, does that mean the input still can be, say, just <em>one</em>, or do we have to manually create lagging input variables <code>x[t-N]</code> to <code>x[t]</code>, one for each LSTM unit defined by the <code>units=N</code> argument?</p>

<p>As I'm writing this it occurs to me what the argument <code>return_sequences</code> does. If set to <code>True</code> all the <code>N</code> outputs are passed forward to the next layer, while if it is set to <code>False</code> it only passes the last <code>h[t]</code> output to the next layer. Am I right?</p>
",604048.0,,604048.0,,2017-05-30 23:11:26,2020-09-21 18:39:06,"In Keras, what exactly am I configuring when I create a stateful `LSTM` layer with N `units`?",<tensorflow><neural-network><keras><lstm>,4,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44273249
41908379,1,72093613,,2017-01-28 09:46:13,,82,205377,"<p>I want to plot the output of this simple neural network: </p>

<pre><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(x_test, y_test, nb_epoch=10, validation_split=0.2, shuffle=True)

model.test_on_batch(x_test, y_test)
model.metrics_names
</code></pre>

<p>I have plotted <em>accuracy</em> and <em>loss</em> of training and validation:</p>

<pre><code>print(history.history.keys())
#  ""Accuracy""
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# ""Loss""
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
</code></pre>

<p>Now I want to add and plot test set's accuracy from <code>model.test_on_batch(x_test, y_test)</code>, but from <code>model.metrics_names</code> I obtain the same value <em>'acc'</em> utilized for plotting accuracy on training data <code>plt.plot(history.history['acc'])</code>. How could I plot test set's accuracy?</p>
",7387749.0,,7758804.0,,2022-04-28 21:57:16,2023-01-03 19:00:09,"Keras - Plot training, validation and test set accuracy",<python><matplotlib><keras>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41908379
51995977,1,51996037,,2018-08-24 00:33:04,,82,86081,"<p>I have a dataset containing grayscale images and I want to train a state-of-the-art CNN on them. I'd very much like to fine-tune a pre-trained model (like the ones <a href=""https://github.com/tensorflow/models/tree/master/research/slim#Pretrained"" rel=""noreferrer"">here</a>).</p>

<p>The problem is that almost all models I can find the weights for have been trained on the ImageNet dataset, which contains RGB images.</p>

<p>I can't use one of those models because their input layer expects a batch of shape <code>(batch_size, height, width, 3)</code> or <code>(64, 224, 224, 3)</code> in my case, but my images batches are <code>(64, 224, 224)</code>.</p>

<p>Is there any way that I can use one of those models? I've thought of dropping the input layer after I've loaded the weights and adding my own (like we do for the top layers). Is this approach correct?</p>
",10267239.0,,,,,2022-11-23 03:40:22,How can I use a pre-trained neural network with grayscale images?,<python><tensorflow><machine-learning><keras><deep-learning>,12,7,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51995977
41668813,1,41670915,,2017-01-16 02:56:46,,81,107061,"<p>I am trying to do a transfer learning; for that purpose I want to remove the last two layers of the neural network and add another two layers. This is an example code which also output the same error.</p>
<pre><code>from keras.models import Sequential
from keras.layers import Input,Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.layers.core import Dropout, Activation
from keras.layers.pooling import GlobalAveragePooling2D
from keras.models import Model

in_img = Input(shape=(3, 32, 32))
x = Convolution2D(12, 3, 3, subsample=(2, 2), border_mode='valid', name='conv1')(in_img)
x = Activation('relu', name='relu_conv1')(x)
x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)
x = Convolution2D(3, 1, 1, border_mode='valid', name='conv2')(x)
x = Activation('relu', name='relu_conv2')(x)
x = GlobalAveragePooling2D()(x)
o = Activation('softmax', name='loss')(x)
model = Model(input=in_img, output=[o])
model.compile(loss=&quot;categorical_crossentropy&quot;, optimizer=&quot;adam&quot;)
#model.load_weights('model_weights.h5', by_name=True)
model.summary()

model.layers.pop()
model.layers.pop()
model.summary()
model.add(MaxPooling2D())
model.add(Activation('sigmoid', name='loss'))
</code></pre>
<p>I removed the layer using <code>pop()</code> but when I tried to add its outputting this error</p>
<pre><code>AttributeError: 'Model' object has no attribute 'add'
</code></pre>
<p>I know the most probable reason for the error is improper use of <code>model.add()</code>. what other syntax should I use?</p>
<p><strong>EDIT:</strong></p>
<p>I tried to remove/add layers in keras but its not  allowing it to be added after loading external weights.</p>
<pre><code>from keras.models import Sequential
from keras.layers import Input,Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.layers.core import Dropout, Activation
from keras.layers.pooling import GlobalAveragePooling2D
from keras.models import Model
in_img = Input(shape=(3, 32, 32))

def gen_model():
    in_img = Input(shape=(3, 32, 32))
    x = Convolution2D(12, 3, 3, subsample=(2, 2), border_mode='valid', name='conv1')(in_img)
    x = Activation('relu', name='relu_conv1')(x)
    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)
    x = Convolution2D(3, 1, 1, border_mode='valid', name='conv2')(x)
    x = Activation('relu', name='relu_conv2')(x)
    x = GlobalAveragePooling2D()(x)
    o = Activation('softmax', name='loss')(x)
    model = Model(input=in_img, output=[o])
    return model

#parent model
model=gen_model()
model.compile(loss=&quot;categorical_crossentropy&quot;, optimizer=&quot;adam&quot;)
model.summary()

#saving model weights
model.save('model_weights.h5')

#loading weights to second model
model2=gen_model()
model2.compile(loss=&quot;categorical_crossentropy&quot;, optimizer=&quot;adam&quot;)
model2.load_weights('model_weights.h5', by_name=True)

model2.layers.pop()
model2.layers.pop()
model2.summary()

#editing layers in the second model and saving as third model
x = MaxPooling2D()(model2.layers[-1].output)
o = Activation('sigmoid', name='loss')(x)
model3 = Model(input=in_img, output=[o])
</code></pre>
<p>its showing this error</p>
<pre><code>RuntimeError: Graph disconnected: cannot obtain value for tensor input_4 at layer &quot;input_4&quot;. The following previous layers were accessed without issue: []
</code></pre>
",996366.0,,4685471.0,,2022-11-16 13:27:30,2022-12-22 00:54:32,How to add and remove new layers in keras after loading weights?,<python><machine-learning><keras><keras-layer>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41668813
47266383,1,47271117,,2017-11-13 14:15:26,,79,171606,"<p>Im trying to save and load weights from the model i have trained.</p>

<p>the code im using to save the model is.</p>

<pre><code>TensorBoard(log_dir='/output')
model.fit_generator(image_a_b_gen(batch_size), steps_per_epoch=1, epochs=1)
model.save_weights('model.hdf5')
model.save_weights('myModel.h5')
</code></pre>

<p>Let me know if this an incorrect way to do it,or if there is a better way to do it.</p>

<p>but when i try to load them,using this,</p>

<pre><code>from keras.models import load_model
model = load_model('myModel.h5')
</code></pre>

<p>but i get this error:</p>

<hr>

<pre><code>ValueError                                Traceback (most recent call 
last)
&lt;ipython-input-7-27d58dc8bb48&gt; in &lt;module&gt;()
      1 from keras.models import load_model
----&gt; 2 model = load_model('myModel.h5')

/home/decentmakeover2/anaconda3/lib/python3.5/site-
packages/keras/models.py in load_model(filepath, custom_objects, compile)
    235         model_config = f.attrs.get('model_config')
    236         if model_config is None:
--&gt; 237             raise ValueError('No model found in config file.')
    238         model_config = json.loads(model_config.decode('utf-8'))
    239         model = model_from_config(model_config, 
custom_objects=custom_objects)

ValueError: No model found in config file.
</code></pre>

<p>Any suggestions on what i may be doing wrong?
Thank you in advance.</p>
",8176285.0,,,,,2021-03-17 18:26:59,Save and load weights in keras,<python><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47266383
53698035,1,53783381,,2018-12-10 00:19:00,,78,138016,"<p>In Tensorflow/ Keras when running the code from <a href=""https://github.com/pierluigiferrari/ssd_keras"" rel=""noreferrer"">https://github.com/pierluigiferrari/ssd_keras</a>, use the estimator: ssd300_evaluation. I received this error. </p>

<blockquote>
  <p>Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.</p>
</blockquote>

<p>This is very similar to the unsolved question: <a href=""https://stackoverflow.com/questions/53414185/google-colab-error-failed-to-get-convolution-algorithm-this-is-probably-becaus"">Google Colab Error : Failed to get convolution algorithm.This is probably because cuDNN failed to initialize</a></p>

<p>With the issue I'm running:</p>

<p>python: 3.6.4.</p>

<p>Tensorflow Version: 1.12.0.</p>

<p>Keras Version: 2.2.4.</p>

<p>CUDA: V10.0.</p>

<p>cuDNN: V7.4.1.5.</p>

<p>NVIDIA GeForce GTX 1080.</p>

<p>Also I ran:</p>

<pre><code>import tensorflow as tf
with tf.device('/gpu:0'):
      a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
      b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
      c = tf.matmul(a, b)
with tf.Session() as sess:
print (sess.run(c))
</code></pre>

<p>With no errors or issues.</p>

<p>The minimalist example is: </p>

<pre><code> from keras import backend as K
 from keras.models import load_model
 from keras.optimizers import Adam
 from scipy.misc import imread
 import numpy as np
 from matplotlib import pyplot as plt

 from models.keras_ssd300 import ssd_300
 from keras_loss_function.keras_ssd_loss import SSDLoss
 from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes
 from keras_layers.keras_layer_DecodeDetections import DecodeDetections
 from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast
 from keras_layers.keras_layer_L2Normalization import L2Normalization
 from data_generator.object_detection_2d_data_generator import DataGenerator
 from eval_utils.average_precision_evaluator import Evaluator
 import tensorflow as tf
 %matplotlib inline
 import keras
 keras.__version__



 # Set a few configuration parameters.
 img_height = 300
 img_width = 300
 n_classes = 20
 model_mode = 'inference'


 K.clear_session() # Clear previous models from memory.

 model = ssd_300(image_size=(img_height, img_width, 3),
            n_classes=n_classes,
            mode=model_mode,
            l2_regularization=0.0005,
            scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], # The scales 
 for MS COCO [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]
            aspect_ratios_per_layer=[[1.0, 2.0, 0.5],
                                     [1.0, 2.0, 0.5, 3.0, 1.0/3.0],
                                     [1.0, 2.0, 0.5, 3.0, 1.0/3.0],
                                     [1.0, 2.0, 0.5, 3.0, 1.0/3.0],
                                     [1.0, 2.0, 0.5],
                                     [1.0, 2.0, 0.5]],
            two_boxes_for_ar1=True,
            steps=[8, 16, 32, 64, 100, 300],
            offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
            clip_boxes=False,
            variances=[0.1, 0.1, 0.2, 0.2],
            normalize_coords=True,
            subtract_mean=[123, 117, 104],
            swap_channels=[2, 1, 0],
            confidence_thresh=0.01,
            iou_threshold=0.45,
            top_k=200,
            nms_max_output_size=400)

 # 2: Load the trained weights into the model.

 # TODO: Set the path of the trained weights.
 weights_path = 'C:/Users/USAgData/TF SSD 
 Keras/weights/VGG_VOC0712Plus_SSD_300x300_iter_240000.h5'

 model.load_weights(weights_path, by_name=True)

 # 3: Compile the model so that Keras won't complain the next time you load it.

 adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)

 ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)

 model.compile(optimizer=adam, loss=ssd_loss.compute_loss)


dataset = DataGenerator()

# TODO: Set the paths to the dataset here.
dir= ""C:/Users/USAgData/TF SSD Keras/VOC/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/""
Pascal_VOC_dataset_images_dir = dir+ 'JPEGImages'
Pascal_VOC_dataset_annotations_dir = dir + 'Annotations/'
Pascal_VOC_dataset_image_set_filename = dir+'ImageSets/Main/test.txt'

# The XML parser needs to now what object class names to look for and in which order to map them to integers.
classes = ['background',
           'aeroplane', 'bicycle', 'bird', 'boat',
           'bottle', 'bus', 'car', 'cat',
           'chair', 'cow', 'diningtable', 'dog',
           'horse', 'motorbike', 'person', 'pottedplant',
           'sheep', 'sofa', 'train', 'tvmonitor']

dataset.parse_xml(images_dirs=[Pascal_VOC_dataset_images_dir],
                  image_set_filenames=[Pascal_VOC_dataset_image_set_filename],
                  annotations_dirs=[Pascal_VOC_dataset_annotations_dir],
                  classes=classes,
                  include_classes='all',
                  exclude_truncated=False,
                  exclude_difficult=False,
                  ret=False)



evaluator = Evaluator(model=model,
                      n_classes=n_classes,
                      data_generator=dataset,
                      model_mode=model_mode)



results = evaluator(img_height=img_height,
                    img_width=img_width,
                    batch_size=8,
                    data_generator_mode='resize',
                    round_confidences=False,
                    matching_iou_threshold=0.5,
                    border_pixels='include',
                    sorting_algorithm='quicksort',
                    average_precision_mode='sample',
                    num_recall_points=11,
                    ignore_neutral_boxes=True,
                    return_precisions=True,
                    return_recalls=True,
                    return_average_precisions=True,
                    verbose=True)
</code></pre>
",3366418.0,,681865.0,,2021-01-02 02:03:42,2021-10-12 06:51:14,"Failed to get convolution algorithm. This is probably because cuDNN failed to initialize,",<python><tensorflow><keras>,30,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53698035
47262955,1,47265298,,2017-11-13 11:11:11,,78,216579,"<pre><code>import tensorflow as tf
import tensorflow 

from tensorflow import keras
from keras.layers import Dense
</code></pre>

<p>I am getting the below error</p>

<pre><code>from keras.layers import Input, Dense
Traceback (most recent call last):

  File ""&lt;ipython-input-6-b5da44e251a5&gt;"", line 1, in &lt;module&gt;
    from keras.layers import Input, Dense

ModuleNotFoundError: No module named 'keras'
</code></pre>

<p>How do I solve this?</p>

<p>Note: I am using Tensorflow version 1.4</p>
",3424990.0,,6117017.0,,2023-01-19 14:10:57,2023-01-19 14:10:57,How to import keras from tf.keras in Tensorflow?,<python><tensorflow><keras><deep-learning><tf.keras>,8,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47262955
58479556,1,58678385,,2019-10-21 03:48:16,,78,187483,"<p>I try to pass 2 loss functions to a model as <a href=""https://keras.io/models/model/"" rel=""noreferrer"">Keras allows that.</a></p>
<blockquote>
<p>loss: String (name of objective function) or objective function or
Loss instance. See losses. If the model has multiple outputs, you can
use a different loss on each output by <strong>passing a dictionary or a list
of losses</strong>. The loss value that will be minimized by the model will
then be the sum of all individual losses.</p>
</blockquote>
<p>The two loss functions:</p>
<pre><code>def l_2nd(beta):
    def loss_2nd(y_true, y_pred):
        ...
        return K.mean(t)

    return loss_2nd
</code></pre>
<p>and</p>
<pre><code>def l_1st(alpha):
    def loss_1st(y_true, y_pred):
        ...
        return alpha * 2 * tf.linalg.trace(tf.matmul(tf.matmul(Y, L, transpose_a=True), Y)) / batch_size

    return loss_1st
</code></pre>
<p>Then I build the model:</p>
<pre><code>l2 = K.eval(l_2nd(self.beta))
l1 = K.eval(l_1st(self.alpha))
self.model.compile(opt, [l2, l1])
</code></pre>
<p>When I train, it produces the error:</p>
<pre><code>1.15.0-rc3 WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630:
calling BaseResourceVariable.__init__ (from
tensorflow.python.ops.resource_variable_ops) with constraint is
deprecated and will be removed in a future version. Instructions for
updating: If using Keras pass *_constraint arguments to layers.
--------------------------------------------------------------------------- 
NotImplementedError                       Traceback (most recent call
last) &lt;ipython-input-20-298384dd95ab&gt; in &lt;module&gt;()
     47                          create_using=nx.DiGraph(), nodetype=None, data=[('weight', int)])
     48 
---&gt; 49     model = SDNE(G, hidden_size=[256, 128],)
     50     model.train(batch_size=100, epochs=40, verbose=2)
     51     embeddings = model.get_embeddings()

10 frames &lt;ipython-input-19-df29e9865105&gt; in __init__(self, graph,
hidden_size, alpha, beta, nu1, nu2)
     72         self.A, self.L = self._create_A_L(
     73             self.graph, self.node2idx)  # Adj Matrix,L Matrix
---&gt; 74         self.reset_model()
     75         self.inputs = [self.A, self.L]
     76         self._embeddings = {}

&lt;ipython-input-19-df29e9865105&gt; in reset_model(self, opt)

---&gt; 84         self.model.compile(opt, loss=[l2, l1])
     85         self.get_embeddings()
     86 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py
in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--&gt; 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

NotImplementedError: Cannot convert a symbolic Tensor (2nd_target:0)
to a numpy array.
</code></pre>
<p>Please help, thanks!</p>
",1508724.0,,220765.0,,2021-12-04 10:56:45,2023-02-28 23:59:38,NotImplementedError: Cannot convert a symbolic Tensor (2nd_target:0) to a numpy array,<python><tensorflow><keras><loss-function>,12,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58479556
49404309,1,49406231,,2018-03-21 10:48:48,,76,47470,"<p>If I have something like:</p>



<pre class=""lang-python prettyprint-override""><code>model = Model(inputs = input, outputs = [y1,y2])

l1 = 0.5
l2 = 0.3
model.compile(loss = [loss1,loss2], loss_weights = [l1,l2], ...)
</code></pre>

<p>what does Keras do with the losses to obtain the final loss?
Is it something like:</p>

<pre class=""lang-python prettyprint-override""><code>final_loss = l1*loss1 + l2*loss2
</code></pre>

<p>Also, what does it mean during training? Is the loss2 only used to update the weights on layers where y2 comes from? Or is it used for all the model's layers?</p>
",9522193.0,,3924118.0,,2020-01-30 18:02:23,2020-01-30 18:02:23,How does keras handle multiple losses?,<deep-learning><keras><backpropagation><loss-function>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/49404309
63886762,1,64376619,,2020-09-14 14:52:50,,75,80295,"<p>I am using a very small model for testing purposes using tensorflow 2.3 and keras.
Looking at my terminal, I get the following warning:</p>
<pre><code>I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:118] None of the MLIR optimization passes are enabled (registered 1)
</code></pre>
<p>However, the code works as expected. But what does this message mean?</p>
<p>Thanks.</p>
",13804443.0,,13804443.0,,2020-09-14 15:25:08,2022-08-08 16:50:21,Tensorflow: None of the MLIR optimization passes are enabled (registered 1),<python><tensorflow><keras><deep-learning>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/63886762
45466020,1,45466355,,2017-08-02 16:16:08,,74,115603,"<p>I have fine-tuned inception model with a new dataset and saved it as "".h5"" model in Keras. now my goal is to run my model on android Tensorflow which accepts "".pb"" extension only. question is that is there any library in Keras or tensorflow to do this conversion? I have seen this post so far :  <a href=""https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"" rel=""noreferrer"">https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html</a> but can't figure out yet. </p>
",1098770.0,,1782792.0,,2018-09-26 15:05:03,2022-04-07 00:07:28,How to export Keras .h5 to tensorflow .pb?,<python><tensorflow><keras>,14,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45466020
36952763,1,36956440,,2016-04-30 08:45:50,,74,188676,"<p>Using Anaconda Python 2.7 Windows 10.</p>

<p>I am training a language model using the Keras exmaple:</p>

<pre><code>print('Build model...')
model = Sequential()
model.add(GRU(512, return_sequences=True, input_shape=(maxlen, len(chars))))
model.add(Dropout(0.2))
model.add(GRU(512, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(len(chars)))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

def sample(a, temperature=1.0):
    # helper function to sample an index from a probability array
    a = np.log(a) / temperature
    a = np.exp(a) / np.sum(np.exp(a))
    return np.argmax(np.random.multinomial(1, a, 1))


# train the model, output generated text after each iteration
for iteration in range(1, 3):
    print()
    print('-' * 50)
    print('Iteration', iteration)
    model.fit(X, y, batch_size=128, nb_epoch=1)
    start_index = random.randint(0, len(text) - maxlen - 1)

    for diversity in [0.2, 0.5, 1.0, 1.2]:
        print()
        print('----- diversity:', diversity)

        generated = ''
        sentence = text[start_index: start_index + maxlen]
        generated += sentence
        print('----- Generating with seed: ""' + sentence + '""')
        sys.stdout.write(generated)

        for i in range(400):
            x = np.zeros((1, maxlen, len(chars)))
            for t, char in enumerate(sentence):
                x[0, t, char_indices[char]] = 1.

            preds = model.predict(x, verbose=0)[0]
            next_index = sample(preds, diversity)
            next_char = indices_char[next_index]

            generated += next_char
            sentence = sentence[1:] + next_char

            sys.stdout.write(next_char)
            sys.stdout.flush()
        print()
</code></pre>

<p>According to Keras documentation, the <code>model.fit</code> method returns a History callback, which has a history attribute containing the lists of successive losses and other metrics.</p>

<pre><code>hist = model.fit(X, y, validation_split=0.2)
print(hist.history)
</code></pre>

<p>After training my model, if I run <code>print(model.history)</code> I get the error:</p>

<pre><code> AttributeError: 'Sequential' object has no attribute 'history'
</code></pre>

<p>How do I return my model history after training my model with the above code?</p>

<p><strong>UPDATE</strong></p>

<p>The issue was that:</p>

<p>The following had to first be defined:</p>

<pre><code>from keras.callbacks import History 
history = History()
</code></pre>

<p>The callbacks option had to be called</p>

<pre><code>model.fit(X_train, Y_train, nb_epoch=5, batch_size=16, callbacks=[history])
</code></pre>

<p>But now if I print</p>

<pre><code>print(history.History)
</code></pre>

<p>it returns</p>

<pre><code>{}
</code></pre>

<p>even though I ran an iteration. </p>
",5310324.0,,5974433.0,,2017-03-10 15:21:49,2022-09-12 19:32:50,How to return history of validation loss in Keras,<python><neural-network><nlp><deep-learning><keras>,12,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36952763
41563720,1,41595178,,2017-01-10 07:51:25,,73,168329,"<p>I want to train a deep network starting with the following layer:</p>

<pre><code>model = Sequential()
model.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3)))
</code></pre>

<p>using </p>

<pre><code>history = model.fit_generator(get_training_data(),
                samples_per_epoch=1, nb_epoch=1,nb_val_samples=5,
                verbose=1,validation_data=get_validation_data()
</code></pre>

<p>with the following generator:</p>

<pre><code>def get_training_data(self):
     while 1:
        for i in range(1,5):
            image = self.X_train[i]
            label = self.Y_train[i]
            yield (image,label)
</code></pre>

<p>(validation generator looks similar).</p>

<p>During training, I get the error: </p>

<pre><code>Error when checking model input: expected convolution2d_input_1 to have 4 
dimensions, but got array with shape (32, 32, 3)
</code></pre>

<p>How can that be, with a first layer</p>

<pre><code> model.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3)))
</code></pre>

<p>?</p>
",1934212.0,,,,,2020-09-22 15:46:09,"Error when checking model input: expected convolution2d_input_1 to have 4 dimensions, but got array with shape (32, 32, 3)",<deep-learning><keras><keras-layer>,9,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41563720
41665799,1,45546663,,2017-01-15 20:14:32,,72,39344,"<p>I want to write a *.txt file with the neural network hyperparameters and the model architecture. Is it possible to write the object model.summary() to my output file?</p>

<pre><code>(...)
summary = str(model.summary())
(...)
out = open(filename + 'report.txt','w')
out.write(summary)
out.close
</code></pre>

<p>It happens that I'm getting ""None"" as you can see below.</p>

<pre><code>Hyperparameters
=========================

learning_rate: 0.01
momentum: 0.8
decay: 0.0
batch size: 128
no. epochs: 3
dropout: 0.5
-------------------------

None
val_acc: 0.232323229313
val_loss: 3.88496732712
train_acc: 0.0965207634216
train_loss: 4.07161939425
train/val loss ratio: 1.04804469418
</code></pre>

<p>Any idea how to deal with that?</p>
",3743194.0,,10375049.0,,2021-06-25 15:03:15,2021-06-25 15:03:15,Keras model.summary() object to string,<python><tensorflow><machine-learning><keras><deep-learning>,9,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41665799
35792278,1,35827171,,2016-03-04 09:25:12,,70,37405,"<p>For a Feedforward Network (FFN), it is easy to compute the number of parameters. Given a CNN, LSTM etc is there a quick way to find the number of parameters in a keras model?</p>
",4497662.0,,2962001.0,,2017-09-05 19:11:37,2021-06-09 03:54:55,How to find Number of parameters of a keras model?,<deep-learning><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35792278
44477489,1,44484106,,2017-06-10 19:55:10,,69,57602,"<p>What is the difference between <code>categorical_accuracy</code> and <code>sparse_categorical_accuracy</code> in Keras? There is no hint in the <a href=""https://keras.io/metrics/"" rel=""noreferrer"">documentation for these metrics</a>, and by asking Dr. Google, I did not find answers for that either.</p>

<p>The source code can be found <a href=""https://github.com/fchollet/keras/blob/master/keras/metrics.py"" rel=""noreferrer"">here</a>:</p>

<pre><code>def categorical_accuracy(y_true, y_pred):
    return K.cast(K.equal(K.argmax(y_true, axis=-1),
                          K.argmax(y_pred, axis=-1)),
                  K.floatx())


def sparse_categorical_accuracy(y_true, y_pred):
    return K.cast(K.equal(K.max(y_true, axis=-1),
                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())),
                  K.floatx())
</code></pre>
",1204330.0,,10908375.0,,2021-04-24 01:56:24,2021-09-02 14:44:41,Keras - Difference between categorical_accuracy and sparse_categorical_accuracy,<python><tensorflow><machine-learning><keras><deep-learning>,4,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44477489
43396572,1,43399308,,2017-04-13 15:44:02,,68,56947,"<p>I have tried to build a CNN with one layer, but I have some problem with it.
Indeed, the compilator says me that</p>
<blockquote>
<p>ValueError: Error when checking model input: expected conv1d_1_input
to have 3 dimensions, but got array with shape (569, 30)</p>
</blockquote>
<p>This is the code</p>
<pre class=""lang-py prettyprint-override""><code>import numpy
from keras.models import Sequential
from keras.layers.convolutional import Conv1D

numpy.random.seed(7)

datasetTraining = numpy.loadtxt(&quot;CancerAdapter.csv&quot;,delimiter=&quot;,&quot;)
X = datasetTraining[:,1:31]
Y = datasetTraining[:,0]
datasetTesting = numpy.loadtxt(&quot;CancereEvaluation.csv&quot;,delimiter=&quot;,&quot;)
X_test = datasetTraining[:,1:31]
Y_test = datasetTraining[:,0]

model = Sequential()
model.add(Conv1D(2,2,activation='relu',input_shape=X.shape))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X, Y, epochs=150, batch_size=5)
scores = model.evaluate(X_test, Y_test)

print(&quot;\n%s: %.2f%%&quot; % (model.metrics_names[1], scores[1]*100))
</code></pre>
",7027646.0,,148072.0,,2021-10-19 15:20:31,2021-10-19 15:20:31,Dimension of shape in conv1D,<python><tensorflow><keras><deep-learning><conv-neural-network>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43396572
62707558,1,68418955,,2020-07-03 02:19:46,,68,202997,"<p>I am trying to import Keras but I get the following error:</p>
<pre><code>ImportError: cannot import name 'adam' from 'keras.optimizers' (/usr/local/lib/python3.8/dist-packages/keras/optimizers/__init__.py)
</code></pre>
<p>The import is invoked here:</p>
<pre><code>from tensorflow import keras
from keras.layers import Conv2D, Input, MaxPool2D,Flatten, Dense, Permute, GlobalAveragePooling2D
from keras.models import Model
from keras.optimizers import adam
import numpy as np
import pickle
import keras
import cv2
import sys
import dlib
import os.path
from keras.models import Sequential
from keras.applications.resnet50 import ResNet50
from keras.applications.resnet50 import Dense
from keras.optimizers import Adam
import pickle
import numpy as np
import cv2
import os
from keras.layers import Dropout
</code></pre>
<p>I am sure Keras is installed along with Tensorflow:</p>
<pre><code>python3 -c 'import keras; print(keras.__version__)' // 2.4.3
</code></pre>
",11356638.0,,,,,2023-01-19 11:17:05,ImportError: cannot import name 'adam' from 'keras.optimizers',<keras>,11,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/62707558
55531427,1,55709360,,2019-04-05 08:39:41,,68,25522,"<p>I am applying transfer-learning on a pre-trained network using the GPU version of keras. I don't understand how to define the parameters <strong><code>max_queue_size</code></strong>, <strong><code>workers</code></strong>, and <strong><code>use_multiprocessing</code></strong>. If I change these parameters (primarily to speed-up learning), I am unsure whether all data is still seen per epoch.</p>

<p><strong><code>max_queue_size</code></strong>:</p>

<ul>
<li><p>maximum size of the internal training queue which is used to ""precache"" samples from the generator </p></li>
<li><p><em>Question:</em> Does this refer to how many batches are prepared on CPU? How is it related to <code>workers</code>? How to define it optimally?</p></li>
</ul>

<p><strong><code>workers</code></strong>: </p>

<ul>
<li><p>number of threads generating batches in parallel. Batches are computed in parallel on the CPU and passed on the fly onto the GPU for neural network computations </p></li>
<li><p><em>Question:</em> How do I find out how many batches my CPU can/should generate in parallel?</p></li>
</ul>

<p><strong><code>use_multiprocessing</code></strong>: </p>

<ul>
<li><p>whether to use process-based threading</p></li>
<li><p><em>Question:</em> Do I have to set this parameter to true if I change <code>workers</code>? Does it relate to CPU usage?</p></li>
</ul>

<p><strong>Related questions</strong> can be found here:</p>

<ul>
<li><a href=""https://github.com/keras-team/keras/issues/8540"" rel=""noreferrer"">Detailed explanation of model.fit_generator() parameters: queue size, workers and use_multiprocessing</a></li>
<li><p><a href=""https://stackoverflow.com/questions/51790943/what-does-worker-mean-in-fit-generator-in-keras"">What does worker mean in fit_generator in Keras?</a></p></li>
<li><p><a href=""https://stackoverflow.com/questions/36986815/what-is-the-parameter-max-q-size-used-for-in-model-fit-generator/36989864#36989864"">What is the parameter “max_q_size” used for in “model.fit_generator”?</a></p></li>
<li><p><a href=""https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"" rel=""noreferrer"">A detailed example of how to use data generators with Keras</a>.</p></li>
</ul>

<p>I am using <code>fit_generator()</code> as follows:</p>

<pre><code>    history = model.fit_generator(generator=trainGenerator,
                                  steps_per_epoch=trainGenerator.samples//nBatches,     # total number of steps (batches of samples)
                                  epochs=nEpochs,                   # number of epochs to train the model
                                  verbose=2,                        # verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch
                                  callbacks=callback,               # keras.callbacks.Callback instances to apply during training
                                  validation_data=valGenerator,     # generator or tuple on which to evaluate the loss and any model metrics at the end of each epoch
                                  validation_steps=
                                  valGenerator.samples//nBatches,   # number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch
                                  class_weight=classWeights,                # optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function
                                  max_queue_size=10,                # maximum size for the generator queue
                                  workers=1,                        # maximum number of processes to spin up when using process-based threading
                                  use_multiprocessing=False,        # whether to use process-based threading
                                  shuffle=True,                     # whether to shuffle the order of the batches at the beginning of each epoch
                                  initial_epoch=0)   
</code></pre>

<p>The specs of my machine are:</p>

<pre><code>CPU : 2xXeon E5-2260 2.6 GHz
Cores: 10
Graphic card: Titan X, Maxwell, GM200
RAM: 128 GB
HDD: 4TB
SSD: 512 GB
</code></pre>
",11277304.0,,11277304.0,,2019-04-16 11:44:05,2019-04-16 13:46:06,"How to define max_queue_size, workers and use_multiprocessing in keras fit_generator()?",<python><tensorflow><machine-learning><keras><gpu>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55531427
44544766,1,44547144,,2017-06-14 12:25:46,,67,95660,"<p>When I run a keras script, I get the following output:</p>

<pre><code>Using TensorFlow backend.
2017-06-14 17:40:44.621761: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use SSE4.1 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621783: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use SSE4.2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621788: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621791: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:40:44.621795: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use FMA instructions, but these are 
available 
on your machine and could speed up CPU computations.
2017-06-14 17:40:44.721911: I 
tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful 
NUMA node read from SysFS had negative value (-1), but there must be 
at least one NUMA node, so returning NUMA node zero
2017-06-14 17:40:44.722288: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 
with properties: 
name: GeForce GTX 850M
major: 5 minor: 0 memoryClockRate (GHz) 0.9015
pciBusID 0000:0a:00.0
Total memory: 3.95GiB
Free memory: 3.69GiB
2017-06-14 17:40:44.722302: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-06-14 17:40:44.722307: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-06-14 17:40:44.722312: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating 
TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 850M, 
pci bus id: 0000:0a:00.0)
</code></pre>

<p>What does this mean? Am I using GPU or CPU version of tensorflow?</p>

<p>Before installing keras, I was working with the GPU version of tensorflow. </p>

<p>Also <code>sudo pip3 list</code> shows <code>tensorflow-gpu(1.1.0)</code> and nothing like <code>tensorflow-cpu</code>.</p>

<p>Running the command mentioned on [this stackoverflow question], gives the following:</p>

<pre><code>The TensorFlow library wasn't compiled to use SSE4.1 instructions, 
but these are available on your machine and could speed up CPU 
computations.
2017-06-14 17:53:31.424793: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use SSE4.2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.424803: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.424812: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use AVX2 instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.424820: W 
tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow 
library wasn't compiled to use FMA instructions, but these are 
available on your machine and could speed up CPU computations.
2017-06-14 17:53:31.540959: I 
tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful 
NUMA node read from SysFS had negative value (-1), but there must be 
at least one NUMA node, so returning NUMA node zero
2017-06-14 17:53:31.541359: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 
with properties: 
name: GeForce GTX 850M
major: 5 minor: 0 memoryClockRate (GHz) 0.9015
pciBusID 0000:0a:00.0
Total memory: 3.95GiB
Free memory: 128.12MiB
2017-06-14 17:53:31.541407: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-06-14 17:53:31.541420: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-06-14 17:53:31.541441: I 
tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating 
TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 850M, 
pci bus id: 0000:0a:00.0)
2017-06-14 17:53:31.547902: E 
tensorflow/stream_executor/cuda/cuda_driver.cc:893] failed to 
allocate 128.12M (134348800 bytes) from device: 
CUDA_ERROR_OUT_OF_MEMORY
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce 
GTX 850M, pci bus id: 0000:0a:00.0
2017-06-14 17:53:31.549482: I 
tensorflow/core/common_runtime/direct_session.cc:257] Device 
mapping:
/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce 
GTX 850M, pci bus id: 0000:0a:00.0
</code></pre>
",5847849.0,,5359882.0,,2017-06-15 10:31:01,2020-04-20 05:49:48,How do I check if keras is using gpu version of tensorflow?,<python><tensorflow><neural-network><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44544766
36720498,1,37379618,,2016-04-19 13:52:43,,66,71772,"<p>I am using Keras (with Theano) to train my CNN model. Does anyone has idea how can I use it in my C++ application? Does anyone tried something similar? I have idea to write some python code that will generate a c++ code with network functions - any suggestion on it?</p>

<p>I found a similar question <a href=""https://stackoverflow.com/questions/36412098/convert-keras-model-to-tensorflow-protobuf"">here</a> how to use Tensorflow Keras model in C++ but without answer.</p>
",5605919.0,,-1.0,,2017-05-23 12:10:08,2019-01-31 10:58:56,Convert Keras model to C++,<c++><tensorflow><theano><conv-neural-network><keras>,7,7,0.0,2019-01-31 11:24:13,,CC BY-SA 3.0,https://stackoverflow.com/q/36720498
41651628,1,41742406,,2017-01-14 15:27:53,,66,85862,"<p>I'm using <a href=""https://keras.io/"" rel=""noreferrer"">Keras</a> with <a href=""https://www.tensorflow.org/"" rel=""noreferrer"">Tensorflow</a> as backend , here is my code:</p>

<pre><code>import numpy as np
np.random.seed(1373) 
import tensorflow as tf
tf.python.control_flow_ops = tf

import os
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.utils import np_utils

batch_size = 128
nb_classes = 10
nb_epoch = 12


img_rows, img_cols = 28, 28

nb_filters = 32

nb_pool = 2

nb_conv = 3


(X_train, y_train), (X_test, y_test) = mnist.load_data()

print(X_train.shape[0])

X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)


X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255


print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')


Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

model = Sequential()

model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
border_mode='valid',
input_shape=(1, img_rows, img_cols)))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
model.add(Activation('relu'))

model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes)) 
model.add(Activation('softmax')) 

model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=[""accuracy""])


model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
verbose=1, validation_data=(X_test, Y_test))

score = model.evaluate(X_test, Y_test, verbose=0)

print('Test score:', score[0])
print('Test accuracy:', score[1])
</code></pre>

<p>and Trackback error:</p>

<pre><code>Using TensorFlow backend.
60000
('X_train shape:', (60000, 1, 28, 28))
(60000, 'train samples')
(10000, 'test samples')
Traceback (most recent call last):
  File ""mnist.py"", line 154, in &lt;module&gt;
    input_shape=(1, img_rows, img_cols)))
  File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 276, in add
    layer.create_input_layer(batch_input_shape, input_dtype)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 370, in create_input_layer
    self(x)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 514, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 572, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py"", line 149, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/keras/layers/convolutional.py"", line 466, in call
    filter_shape=self.W_shape)
  File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 1579, in conv2d
    x = tf.nn.conv2d(x, kernel, strides, padding=padding)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 396, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Negative dimension size caused by subtracting 3 from 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [?,1,28,28], [3,3,28,32].
</code></pre>

<p>First I saw some answers that problem is with <code>Tensorflow</code> version so I upgrade <code>Tensorflow</code> to <code>0.12.0</code>, but still exist , is that problem with network or I missing something, what should <code>input_shape</code> looks like?</p>

<p><strong>Update</strong>
Here is <code>./keras/keras.json</code>:</p>

<pre><code>{
    ""image_dim_ordering"": ""tf"", 
    ""epsilon"": 1e-07, 
    ""floatx"": ""float32"", 
    ""backend"": ""tensorflow""
}
</code></pre>
",2326911.0,,2326911.0,,2017-02-21 13:04:55,2022-01-07 15:25:38,Negative dimension size caused by subtracting 3 from 1 for 'Conv2D',<python><tensorflow><keras>,9,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41651628
68836551,1,68841446,,2021-08-18 17:01:31,,65,154460,"<p>Im attempting to find model performance metrics (F1 score, accuracy, recall) following this guide <a href=""https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/"" rel=""noreferrer"">https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/</a></p>
<p>This exact code was working a few months ago but now returning all sorts of errors, very confusing since i havent changed one character of this code. Maybe a package update has changed things?</p>
<p>I fit the sequential model with model.fit, then used model.evaluate to find test accuracy. Now i am attempting to use model.predict_classes to make class predictions (model is a multi-class classifier). Code shown below:</p>
<pre><code>model = Sequential()
model.add(Dense(24, input_dim=13, activation='relu'))
model.add(Dense(18, activation='relu'))
model.add(Dense(6, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

-

history = model.fit(X_train, y_train, batch_size = 256, epochs = 10, verbose = 2, validation_split = 0.2)

-

score, acc = model.evaluate(X_test, y_test,verbose=2, batch_size= 256)
print('test accuracy:', acc)

-

yhat_classes = model.predict_classes(X_test)
 
</code></pre>
<p>last line returns error &quot;AttributeError: 'Sequential' object has no attribute 'predict_classes'&quot;</p>
<p>This exact code was working not long ago so struggling a bit, thanks for any help</p>
",10377186.0,,,,,2023-02-21 13:22:51,Keras AttributeError: 'Sequential' object has no attribute 'predict_classes',<python><keras>,10,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/68836551
46883606,1,46884086,,2017-10-23 07:03:59,,65,41545,"<p>In the user manual, it shows the different kernel_initializer below</p>
<p><a href=""https://keras.io/initializers/"" rel=""noreferrer"">https://keras.io/initializers/</a></p>
<p>the main purpose is to initialize the weight matrix in the neural network.</p>
<p>Anyone knows what the default initializer is? the document didn't show the default.</p>
",2753413.0,,-1.0,,2020-06-20 09:12:55,2020-06-18 08:15:18,what is the default kernel_initializer in keras,<neural-network><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46883606
59317919,1,60131716,,2019-12-13 07:24:14,,65,20182,"<p>Training an image classifier using <code>.fit_generator()</code> or <code>.fit()</code> and passing a dictionary to <code>class_weight=</code> as an argument.</p>

<p>I never got errors in TF1.x but in 2.1 I get the following output when starting training:</p>

<pre class=""lang-none prettyprint-override""><code>WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
</code></pre>

<p>What does it mean to coerce something from <code>...</code> to <code>['...']</code>?</p>

<p>The source for this warning on <code>tensorflow</code>'s repo is <a href=""https://github.com/tensorflow/tensorflow/blob/d1574c209396d38ebe3c20b3ba1cb4c8d82170ae/tensorflow/python/keras/engine/data_adapter.py#L1090"" rel=""noreferrer"">here</a>, comments placed are:</p>

<blockquote>
  <p>Attempt to coerce sample_weight_modes to the target structure. This implicitly depends on the fact that Model flattens outputs for its internal representation.</p>
</blockquote>
",1838257.0,,1838257.0,,2020-02-19 14:07:26,2020-04-04 19:18:09,WARNING:tensorflow:sample_weight modes were coerced from ... to ['...'],<python><tensorflow><keras><tensorflow2.0><tf.keras>,4,7,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59317919
45735070,1,45737582,,2017-08-17 12:25:32,,65,47623,"<p>I've trained a sentiment classifier model using Keras library by following the below steps(broadly).</p>

<ol>
<li>Convert Text corpus into sequences using Tokenizer object/class</li>
<li>Build a model using the model.fit() method </li>
<li>Evaluate this model</li>
</ol>

<p>Now for scoring using this model, I was able to save the model to a file and load from a file. However I've not found a way to save the Tokenizer object to file. Without this I'll have to process the corpus every time I need to score even a single sentence. Is there a way around this?</p>
",5189033.0,,5974433.0,,2017-12-30 13:35:34,2021-09-16 02:40:08,Keras Text Preprocessing - Saving Tokenizer object to file for scoring,<machine-learning><neural-network><nlp><deep-learning><keras>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45735070
34097988,1,34975902,,2015-12-04 21:44:47,,64,183706,"<p>I am trying to work on neural networks in Python using the following Keras packages:</p>

<pre><code>from keras.utils import np_utils
from keras.layers.core import Dense, Activation, Dropout
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
</code></pre>

<p>But, I am getting the following error:</p>

<pre><code> 15 import theano
 ---&gt; 16 from theano import gof
 17 from theano.compat.python2x import partial
 18 import theano.compile.mode
 ImportError: cannot import name gof
</code></pre>

<p>Installing installed <code>conda install keras</code>. Later I tried to use <code>pip install Theano</code>, but it did not work. I Tried to install using <code>pip install git</code>, but I am getting this error: <code>cannot find command git.</code> So I installed Git and I set the environment variables.</p>

<p>So, is there any procedure to install these packages?</p>
",5641188.0,,400589.0,,2017-02-24 22:22:55,2019-04-19 09:13:44,How do I install Keras and Theano in Anaconda Python on Windows?,<python-2.7><python-3.x><anaconda><theano><keras>,8,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34097988
7694978,1,7696379,,2011-10-08 05:20:52,,64,5164,"<p><strong>Update(July 2020): Question is 9 years old but still one that I'm deeply interested in. In the time since, machine learning(RNN's, CNN's, GANS,etc), new approaches and cheap GPU's have risen that enable new approaches. I thought it would be fun to revisit this question to see if there are new approaches.</strong></p>
<p>I am learning programming (Python and algorithms) and was trying to work on a project that I find interesting. I have created a few basic Python scripts, but I’m not sure how to approach a solution to a game I am trying to build.</p>
<p><strong>Here’s how the game will work:</strong></p>
<p>Users will be given items with a value. For example,</p>
<pre><code>Apple = 1
Pears = 2
Oranges  = 3
</code></pre>
<p>They will then get a chance to choose any combo of them they like (i.e. 100 apples, 20 pears, and one orange). The only output the computer gets is the total value (in this example, it's currently $143). The computer will try to guess what they have. Which obviously it won’t be able to get correctly the first turn.</p>
<pre><code>         Value    quantity(day1)    value(day1)
Apple      1        100                100
Pears      2         20                 40
Orange     3          1                  3
Total               121                143
</code></pre>
<p>The next turn the user can modify their numbers but no more than 5% of the total quantity (or some other percent we may chose. I’ll use 5% for example.). The prices of fruit can change(at random) so the total value may change based on that also (for simplicity I am not changing fruit prices in this example). Using the above example, on day 2 of the game, the user returns a value of $152 and $164 on day 3. Here's an example:</p>
<pre><code>Quantity (day2)   %change (day2)    Value (day2)   Quantity (day3)   %change (day3)   Value(day3)
 104                                 104            106                                106
  21                                  42             23                                 46
   2                                   6              4                                 12
 127               4.96%             152            133               4.72%            164
</code></pre>
<p>*(I hope the tables show up right, I had to manually space them so hopefully it's not just doing it on my screen, if it doesn't work let me know and I'll try to upload a screenshot.)</p>
<p>I am trying to see if I can figure out what the quantities are over time (assuming the user will have the patience to keep entering numbers). I know right now my only restriction is the total value cannot be more than 5% so I cannot be within 5% accuracy right now so the user will be entering it forever.</p>
<p><strong>What I have done so far</strong></p>
<p>Here’s my solution so far (not much). Basically, I take all the values and figure out all the possible combinations of them (I am done this part). Then I take all the possible combos and put them in a database as a dictionary (so for example for $143, there could be a dictionary entry {apple:143, Pears:0, Oranges :0}..all the way to {apple:0, Pears:1, Oranges :47}. I do this each time I get a new number so I have a list of all possibilities.</p>
<p>Here’s where I’m stuck. In using the rules above, how can I figure out the best possible solution? I think I’ll need a fitness function that automatically compares the two days data and removes any possibilities that have more than 5% variance of the previous days data.</p>
<p><strong>Questions:</strong></p>
<p>So my question with user changing the total and me having a list of all the probabilities, how should I approach this? What do I need to learn? Is there any algorithms out there or theories that I can use that are applicable? Or, to help me understand my mistake, can you suggest what rules I can add to make this goal feasible (if it's not in its current state. I was thinking adding more fruits and saying they must pick at least 3, etc..)?  Also, I only have a vague understanding of genetic algorithms, but I thought I could use them here, if is there something I can use?</p>
<p>I'm very very eager to learn so any advice or tips would be greatly appreciated (just please don't tell me this game is impossible).</p>
<p>UPDATE: Getting feedback that this is hard to solve. So I thought I'd add another condition to the game that won't interfere with what the player is doing (game stays the same for them) but everyday the value of the fruits change price (randomly). Would that make it easier to solve? Because within a 5% movement and certain fruit value changes, only a few combinations are probable over time.</p>
<p>Day 1, anything is possible and getting a close enough range is almost impossible, but as the prices of fruits change and the user can only choose a 5% change, then shouldn't (over time) the range be narrow and narrow. In the above example, if prices are volatile enough I think I could brute force a solution that gave me a range to guess in, but I'm trying to figure out if there's a more elegant solution or other solutions to keep narrowing this range over time.</p>
<p>UPDATE2: After reading and asking around, I believe this is a hidden Markov/Viterbi problem that tracks the changes in fruit prices as well as total sum (weighting the last data point the heaviest). I'm not sure how to apply the relationship though. I think this is the case and could be wrong but at the least I'm starting to suspect this is a some type of machine learning problem.</p>
<p>Update 3: I am created a test case (with smaller numbers) and a generator to help automate the user generated data and I am trying to create a graph from it to see what's more likely.</p>
<p>Here's the code, along with the total values and comments on what the users actually fruit quantities are.</p>
<pre><code>#!/usr/bin/env python
import itertools

# Fruit price data
fruitPriceDay1 = {'Apple':1, 'Pears':2, 'Oranges':3}
fruitPriceDay2 = {'Apple':2, 'Pears':3, 'Oranges':4}
fruitPriceDay3 = {'Apple':2, 'Pears':4, 'Oranges':5}

# Generate possibilities for testing (warning...will not scale with large numbers)
def possibilityGenerator(target_sum, apple, pears, oranges):
    allDayPossible = {}
    counter = 1
    apple_range = range(0, target_sum + 1, apple)
    pears_range = range(0, target_sum + 1, pears)
    oranges_range = range(0, target_sum + 1, oranges)
    for i, j, k in itertools.product(apple_range, pears_range, oranges_range):
        if i + j + k == target_sum:
            currentPossible = {}

            #print counter
            #print 'Apple', ':', i/apple, ',', 'Pears', ':', j/pears, ',', 'Oranges', ':', k/oranges
            currentPossible['apple'] = i/apple
            currentPossible['pears'] = j/pears
            currentPossible['oranges'] = k/oranges

            #print currentPossible
            allDayPossible[counter] = currentPossible
            counter = counter +1
    return allDayPossible

# Total sum being returned by user for value of fruits
totalSumDay1=26 # Computer does not know this but users quantities are apple: 20, pears 3, oranges 0 at the current prices of the day
totalSumDay2=51 # Computer does not know this but users quantities are apple: 21, pears 3, oranges 0 at the current prices of the day
totalSumDay3=61 # Computer does not know this but users quantities are apple: 20, pears 4, oranges 1 at the current prices of the day
graph = {}
graph['day1'] = possibilityGenerator(totalSumDay1, fruitPriceDay1['Apple'], fruitPriceDay1['Pears'], fruitPriceDay1['Oranges'] )
graph['day2'] = possibilityGenerator(totalSumDay2, fruitPriceDay2['Apple'], fruitPriceDay2['Pears'], fruitPriceDay2['Oranges'] )
graph['day3'] = possibilityGenerator(totalSumDay3, fruitPriceDay3['Apple'], fruitPriceDay3['Pears'], fruitPriceDay3['Oranges'] )

# Sample of dict = 1 : {'oranges': 0, 'apple': 0, 'pears': 0}..70 : {'oranges': 8, 'apple': 26, 'pears': 13}
print graph
</code></pre>
",640558.0,,640558.0,,2020-07-06 15:18:15,2020-07-12 12:11:08,How to approach a number guessing game (with a twist) algorithm?,<python><algorithm><tensorflow><machine-learning><keras>,7,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/7694978
42755820,1,42758532,,2017-03-13 02:35:03,,63,32402,"<p>I have a dialog corpus like below. And I want to implement a LSTM model which predicts a system action. The system action is described as a bit vector. And a user input is calculated as a word-embedding which is also a bit vector.</p>

<pre><code>t1: user: ""Do you know an apple?"", system: ""no""(action=2)
t2: user: ""xxxxxx"", system: ""yyyy"" (action=0)
t3: user: ""aaaaaa"", system: ""bbbb"" (action=5)
</code></pre>

<p>So what I want to realize is ""many to many (2)"" model. When my model receives a user input, it must output a system action.
<a href=""https://i.stack.imgur.com/13opm.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/13opm.jpg"" alt=""enter image description here""></a>
But I cannot understand <code>return_sequences</code> option and <code>TimeDistributed</code> layer after LSTM. To realize ""many-to-many (2)"", <code>return_sequences==True</code> and adding a <code>TimeDistributed</code> after LSTMs are required? I appreciate if you would give more description of them.</p>

<blockquote>
  <p><strong>return_sequences</strong>: Boolean. Whether to return the last output in the output sequence, or the full sequence.</p>
  
  <p><strong>TimeDistributed</strong>: This wrapper allows to apply a layer to every temporal slice of an input.</p>
</blockquote>

<h3>Updated 2017/03/13 17:40</h3>

<p>I think I could understand the <code>return_sequence</code> option. But I am not still sure about <code>TimeDistributed</code>. If I add a <code>TimeDistributed</code> after LSTMs, is the model the same as ""my many-to-many(2)"" below? So I think Dense layers are applied for each output.
<a href=""https://i.stack.imgur.com/DiPyQ.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/DiPyQ.jpg"" alt=""enter image description here""></a></p>
",3548063.0,,3548063.0,,2018-04-16 19:18:07,2018-04-16 19:18:07,How to use return_sequences option and TimeDistributed layer in Keras?,<deep-learning><keras><lstm><recurrent-neural-network>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42755820
44476706,1,44488571,,2017-06-10 18:28:24,,62,60161,"<p>I used Keras biomedical image segmentation to segment brain neurons. I used <code>model.evaluate()</code> it gave me Dice coefficient: 0.916. However, when I used <code>model.predict()</code>, then loop through the predicted images by calculating the Dice coefficient, the Dice coefficient is 0.82. Why are these two values different?</p>
",6152687.0,,3924118.0,,2019-10-25 17:45:35,2020-04-30 21:50:55,What is the difference between Keras model.evaluate() and model.predict()?,<machine-learning><neural-network><deep-learning><keras><image-segmentation>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44476706
52582275,1,52661189,,2018-09-30 21:19:49,,62,41174,"<p>For the application, such as <strong>pair text similarity</strong>, the input data is similar to: <code>pair_1, pair_2</code>. In these problems, we usually have multiple input data. Previously, I implemented my models successfully:</p>

<pre><code>model.fit([pair_1, pair_2], labels, epochs=50)
</code></pre>

<p>I decided to replace my input pipeline with <a href=""https://www.tensorflow.org/api_docs/python/tf/data"" rel=""noreferrer"">tf.data</a> API. To this end, I create a Dataset similar to:</p>

<pre><code>dataset = tf.data.Dataset.from_tensor_slices((pair_1, pair2, labels))
</code></pre>

<p>It compiles successfully but when start to train it throws the following exception:</p>

<pre><code>AttributeError: 'tuple' object has no attribute 'ndim'
</code></pre>

<p>My Keras and Tensorflow version respectively are <code>2.1.6</code> and <code>1.11.0</code>. I found a similar issue in Tensorflow repository:
<a href=""https://github.com/tensorflow/tensorflow/issues/20698"" rel=""noreferrer"">tf.keras multi-input models don't work when using tf.data.Dataset</a>.</p>

<p>Does anyone know how to fix the issue?</p>

<p><strong>Here is some main part of the code</strong>:</p>

<pre class=""lang-py prettyprint-override""><code>(q1_test, q2_test, label_test) = test
(q1_train, q2_train, label_train) = train

    def tfdata_generator(sent1, sent2, labels, is_training):
        '''Construct a data generator using tf.Dataset'''

        dataset = tf.data.Dataset.from_tensor_slices((sent1, sent2, labels))
        if is_training:
            dataset = dataset.shuffle(1000)  # depends on sample size

        dataset = dataset.repeat()
        dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)

        return dataset

train_dataset = tfdata_generator(q1_train, q2_train, label_train, is_training=True, batch_size=_BATCH_SIZE)
test_dataset = tfdata_generator(q1_test, q2_test, label_test, is_training=False, batch_size=_BATCH_SIZE)


inps1 = keras.layers.Input(shape=(50,))
inps2 = keras.layers.Input(shape=(50,))

embed = keras.layers.Embedding(input_dim=nb_vocab, output_dim=300, weights=[embedding], trainable=False)
embed1 = embed(inps1)
embed2 = embed(inps2)

gru = keras.layers.CuDNNGRU(256)
gru1 = gru(embed1)
gru2 = gru(embed2)

concat = keras.layers.concatenate([gru1, gru2])

preds = keras.layers.Dense(1, 'sigmoid')(concat)

model = keras.models.Model(inputs=[inps1, inps2], outputs=preds)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
print(model.summary())

model.fit(
    train_dataset.make_one_shot_iterator(),
    steps_per_epoch=len(q1_train) // _BATCH_SIZE,
    epochs=50,
    validation_data=test_dataset.make_one_shot_iterator(),
    validation_steps=len(q1_test) // _BATCH_SIZE,
    verbose=1)
</code></pre>
",1462770.0,,1462770.0,,2018-10-07 15:22:18,2020-03-15 22:21:30,tf.data with multiple inputs / outputs in Keras,<tensorflow><keras><tensorflow-datasets>,2,5,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52582275
47665391,1,47665700,,2017-12-06 01:28:16,,62,142110,"<p>I have checked all the solutions, but still, I am facing the same error. My training images shape is <code>(26721, 32, 32, 1)</code>, which I believe it is 4 dimension, but I don't know why error shows it is 5 dimension. </p>

<pre><code> model = Sequential()

 model.add(Convolution2D(16, 5, 5, border_mode='same', input_shape= input_shape ))
</code></pre>

<p>So this is how I am defining <code>model.fit_generator</code> </p>

<pre><code>model.fit_generator(train_dataset, train_labels, nb_epoch=epochs, verbose=1,validation_data=(valid_dataset, valid_labels), nb_val_samples=valid_dataset.shape[0],callbacks=model_callbacks)
</code></pre>
",7732719.0,,3924118.0,,2020-01-03 12:39:30,2021-02-15 17:27:23,"Keras ValueError: Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=5",<python><tensorflow><deep-learning><keras><conv-neural-network>,6,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47665391
45943675,1,45944225,,2017-08-29 16:04:44,,61,55553,"<p>I am using Keras with a Tensorflow backend in Python. To be more precise tensorflow <strong>1.2.1</strong> and its build-in contrib.keras lib.</p>

<p>I want to use the <code>fit_generator</code> method of a Sequential model object, but I am confused with what I should pass as the method-parameters.</p>

<p>From reading the doc <a href=""https://keras.io/models/sequential/#fit_generator"" rel=""noreferrer"">here</a> I got the following information:  </p>

<ul>
<li><strong>generator</strong> : a python training data batch generator; endlessly looping over its training data</li>
<li><strong>validation_data</strong>:  -<em>in my case</em> - a python validation data batch generator; the doc doesn't mention endless looping over its validation data</li>
<li><strong>steps_per_epoch</strong> : <code>number of training batches = uniqueTrainingData / batchSize</code></li>
<li><strong>validation steps</strong> : <code>???</code> ; = uniqueValidationData / batch size ???</li>
<li><strong>use_multiprocessing</strong> : boolean; don't pass non picklable arguments ???</li>
<li><strong>workers</strong> : max number of used processes </li>
</ul>

<p>As indicated above with ??? I don't really know what validation_steps means.
I know the definition of the above linked doc (<code>Number of steps to yield from validation generator at the end of every epoch</code>) but that only confuses my in the given context. From the doc i know that the validation_data generator has to yield data, label tuples in the form <code>(inputs, targets)</code>. In contrast to that the above statement indicates that there have to be multiple ""steps to yield from validation generator at the end of every epoch"" which in this context would mean, that multiple validation batches would be yielded after each training epoch.  </p>

<p>Questions about <code>validation_steps</code>:</p>

<ul>
<li>Does it really work that way? If so: Why? I thought that after each epoch one validation batch, which ideally wasn't used before, is used for validation to ensure that the training gets validated without risking to ""train"" the model to perform better on already used validation sets.  </li>
<li>In context of the previous question: Why is the recommended amount of validation steps <code>uniqueValidationData / batches</code> and not <code>uniqueValidationData / epochs</code>? Isn't it better to have e.g. 100 validation batches for 100 epochs instead of x validation batches where x could be less or more than the specified number of epochs? Alternatively: If you have much less validation batches than number of epoches, is the model trained without validation for the rest of the epochs or do validation sets get reused / reshuffled+reused? </li>
<li>Is it important that the training and validation batches have the same batch size (shared divisor of the dividends trainingDataCount and validationDataCount)?</li>
</ul>

<p>Additional question about <code>use_multiprocessing</code>:</p>

<ul>
<li>Are numpy arrays picklable or do I have to convert them to multidimensional lists?</li>
</ul>
",8355555.0,,3689502.0,,2019-10-08 23:11:23,2019-10-08 23:11:23,Meaning of validation_steps in Keras Sequential fit_generator parameter list,<parameters><keras><generator><data-fitting>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45943675
39124676,1,39192224,,2016-08-24 13:26:43,,61,81429,"<p>When I load the whole dataset in memory and train the network in Keras using following code:</p>

<pre><code>model.fit(X, y, nb_epoch=40, batch_size=32, validation_split=0.2, verbose=1)
</code></pre>

<p>This generates a progress bar per epoch with metrics like ETA, accuracy, loss, etc</p>

<p>When I train the network in batches, I'm using the following code</p>

<pre><code>for e in range(40):
        for X, y in data.next_batch():
            model.fit(X, y, nb_epoch=1, batch_size=data.batch_size, verbose=1)
</code></pre>

<p>This will generate a progress bar for each batch instead of each epoch. Is it possible to generate a progress bar for each epoch during batchwise training? </p>
",3138699.0,,,,,2021-06-25 19:48:10,Show progress bar for each epoch during batchwise training in Keras,<python><machine-learning><keras>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39124676
38445982,1,38446890,,2016-07-18 21:05:58,,61,73237,"<p>When you run a Keras neural network model you might see something like this in the console: </p>

<pre><code>Epoch 1/3
   6/1000 [..............................] - ETA: 7994s - loss: 5111.7661
</code></pre>

<p>As time goes on the loss hopefully improves. I want to log these losses to a file over time so that I can learn from them. I have tried: </p>

<pre><code>logging.basicConfig(filename='example.log', filemode='w', level=logging.DEBUG)
</code></pre>

<p>but this doesn't work. I am not sure what level of logging I need in this situation. </p>

<p>I have also tried using a callback like in: </p>

<pre><code>def generate_train_batch():
    while 1:
        for i in xrange(0,dset_X.shape[0],3):
            yield dset_X[i:i+3,:,:,:],dset_y[i:i+3,:,:]

class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
logloss=LossHistory()
colorize.fit_generator(generate_train_batch(),samples_per_epoch=1000,nb_epoch=3,callbacks=['logloss'])
</code></pre>

<p>but obviously this isn't writing to a file. Whatever the method, through a callback or the logging module or anything else, I would love to hear your solutions for logging loss of a keras neural network to a file. Thanks! </p>
",1123905.0,,5974433.0,,2016-07-18 23:27:58,2020-05-02 23:09:12,How to log Keras loss output to a file,<python><logging><machine-learning><neural-network><keras>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38445982
37213388,1,37213763,,2016-05-13 15:01:24,,61,160688,"<p>I have a few thousand audio files and I want to classify them using Keras and Theano. So far, I generated a 28x28 spectrograms (bigger is probably better, but I am just trying to get the algorithm work at this point) of each audio file and read the image into a matrix. So in the end I get this big image matrix to feed into the network for image classification.</p>

<p>In a tutorial I found this mnist classification code:</p>

<pre><code>import numpy as np

from keras.datasets import mnist
from keras.models import Sequential
from keras.layers.core import Dense
from keras.utils import np_utils

batch_size = 128
nb_classes = 10
nb_epochs = 2

(X_train, y_train), (X_test, y_test) = mnist.load_data()

X_train = X_train.reshape(60000, 784)
X_test = X_test.reshape(10000, 784)
X_train = X_train.astype(""float32"")
X_test = X_test.astype(""float32"")
X_train /= 255
X_test /= 255

print(X_train.shape[0], ""train samples"")
print(X_test.shape[0], ""test samples"")

y_train = np_utils.to_categorical(y_train, nb_classes)
y_test =  np_utils.to_categorical(y_test, nb_classes)

model = Sequential()

model.add(Dense(output_dim = 100, input_dim = 784, activation= ""relu""))
model.add(Dense(output_dim = 200, activation = ""relu""))
model.add(Dense(output_dim = 200, activation = ""relu""))
model.add(Dense(output_dim = nb_classes, activation = ""softmax""))

model.compile(optimizer = ""adam"", loss = ""categorical_crossentropy"")

model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test))
score = model.evaluate(X_test, y_test, show_accuracy = True, verbose = 0)
print(""Test score: "", score[0])
print(""Test accuracy: "", score[1])
</code></pre>

<p>This code runs, and I get the result as expected:</p>

<pre><code>(60000L, 'train samples')
(10000L, 'test samples')
Train on 60000 samples, validate on 10000 samples
Epoch 1/2
2s - loss: 0.2988 - acc: 0.9131 - val_loss: 0.1314 - val_acc: 0.9607
Epoch 2/2
2s - loss: 0.1144 - acc: 0.9651 - val_loss: 0.0995 - val_acc: 0.9673
('Test score: ', 0.099454972004890438)
('Test accuracy: ', 0.96730000000000005)
</code></pre>

<p>Up to this point everything runs perfectly, however when I apply the above algorithm to my dataset, accuracy gets stuck.</p>

<p>My code is as follows:</p>

<pre><code>import os

import pandas as pd

from sklearn.cross_validation import train_test_split

from keras.models import Sequential
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.layers.core import Dense, Activation, Dropout, Flatten
from keras.utils import np_utils

import AudioProcessing as ap
import ImageTools as it

batch_size = 128
nb_classes = 2
nb_epoch = 10  


for i in range(20):
    print ""\n""
# Generate spectrograms if necessary
if(len(os.listdir(""./AudioNormalPathalogicClassification/Image"")) &gt; 0):
    print ""Audio files are already processed. Skipping...""
else:
    print ""Generating spectrograms for the audio files...""
    ap.audio_2_image(""./AudioNormalPathalogicClassification/Audio/"",""./AudioNormalPathalogicClassification/Image/"","".wav"","".png"",(28,28))

# Read the result csv
df = pd.read_csv('./AudioNormalPathalogicClassification/Result/result.csv', header = None)

df.columns = [""RegionName"",""IsNormal""]

bool_mapping = {True : 1, False : 0}

nb_classes = 2

for col in df:
    if(col == ""RegionName""):
        a = 3      
    else:
        df[col] = df[col].map(bool_mapping)

y = df.iloc[:,1:].values

y = np_utils.to_categorical(y, nb_classes)

# Load images into memory
print ""Loading images into memory...""
X = it.load_images(""./AudioNormalPathalogicClassification/Image/"","".png"")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

X_train = X_train.reshape(X_train.shape[0], 784)
X_test = X_test.reshape(X_test.shape[0], 784)
X_train = X_train.astype(""float32"")
X_test = X_test.astype(""float32"")
X_train /= 255
X_test /= 255

print(""X_train shape: "" + str(X_train.shape))
print(str(X_train.shape[0]) + "" train samples"")
print(str(X_test.shape[0]) + "" test samples"")

model = Sequential()


model.add(Dense(output_dim = 100, input_dim = 784, activation= ""relu""))
model.add(Dense(output_dim = 200, activation = ""relu""))
model.add(Dense(output_dim = 200, activation = ""relu""))
model.add(Dense(output_dim = nb_classes, activation = ""softmax""))

model.compile(loss = ""categorical_crossentropy"", optimizer = ""adam"")

print model.summary()

model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epoch, show_accuracy = True, verbose = 1, validation_data = (X_test, y_test))
score = model.evaluate(X_test, y_test, show_accuracy = True, verbose = 1)
print(""Test score: "", score[0])
print(""Test accuracy: "", score[1])
</code></pre>

<p>AudioProcessing.py</p>

<pre><code>import os
import scipy as sp
import scipy.io.wavfile as wav
import matplotlib.pylab as pylab
import Image

def save_spectrogram_scipy(source_filename, destination_filename, size):
    dt = 0.0005
    NFFT = 1024       
    Fs = int(1.0/dt)  
    fs, audio = wav.read(source_filename)
    if(len(audio.shape) &gt;= 2):
        audio = sp.mean(audio, axis = 1)
    fig = pylab.figure()    
    ax = pylab.Axes(fig, [0,0,1,1])    
    ax.set_axis_off()
    fig.add_axes(ax) 
    pylab.specgram(audio, NFFT = NFFT, Fs = Fs, noverlap = 900, cmap=""gray"")
    pylab.savefig(destination_filename)
    img = Image.open(destination_filename).convert(""L"")
    img = img.resize(size)
    img.save(destination_filename)
    pylab.clf()
    del img

def audio_2_image(source_directory, destination_directory, audio_extension, image_extension, size):
    nb_files = len(os.listdir(source_directory));
    count = 0
    for file in os.listdir(source_directory):
        if file.endswith(audio_extension):        
            destinationName = file[:-4]
            save_spectrogram_scipy(source_directory + file, destination_directory + destinationName + image_extension, size)
            count += 1
            print (""Generating spectrogram for files "" + str(count) + "" / "" + str(nb_files) + ""."")
</code></pre>

<p>ImageTools.py</p>

<pre><code>import os
import numpy as np
import matplotlib.image as mpimg
def load_images(source_directory, image_extension):
    image_matrix = []
    nb_files = len(os.listdir(source_directory));
    count = 0
    for file in os.listdir(source_directory):
        if file.endswith(image_extension):
            with open(source_directory + file,""r+b"") as f:
                img = mpimg.imread(f)
                img = img.flatten()                
                image_matrix.append(img)
                del img
                count += 1
                #print (""File "" + str(count) + "" / "" + str(nb_files) + "" loaded."")
    return np.asarray(image_matrix)
</code></pre>

<p>So I run the above code and recieve:</p>

<pre><code>Audio files are already processed. Skipping...
Loading images into memory...
X_train shape: (2394L, 784L)
2394 train samples
1027 test samples
--------------------------------------------------------------------------------
Initial input shape: (None, 784)
--------------------------------------------------------------------------------
Layer (name)                  Output Shape                  Param #
--------------------------------------------------------------------------------
Dense (dense)                 (None, 100)                   78500
Dense (dense)                 (None, 200)                   20200
Dense (dense)                 (None, 200)                   40200
Dense (dense)                 (None, 2)                     402
--------------------------------------------------------------------------------
Total params: 139302
--------------------------------------------------------------------------------
None
Train on 2394 samples, validate on 1027 samples
Epoch 1/10
2394/2394 [==============================] - 0s - loss: 0.6898 - acc: 0.5455 - val_loss: 0.6835 - val_acc: 0.5716
Epoch 2/10
2394/2394 [==============================] - 0s - loss: 0.6879 - acc: 0.5522 - val_loss: 0.6901 - val_acc: 0.5716
Epoch 3/10
2394/2394 [==============================] - 0s - loss: 0.6880 - acc: 0.5522 - val_loss: 0.6842 - val_acc: 0.5716
Epoch 4/10
2394/2394 [==============================] - 0s - loss: 0.6883 - acc: 0.5522 - val_loss: 0.6829 - val_acc: 0.5716
Epoch 5/10
2394/2394 [==============================] - 0s - loss: 0.6885 - acc: 0.5522 - val_loss: 0.6836 - val_acc: 0.5716
Epoch 6/10
2394/2394 [==============================] - 0s - loss: 0.6887 - acc: 0.5522 - val_loss: 0.6832 - val_acc: 0.5716
Epoch 7/10
2394/2394 [==============================] - 0s - loss: 0.6882 - acc: 0.5522 - val_loss: 0.6859 - val_acc: 0.5716
Epoch 8/10
2394/2394 [==============================] - 0s - loss: 0.6882 - acc: 0.5522 - val_loss: 0.6849 - val_acc: 0.5716
Epoch 9/10
2394/2394 [==============================] - 0s - loss: 0.6885 - acc: 0.5522 - val_loss: 0.6836 - val_acc: 0.5716
Epoch 10/10
2394/2394 [==============================] - 0s - loss: 0.6877 - acc: 0.5522 - val_loss: 0.6849 - val_acc: 0.5716
1027/1027 [==============================] - 0s
('Test score: ', 0.68490593621422047)
('Test accuracy: ', 0.57156767283349563)
</code></pre>

<p>I tried changing the network, adding more epochs, but I always get the same result no matter what. I don't understand why I am getting the same result.</p>

<p>Any help would be appreciated. Thank you.</p>

<p>Edit:
I found a mistake where pixel values were not read correctly. I fixed the ImageTools.py below as:</p>

<pre><code>import os
import numpy as np
from scipy.misc import imread

def load_images(source_directory, image_extension):
    image_matrix = []
    nb_files = len(os.listdir(source_directory));
    count = 0
    for file in os.listdir(source_directory):
        if file.endswith(image_extension):
            with open(source_directory + file,""r+b"") as f:
                img = imread(f)                
                img = img.flatten()                        
                image_matrix.append(img)
                del img
                count += 1
                #print (""File "" + str(count) + "" / "" + str(nb_files) + "" loaded."")
    return np.asarray(image_matrix)
</code></pre>

<p>Now I actually get grayscale pixel values from 0 to 255, so now my dividing it by 255 makes sense. However, I still get the same result.</p>
",2515942.0,,2515942.0,,2016-05-15 13:11:50,2023-04-30 08:21:54,Keras accuracy does not change,<python><audio><machine-learning><theano><keras>,20,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37213388
51455863,1,51455864,,2018-07-21 12:02:18,,60,17605,"<p>Both Tensorflow Keras models and Tensorflow Estimators are able to train neural network models and use them to predict new data. They are both high-level APIs that sits on top of the low-level core TensorFlow API. So when should I use one over the other?</p>
",3966682.0,,,,,2022-02-25 23:04:12,What's the difference between a Tensorflow Keras Model and Estimator?,<tensorflow><keras><tensorflow-estimator>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51455863
43829711,1,50751553,,2017-05-07 09:05:20,,59,86373,"<p>I can not for the life of me figure out how to switch the image ordering. images are read in (x,x,3) format, theano requires it to be in (3,x,x) format. I tried changing the order with
<code>numpy.array([img[:,:,i] for i in range(3)])</code></p>

<p>which i guess gets the job done, but it is both ugly and i can't figure out how to reverse it to get the original image back.</p>
",7975668.0,,7975668.0,,2018-05-11 02:30:03,2022-06-16 03:23:04,What is the correct way to change image channel ordering between channels first and channels last?,<python><numpy><machine-learning><keras><theano>,6,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43829711
61742556,1,61742957,,2020-05-12 02:07:54,,58,174132,"<p>I am training a facial expression (angry vs happy)  model. Last dense output layer was previously 1 but when i predict an image it's output was always 1 with 64 % accuracy. So i changed it to 2 for 2 outputs. But now i am getting this  error::</p>
<pre><code>Epoch 1/15

---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&lt;ipython-input-54-9c7272c38dcb&gt; in &lt;module&gt;()
     11     epochs=epochs,
     12     validation_data = val_data_gen,
---&gt; 13     validation_steps = validation_steps,
     14 
     15 )

10 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, &quot;ag_error_metadata&quot;):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step  **
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__
        losses = self.call(y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1527 categorical_crossentropy
        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4561 categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with
        raise ValueError(&quot;Shapes %s and %s are incompatible&quot; % (self, other))

    ValueError: Shapes (None, 1) and (None, 2) are incompatible
</code></pre>
<p>The relevant code is :</p>
<pre><code>    model = Sequential([
    Conv2D(32,3, activation='relu', input_shape=(48,48,1)),
    BatchNormalization(),
    MaxPooling2D(pool_size=(3, 3)),
  
    Flatten(),
    Dense(512, activation='relu'),
    Dense(2,activation='softmax')
])
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])


model.summary()

Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 46, 46, 32)        320       
_________________________________________________________________
batch_normalization_4 (Batch (None, 46, 46, 32)        128       
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 15, 15, 32)        0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 7200)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 512)               3686912   
_________________________________________________________________
dense_9 (Dense)              (None, 2)                 1026      
=================================================================
Total params: 3,688,386
Trainable params: 3,688,322
Non-trainable params: 64
_________________________________________________________________


epochs = 15
steps_per_epoch = train_data_gen.n//train_data_gen.batch_size
validation_steps = val_data_gen.n//val_data_gen.batch_size



history = model.fit(
    x=train_data_gen,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data = val_data_gen,
    validation_steps = validation_steps,
    
)
</code></pre>
",13507534.0,,860196.0,,2020-09-22 17:16:12,2022-07-30 11:04:03,"ValueError: Shapes (None, 1) and (None, 2) are incompatible",<tensorflow><keras><conv-neural-network>,8,7,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/61742556
57874436,1,57973957,,2019-09-10 15:58:29,,58,116083,"<p>While running a sentdex tutorial script of a cryptocurrency RNN, link here</p>

<p><a href=""https://www.youtube.com/watch?v=yWkpRdpOiPY&amp;list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&amp;index=11"" rel=""noreferrer"">YouTube Tutorial: Cryptocurrency-predicting RNN Model</a>,</p>

<p>but have encountered an error when attempting to train the model. My tensorflow version is 2.0.0 and I'm running python 3.6. When attempting to train the model I receive the following error:</p>

<pre class=""lang-py prettyprint-override""><code>File ""C:\python36-64\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 734, in fit
    use_multiprocessing=use_multiprocessing)

File ""C:\python36-64\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 224, in fit
    distribution_strategy=strategy)

File ""C:\python36-64\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 497, in _process_training_inputs
    adapter_cls = data_adapter.select_data_adapter(x, y)

File ""C:\python36-64\lib\site-packages\tensorflow_core\python\keras\engine\data_adapter.py"", line 628, in select_data_adapter
    _type_name(x), _type_name(y)))

ValueError: Failed to find data adapter that can handle input: &lt;class 'numpy.ndarray'&gt;, (&lt;class 'list'&gt; containing values of types {""&lt;class 'numpy.float64'&gt;""})
</code></pre>

<p>Any advice would be greatly appreciated!</p>
",12047797.0,,7758804.0,,2019-09-10 16:13:56,2022-01-20 20:09:49,Tensorflow Data Adapter Error: ValueError: Failed to find data adapter that can handle input,<python><tensorflow><keras><lstm>,7,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/57874436
40496069,1,43957826,,2016-11-08 20:43:45,,58,71502,"<p>I'd like to reset (randomize) the weights of all layers in my Keras (deep learning) model. The reason is that I want to be able to train the model several times with different data splits without having to do the (slow) model recompilation every time.</p>
<p>Inspired by <a href=""https://github.com/fchollet/keras/pull/1908"" rel=""noreferrer"">this discussion</a>, I'm trying the following code:</p>
<pre><code># Reset weights
for layer in KModel.layers:
    if hasattr(layer,'init'):
        input_dim = layer.input_shape[1]
        new_weights = layer.init((input_dim, layer.output_dim),name='{}_W'.format(layer.name))
        layer.trainable_weights[0].set_value(new_weights.get_value())
</code></pre>
<p>However, it only partly works.</p>
<p>Partly, becuase I've inspected some layer.get_weights() values, and they seem to change. But when I restart the training, the cost values are much lower than the initial cost values on the first run. It's almost like I've succeeded resetting some of the weights, but not all of them.</p>
",3420102.0,,4685471.0,,2021-10-13 09:09:28,2022-12-09 01:53:45,Reset weights in Keras layer,<python><tensorflow><machine-learning><keras><keras-layer>,10,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/40496069
37911321,1,37912576,,2016-06-19 20:04:24,,58,35006,"<p>In Keras, to predict class of a datatest, the <code>predict_classes()</code> is used.</p>

<p>For example:</p>

<pre><code>classes = model.predict_classes(X_test, batch_size=32)
</code></pre>

<p>My question is, I know the usage of <code>batch_size</code> in training, but why does it need a <code>batch_size</code> for prediction? how does it work?</p>
",2147347.0,,2147347.0,,2018-07-30 06:59:12,2021-03-21 06:48:10,Why does prediction needs batch size in Keras?,<neural-network><classification><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/37911321
43915482,1,43915483,,2017-05-11 12:30:20,,58,49684,"<p>Sometimes the default <a href=""https://keras.io/activations/"" rel=""noreferrer"">standard activations</a> like ReLU, tanh, softmax, ... and the <a href=""https://keras.io/layers/advanced-activations/"" rel=""noreferrer"">advanced activations</a> like LeakyReLU aren't enough. And it might also not be in <a href=""https://github.com/farizrahman4u/keras-contrib"" rel=""noreferrer"">keras-contrib</a>.</p>

<p>How do you create your own activation function?</p>
",562769.0,,562769.0,,2019-09-03 14:14:39,2021-01-04 18:24:41,How do you create a custom activation function with Keras?,<python><keras><keras-layer>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43915482
43306323,1,45055094,,2017-04-09 11:46:45,,58,39023,"<p>The Keras layer documentation specifies the input and output sizes for convolutional layers:
<a href=""https://keras.io/layers/convolutional/"" rel=""noreferrer"">https://keras.io/layers/convolutional/</a></p>

<p>Input shape: <code>(samples, channels, rows, cols)</code></p>

<p>Output shape: <code>(samples, filters, new_rows, new_cols)</code></p>

<p>And the kernel size is a spatial parameter, i.e. detemines only width and height.</p>

<p>So an input with <code>c</code> channels will yield an output with <code>filters</code> channels regardless of the value of <code>c</code>. It must therefore apply 2D convolution with a spatial <code>height x width</code> filter and then aggregate the results somehow for each learned filter. </p>

<p>What is this aggregation operator? is it a summation across channels? can I control it? I couldn't find any information on the Keras documentation.</p>

<ul>
<li>Note that in TensorFlow the filters are specified in the depth channel as well:
<a href=""https://www.tensorflow.org/api_guides/python/nn#Convolution"" rel=""noreferrer"">https://www.tensorflow.org/api_guides/python/nn#Convolution</a>,
So the depth operation is clear.</li>
</ul>

<p>Thanks.</p>
",635622.0,,,,,2018-12-26 09:37:59,Keras Conv2D and input channels,<python><keras>,3,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43306323
46135499,1,46140332,,2017-09-09 22:02:40,,57,36399,"<p>Keras' <code>fit_generator()</code> model method expects a generator which produces tuples of the shape (input, targets), where both elements are NumPy arrays. <a href=""https://keras.io/models/model/"" rel=""noreferrer"">The documentation</a> seems to imply that if I simply wrap a <a href=""https://www.tensorflow.org/programmers_guide/datasets"" rel=""noreferrer""><code>Dataset</code> iterator</a> in a generator, and make sure to convert the Tensors to NumPy arrays, I should be good to go. This code, however, gives me an error:</p>

<pre><code>import numpy as np
import os
import keras.backend as K
from keras.layers import Dense, Input
from keras.models import Model
import tensorflow as tf
from tensorflow.contrib.data import Dataset

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

with tf.Session() as sess:
    def create_data_generator():
        dat1 = np.arange(4).reshape(-1, 1)
        ds1 = Dataset.from_tensor_slices(dat1).repeat()

        dat2 = np.arange(5, 9).reshape(-1, 1)
        ds2 = Dataset.from_tensor_slices(dat2).repeat()

        ds = Dataset.zip((ds1, ds2)).batch(4)
        iterator = ds.make_one_shot_iterator()
        while True:
            next_val = iterator.get_next()
            yield sess.run(next_val)

datagen = create_data_generator()

input_vals = Input(shape=(1,))
output = Dense(1, activation='relu')(input_vals)
model = Model(inputs=input_vals, outputs=output)
model.compile('rmsprop', 'mean_squared_error')
model.fit_generator(datagen, steps_per_epoch=1, epochs=5,
                    verbose=2, max_queue_size=2)
</code></pre>

<p>Here's the error I get:</p>

<pre><code>Using TensorFlow backend.
Epoch 1/5
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 270, in __init__
    fetch, allow_tensor=True, allow_operation=True))
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2708, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2787, in _as_graph_element_locked
    raise ValueError(""Tensor %s is not an element of this graph."" % obj)
ValueError: Tensor Tensor(""IteratorGetNext:0"", shape=(?, 1), dtype=int64) is not an element of this graph.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/jsaporta/anaconda3/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/home/jsaporta/anaconda3/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py"", line 568, in data_generator_task
    generator_output = next(self._generator)
  File ""./datagen_test.py"", line 25, in create_data_generator
    yield sess.run(next_val)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1109, in _run
    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 413, in __init__
    self._fetch_mapper = _FetchMapper.for_fetch(fetches)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 233, in for_fetch
    return _ListFetchMapper(fetch)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 340, in __init__
    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 340, in &lt;listcomp&gt;
    self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 241, in for_fetch
    return _ElementFetchMapper(fetches, contraction_fn)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 277, in __init__
    'Tensor. (%s)' % (fetch, str(e)))
ValueError: Fetch argument &lt;tf.Tensor 'IteratorGetNext:0' shape=(?, 1) dtype=int64&gt; cannot be interpreted as a Tensor. (Tensor Tensor(""IteratorGetNext:0"", shape=(?, 1), dtype=int64) is not an element of this graph.)

Traceback (most recent call last):
  File ""./datagen_test.py"", line 34, in &lt;module&gt;
    verbose=2, max_queue_size=2)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/home/jsaporta/anaconda3/lib/python3.6/site-packages/keras/engine/training.py"", line 2011, in fit_generator
    generator_output = next(output_generator)
StopIteration
</code></pre>

<p>Strangely enough, adding a line containing <code>next(datagen)</code> directly after where I initialize <code>datagen</code> causes the code to run just fine, with no errors.</p>

<p>Why does my original code not work? Why does it begin to work when I add that line to my code? Is there a more efficient way to use TensorFlow's Dataset API with Keras that doesn't involve converting Tensors to NumPy arrays and back again?</p>
",4444582.0,,,,,2019-05-20 03:36:48,How to Properly Combine TensorFlow's Dataset API and Keras?,<tensorflow><keras>,6,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46135499
43882796,1,46331227,,2017-05-10 02:46:42,,56,26443,"<p>I read all sorts of texts about it, and none seem to answer this very basic question. It's always ambiguous:</p>

<p>In a <code>stateful = False</code> LSTM layer, does keras reset states after:</p>

<ul>
<li>Each sequence; or    </li>
<li>Each batch?</li>
</ul>

<p>Suppose I have X_train shaped as (1000,20,1), meaning 1000 sequences of 20 steps of a single value. If I make:</p>

<pre><code>model.fit(X_train, y_train, batch_size=200, nb_epoch=15)
</code></pre>

<p>Will it reset states for every single sequence (resets states 1000 times)?<br>
Or will it reset states for every batch (resets states 5 times)?</p>
",2097240.0,,2097240.0,,2017-05-10 03:05:40,2022-12-31 10:31:58,When does keras reset an LSTM state?,<keras><lstm><keras-layer>,5,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43882796
42177658,1,42177775,,2017-02-11 15:32:24,,56,84570,"<p>I tried to switch Backend with Keras (from TensorFlow to Theano) but did not manage.
I followed the temps described <a href=""https://keras.io/backend/"" rel=""noreferrer"">here</a> but it doesn't work. I created a keras.json in the keras' directory (as it did not exist) but it doesn't change anything when I import it from Python.</p>
",1426385.0,,5954249.0,,2017-08-23 10:31:29,2023-02-09 05:37:54,How to switch Backend with Keras (from TensorFlow to Theano),<backend><theano><keras>,10,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42177658
55908188,1,55909624,,2019-04-29 17:25:44,,56,119373,"<p>I've keras model defined as follow</p>

<pre class=""lang-py prettyprint-override""><code>class ConvLayer(Layer) :
    def __init__(self, nf, ks=3, s=2, **kwargs):
        self.nf = nf
        self.grelu = GeneralReLU(leak=0.01)
        self.conv = (Conv2D(filters     = nf,
                            kernel_size = ks,
                            strides     = s,
                            padding     = ""same"",
                            use_bias    = False,
                            activation  = ""linear""))
        super(ConvLayer, self).__init__(**kwargs)

    def rsub(self): return -self.grelu.sub
    def set_sub(self, v): self.grelu.sub = -v
    def conv_weights(self): return self.conv.weight[0]

    def build(self, input_shape):
        # No weight to train.
        super(ConvLayer, self).build(input_shape)  # Be sure to call this at the end

    def compute_output_shape(self, input_shape):
        output_shape = (input_shape[0],
                        input_shape[1]/2,
                        input_shape[2]/2,
                        self.nf)
        return output_shape

    def call(self, x):
        return self.grelu(self.conv(x))

    def __repr__(self):
        return f'ConvLayer(nf={self.nf}, activation={self.grelu})'
</code></pre>

<pre class=""lang-py prettyprint-override""><code>class ConvModel(tf.keras.Model):
    def __init__(self, nfs, input_shape, output_shape, use_bn=False, use_dp=False):
        super(ConvModel, self).__init__(name='mlp')
        self.use_bn = use_bn
        self.use_dp = use_dp
        self.num_classes = num_classes

        # backbone layers
        self.convs = [ConvLayer(nfs[0], s=1, input_shape=input_shape)]
        self.convs += [ConvLayer(nf) for nf in nfs[1:]]
        # classification layers
        self.convs.append(AveragePooling2D())
        self.convs.append(Dense(output_shape, activation='softmax'))

    def call(self, inputs):
        for layer in self.convs: inputs = layer(inputs)
        return inputs
</code></pre>

<p>I'm able to compile this model without any issues</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr), 
              loss='categorical_crossentropy',
              metrics=['accuracy'])
</code></pre>

<p>But when I query the summary for this model, I see this error</p>

<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; model = ConvModel(nfs, input_shape=(32, 32, 3), output_shape=num_classes)
&gt;&gt;&gt; model.summary()
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-220-5f15418b3570&gt; in &lt;module&gt;()
----&gt; 1 model.summary()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py in summary(self, line_length, positions, print_fn)
   1575     """"""
   1576     if not self.built:
-&gt; 1577       raise ValueError('This model has not yet been built. '
   1578                        'Build the model first by calling `build()` or calling '
   1579                        '`fit()` with some data, or specify '

ValueError: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.
</code></pre>

<p>I'm providing <code>input_shape</code> for the first layer of my model, why is throwing this error?</p>
",1269281.0,,1269281.0,,2019-04-29 18:57:11,2022-10-19 05:02:00,This model has not yet been built error on model.summary(),<python><tensorflow><keras><tensorflow2.0>,8,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55908188
55496289,1,55496390,,2019-04-03 13:23:46,,56,122277,"<p>I am trying to run some code to create an LSTM model but i get an error:</p>

<p><code>AttributeError: module 'tensorflow' has no attribute 'get_default_graph'</code></p>

<p>My code is as follows:</p>

<pre><code>from keras.models import Sequential

model = Sequential()
model.add(Dense(32, input_dim=784))
model.add(Activation('relu'))
model.add(LSTM(17))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>I have found someone else with a similar problem and they updated tensorflow and it works; but mine is up to date and still does not work. I am new to using keras and machine learning so I apologise if this is something silly!</p>
",10724050.0,,10724050.0,,2019-04-03 13:34:06,2022-04-13 10:21:54,"How to fix ""AttributeError: module 'tensorflow' has no attribute 'get_default_graph'""?",<python><tensorflow><keras><keras-layer><tf.keras>,19,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55496289
45632549,1,45632689,,2017-08-11 10:08:03,,55,66931,"<p>I'm pretty new to keras I have built a simple network to try:</p>

<pre><code>import numpy as np;

from keras.models import Sequential;
from keras.layers import Dense,Activation;

data= np.genfromtxt(""./kerastests/mydata.csv"", delimiter=';')
x_target=data[:,29]
x_training=np.delete(data,6,axis=1)
x_training=np.delete(x_training,28,axis=1)

model=Sequential()
model.add(Dense(20,activation='relu', input_dim=x_training.shape[1]))
model.add(Dense(10,activation='relu'))
model.add(Dense(1));

model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])
model.fit(x_training, x_target)
</code></pre>

<p>From my source data, I have removed 2 columns, as you can see. One is a column that came with dates in a string format (in the dataset, besides it, I have a column for the day, another for the month, and another for the year, so I don't need that column) and the other column is the column I use as target for the model).</p>

<p>When I train this model I get this output:</p>

<pre><code>32/816 [&gt;.............................] - ETA: 23s - loss: 13541942.0000 - acc: 0.0000e+00
800/816 [============================&gt;.] - ETA: 0s - loss: 11575466.0400 - acc: 0.0000e+00 
816/816 [==============================] - 1s - loss: 11536905.2353 - acc: 0.0000e+00     
Epoch 2/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 6794785.0000 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5381360.4314 - acc: 0.0000e+00     
Epoch 3/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 6235184.0000 - acc: 0.0000e+00
800/816 [============================&gt;.] - ETA: 0s - loss: 5199512.8700 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5192977.4216 - acc: 0.0000e+00     
Epoch 4/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 4680165.5000 - acc: 0.0000e+00
736/816 [==========================&gt;...] - ETA: 0s - loss: 5050110.3043 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5168771.5490 - acc: 0.0000e+00     
Epoch 5/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 5932391.0000 - acc: 0.0000e+00
768/816 [===========================&gt;..] - ETA: 0s - loss: 5198882.9167 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5159585.9020 - acc: 0.0000e+00     
Epoch 6/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 4488318.0000 - acc: 0.0000e+00
768/816 [===========================&gt;..] - ETA: 0s - loss: 5144843.8333 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5151492.1765 - acc: 0.0000e+00     
Epoch 7/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 6920405.0000 - acc: 0.0000e+00
800/816 [============================&gt;.] - ETA: 0s - loss: 5139358.5000 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5169839.2941 - acc: 0.0000e+00     
Epoch 8/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 3973038.7500 - acc: 0.0000e+00
672/816 [=======================&gt;......] - ETA: 0s - loss: 5183285.3690 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5141417.0000 - acc: 0.0000e+00     
Epoch 9/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 4969548.5000 - acc: 0.0000e+00
768/816 [===========================&gt;..] - ETA: 0s - loss: 5126550.1667 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5136524.5098 - acc: 0.0000e+00     
Epoch 10/10
 32/816 [&gt;.............................] - ETA: 0s - loss: 6334703.5000 - acc: 0.0000e+00
768/816 [===========================&gt;..] - ETA: 0s - loss: 5197778.8229 - acc: 0.0000e+00
816/816 [==============================] - 0s - loss: 5141391.2059 - acc: 0.0000e+00    
</code></pre>

<p>Why is this happening? My data is a time series. I know that for time series people do not usually use <code>Dense</code> neurons, but it is just a test. What really tricks me is that accuracy is always 0. And, with other tests, I did even lose: gets to a ""NAN"" value.</p>

<p>Could anybody help here?</p>
",574633.0,,3924118.0,,2020-01-26 21:32:45,2022-08-26 18:12:53,Why is the accuracy for my Keras model always 0 when training?,<tensorflow><neural-network><keras>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45632549
43076609,1,50544931,,2017-03-28 17:53:43,,54,70765,"<p>I am building a multi-class classifier with Keras 2.02 (with Tensorflow backend)，and I do not know how to calculate precision and recall in Keras. Please help me.</p>
",4787786.0,,,,,2019-10-03 08:26:52,How to calculate precision and recall in Keras,<python><precision><keras><precision-recall>,5,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43076609
43818584,1,43821374,,2017-05-06 08:55:55,,54,64234,"<p>I'm working on a image class-incremental classifier approach using a CNN as a feature extractor and a fully-connected block for classifying.</p>

<p>First, I did a fine-tuning of a VGG per-trained network to do a new task. Once the net is trained for the new task, i store some examples for every class in order to avoid forgetting when new classes are available.</p>

<p>When some classes are available, i have to compute every output of the exemplars included the exemplars for the new classes. Now adding zeros to the outputs for old classes and adding the label corresponding to each new class on the new classes outputs i have my new labels, i.e:
if 3 new classes enter....</p>

<p>Old class type output: <code>[0.1, 0.05, 0.79, ..., 0 0 0]</code></p>

<p>New class type output: <code>[0.1, 0.09, 0.3, 0.4, ..., 1 0 0]</code> **the last outputs correspond to the class.</p>

<p>My question is, how i can change the loss function for a custom one to train for the new classes?
The loss function that i want to implement is defined as:</p>

<p><a href=""https://i.stack.imgur.com/0kImf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/0kImf.png"" alt=""loss function""></a></p>

<p>where distillation loss corresponds to the outputs for old classes to avoid forgetting, and classification loss corresponds to the new classes.</p>

<p>If you can provide me a sample of code to change the loss function in keras would be nice.</p>

<p>Thanks!!!!!</p>
",6729283.0,,10908375.0,,2020-09-16 14:22:59,2021-02-17 13:34:00,Custom loss function in Keras,<python><tensorflow><keras><deep-learning><computer-vision>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43818584
42621864,1,42622446,,2017-03-06 09:26:23,,54,32569,"<p>To save a model in Keras, what are the differences between the output files of:</p>

<ol>
<li><code>model.save()</code> </li>
<li><code>model.save_weights()</code></li>
<li><code>ModelCheckpoint()</code> in the callback</li>
</ol>

<p>The saved file from <code>model.save()</code> is larger than the model from <code>model.save_weights()</code>, but significantly larger than a JSON or Yaml model architecture file.  Why is this?  </p>

<p>Restating this: Why is size(model.save()) + size(something) = size(model.save_weights()) + size(model.to_json()), what is that ""something""?</p>

<p>Would it be more efficient to just <code>model.save_weights()</code> and <code>model.to_json()</code>, and load from these than to just do <code>model.save()</code> and <code>load_model()</code>?  </p>

<p>What are the differences?</p>
",3993741.0,,7117003.0,,2018-04-14 20:12:30,2022-02-25 11:21:25,Difference between Keras model.save() and model.save_weights()?,<machine-learning><tensorflow><neural-network><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42621864
43728235,1,43730861,,2017-05-02 00:12:20,,54,36530,"<p>Both MaxPooling1D and GlobalMaxPooling1D are described as a max pooling operation for temporal data. </p>

<p><code>keras.layers.pooling.MaxPooling1D(pool_size=2, strides=None, padding='valid')</code></p>

<p>I understand that GlobalMaxPooling1D takes no input parameters. 
<code>keras.layers.pooling.GlobalMaxPooling1D()</code></p>

<p>I would just like to visually understand how the two of them differ in the way they work?</p>
",5755192.0,,,,,2022-10-13 21:00:56,What is the difference between Keras' MaxPooling1D and GlobalMaxPooling1D functions?,<keras><max-pooling>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43728235
47555829,1,47556342,,2017-11-29 15:03:38,,54,96554,"<p>I am trying out sample <code>keras</code> code from the below <code>keras</code> documentation page,
<a href=""https://keras.io/applications/"" rel=""noreferrer"">https://keras.io/applications/</a></p>

<p>What <code>preprocess_input(x)</code> function of <code>keras</code> module does in the below code? Why do we have to do <code>expand_dims(x, axis=0)</code> before that is passed to the <code>preprocess_input()</code> method?</p>

<pre><code>from keras.applications.resnet50 import ResNet50
from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input
import numpy as np

model = ResNet50(weights='imagenet')

img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
</code></pre>

<p>Is there any documentation with a good explanation of these functions?</p>

<p>Thanks!</p>
",4724057.0,,10455534.0,,2019-02-02 10:56:13,2021-10-20 07:26:42,preprocess_input() method in keras,<python><keras>,4,5,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47555829
45393429,1,45428197,,2017-07-29 19:48:00,,53,95647,"<p>I have a model that I've trained for 40 epochs. I kept checkpoints for each epochs, and I have also saved the model with <code>model.save()</code>. The code for training is:</p>

<pre><code>n_units = 1000
model = Sequential()
model.add(LSTM(n_units, input_shape=(None, vec_size), return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(n_units, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(n_units))
model.add(Dropout(0.2))
model.add(Dense(vec_size, activation='linear'))
model.compile(loss='mean_squared_error', optimizer='adam')
# define the checkpoint
filepath=""word2vec-{epoch:02d}-{loss:.4f}.hdf5""
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]
# fit the model
model.fit(x, y, epochs=40, batch_size=50, callbacks=callbacks_list)
</code></pre>

<p>However, when I load the model and try training it again, it starts all over as if it hasn't been trained before. The loss doesn't start from the last training.</p>

<p>What confuses me is when I load the model and redefine the model structure and use <code>load_weight</code>, <code>model.predict()</code> works well. Thus, I believe the model weights are loaded:</p>

<pre><code>model = Sequential()
model.add(LSTM(n_units, input_shape=(None, vec_size), return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(n_units, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(n_units))
model.add(Dropout(0.2))
model.add(Dense(vec_size, activation='linear'))
filename = ""word2vec-39-0.0027.hdf5""
model.load_weights(filename)
model.compile(loss='mean_squared_error', optimizer='adam')
</code></pre>

<p>However, When I continue training with this, the loss is as high as the initial stage:</p>

<pre><code>filepath=""word2vec-{epoch:02d}-{loss:.4f}.hdf5""
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]
# fit the model
model.fit(x, y, epochs=40, batch_size=50, callbacks=callbacks_list)
</code></pre>

<p>I searched and found some examples of saving and loading models <a href=""http://machinelearningmastery.com/save-load-keras-deep-learning-models/"" rel=""noreferrer"">here</a> and <a href=""https://github.com/fchollet/keras/issues/1872"" rel=""noreferrer"">here</a>. However, none of them work.</p>

<hr>

<p><strong>Update 1</strong></p>

<p>I looked at <a href=""https://stackoverflow.com/questions/42666046/loading-a-trained-keras-model-and-continue-training"">this question</a>, tried it and it works: </p>

<pre><code>model.save('partly_trained.h5')
del model
load_model('partly_trained.h5')
</code></pre>

<p>But when I close Python and reopen it, then run <code>load_model</code> again, it fails. The loss is as high as the initial state.</p>

<hr>

<p><strong>Update 2</strong></p>

<p>I tried <a href=""https://stackoverflow.com/a/45428197/5305519"">Yu-Yang's example code</a> and it works. However, when I use my code again, it still failed.</p>

<p>This is result form the original training. The second epoch should start with loss = 3.1***:</p>

<pre><code>13700/13846 [============================&gt;.] - ETA: 0s - loss: 3.0519
13750/13846 [============================&gt;.] - ETA: 0s - loss: 3.0511
13800/13846 [============================&gt;.] - ETA: 0s - loss: 3.0512Epoch 00000: loss improved from inf to 3.05101, saving model to LPT-00-3.0510.h5

13846/13846 [==============================] - 81s - loss: 3.0510    
Epoch 2/60

   50/13846 [..............................] - ETA: 80s - loss: 3.1754
  100/13846 [..............................] - ETA: 78s - loss: 3.1174
  150/13846 [..............................] - ETA: 78s - loss: 3.0745
</code></pre>

<p>I closed Python, reopened it, loaded the model with <code>model = load_model(""LPT-00-3.0510.h5"")</code> then train with:</p>

<pre><code>filepath=""LPT-{epoch:02d}-{loss:.4f}.h5""
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]
# fit the model
model.fit(x, y, epochs=60, batch_size=50, callbacks=callbacks_list)
</code></pre>

<p>The loss starts with 4.54:</p>

<pre><code>Epoch 1/60
   50/13846 [..............................] - ETA: 162s - loss: 4.5451
   100/13846 [..............................] - ETA: 113s - loss: 4.3835
</code></pre>
",7367243.0,,5305519.0,,2020-05-11 23:52:58,2022-08-23 09:02:08,Keras: How to save model and continue training?,<python><keras>,8,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45393429
47868265,1,57807971,,2017-12-18 12:12:45,,53,15822,"<p>The docs for an <a href=""https://keras.io/layers/embeddings/"" rel=""noreferrer"">Embedding Layer</a> in Keras say:</p>

<blockquote>
  <p>Turns positive integers (indexes) into dense vectors of fixed size. eg. <code>[[4], [20]]</code> -> <code>[[0.25, 0.1], [0.6, -0.2]]</code></p>
</blockquote>

<p>I believe this could also be achieved by encoding the inputs as one-hot vectors of length <code>vocabulary_size</code>, and feeding them into a <a href=""https://keras.io/layers/core/#dense"" rel=""noreferrer"">Dense Layer</a>.</p>

<p>Is an Embedding Layer merely a convenience for this two-step process, or is something fancier going on under the hood?</p>
",58866.0,,712995.0,,2017-12-18 16:10:39,2022-05-31 01:45:21,What is the difference between an Embedding Layer and a Dense Layer?,<machine-learning><neural-network><deep-learning><keras><keras-layer>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47868265
58678836,1,58799021,,2019-11-03 09:23:52,,53,39448,"<p>I'm trying to save my TensorFlow model using <code>model.save()</code>, however - I am getting this error.</p>

<p>The model summary is provided here:
<a href=""https://i.stack.imgur.com/nkrR1.png"" rel=""noreferrer"">Model Summary</a></p>

<p>The code for the transformer model:</p>

<pre class=""lang-py prettyprint-override""><code>def transformer(vocab_size, num_layers, units, d_model, num_heads, dropout, name=""transformer""):
    inputs = tf.keras.Input(shape=(None,), name=""inputs"")
    dec_inputs = tf.keras.Input(shape=(None,), name=""dec_inputs"")

    enc_padding_mask = tf.keras.layers.Lambda(
        create_padding_mask, output_shape=(1, 1, None),
        name='enc_padding_mask')(inputs)
    # mask the future tokens for decoder inputs at the 1st attention block
    look_ahead_mask = tf.keras.layers.Lambda(
        create_look_ahead_mask,
        output_shape=(1, None, None),
        name='look_ahead_mask')(dec_inputs)
    # mask the encoder outputs for the 2nd attention block
    dec_padding_mask = tf.keras.layers.Lambda(
        create_padding_mask, output_shape=(1, 1, None),
        name='dec_padding_mask')(inputs)

    enc_outputs = encoder(
        vocab_size=vocab_size,
        num_layers=num_layers,
        units=units,
        d_model=d_model,
        num_heads=num_heads,
        dropout=dropout,
    )(inputs=[inputs, enc_padding_mask])

    dec_outputs = decoder(
        vocab_size=vocab_size,
        num_layers=num_layers,
        units=units,
        d_model=d_model,
        num_heads=num_heads,
        dropout=dropout,
    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])

    outputs = tf.keras.layers.Dense(units=vocab_size, name=""outputs"")(dec_outputs)

    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)
</code></pre>

<p>I don't understand why it's giving this error since the model trains perfectly fine. 
Any help would be appreciated.</p>

<p>My saving code for reference:</p>

<pre class=""lang-py prettyprint-override""><code>print(""Saving the model."")
saveloc = ""C:/tmp/solar.h5""
model.save(saveloc)
print(""Model saved to: "" + saveloc + "" succesfully."")
</code></pre>
",12315223.0,,,,,2021-12-16 10:37:41,NotImplementedError: Layers with arguments in `__init__` must override `get_config`,<python><tensorflow><keras>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58678836
34673396,1,37979686,,2016-01-08 09:22:31,,53,30086,"<p>I have just built my first model using Keras and this is the output. It looks like the standard output you get after building any Keras artificial neural network. Even after looking in the documentation, I do not fully understand what the epoch is and what the loss is which is printed in the output.</p>

<p><strong>What is epoch and loss in Keras?</strong> </p>

<p>(I know it's probably an extremely basic question, but I couldn't seem to locate the answer online, and if the answer is really that hard to glean from the documentation I thought others would have the same question and thus decided to post it here.)</p>

<pre><code>Epoch 1/20
1213/1213 [==============================] - 0s - loss: 0.1760     
Epoch 2/20
1213/1213 [==============================] - 0s - loss: 0.1840     
Epoch 3/20
1213/1213 [==============================] - 0s - loss: 0.1816     
Epoch 4/20
1213/1213 [==============================] - 0s - loss: 0.1915     
Epoch 5/20
1213/1213 [==============================] - 0s - loss: 0.1928     
Epoch 6/20
1213/1213 [==============================] - 0s - loss: 0.1964     
Epoch 7/20
1213/1213 [==============================] - 0s - loss: 0.1948     
Epoch 8/20
1213/1213 [==============================] - 0s - loss: 0.1971     
Epoch 9/20
1213/1213 [==============================] - 0s - loss: 0.1899     
Epoch 10/20
1213/1213 [==============================] - 0s - loss: 0.1957     
Epoch 11/20
1213/1213 [==============================] - 0s - loss: 0.1923     
Epoch 12/20
1213/1213 [==============================] - 0s - loss: 0.1910     
Epoch 13/20
1213/1213 [==============================] - 0s - loss: 0.2104     
Epoch 14/20
1213/1213 [==============================] - 0s - loss: 0.1976     
Epoch 15/20
1213/1213 [==============================] - 0s - loss: 0.1979     
Epoch 16/20
1213/1213 [==============================] - 0s - loss: 0.2036     
Epoch 17/20
1213/1213 [==============================] - 0s - loss: 0.2019     
Epoch 18/20
1213/1213 [==============================] - 0s - loss: 0.1978     
Epoch 19/20
1213/1213 [==============================] - 0s - loss: 0.1954     
Epoch 20/20
1213/1213 [==============================] - 0s - loss: 0.1949
</code></pre>
",4984897.0,,,,,2016-06-22 23:10:45,What does the standard Keras model output mean? What is epoch and loss in Keras?,<python><machine-learning><neural-network><keras><data-science>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34673396
48851558,1,48851837,,2018-02-18 12:15:42,,52,162108,"<p>I'm classifying movie reviews as positive or negative using binary crossentropy. So, when I'm trying to wrap my keras model with tensorflow estimator, I get the error:</p>
<pre><code>Tensorflow estimator ValueError: logits and labels must have the same shape ((?, 1) vs (?,))
</code></pre>
<p>I'm using sigmoid activation as my last layer, guess I'm missing something trivial here. Any help?</p>
<pre><code>from tensorflow import keras
import tensorflow as tf
print(&quot;Tensorflow {} loaded&quot;.format(tf.__version__))
import numpy as np

keras.__version__
from keras.datasets import imdb

(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)
def vectorize_sequences(sequences, dimension=10000):
    # Create an all-zero matrix of shape (len(sequences), dimension)
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.  # set specific indices of results[i] to 1s
    return results.astype('float32')

# Our vectorized training data
x_train = vectorize_sequences(train_data)

# Our vectorized test data
x_test = vectorize_sequences(test_data)

# Our vectorized labels
y_train = np.asarray(train_labels).astype('float32')
y_test = np.asarray(test_labels).astype('float32')

x_val = x_train[:10000]
partial_x_train = x_train[10000:]
y_val = y_train[:10000]
partial_y_train = y_train[10000:]

model = keras.models.Sequential()
model.add(keras.layers.Dense(16, activation='relu', input_shape=(10000,), name='reviews'))
model.add(keras.layers.Dense(16, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
estimator_model = keras.estimator.model_to_estimator(keras_model=model)

def input_function(features,labels=None,shuffle=False,epochs=None,batch_size=None):
    input_fn = tf.estimator.inputs.numpy_input_fn(
        x={&quot;reviews_input&quot;: features},
        y=labels,
        shuffle=shuffle,
        num_epochs=epochs,
        batch_size=batch_size
    )
    return input_fn

estimator_model.train(input_fn=input_function(partial_x_train, partial_y_train, True,20,512))
score = estimator_model.evaluate(input_function(x_val, labels=y_val))
print(score)
</code></pre>
",8010010.0,,4685471.0,,2022-03-30 09:29:14,2023-05-14 15:37:53,"Tensorflow estimator ValueError: logits and labels must have the same shape ((?, 1) vs (?,))",<python><tensorflow><keras>,6,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48851558
39263002,1,39271995,,2016-09-01 05:02:37,,52,34465,"<p>I've working on a CNN over several hundred GBs of images. I've created a training function that bites off 4Gb chunks of these images and calls <code>fit</code> over each of these pieces. I'm worried that I'm only training on the last piece on not the entire dataset.</p>

<p>Effectively, my pseudo-code looks like this:</p>

<pre><code>DS = lazy_load_400GB_Dataset()
for section in DS:
    X_train = section.images
    Y_train = section.classes

    model.fit(X_train, Y_train, batch_size=16, nb_epoch=30)
</code></pre>

<p>I know that the API and the Keras forums say that this will train over the entire dataset, but I can't intuitively understand why the network wouldn't relearn over just the last training chunk.</p>

<p>Some help understanding this would be much appreciated.</p>

<p>Best,
Joe</p>
",4652819.0,,,,,2018-04-23 03:33:49,"Calling ""fit"" multiple times in Keras",<machine-learning><neural-network><theano><conv-neural-network><keras>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39263002
43469281,1,43470074,,2017-04-18 10:09:20,,52,138691,"<p>I trained a model to classify images from 2 classes and saved it using <code>model.save()</code>. Here is the code I used:</p>
<pre><code>from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K


# dimensions of our images.
img_width, img_height = 320, 240

train_data_dir = 'data/train'
validation_data_dir = 'data/validation'
nb_train_samples = 200  #total
nb_validation_samples = 10  # total
epochs = 6
batch_size = 10

if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=input_shape))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# this is the augmentation configuration we will use for testing:
# only rescaling
test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=5)

model.save('model.h5')
</code></pre>
<p>It successfully trained with 0.98 accuracy which is pretty good. To load and test this model on new images, I used the below code:</p>
<pre><code>from keras.models import load_model
import cv2
import numpy as np

model = load_model('model.h5')

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

img = cv2.imread('test.jpg')
img = cv2.resize(img,(320,240))
img = np.reshape(img,[1,320,240,3])

classes = model.predict_classes(img)

print classes
</code></pre>
<p>It outputs:</p>
<blockquote>
<p>[[0]]</p>
</blockquote>
<p>Why wouldn't it give out the actual name of the class and why <code>[[0]]</code>?</p>
",6554943.0,,11107541.0,,2022-12-22 05:00:21,2022-12-22 05:00:21,How to predict input image using trained model in Keras?,<python><machine-learning><keras><computer-vision>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43469281
42943291,1,42964543,,2017-03-22 05:17:02,,50,52421,"<p>The Keras documentation could be improved here. After reading through this, I still do not understand what this does exactly: <a href=""https://keras.io/preprocessing/sequence/"" rel=""noreferrer"">Keras.io.preprocessing.sequence.pad_sequences</a></p>

<p>Could someone illuminate what this function does, and ideally provide an example?</p>
",914689.0,,914689.0,,2019-10-07 20:07:28,2021-04-21 10:35:09,What does Keras.io.preprocessing.sequence.pad_sequences do?,<python><deep-learning><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42943291
54527439,1,54532702,,2019-02-05 03:42:55,,50,36232,"<p>Are these libraries fairly interchangeable?</p>

<p>Looking here, <a href=""https://stackshare.io/stackups/keras-vs-pytorch-vs-scikit-learn"" rel=""noreferrer"">https://stackshare.io/stackups/keras-vs-pytorch-vs-scikit-learn</a>, it seems the major difference is the underlying framework (at least for PyTorch).</p>
",9286096.0,,9286096.0,,2019-11-14 14:01:48,2019-11-14 14:01:48,"Differences in SciKit Learn, Keras, or Pytorch",<python><machine-learning><keras><scikit-learn><pytorch>,1,3,0.0,2019-02-06 15:17:28,,CC BY-SA 4.0,https://stackoverflow.com/q/54527439
44151760,1,44152923,,2017-05-24 07:29:30,,50,74376,"<p>I am working on a simple cnn classifier using keras with tensorflow background.</p>

<pre><code>def cnnKeras(training_data, training_labels, test_data, test_labels, n_dim):
  print(""Initiating CNN"")
  seed = 8
  numpy.random.seed(seed)
  model = Sequential()
  model.add(Convolution2D(64, 1, 1, init='glorot_uniform', 
   border_mode='valid',input_shape=(16, 1, 1), activation='relu'))
  model.add(MaxPooling2D(pool_size=(1, 1)))
  model.add(Convolution2D(32, 1, 1, init='glorot_uniform', 
   activation='relu'))
  model.add(MaxPooling2D(pool_size=(1, 1)))
  model.add(Dropout(0.25))
  model.add(Flatten())
  model.add(Dense(128, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(1, activation='softmax'))
  # Compile model
  model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam', metrics=['accuracy'])
  model.fit(training_data, training_labels, validation_data=(
    test_data, test_labels), nb_epoch=30, batch_size=8, verbose=2)

  scores = model.evaluate(test_data, test_labels, verbose=1)
  print(""Baseline Error: %.2f%%"" % (100 - scores[1] * 100))
  # model.save('trained_CNN.h5')
  return None
</code></pre>

<p>It is a binary classification problem, but I keep getting the message <code>Received a label value of 1 which is outside the valid range of [0, 1)</code> which does not make any sense to me. Any suggesstions?</p>
",7432133.0,,7432133.0,,2019-12-03 00:12:19,2021-08-25 05:05:34,"Received a label value of 1 which is outside the valid range of [0, 1) - Python, Keras",<python><machine-learning><keras>,8,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44151760
49492255,1,54517478,,2018-03-26 13:07:35,,49,26953,"<p>I have a trained Keras model and I would like:</p>

<p>1) to replace Con2D layer with the same but without bias.</p>

<p>2) to add BatchNormalization layer before first Activation</p>

<p>How can I do this?</p>

<pre class=""lang-python prettyprint-override""><code>def keras_simple_model():
    from keras.models import Model
    from keras.layers import Input, Dense,  GlobalAveragePooling2D
    from keras.layers import Conv2D, MaxPooling2D, Activation

    inputs1 = Input((28, 28, 1))
    x = Conv2D(4, (3, 3), activation=None, padding='same', name='conv1')(inputs1)
    x = Activation('relu')(x)
    x = Conv2D(4, (3, 3), activation=None, padding='same', name='conv2')(x)
    x = Activation('relu')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)

    x = Conv2D(8, (3, 3), activation=None, padding='same', name='conv3')(x)
    x = Activation('relu')(x)
    x = Conv2D(8, (3, 3), activation=None, padding='same', name='conv4')(x)
    x = Activation('relu')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)

    x = GlobalAveragePooling2D()(x)
    x = Dense(10, activation=None)(x)
    x = Activation('softmax')(x)

    model = Model(inputs=inputs1, outputs=x)
    return model


if __name__ == '__main__':
    model = keras_simple_model()
    print(model.summary())
</code></pre>
",2115332.0,,9215780.0,,2023-02-16 09:27:04,2023-02-20 22:45:29,How to replace (or insert) intermediate layer in Keras model?,<tensorflow><keras>,4,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49492255
49100556,1,49100617,,2018-03-04 21:13:27,,49,58964,"<p>How <code>train_on_batch()</code> is different from <code>fit()</code>? What are the cases when we should use <code>train_on_batch()</code>?</p>
",6633920.0,,3924118.0,,2019-10-08 22:32:22,2022-12-31 22:13:02,What is the use of train_on_batch() in keras?,<machine-learning><deep-learning><keras>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/49100556
51299836,1,51303340,,2018-07-12 07:36:01,,49,85434,"<p>I've got multiple outputs from my model from multiple Dense layers. My model has <code>'accuracy'</code> as the only metric in compilation. I'd like to know the loss and accuracy for each output. This is some part of my code.</p>

<pre><code>scores = model.evaluate(X_test, [y_test_one, y_test_two], verbose=1)
</code></pre>

<p>When I printed out the scores, this is the result.</p>

<pre><code>[0.7185557290413819, 0.3189622712272771, 0.39959345855771927, 0.8470299135229717, 0.8016634374641469]
</code></pre>

<p>What are these numbers represent?</p>

<p>I'm new to Keras and this might be a trivial question. However, I have read the docs from Keras but I'm still not sure.</p>
",8822850.0,,2099607.0,,2018-07-12 11:02:27,2021-11-25 14:53:19,What values are returned from model.evaluate() in Keras?,<python><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51299836
50063613,1,52683522,,2018-04-27 13:35:43,,49,35561,"<p>Currently I stumbled across variational autoencoders and tried to make them work on MNIST using keras. I found a tutorial on <a href=""https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py"" rel=""noreferrer"">github</a>.</p>

<p>My question concerns the following lines of code:</p>



<pre class=""lang-python prettyprint-override""><code># Build model
vae = Model(x, x_decoded_mean)

# Calculate custom loss
xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)
kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
vae_loss = K.mean(xent_loss + kl_loss)

# Compile
vae.add_loss(vae_loss)
vae.compile(optimizer='rmsprop')
</code></pre>

<p>Why is add_loss used instead of specifying it as compile option? Something like  <code>vae.compile(optimizer='rmsprop', loss=vae_loss)</code> does not seem to work and throws the following error:</p>

<pre class=""lang-python prettyprint-override""><code>ValueError: The model cannot be compiled because it has no loss to optimize.
</code></pre>

<p>What is the difference between this function and a custom loss function, that I can add as an argument for Model.fit()?</p>

<p>Thanks in advance! </p>

<p>P.S.: I know there are several issues concerning this on github, but most of them were open and uncommented. If this has been resolved already, please share the link!</p>

<hr>

<h3>Edit 1</h3>

<p>I removed the line which adds the loss to the model and used the loss argument of the compile function. It looks like this now:</p>



<pre class=""lang-python prettyprint-override""><code># Build model
vae = Model(x, x_decoded_mean)

# Calculate custom loss
xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)
kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
vae_loss = K.mean(xent_loss + kl_loss)

# Compile
vae.compile(optimizer='rmsprop', loss=vae_loss)
</code></pre>

<p>This throws an TypeError:</p>

<pre class=""lang-python prettyprint-override""><code>TypeError: Using a 'tf.Tensor' as a Python 'bool' is not allowed. Use 'if t is not None:' instead of 'if t:' to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
</code></pre>

<hr>

<h3>Edit 2</h3>

<p>Thanks to @MarioZ's efforts, I was able to figure out a workaround for this. </p>



<pre class=""lang-python prettyprint-override""><code># Build model
vae = Model(x, x_decoded_mean)

# Calculate custom loss in separate function
def vae_loss(x, x_decoded_mean):
    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
    vae_loss = K.mean(xent_loss + kl_loss)
    return vae_loss

# Compile
vae.compile(optimizer='rmsprop', loss=vae_loss)

...

vae.fit(x_train, 
    x_train,        # &lt;-- did not need this previously
    shuffle=True,
    epochs=epochs,
    batch_size=batch_size,
    validation_data=(x_test, x_test))     # &lt;-- worked with (x_test, None) before
</code></pre>

<p>For some strange reason, I had to explicitly specify y and y_test while fitting the model. Originally, I didn't need to do this. The produced samples seem reasonable to me. </p>

<p>Although I could resolve this, I still don't know what the differences and disadvantages of these two methods are (other than needing a different syntax). Can someone give me more insight?</p>
",8334261.0,,3924118.0,,2019-10-23 16:33:22,2021-03-05 04:00:23,What is the purpose of the add_loss function in Keras?,<neural-network><keras><autoencoder>,5,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50063613
47240348,1,47241264,,2017-11-11 16:46:47,,48,27046,"<p><a href=""https://i.stack.imgur.com/be1s4.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/be1s4.png"" alt=""enter image description here""></a></p>

<p>What is the meaning of the (None, 100) in Output Shape?
Is this(""None"") the Sample number or the hidden dimension?</p>
",6890808.0,,5884955.0,,2019-04-24 21:42:08,2019-05-09 21:11:55,"What is the meaning of the ""None"" in model.summary of KERAS?",<tensorflow><machine-learning><keras>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47240348
44036971,1,44037698,,2017-05-18 00:58:45,,48,62527,"<p>I have a problem which deals with predicting two outputs when given a vector of predictors.
Assume that a predictor vector looks like <code>x1, y1, att1, att2, ..., attn</code>, which says <code>x1, y1</code> are coordinates and <code>att's </code> are the other attributes attached to the occurrence of <code>x1, y1</code> coordinates. Based on this predictor set I want to predict <code>x2, y2</code>. This is a time series problem, which I am trying to solve using multiple regresssion.
My question is how do I setup keras, which can give me 2 outputs in the final layer.</p>
",4269003.0,,10908375.0,,2020-08-17 19:54:48,2021-08-10 14:35:10,Multiple outputs in Keras,<python><tensorflow><keras><deep-learning><neural-network>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44036971
48428415,1,48429585,,2018-01-24 17:30:16,,48,75965,"<p>currently I have cuda 8.0 and cuda 9.0 installed in Gpu support system. I ran into this error while importing from keras module. It says like failed to load native tensorflow runtime. The error log which i received was:</p>
<pre><code>Traceback (most recent call last):
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py&quot;, line 58, in &lt;module&gt;
from tensorflow.python.pywrap_tensorflow_internal import *
File &quot;/usr/local/lib/python3.5/dist-
packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 28, in &lt;module&gt;
_pywrap_tensorflow_internal = swig_import_helper()
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
File &quot;/usr/lib/python3.5/imp.py&quot;, line 242, in load_module
return load_dynamic(name, filename, file)
File &quot;/usr/lib/python3.5/imp.py&quot;, line 342, in load_dynamic
return _load(spec)

ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File &quot;Try1.py&quot;, line 11, in &lt;module&gt;
from keras.models import Sequential
File &quot;/usr/local/lib/python3.5/dist-packages/Keras-2.0.9-py3.5.egg/keras/__init__.py&quot;, line 3, in &lt;module&gt;
File &quot;/usr/local/lib/python3.5/dist-packages/Keras-2.0.9-py3.5.egg/keras/utils/__init__.py&quot;, line 6, in &lt;module&gt;
File &quot;/usr/local/lib/python3.5/dist-packages/Keras-2.0.9-py3.5.egg/keras/utils/conv_utils.py&quot;, line 3, in &lt;module&gt;
File &quot;/usr/local/lib/python3.5/dist-packages/Keras-2.0.9-py3.5.egg/keras/backend/__init__.py&quot;, line 83, in &lt;module&gt;
File &quot;/usr/local/lib/python3.5/dist-packages/Keras-2.0.9-py3.5.egg/keras/backend/tensorflow_backend.py&quot;, line 1, in &lt;module&gt;
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py&quot;, line 24, in &lt;module&gt;
from tensorflow.python import *
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py&quot;, line 49, in &lt;module&gt;
from tensorflow.python import pywrap_tensorflow
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py&quot;, line 73, in &lt;module&gt;
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py&quot;, line 58, in &lt;module&gt;
from tensorflow.python.pywrap_tensorflow_internal import *
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 28, in &lt;module&gt;
_pywrap_tensorflow_internal = swig_import_helper()
File &quot;/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py&quot;, line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
File &quot;/usr/lib/python3.5/imp.py&quot;, line 242, in load_module
return load_dynamic(name, filename, file)
File &quot;/usr/lib/python3.5/imp.py&quot;, line 342, in load_dynamic
return _load(spec)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.
</code></pre>
<p>When I run nvcc --version, the cuda version returned is,</p>
<pre><code>Cuda compilation tools, release 8.0, V8.0.61
</code></pre>
<p>I read about some similar post but couldn't solve my issue. Mostly I think this is a clash between two cuda versions. Can anyone tell me how to solve this?</p>
",3316224.0,,11107541.0,,2022-12-29 02:43:32,2022-12-29 02:43:32,ImportError: libcublas.so.9.0: cannot open shared object file,<python-3.x><tensorflow><cuda><keras>,12,5,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48428415
39681046,1,43090574,,2016-09-24 21:16:44,,48,16345,"<p>I'm having a hard time conceptualizing the difference between stateful and stateless LSTMs in Keras. My understanding is that at the end of each batch, the ""state of the network is reset"" in the stateless case, whereas for the stateful case, the state of the network is preserved for each batch, and must then be manually reset at the end of each epoch.</p>

<p>My questions are as follows:
1. In the stateless case, how is the network learning if the state isn't preserved in-between batches?
2. When would one use the stateless vs stateful modes of an LSTM?</p>
",190894.0,,,,,2022-06-12 04:56:31,Keras - stateful vs stateless LSTMs,<tensorflow><deep-learning><keras><lstm>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39681046
43715047,1,43856966,,2017-05-01 06:10:44,,48,109877,"<p>I am using Windows 10, Python 3.5, and tensorflow 1.1.0. I have the following script:</p>

<pre><code>import tensorflow as tf
import tensorflow.contrib.keras.api.keras.backend as K
from tensorflow.contrib.keras.api.keras.layers import Dense

tf.reset_default_graph()
init = tf.global_variables_initializer()
sess =  tf.Session()
K.set_session(sess) # Keras will use this sesssion to initialize all variables

input_x = tf.placeholder(tf.float32, [None, 10], name='input_x')    
dense1 = Dense(10, activation='relu')(input_x)

sess.run(init)

dense1.get_weights()
</code></pre>

<p>I get the error: <code>AttributeError: 'Tensor' object has no attribute 'weights'</code></p>

<p>What am I doing wrong, and how do I get the weights of <code>dense1</code>? I have look at <a href=""https://stackoverflow.com/questions/42053170/keras-how-can-i-get-biasess-weights"">this</a> and <a href=""https://stackoverflow.com/questions/42411891/how-to-extract-bias-weights-in-keras-sequential-model"">this</a> SO post, but I still can't make it work.</p>
",3747801.0,,3924118.0,,2019-12-07 16:01:57,2021-01-06 10:23:35,How do I get the weights of a layer in Keras?,<python><tensorflow><deep-learning><keras><keras-layer>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43715047
44829085,1,44829372,,2017-06-29 15:17:16,,47,82342,"<p><strong><em>I have aldready spent a considerable of time digging around on stack overflow and else looking for the answer, but couldn't find anything</em></strong></p>

<p>Hi all,</p>

<p>I am running Tensorflow with Keras on top.
I am 90% sure I installed Tensorflow GPU, is there any way to check which install I did?</p>

<p>I was trying to do run some CNN models from Jupyter notebook and I noticed that Keras was running the model on the CPU (checked task manager, CPU was at 100%).</p>

<p>I tried running this code from the tensorflow website:</p>

<pre><code># Creates a graph.
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print(sess.run(c))
</code></pre>

<p>And this is what I got:</p>

<pre><code>MatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0
2017-06-29 17:09:38.783183: I c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\common_runtime\simple_placer.cc:847] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0
b: (Const): /job:localhost/replica:0/task:0/cpu:0
2017-06-29 17:09:38.784779: I c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\common_runtime\simple_placer.cc:847] b: (Const)/job:localhost/replica:0/task:0/cpu:0
a: (Const): /job:localhost/replica:0/task:0/cpu:0
2017-06-29 17:09:38.786128: I c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\common_runtime\simple_placer.cc:847] a: (Const)/job:localhost/replica:0/task:0/cpu:0
[[ 22.  28.]
 [ 49.  64.]]
</code></pre>

<p>Which to me shows I am running on my CPU, for some reason.</p>

<p>I have a GTX1050 (driver version 382.53), I installed CUDA, and Cudnn, and tensorflow installed without any problems. I installed Visual Studio 2015 as well since it was listed as a compatible version.</p>

<p>I remember CUDA mentioning something about an incompatible driver being installed, but if I recall correctly CUDA should have installed its own driver.</p>

<p><strong>Edit:</strong>
I ran theses commands to list the available devices</p>

<pre><code>from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
</code></pre>

<p>and this is what I get</p>

<pre><code>[name: ""/cpu:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 14922788031522107450
]
</code></pre>

<p>and a whole lot of warnings like this</p>

<pre><code>2017-06-29 17:32:45.401429: W c:\tf_jenkins\home\workspace\release-win\m\windows\py\35\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
</code></pre>

<p><strong>Edit 2</strong></p>

<p>Tried running</p>

<pre><code>pip3 install --upgrade tensorflow-gpu
</code></pre>

<p>and I get</p>

<pre><code>Requirement already up-to-date: tensorflow-gpu in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages
Requirement already up-to-date: markdown==2.2.0 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: html5lib==0.9999999 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: werkzeug&gt;=0.11.10 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: wheel&gt;=0.26 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: bleach==1.5.0 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: six&gt;=1.10.0 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: protobuf&gt;=3.2.0 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: backports.weakref==1.0rc1 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: numpy&gt;=1.11.0 in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: setuptools in c:\users\xxx\appdata\local\programs\python\python35\lib\site-packages (from protobuf&gt;=3.2.0-&gt;tensorflow-gpu)
</code></pre>

<p><strong>Solved:</strong>
Check comments for solution.
Thanks to all who helped!</p>

<p>I am new to this, so any help is greatly appreciated!
Thank you.</p>
",5127598.0,,5127598.0,,2020-04-13 20:23:28,2023-06-03 11:50:50,Tensorflow not running on GPU,<tensorflow><keras><nvidia><cudnn>,8,18,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44829085
39561560,1,41398799,,2016-09-18 19:07:23,,47,42631,"<p>I am interested in building reinforcement learning models with the simplicity of the Keras API. Unfortunately, I am unable to extract the gradient of the output (not error) with respect to the weights. I found the following code that performs a similar function (<a href=""https://stackoverflow.com/questions/36968128/saliency-maps-of-neural-networks-using-keras"">Saliency maps of neural networks (using Keras)</a>)</p>

<pre><code>get_output = theano.function([model.layers[0].input],model.layers[-1].output,allow_input_downcast=True)
fx = theano.function([model.layers[0].input] ,T.jacobian(model.layers[-1].output.flatten(),model.layers[0].input), allow_input_downcast=True)
grad = fx([trainingData])
</code></pre>

<p>Any ideas on how to calculate the gradient of the model output with respect to the weights for each layer would be appreciated.</p>
",5000294.0,,5000294.0,,2019-01-05 20:45:14,2020-07-11 21:00:42,Getting gradient of model output w.r.t weights using Keras,<python><theano><keras>,2,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/39561560
45961428,1,73376415,,2017-08-30 13:11:56,,47,73374,"<p>Hi I have been trying to make a custom loss function in keras for dice_error_coefficient. It has its implementations in <strong>tensorboard</strong> and I tried using the same function in keras with tensorflow but it keeps returning a <strong>NoneType</strong> when I used <strong>model.train_on_batch</strong> or <strong>model.fit</strong> where as it gives proper values when used in metrics in the model. Can please someone help me out with what should i do? I have tried following libraries like Keras-FCN by ahundt where he has used custom loss functions but none of it seems to work. The target and output in the code are y_true and y_pred respectively as used in the losses.py file in keras.</p>

<pre><code>def dice_hard_coe(target, output, threshold=0.5, axis=[1,2], smooth=1e-5):
    """"""References
    -----------
    - `Wiki-Dice &lt;https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient&gt;`_
    """"""

    output = tf.cast(output &gt; threshold, dtype=tf.float32)
    target = tf.cast(target &gt; threshold, dtype=tf.float32)
    inse = tf.reduce_sum(tf.multiply(output, target), axis=axis)
    l = tf.reduce_sum(output, axis=axis)
    r = tf.reduce_sum(target, axis=axis)
    hard_dice = (2. * inse + smooth) / (l + r + smooth)
    hard_dice = tf.reduce_mean(hard_dice)
    return hard_dice
</code></pre>
",8538125.0,,2523237.0,,2017-08-30 14:04:18,2022-08-16 15:20:55,Make a custom loss function in keras,<python><machine-learning><tensorflow><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45961428
59737875,1,62113860,,2020-01-14 16:22:25,,46,92568,"<p>I'm trying to <strong>change</strong> the learning rate of my model after it has been trained with a different learning rate.</p>

<p>I read <a href=""https://github.com/keras-team/keras/issues/888"" rel=""noreferrer"">here</a>, <a href=""https://github.com/keras-team/keras/issues/898"" rel=""noreferrer"">here</a>, <a href=""https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2"">here</a> and some other places i can't even find anymore.</p>

<p>I tried:</p>

<pre><code>model.optimizer.learning_rate.set_value(0.1)
model.optimizer.lr = 0.1
model.optimizer.learning_rate = 0.1
K.set_value(model.optimizer.learning_rate, 0.1)
K.set_value(model.optimizer.lr, 0.1)
model.optimizer.lr.assign(0.1)
</code></pre>

<p>... but none of them worked!
I don't understand how there could be such confusion around such a simple thing. Am I missing something?</p>

<p><strong>EDIT: Working example</strong></p>

<p>Here is a working example of what I'd like to do:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense
import keras
import numpy as np

model = Sequential()

model.add(Dense(1, input_shape=(10,)))

optimizer = keras.optimizers.Adam(lr=0.01)
model.compile(loss='mse',
              optimizer=optimizer)

model.fit(np.random.randn(50,10), np.random.randn(50), epochs=50)

# Change learning rate to 0.001 and train for 50 more epochs

model.fit(np.random.randn(50,10), np.random.randn(50), initial_epoch=50, epochs=50)
</code></pre>
",4690023.0,,4690023.0,,2020-01-14 16:36:58,2021-08-17 23:24:07,Keras: change learning rate,<python><tensorflow><keras>,6,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59737875
51806852,1,55386355,,2018-08-12 07:53:41,,45,40288,"<p>Inspired by <a href=""https://www.tensorflow.org/guide/keras#model_subclassing"" rel=""noreferrer"">tf.keras.Model subclassing</a> I created custom model.<br>
I can train it and get successfull results, but <strong>I can't save it</strong>.<br>
I use python3.6 with tensorflow v1.10 (or v1.9)  </p>

<p>Minimal complete code example here:</p>

<pre><code>import tensorflow as tf
from tensorflow.keras.datasets import mnist


class Classifier(tf.keras.Model):
    def __init__(self):
        super().__init__(name=""custom_model"")

        self.batch_norm1 = tf.layers.BatchNormalization()
        self.conv1 = tf.layers.Conv2D(32, (7, 7))
        self.pool1 = tf.layers.MaxPooling2D((2, 2), (2, 2))

        self.batch_norm2 = tf.layers.BatchNormalization()
        self.conv2 = tf.layers.Conv2D(64, (5, 5))
        self.pool2 = tf.layers.MaxPooling2D((2, 2), (2, 2))

    def call(self, inputs, training=None, mask=None):
        x = self.batch_norm1(inputs)
        x = self.conv1(x)
        x = tf.nn.relu(x)
        x = self.pool1(x)

        x = self.batch_norm2(x)
        x = self.conv2(x)
        x = tf.nn.relu(x)
        x = self.pool2(x)

        return x


if __name__ == '__main__':
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    x_train = x_train.reshape(*x_train.shape, 1)[:1000]
    y_train = y_train.reshape(*y_train.shape, 1)[:1000]

    x_test = x_test.reshape(*x_test.shape, 1)
    y_test = y_test.reshape(*y_test.shape, 1)

    y_train = tf.keras.utils.to_categorical(y_train)
    y_test = tf.keras.utils.to_categorical(y_test)

    model = Classifier()

    inputs = tf.keras.Input((28, 28, 1))

    x = model(inputs)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(10, activation=""sigmoid"")(x)

    model = tf.keras.Model(inputs=inputs, outputs=x)
    model.compile(optimizer=""adam"", loss=""binary_crossentropy"", metrics=[""accuracy""])
    model.fit(x_train, y_train, epochs=1, shuffle=True)

    model.save(""./my_model"")
</code></pre>

<p>Error message:  </p>

<pre><code>1000/1000 [==============================] - 1s 1ms/step - loss: 4.6037 - acc: 0.7025
Traceback (most recent call last):
  File ""/home/user/Data/test/python/mnist/mnist_run.py"", line 62, in &lt;module&gt;
    model.save(""./my_model"")
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1278, in save
    save_model(self, filepath, overwrite, include_optimizer)
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py"", line 101, in save_model
    'config': model.get_config()
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1049, in get_config
    layer_config = layer.get_config()
  File ""/home/user/miniconda3/envs/ml3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1028, in get_config
    raise NotImplementedError
NotImplementedError

Process finished with exit code 1
</code></pre>

<p>I looked into the error line and found out that <strong>get_config</strong> method checks <strong>self._is_graph_network</strong></p>

<p>Do anybody deal with this problem?</p>

<p>Thanks!</p>

<p><strong>Update 1:</strong><br>
On the keras 2.2.2 (not tf.keras)<br>
Found comment (for model saving)<br>
file: keras/engine/network.py<br>
Function: get_config  </p>

<blockquote>
  <p># Subclassed networks are not serializable<br>
  # (unless serialization is implemented by<br>
  # the author of the subclassed network).  </p>
</blockquote>

<p>So, obviously it won't work...<br>
I wonder, why don't they point it out in the <a href=""https://www.tensorflow.org/guide/keras"" rel=""noreferrer"">documentation</a> (Like: ""Use subclassing without ability to save!"")</p>

<p><strong>Update 2:</strong><br>
Found in <a href=""https://keras.io/models/about-keras-models/"" rel=""noreferrer"">keras documentation</a>:  </p>

<blockquote>
  <p>In subclassed models, the model's topology is defined as Python code<br>
  (rather than as a static graph of layers). That means the model's<br>
  topology cannot be inspected or serialized. As a result, the following<br>
  methods and attributes are not available for subclassed models:  </p>
  
  <p>model.inputs        and model.outputs.<br>
  model.to_yaml()     and model.to_json()<br>
  model.get_config()  and model.save().  </p>
</blockquote>

<p><strong>So, there is no way to save model by using subclassing.</strong><br>
It's possible to only use <code>Model.save_weights()</code></p>
",3049753.0,,3049753.0,,2018-08-13 11:04:12,2021-07-28 14:37:25,Can't save custom subclassed model,<python-3.x><tensorflow><keras>,7,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51806852
50393666,1,50396580,,2018-05-17 14:11:37,,45,21711,"<p>Occasionally I see some models are using <code>SpatialDropout1D</code> instead of <code>Dropout</code>. For example, in the Part of speech tagging neural network, they use:</p>



<pre class=""lang-python prettyprint-override""><code>model = Sequential()
model.add(Embedding(s_vocabsize, EMBED_SIZE,
                    input_length=MAX_SEQLEN))
model.add(SpatialDropout1D(0.2)) ##This
model.add(GRU(HIDDEN_SIZE, dropout=0.2, recurrent_dropout=0.2))
model.add(RepeatVector(MAX_SEQLEN))
model.add(GRU(HIDDEN_SIZE, return_sequences=True))
model.add(TimeDistributed(Dense(t_vocabsize)))
model.add(Activation(""softmax""))
</code></pre>

<p>According to Keras' documentation, it says:</p>

<blockquote>
  <p>This version performs the same function as Dropout, however it drops
  entire 1D feature maps instead of individual elements.</p>
</blockquote>

<p>However, I am unable to understand the meaning of <strong>entrie 1D feature</strong>. More specifically, I am unable to visualize <code>SpatialDropout1D</code> in the same model explained in <a href=""https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network"" rel=""noreferrer"">quora</a>.
Can someone explain this concept by using the same model as in quora?</p>

<p>Also, under what situation we will use <code>SpatialDropout1D</code> instead of <code>Dropout</code>?</p>
",9793316.0,,712995.0,,2018-05-17 20:31:34,2021-05-28 12:10:59,How to understand SpatialDropout1D and when to use it?,<machine-learning><keras><deep-learning><conv-neural-network><dropout>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50393666
43547402,1,45305384,,2017-04-21 16:11:03,,45,64404,"<p>I've tried to use the code given from Keras before they're removed. Here's the code:</p>
<pre><code>def precision(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def recall(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def fbeta_score(y_true, y_pred, beta=1):
    if beta &lt; 0:
        raise ValueError('The lowest choosable beta is zero (only precision).')

    # If there are no true positives, fix the F score at 0 like sklearn.
    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:
        return 0

    p = precision(y_true, y_pred)
    r = recall(y_true, y_pred)
    bb = beta ** 2
    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())
    return fbeta_score

def fmeasure(y_true, y_pred):
    return fbeta_score(y_true, y_pred, beta=1)
</code></pre>
<p>From what I saw, it seems like they use the correct formula. But, when I tried to use it as a metric in the training process, I got exactly equal output for val_accuracy, val_precision, val_recall, and val_fmeasure. I do believe that it might happen even if the formula correct, but I believe it is unlikely. Any explanation for this issue?</p>
",7676016.0,,11107541.0,,2022-12-27 22:43:01,2022-12-27 22:43:01,How to calculate F1 Macro in Keras?,<keras>,6,7,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43547402
48828478,1,48828561,,2018-02-16 14:02:47,,45,77521,"<p>I am trying to produce a CNN using Keras, and wrote the following code:</p>

<pre><code>batch_size = 64
epochs = 20
num_classes = 5

cnn_model = Sequential()
cnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear',
                     input_shape=(380, 380, 1), padding='same'))
cnn_model.add(Activation('relu'))
cnn_model.add(MaxPooling2D((2, 2), padding='same'))
cnn_model.add(Conv2D(64, (3, 3), activation='linear', padding='same'))
cnn_model.add(Activation('relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
cnn_model.add(Conv2D(128, (3, 3), activation='linear', padding='same'))
cnn_model.add(Activation('relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
cnn_model.add(Flatten())
cnn_model.add(Dense(128, activation='linear'))
cnn_model.add(Activation('relu'))
cnn_model.add(Dense(num_classes, activation='softmax'))

cnn_model.compile(loss=keras.losses.categorical_crossentropy,
                  optimizer=keras.optimizers.Adam(), metrics=['accuracy'])
</code></pre>

<p>I want to use Keras's <strong>LeakyReLU</strong> activation layer instead of using <code>Activation('relu')</code>. However, I tried using <code>LeakyReLU(alpha=0.1)</code> in place, but this is an activation layer in Keras, and I get an error about using an activation layer and not an activation function.</p>

<p>How can I use <strong>LeakyReLU</strong> in this example?</p>
",9340209.0,,4685471.0,,2021-02-26 19:54:53,2022-07-07 13:11:35,How do you use Keras LeakyReLU in Python?,<python><machine-learning><keras><neural-network>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48828478
44907377,1,44907684,,2017-07-04 13:30:34,,44,41576,"<p>What is ""epoch"" in <code>keras.models.Model.fit</code>? Is it one gradient update? If it is more than one gradient update, then what is defining an epoch?</p>

<p>Suppose I am feeding my own batches to <code>fit</code>. I would regard ""epoch"" as finishing to process entire training set (is this correct)? Then how to control keras for this way? Can I set <code>batch_size</code> equal to <code>x</code> and <code>y</code> size and <code>epochs</code> to 1?</p>
",258483.0,,,,,2017-07-04 13:45:24,"What is ""epoch"" in keras.models.Model.fit?",<machine-learning><keras><batch-processing>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44907377
34702041,1,34705152,,2016-01-10 04:23:16,,44,23133,"<p>I don't understand which accuracy in the output to use to compare my 2 Keras models to see which one is better. </p>

<p>Do I use the ""acc"" (from the training data?) one or the ""val acc"" (from the validation data?) one?</p>

<p>There are different accs and val accs for each epoch. How do I know the acc or val acc for my model as a whole? Do I average all of the epochs accs or val accs to find the acc or val acc of the model as a whole?</p>

<p><strong>Model 1 Output</strong></p>

<pre><code>Train on 970 samples, validate on 243 samples
Epoch 1/20
0s - loss: 0.1708 - acc: 0.7990 - val_loss: 0.2143 - val_acc: 0.7325
Epoch 2/20
0s - loss: 0.1633 - acc: 0.8021 - val_loss: 0.2295 - val_acc: 0.7325
Epoch 3/20
0s - loss: 0.1657 - acc: 0.7938 - val_loss: 0.2243 - val_acc: 0.7737
Epoch 4/20
0s - loss: 0.1847 - acc: 0.7969 - val_loss: 0.2253 - val_acc: 0.7490
Epoch 5/20
0s - loss: 0.1771 - acc: 0.8062 - val_loss: 0.2402 - val_acc: 0.7407
Epoch 6/20
0s - loss: 0.1789 - acc: 0.8021 - val_loss: 0.2431 - val_acc: 0.7407
Epoch 7/20
0s - loss: 0.1789 - acc: 0.8031 - val_loss: 0.2227 - val_acc: 0.7778
Epoch 8/20
0s - loss: 0.1810 - acc: 0.8010 - val_loss: 0.2438 - val_acc: 0.7449
Epoch 9/20
0s - loss: 0.1711 - acc: 0.8134 - val_loss: 0.2365 - val_acc: 0.7490
Epoch 10/20
0s - loss: 0.1852 - acc: 0.7959 - val_loss: 0.2423 - val_acc: 0.7449
Epoch 11/20
0s - loss: 0.1889 - acc: 0.7866 - val_loss: 0.2523 - val_acc: 0.7366
Epoch 12/20
0s - loss: 0.1838 - acc: 0.8021 - val_loss: 0.2563 - val_acc: 0.7407
Epoch 13/20
0s - loss: 0.1835 - acc: 0.8041 - val_loss: 0.2560 - val_acc: 0.7325
Epoch 14/20
0s - loss: 0.1868 - acc: 0.8031 - val_loss: 0.2573 - val_acc: 0.7407
Epoch 15/20
0s - loss: 0.1829 - acc: 0.8072 - val_loss: 0.2581 - val_acc: 0.7407
Epoch 16/20
0s - loss: 0.1878 - acc: 0.8062 - val_loss: 0.2589 - val_acc: 0.7407
Epoch 17/20
0s - loss: 0.1833 - acc: 0.8072 - val_loss: 0.2613 - val_acc: 0.7366
Epoch 18/20
0s - loss: 0.1837 - acc: 0.8113 - val_loss: 0.2605 - val_acc: 0.7325
Epoch 19/20
0s - loss: 0.1906 - acc: 0.8010 - val_loss: 0.2555 - val_acc: 0.7407
Epoch 20/20
0s - loss: 0.1884 - acc: 0.8062 - val_loss: 0.2542 - val_acc: 0.7449
</code></pre>

<p><strong>Model 2 Output</strong></p>

<pre><code>Train on 970 samples, validate on 243 samples
Epoch 1/20
0s - loss: 0.1735 - acc: 0.7876 - val_loss: 0.2386 - val_acc: 0.6667
Epoch 2/20
0s - loss: 0.1733 - acc: 0.7825 - val_loss: 0.1894 - val_acc: 0.7449
Epoch 3/20
0s - loss: 0.1781 - acc: 0.7856 - val_loss: 0.2028 - val_acc: 0.7407
Epoch 4/20
0s - loss: 0.1717 - acc: 0.8021 - val_loss: 0.2545 - val_acc: 0.7119
Epoch 5/20
0s - loss: 0.1757 - acc: 0.8052 - val_loss: 0.2252 - val_acc: 0.7202
Epoch 6/20
0s - loss: 0.1776 - acc: 0.8093 - val_loss: 0.2449 - val_acc: 0.7490
Epoch 7/20
0s - loss: 0.1833 - acc: 0.7897 - val_loss: 0.2272 - val_acc: 0.7572
Epoch 8/20
0s - loss: 0.1827 - acc: 0.7928 - val_loss: 0.2376 - val_acc: 0.7531
Epoch 9/20
0s - loss: 0.1795 - acc: 0.8062 - val_loss: 0.2445 - val_acc: 0.7490
Epoch 10/20
0s - loss: 0.1746 - acc: 0.8103 - val_loss: 0.2491 - val_acc: 0.7449
Epoch 11/20
0s - loss: 0.1831 - acc: 0.8082 - val_loss: 0.2477 - val_acc: 0.7449
Epoch 12/20
0s - loss: 0.1831 - acc: 0.8113 - val_loss: 0.2496 - val_acc: 0.7490
Epoch 13/20
0s - loss: 0.1920 - acc: 0.8000 - val_loss: 0.2459 - val_acc: 0.7449
Epoch 14/20
0s - loss: 0.1945 - acc: 0.7928 - val_loss: 0.2446 - val_acc: 0.7490
Epoch 15/20
0s - loss: 0.1852 - acc: 0.7990 - val_loss: 0.2459 - val_acc: 0.7449
Epoch 16/20
0s - loss: 0.1800 - acc: 0.8062 - val_loss: 0.2495 - val_acc: 0.7449
Epoch 17/20
0s - loss: 0.1891 - acc: 0.8000 - val_loss: 0.2469 - val_acc: 0.7449
Epoch 18/20
0s - loss: 0.1891 - acc: 0.8041 - val_loss: 0.2467 - val_acc: 0.7531
Epoch 19/20
0s - loss: 0.1853 - acc: 0.8072 - val_loss: 0.2511 - val_acc: 0.7449
Epoch 20/20
0s - loss: 0.1905 - acc: 0.8062 - val_loss: 0.2460 - val_acc: 0.7531
</code></pre>
",4984897.0,,,,,2016-04-01 15:00:49,How to tell which Keras model is better?,<python><machine-learning><keras><data-science>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34702041
47312219,1,47312861,,2017-11-15 16:11:30,,44,39718,"<p>What is the definition of <strong>non-trainable</strong> parameter in a model? </p>

<p>For example, while you are building your own model, its value is 0 as a default, but when you want to use an inception model, it is becoming something else rather than 0. What would be the reason behind it? </p>
",3013290.0,,3924118.0,,2019-10-24 01:05:27,2019-10-24 01:05:27,What is the definition of a non-trainable parameter?,<tensorflow><deep-learning><keras><theano><caffe>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47312219
43743593,1,54338259,,2017-05-02 17:08:40,,44,80156,"<p>I would like to access the layer size of all the layers in a <code>Sequential</code> Keras model. My code:</p>

<pre><code>model = Sequential()
model.add(Conv2D(filters=32, 
               kernel_size=(3,3), 
               input_shape=(64,64,3)
        ))
model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))
</code></pre>

<p>Then I would like some code like the following to work</p>

<pre><code>for layer in model.layers:
    print(layer.get_shape())
</code></pre>

<p>.. but it doesn't. I get the error: <code>AttributeError: 'Conv2D' object has no attribute 'get_shape'</code></p>
",3747801.0,,,,,2022-04-04 17:14:01,Keras: How to get layer shapes in a Sequential model,<python><tensorflow><deep-learning><keras><theano>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43743593
42504669,1,42506478,,2017-02-28 09:20:05,,44,38211,"<p>I'm using Keras with Tensorflow as backend.</p>

<p>I am trying to save a model in my main process and then load/run (i.e. call <code>model.predict</code>) within another process.</p>

<p>I'm currently just trying the naive approach from the docs to save/load the model: <a href=""https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model"" rel=""noreferrer"">https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model</a>.<br>
So basically:</p>

<ol>
<li><code>model.save()</code> in main process</li>
<li><code>model = load_model()</code> in child process</li>
<li><code>model.predict()</code> in child process</li>
</ol>

<p>However, it simply hangs on the <code>load_model</code> call.</p>

<p>Searching around I've discovered this potentially related answer suggesting that Keras can only be utilized in one process: <a href=""https://stackoverflow.com/questions/38176827/using-multiprocessing-with-theano"">using multiprocessing with theano</a> but am unsure if this is true (can't seem to find much on this).</p>

<p>Is there a way to accomplish my goal?  A high level description or short example is greatly appreciated.</p>

<p>Note: I've attempted approaches along the lines of passing a graph to the process but failed since it seems tensorflow graphs aren't pickable (related SO post for that here: <a href=""https://stackoverflow.com/questions/34900246/tensorflow-passing-a-session-to-a-python-multiprocess"">Tensorflow: Passing a session to a python multiprocess</a>).  If there is indeed a way to pass the tensorflow graph/model to the child process then I am open to that as well.</p>

<p>Thanks!</p>
",3431836.0,,-1.0,,2017-05-23 11:47:13,2018-12-18 19:27:23,Keras + Tensorflow and Multiprocessing in Python,<python><tensorflow><neural-network><keras><python-multiprocessing>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42504669
43855162,1,43863854,,2017-05-08 18:49:56,,44,76109,"<p>I try to participate in my first Kaggle competition where <code>RMSLE</code> is given as the required loss function. For I have found nothing how to implement this <code>loss function</code> I tried to settle for <code>RMSE</code>. I know this was part of <code>Keras</code> in the past, is there any way to use it in the latest version, maybe with a customized function via <code>backend</code>?</p>

<p>This is the NN I designed:</p>

<pre><code>from keras.models import Sequential
from keras.layers.core import Dense , Dropout
from keras import regularizers

model = Sequential()
model.add(Dense(units = 128, kernel_initializer = ""uniform"", activation = ""relu"", input_dim = 28,activity_regularizer = regularizers.l2(0.01)))
model.add(Dropout(rate = 0.2))
model.add(Dense(units = 128, kernel_initializer = ""uniform"", activation = ""relu""))
model.add(Dropout(rate = 0.2))
model.add(Dense(units = 1, kernel_initializer = ""uniform"", activation = ""relu""))
model.compile(optimizer = ""rmsprop"", loss = ""root_mean_squared_error"")#, metrics =[""accuracy""])

model.fit(train_set, label_log, batch_size = 32, epochs = 50, validation_split = 0.15)
</code></pre>

<p>I tried a customized <code>root_mean_squared_error</code> function I found on GitHub but for all I know the syntax is not what is required. I think the <code>y_true</code> and the <code>y_pred</code> would have to be defined before passed to the return but I have no idea how exactly, I just started with programming in python and I am really not that good in math...</p>

<pre><code>from keras import backend as K

def root_mean_squared_error(y_true, y_pred):
        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) 
</code></pre>

<p>I receive the following error with this function: </p>

<pre><code>ValueError: ('Unknown loss function', ':root_mean_squared_error')
</code></pre>

<p>Thanks for your ideas, I appreciate every help!</p>
",6589039.0,,,,,2021-10-12 13:19:48,RMSE/ RMSLE loss function in Keras,<python><keras><custom-function><loss-function>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43855162
50283844,1,50284846,,2018-05-11 01:48:25,,43,90138,"<p>I built a Sequential model with the VGG16 network at the initial base, for example: </p>



<pre class=""lang-python prettyprint-override""><code>from keras.applications import VGG16
conv_base = VGG16(weights='imagenet',
                  # do not include the top, fully-connected Dense layers 
                  include_top=False,
                  input_shape=(150, 150, 3))

from keras import models
from keras import layers

model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
# the 3 corresponds to the three output classes
model.add(layers.Dense(3, activation='sigmoid'))
</code></pre>

<p>My model looks like this: </p>

<pre class=""lang-python prettyprint-override""><code>model.summary()
</code></pre>

<blockquote>
  <hr>

<pre class=""lang-python prettyprint-override""><code>Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Model)                (None, 4, 4, 512)         14714688  
_________________________________________________________________
flatten_1 (Flatten)          (None, 8192)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 256)               2097408   
_________________________________________________________________
dense_8 (Dense)              (None, 3)                 771       
=================================================================
Total params: 16,812,867
Trainable params: 16,812,867
Non-trainable params: 0
_________________________________________________________________
</code></pre>
</blockquote>

<p>Now, I want to get the layer names associated with the vgg16 Model portion of my network.  I.e. something like: </p>

<pre class=""lang-python prettyprint-override""><code>layer_name = 'block3_conv1'
filter_index = 0

layer_output = model.get_layer(layer_name).output
loss = K.mean(layer_output[:, :, :, filter_index])
</code></pre>

<p>However, since the vgg16 convolutional is shown as a Model and it's layers are not being exposed, I get the error: </p>

<blockquote>
  <p>ValueError: No such layer: block3_conv1</p>
</blockquote>

<p>How do I do this? </p>
",4521204.0,,8563649.0,,2018-05-11 07:07:11,2022-05-10 09:49:09,"In Keras, how to get the layer name associated with a ""Model"" object contained in my model?",<keras><keras-layer><conv-neural-network>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50283844
46503816,1,46504997,,2017-09-30 14:48:04,,43,50751,"<p>I am very confused by these two parameters in the conv1d layer from keras:
<a href=""https://keras.io/layers/convolutional/#conv1d"" rel=""noreferrer"">https://keras.io/layers/convolutional/#conv1d</a></p>

<p>the documentation says:</p>

<pre><code>filters: Integer, the dimensionality of the output space (i.e. the number output of filters in the convolution).
kernel_size: An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.
</code></pre>

<p>But that does not seem to relate to the standard terminologies I see on many tutorials such as <a href=""https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner"" rel=""noreferrer"">https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner</a>'s-Guide-To-Understanding-Convolutional-Neural-Networks/ and <a href=""https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/</a></p>

<p>Using the second tutorial link which uses Keras, I'd imagine that in fact 'kernel_size' is relevant to the conventional 'filter' concept which defines the sliding window on the input feature space. But what about the 'filter' parameter in conv1d? What does it do? </p>

<p>For example, in the following code snippet:</p>

<pre><code>model.add(embedding_layer)
model.add(Dropout(0.2))
model.add(Conv1D(filters=100, kernel_size=4, padding='same', activation='relu'))
</code></pre>

<p>suppose the embedding layer outputs a matrix of dimension 50 (rows, each row is a word in a sentence) x 300 (columns, the word vector dimension), how does the conv1d layer transforms that matrix?</p>

<p>Many thanks</p>
",1783398.0,,,,,2022-11-11 16:02:07,Keras conv1d layer parameters: filters and kernel_size,<keras><convolution>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46503816
58352326,1,58526969,,2019-10-12 08:32:27,,43,84882,"<p><a href=""https://colab.research.google.com/drive/1lipWy-B6BrtZlARM_amdnc7zgKiFaSRR"" rel=""noreferrer"">error_giving_notebook</a></p>

<p><a href=""https://colab.research.google.com/drive/1ksJgAXniJZIm8S4EmPDIE3hA7DuwWs0a"" rel=""noreferrer"">non_problematic_notebook</a></p>

<p>As it can be seen that I have used tf.function decorator in the 'error_giving_notebook' and it throws a ValueError while the same notebook without any changes except for removing the tf.function decorator runs smoothly in 'non_problematic_notebook'. What can be the reason? </p>
",9435613.0,,9435613.0,,2019-10-12 09:04:11,2023-01-23 10:04:27,Running the Tensorflow 2.0 code gives 'ValueError: tf.function-decorated function tried to create variables on non-first call'. What am I doing wrong?,<keras><deep-learning><keras-layer><tensorflow2.0><tf.keras>,3,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58352326
47302085,1,47306502,,2017-11-15 07:56:29,,43,13965,"<p>It is not yet clear for me what <code>metrics</code> are (as given in the code below). What exactly are they evaluating? Why do we need to define them in the <code>model</code>? Why we can have multiple metrics in one model? And more importantly what is the mechanics behind all this? 
Any scientific reference is also appreciated.</p>



<pre class=""lang-python prettyprint-override""><code>model.compile(loss='mean_squared_error',
              optimizer='sgd',
              metrics=['mae', 'acc'])
</code></pre>
",3705055.0,,8563649.0,,2018-04-19 13:03:37,2021-08-06 06:19:06,"What is ""metrics"" in Keras?",<python><machine-learning><neural-network><deep-learning><keras>,5,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47302085
49295311,1,49299921,,2018-03-15 09:11:29,,43,43374,"<p>I want to pass the output of ConvLSTM and Conv2D to a Dense Layer in Keras, what is the difference between using global average pooling and flatten
Both is working in my case.</p>



<pre class=""lang-python prettyprint-override""><code>model.add(ConvLSTM2D(filters=256,kernel_size=(3,3)))
model.add(Flatten())
# or model.add(GlobalAveragePooling2D())
model.add(Dense(256,activation='relu'))
</code></pre>
",5797699.0,,10908375.0,,2021-03-25 12:22:29,2023-01-15 07:54:21,what is the difference between Flatten() and GlobalAveragePooling2D() in keras,<python><tensorflow><keras><deep-learning><keras-layer>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49295311
43529931,1,43668304,,2017-04-20 21:07:38,,43,15881,"<p>I would like to calculate NN model certainty/confidence (see <a href=""http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html"" rel=""noreferrer"">What my deep model doesn't know</a>) - when NN tells me an image represents ""8"", I would like to know how certain it is. Is my model 99% certain it is ""8"" or is it 51% it is ""8"", but it could also be ""6""? Some digits are quite ambiguous and I would like to know for which images the model is just ""flipping a coin"".</p>

<p>I have found some theoretical writings about this but I have trouble putting this in code. If I understand correctly, I should evaluate a testing image multiple times while ""killing off"" different neurons (using dropout) and then...?</p>

<p>Working on MNIST dataset, I am running the following model:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense, Activation, Conv2D, Flatten, Dropout

model = Sequential()
model.add(Conv2D(128, kernel_size=(7, 7),
                 activation='relu',
                 input_shape=(28, 28, 1,)))
model.add(Dropout(0.20))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Dropout(0.20))
model.add(Flatten())
model.add(Dense(units=64, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(units=10, activation='softmax'))
model.summary()
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
model.fit(train_data, train_labels,  batch_size=100, epochs=30, validation_data=(test_data, test_labels,))
</code></pre>

<p><em>How should I predict with this model so that I get its certainty about predictions too?</em> I would appreciate some practical examples (preferably in Keras, but any will do).</p>

<p>To clarify, I am looking for an example of how to get certainty using <a href=""http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html"" rel=""noreferrer"">the method outlined by Yurin Gal</a> (or an explanation of why some other method yields better results). </p>
",593487.0,,3924118.0,,2019-11-21 18:02:39,2019-12-04 11:48:17,How to calculate prediction uncertainty using Keras?,<machine-learning><neural-network><deep-learning><keras><uncertainty>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43529931
42415076,1,47520976,,2017-02-23 11:54:30,,43,25759,"<p>I'm using a <a href=""/questions/tagged/scikit-learn"" class=""post-tag"" title=""show questions tagged &#39;scikit-learn&#39;"" aria-label=""show questions tagged &#39;scikit-learn&#39;"" rel=""tag"" aria-labelledby=""tag-scikit-learn-tooltip-container"">scikit-learn</a> custom pipeline (<code>sklearn.pipeline.Pipeline</code>) in conjunction with <code>RandomizedSearchCV</code> for hyper-parameter optimization. This works great.</p>
<p>Now I would like to insert a <a href=""/questions/tagged/keras"" class=""post-tag"" title=""show questions tagged &#39;keras&#39;"" aria-label=""show questions tagged &#39;keras&#39;"" rel=""tag"" aria-labelledby=""tag-keras-tooltip-container"">keras</a> model as a first step into the pipeline. The parameters of the model should be optimized. The computed (fitted) <a href=""/questions/tagged/keras"" class=""post-tag"" title=""show questions tagged &#39;keras&#39;"" aria-label=""show questions tagged &#39;keras&#39;"" rel=""tag"" aria-labelledby=""tag-keras-tooltip-container"">keras</a> model should then be used later on in the pipeline by other steps, so I think I have to store the model as a global variable so that the other pipeline steps can use it. Is this right?</p>
<p>I know that <a href=""/questions/tagged/keras"" class=""post-tag"" title=""show questions tagged &#39;keras&#39;"" aria-label=""show questions tagged &#39;keras&#39;"" rel=""tag"" aria-labelledby=""tag-keras-tooltip-container"">keras</a> offers some <em>wrappers</em> for the <a href=""/questions/tagged/scikit-learn"" class=""post-tag"" title=""show questions tagged &#39;scikit-learn&#39;"" aria-label=""show questions tagged &#39;scikit-learn&#39;"" rel=""tag"" aria-labelledby=""tag-scikit-learn-tooltip-container"">scikit-learn</a>  API, but the problem is that these <em>wrappers</em> already do classification/regression, but I only want to compute the <a href=""/questions/tagged/keras"" class=""post-tag"" title=""show questions tagged &#39;keras&#39;"" aria-label=""show questions tagged &#39;keras&#39;"" rel=""tag"" aria-labelledby=""tag-keras-tooltip-container"">keras</a> model and nothing else.</p>
<p>How can this be done?</p>
<p>For example, I have a method which returns the model:</p>
<pre class=""lang-py prettyprint-override""><code>def create_model(file_path, argument2,...):
  ...
  return model
</code></pre>
<p>The method needs some fixed parameters like a <code>file_path</code> etc. but <code>X</code> and <code>y</code> are not needed (or can be ignored). The parameters of the model should be optimized (number of layers etc.).</p>
",1684118.0,,10452700.0,,2023-04-29 09:53:28,2023-04-29 09:53:28,How to insert Keras model into scikit-learn pipeline?,<machine-learning><scikit-learn><pipeline><keras><hyperparameters>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42415076
44843581,1,44843804,,2017-06-30 09:51:04,,43,61390,"<p>I am using Keras with TensorFlow backend to train CNN models. </p>

<p>What is the between <code>model.fit()</code> and <code>model.evaluate()</code>? Which one should I ideally use? (I am using <code>model.fit()</code> as of now). </p>

<p>I know the utility of <code>model.fit()</code> and <code>model.predict()</code>. But I am unable to understand the utility of <code>model.evaluate()</code>. Keras documentation just says:</p>

<blockquote>
  <p>It is used to evaluate the model.  </p>
</blockquote>

<p>I feel this is a very vague definition. </p>
",8199433.0,,3924118.0,,2019-03-31 09:17:52,2022-02-04 18:27:46,What is the difference between model.fit() an model.evaluate() in Keras?,<tensorflow><model><keras><evaluate>,6,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44843581
44647258,1,44658650,,2017-06-20 08:03:19,,43,27031,"<p>I'm trying to build a LSTM autoencoder with the goal of getting a fixed sized vector from a sequence, which represents the sequence as good as possible. This autoencoder consists of two parts:</p>

<ul>
<li><code>LSTM</code> Encoder: Takes a sequence and returns an output vector (<code>return_sequences = False</code>)</li>
<li><code>LSTM</code> Decoder: Takes an output vector and returns a sequence (<code>return_sequences = True</code>)</li>
</ul>

<p>So, in the end, the encoder is a <strong>many to one</strong> LSTM and the decoder is a <strong>one to many</strong> LSTM.</p>

<p><a href=""https://i.stack.imgur.com/kwhAP.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/kwhAP.jpg"" alt=""enter image description here""></a>
Image source: <a href=""http://karpathy.github.io/2015/05/21/rnn-effectiveness/"" rel=""noreferrer"">Andrej Karpathy</a></p>

<p>On a high level the coding looks like this (similar as described <a href=""https://github.com/fchollet/keras/issues/5138"" rel=""noreferrer"">here</a>):</p>

<pre><code>encoder = Model(...)
decoder = Model(...)

autoencoder = Model(encoder.inputs, decoder(encoder(encoder.inputs)))

autoencoder.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

autoencoder.fit(data, data,
          batch_size=100,
          epochs=1500)
</code></pre>

<p>The shape (number of training examples, sequence length, input dimension) of the <code>data</code> array is <code>(1200, 10, 5)</code> and looks like this:</p>

<pre><code>array([[[1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0],
        [0, 0, 1, 0, 0],
        ..., 
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0]],
        ... ]
</code></pre>

<p><strong>Problem:</strong> I am not sure how to proceed, especially how to integrate <code>LSTM</code> to <code>Model</code> and how to get the decoder to generate a sequence from a vector.</p>

<p>I am using <code>keras</code> with <code>tensorflow</code> backend.</p>

<p><strong>EDIT:</strong> If someone wants to try out, here is my procedure to generate random sequences with moving ones (including padding):</p>

<pre><code>import random
import math

def getNotSoRandomList(x):
    rlen = 8
    rlist = [0 for x in range(rlen)]
    if x &lt;= 7:
        rlist[x] = 1
    return rlist


sequence = [[getNotSoRandomList(x) for x in range(round(random.uniform(0, 10)))] for y in range(5000)]

### Padding afterwards

from keras.preprocessing import sequence as seq

data = seq.pad_sequences(
    sequences = sequence,
    padding='post',
    maxlen=None,
    truncating='post',
    value=0.
)
</code></pre>
",2612484.0,,951894.0,,2018-02-28 00:57:59,2020-01-03 09:58:50,LSTM Autoencoder,<python><machine-learning><tensorflow><deep-learning><keras>,3,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44647258
50920908,1,50921588,,2018-06-19 04:58:05,,42,116795,"<p>I am building a multiclass model with Keras.</p>

<pre><code>model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(X_test, y_test))  # starts training
</code></pre>

<p>Here is how my test data looks like (it's text data).</p>

<pre><code>X_test
Out[25]: 
array([[621, 139, 549, ...,   0,   0,   0],
       [621, 139, 543, ...,   0,   0,   0]])

y_test
Out[26]: 
array([[0, 0, 1],
       [0, 1, 0]])
</code></pre>

<p>After generating predictions...</p>

<pre><code>predictions = model.predict(X_test)
predictions
Out[27]: 
array([[ 0.29071924,  0.2483743 ,  0.46090645],
       [ 0.29566404,  0.45295066,  0.25138539]], dtype=float32)
</code></pre>

<p>I did the following to get the confusion matrix.</p>

<pre><code>y_pred = (predictions &gt; 0.5)

confusion_matrix(y_test, y_pred)
Traceback (most recent call last):

  File ""&lt;ipython-input-38-430e012b2078&gt;"", line 1, in &lt;module&gt;
    confusion_matrix(y_test, y_pred)

  File ""/Users/abrahammathew/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py"", line 252, in confusion_matrix
    raise ValueError(""%s is not supported"" % y_type)

ValueError: multilabel-indicator is not supported
</code></pre>

<p>However, I am getting the above error.</p>

<p>How can I get a confusion matrix when doing a multiclass neural network in Keras?</p>
",2725751.0,,6013016.0,,2020-06-22 04:32:26,2020-06-22 04:32:26,Get Confusion Matrix From a Keras Multiclass Model,<python><keras><scikit-learn><multiclass-classification>,1,0,0.0,2019-05-27 13:22:27,,CC BY-SA 4.0,https://stackoverflow.com/q/50920908
73600481,1,73601542,,2022-09-04 15:10:31,,42,3438,"<hr />
<p><strong>TLDR</strong>:</p>
<p><em>A simple (single hidden-layer) feed-forward Pytorch model trained to predict the function <code>y = sin(X1) + sin(X2) + ... sin(X10)</code> substantially underperforms an identical model built/trained with Keras. Why is this so and what can be done to mitigate the difference in performance?</em></p>
<hr />
<p>In training a regression model, I noticed that PyTorch drastically underperforms an identical model built with Keras.</p>
<p><strong>This phenomenon has been observed and reported previously</strong>:</p>
<ul>
<li><p><a href=""https://discuss.pytorch.org/t/the-same-model-produces-worse-results-on-pytorch-than-on-tensorflow/5380"" rel=""noreferrer"">The same model produces worse results on pytorch than on tensorflow</a></p>
</li>
<li><p><a href=""https://discuss.pytorch.org/t/cnn-model-in-pytorch-giving-30-less-accuracy-to-tensoflowflow-model/85410"" rel=""noreferrer"">CNN model in pytorch giving 30% less accuracy to Tensoflowflow model</a>:</p>
</li>
<li><p><a href=""https://discuss.pytorch.org/t/pytorch-adam-vs-tensorflow-adam/74471"" rel=""noreferrer"">PyTorch Adam vs Tensorflow Adam</a></p>
</li>
<li><p><a href=""https://discuss.pytorch.org/t/suboptimal-convergence-when-compared-with-tensorflow-model/5099"" rel=""noreferrer"">Suboptimal convergence when compared with TensorFlow model</a></p>
</li>
<li><p><a href=""https://discuss.pytorch.org/t/rnn-and-adam-slower-convergence-than-keras/11278"" rel=""noreferrer"">RNN and Adam: slower convergence than Keras</a></p>
</li>
<li><p><a href=""https://discuss.pytorch.org/t/pytorch-comparable-but-worse-than-keras-on-a-simple-feed-forward-network/9928"" rel=""noreferrer"">PyTorch comparable but worse than keras on a simple feed forward network</a></p>
</li>
<li><p><a href=""https://www.reddit.com/r/pytorch/comments/ox0g4e/why_is_the_pytorch_model_doing_worse_than_the/"" rel=""noreferrer"">Why is the PyTorch model doing worse than the same model in Keras even with the same weight initialization?</a></p>
</li>
<li><p><a href=""https://stackoverflow.com/questions/59344571/why-keras-behave-better-than-pytorch-under-the-same-network-configuration"">Why Keras behave better than Pytorch under the same network configuration?</a></p>
</li>
</ul>
<p><strong>The following explanations and suggestions have been made previously as well</strong>:</p>
<ol>
<li><p>Using the same decimal precision (32 vs 64): <a href=""https://discuss.pytorch.org/t/the-same-model-produces-worse-results-on-pytorch-than-on-tensorflow/5380"" rel=""noreferrer"">1</a>, <a href=""https://www.reddit.com/r/MachineLearning/comments/7nw67c/d_pytorch_are_adam_and_rmsprop_okay/"" rel=""noreferrer"">2</a>,</p>
</li>
<li><p>Using a CPU instead of a GPU: <a href=""https://discuss.pytorch.org/t/the-same-model-produces-worse-results-on-pytorch-than-on-tensorflow/5380"" rel=""noreferrer"">1</a>,<a href=""https://discuss.pytorch.org/t/rnn-and-adam-slower-convergence-than-keras/11278/2?u=smth"" rel=""noreferrer"">2</a></p>
</li>
<li><p>Change <code>retain_graph=True</code> to <code>create_graph=True</code> in computing the 2nd derivative with <code>autograd.grad</code>: <a href=""https://discuss.pytorch.org/t/pytorch-adam-vs-tensorflow-adam/74471"" rel=""noreferrer"">1</a></p>
</li>
<li><p>Check if keras is using a regularizer, constraint, bias, or loss function in a different way from pytorch: <a href=""https://discuss.pytorch.org/t/suboptimal-convergence-when-compared-with-tensorflow-model/5099/2"" rel=""noreferrer"">1</a>,<a href=""https://discuss.pytorch.org/t/pytorch-comparable-but-worse-than-keras-on-a-simple-feed-forward-network/9928/4"" rel=""noreferrer"">2</a></p>
</li>
<li><p>Ensure you are computing the validation loss in the same way: <a href=""https://discuss.pytorch.org/t/suboptimal-convergence-when-compared-with-tensorflow-model/5099/3"" rel=""noreferrer"">1</a></p>
</li>
<li><p>Use the same initialization routine: <a href=""https://discuss.pytorch.org/t/suboptimal-convergence-when-compared-with-tensorflow-model/5099/3"" rel=""noreferrer"">1</a>,<a href=""https://stackoverflow.com/questions/59344571/why-keras-behave-better-than-pytorch-under-the-same-network-configuration"">2</a></p>
</li>
<li><p>Training the pytorch model for longer epochs: <a href=""https://discuss.pytorch.org/t/rnn-and-adam-slower-convergence-than-keras/11278?u=smth"" rel=""noreferrer"">1</a></p>
</li>
<li><p>Trying several random seeds: <a href=""https://discuss.pytorch.org/t/rnn-and-adam-slower-convergence-than-keras/11278/8?u=smth"" rel=""noreferrer"">1</a></p>
</li>
<li><p>Ensure that <code>model.eval()</code> is called in validation step when training pytorch model: <a href=""https://discuss.pytorch.org/t/pytorch-comparable-but-worse-than-keras-on-a-simple-feed-forward-network/9928"" rel=""noreferrer"">1</a></p>
</li>
<li><p>The main issue is with the Adam optimizer, not the initialization: <a href=""https://www.reddit.com/r/MachineLearning/comments/7nw67c/d_pytorch_are_adam_and_rmsprop_okay/"" rel=""noreferrer"">1</a></p>
</li>
</ol>
<p>To understand this issue, I trained a simple two-layer neural network (much simpler than my original model) in Keras and PyTorch, using the same hyperparameters and initialization routines, and following all the recommendations listed above. However, the PyTorch model results in a mean squared error (MSE) that is  400% higher than the MSE of the Keras model.</p>
<p><strong>Here is my code:</strong></p>
<p><strong>0. Imports</strong></p>
<pre class=""lang-py prettyprint-override""><code>import numpy as np
from scipy.stats import pearsonr

from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics

from torch.utils.data import Dataset, DataLoader

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.regularizers import L2
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
</code></pre>
<p><strong>1. Generate a reproducible dataset</strong></p>
<pre class=""lang-py prettyprint-override""><code>
def get_data():

    np.random.seed(0)
    Xtrain = np.random.normal(0, 1, size=(7000,10))
    Xval = np.random.normal(0, 1, size=(700,10))
    ytrain = np.sum(np.sin(Xtrain), axis=-1)
    yval = np.sum(np.sin(Xval), axis=-1)
    scaler = MinMaxScaler()
    ytrain = scaler.fit_transform(ytrain.reshape(-1,1)).reshape(-1)
    yval = scaler.transform(yval.reshape(-1,1)).reshape(-1) 

    return Xtrain, Xval, ytrain, yval



class XYData(Dataset):
    
    def __init__(self, X, y):
        
        super(XYData, self).__init__()
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32)
        self.len = len(y)
         
    def __getitem__(self, index):
        
        return (self.X[index], self.y[index])


    def __len__(self):

        return self.len

# Data, dataset, and dataloader
Xtrain, Xval, ytrain, yval = get_data()
traindata = XYData(Xtrain, ytrain)
valdata = XYData(Xval, yval)
trainloader = DataLoader(dataset=traindata, shuffle=True, batch_size=32, drop_last=False)
valloader = DataLoader(dataset=valdata, shuffle=True, batch_size=32, drop_last=False)
</code></pre>
<p><strong>2. Build Keras and PyTorch models with identical hyperparameters and initialization methods</strong></p>
<pre class=""lang-py prettyprint-override""><code>class TorchLinearModel(nn.Module):
    
    def __init__(self, input_dim=10, random_seed=0):
        
        super(TorchLinearModel, self).__init__()
        _ = torch.manual_seed(random_seed)
        self.hidden_layer = nn.Linear(input_dim,100)
        self.initialize_layer(self.hidden_layer)        
        self.output_layer = nn.Linear(100, 1)
        self.initialize_layer(self.output_layer)

    def initialize_layer(self, layer):
        
        _ = torch.nn.init.xavier_normal_(layer.weight)
        #_ = torch.nn.init.xavier_uniform_(layer.weight)
        _ = torch.nn.init.constant(layer.bias,0)
        
    def forward(self, x):
        x = self.hidden_layer(x)
        x = self.output_layer(x)
        return x




def mean_squared_error(ytrue, ypred):
    
    return torch.mean(((ytrue - ypred) ** 2))


def build_torch_model():

    torch_model = TorchLinearModel()
    optimizer = optim.Adam(torch_model.parameters(), 
                           betas=(0.9,0.9999),
                           eps=1e-7,
                           lr=1e-3,
                           weight_decay=0)
    return torch_model, optimizer




def build_keras_model():
    
    x = layers.Input(shape=10)
    z = layers.Dense(units=100, activation=None, use_bias=True, kernel_regularizer=None, 
                     bias_regularizer=None)(x)
    y = layers.Dense(units=1, activation=None, use_bias=True, kernel_regularizer=None, 
                     bias_regularizer=None)(z)
    keras_model = Model(x, y, name='linear')
    optimizer = Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.9999, epsilon=1e-7, 
                     amsgrad=False)
    
    keras_model.compile(optimizer=optimizer, loss='mean_squared_error')
    
    return keras_model




# Instantiate models
torch_model, optimizer = build_torch_model()
keras_model = build_keras_model()

</code></pre>
<p><strong>3. Train PyTorch model for 100 epochs:</strong></p>
<pre class=""lang-py prettyprint-override""><code>
torch_trainlosses, torch_vallosses = [], []

for epoch in range(100):

    # Training
    losses = []
    _ = torch_model.train()
    
    for i, (x,y) in enumerate(trainloader):
        optimizer.zero_grad()                          
        ypred = torch_model(x)
        loss = mean_squared_error(y, ypred) 
        _ = loss.backward()
        _ = optimizer.step()
        losses.append(loss.item())
    torch_trainlosses.append(np.mean(losses))
    
    # Validation
    losses = []
    _ = torch_model.eval()

    with torch.no_grad():
        for i, (x, y) in enumerate(valloader):
            ypred = torch_model(x)
            loss = mean_squared_error(y, ypred) 
            losses.append(loss.item())
    torch_vallosses.append(np.mean(losses))
    
    print(f&quot;epoch={epoch+1}, train_loss={torch_trainlosses[-1]:.4f}, val_loss={torch_vallosses[-1]:.4f}&quot;)
    
</code></pre>
<p><strong>4. Train Keras model for 100 epochs:</strong></p>
<pre class=""lang-py prettyprint-override""><code>history = keras_model.fit(Xtrain, ytrain, sample_weight=None, batch_size=32, epochs=100, 
                    validation_data=(Xval, yval))
</code></pre>
<p><strong>5. Loss in training history</strong></p>
<pre class=""lang-py prettyprint-override""><code>plt.plot(torch_trainlosses, color='blue', label='PyTorch Train')    
plt.plot(torch_vallosses, color='blue', linestyle='--', label='PyTorch Val')  
plt.plot(history.history['loss'], color='brown', label='Keras Train')
plt.plot(history.history['val_loss'], color='brown', linestyle='--', label='Keras Val')
plt.legend()
</code></pre>
<p><a href=""https://i.stack.imgur.com/RajJk.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/RajJk.png"" alt=""enter image description here"" /></a></p>
<p><em>Keras records a much lower error in the training. Since this may be due to a difference in how Keras computes the loss, I calculated the prediction error on the validation set with sklearn.metrics.mean_squared_error</em></p>
<p><strong>6. Validation error after training</strong></p>
<pre class=""lang-py prettyprint-override""><code>ypred_keras = keras_model.predict(Xval).reshape(-1)
ypred_torch = torch_model(torch.tensor(Xval, dtype=torch.float32))
ypred_torch = ypred_torch.detach().numpy().reshape(-1)


mse_keras = metrics.mean_squared_error(yval, ypred_keras)
mse_torch = metrics.mean_squared_error(yval, ypred_torch)
print('Percent error difference:', (mse_torch / mse_keras - 1) * 100) 

r_keras = pearsonr(yval, ypred_keras)[0] 
r_pytorch = pearsonr(yval, ypred_torch)[0]  
print(&quot;r_keras:&quot;, r_keras)
print(&quot;r_pytorch:&quot;, r_pytorch)

plt.scatter(ypred_keras, yval); plt.title('Keras'); plt.show(); plt.close()
plt.scatter(ypred_torch, yval); plt.title('Pytorch'); plt.show(); plt.close()
</code></pre>
<pre class=""lang-py prettyprint-override""><code>Percent error difference: 479.1312469426776
r_keras: 0.9115184443702814
r_pytorch: 0.21728812737220082
</code></pre>
<p><a href=""https://i.stack.imgur.com/y9y8x.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/y9y8x.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/KaLYZ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/KaLYZ.png"" alt=""enter image description here"" /></a></p>
<p><em>The correlation of predicted values with ground truth is 0.912 for Keras but 0.217 for Pytorch, and the error for Pytorch is 479% higher!</em></p>
<p><strong>7. Other trials</strong>
I also tried:</p>
<ul>
<li>Lowering the learning rate for Pytorch (lr=1e-4), <strong>R increases from 0.217 to 0.576</strong>, but it's still much worse than Keras (r=0.912).</li>
<li>Increasing the learning rate for Pytorch (lr=1e-2), <strong>R is worse at 0.095</strong></li>
<li>Training numerous times with different random seeds. The <strong>performance is roughly the same</strong>, regardless.</li>
<li>Trained for longer than 100 epochs. No improvement was observed!</li>
<li>Used <code>torch.nn.init.xavier_uniform_</code> instead of <code>torch.nn.init.xavier_normal_</code> in the initialization of the weights. R <strong>improves from 0.217 to 0.639</strong>, but it's still worse than Keras (0.912).</li>
</ul>
<hr />
<p><strong>What can be done to ensure that the PyTorch model converges to a reasonable error comparable with the Keras model?</strong></p>
<hr />
",8437546.0,,8437546.0,,2022-09-04 15:33:05,2022-09-04 17:41:45,400% higher error with PyTorch compared with identical Keras model (with Adam optimizer),<tensorflow><keras><pytorch><adam>,1,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/73600481
41531695,1,41534323,,2017-01-08 10:28:55,,42,41510,"<p>I can't find how Keras defines ""accuracy"" and ""loss"".  I know I can specify different metrics (e.g. mse, cross entropy) - but keras prints out a standard ""accuracy"".  How is that defined? Likewise for loss: I know I can specify different types of regularization -- are those in the loss?</p>

<p>Ideally, I'd like to print out the equation used to define it; if not, I'll settle for an answer here.</p>
",785494.0,,2230844.0,,2018-02-21 15:24:12,2018-02-21 15:24:12,"How does keras define ""accuracy"" and ""loss""?",<python><tensorflow><machine-learning><deep-learning><keras>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41531695
46654424,1,46656508,,2017-10-09 20:25:09,,42,60256,"<p>Sometimes I run into a problem:</p>
<pre><code>OOM when allocating tensor with shape
</code></pre>
<p>e.g.</p>
<pre><code>OOM when allocating tensor with shape (1024, 100, 160)
</code></pre>
<p>Where 1024 is my batch size and I don't know what's the rest. If I reduce the batch size or the number of neurons in the model, it runs fine.</p>
<p>Is there a generic way to calculate optimal batch size based on model and GPU memory, so the program doesn't crash?</p>
<p>In short: I want the largest batch size possible in terms of my model, which will fit into my GPU memory and won't crash the program.</p>
",672018.0,,4685471.0,,2022-07-18 21:18:47,2023-03-09 13:21:09,How to calculate optimal batch size,<machine-learning><neural-network><deep-learning><keras><gradient-descent>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/46654424
42821330,1,44891281,,2017-03-15 21:49:19,,42,16083,"<p>Restore original text from Keras’s imdb dataset</p>

<p>I want to restore imdb’s original text from Keras’s imdb dataset.</p>

<p>First, when I load Keras’s imdb dataset, it returned sequence of word index.</p>

<p>

<pre><code>&gt;&gt;&gt; (X_train, y_train), (X_test, y_test) = imdb.load_data()
&gt;&gt;&gt; X_train[0]
[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
</code></pre>

<p>I found imdb.get_word_index method(), it returns word index dictionary like {‘create’: 984, ‘make’: 94,…}. For converting, I create index word dictionary.


<pre><code>&gt;&gt;&gt; word_index = imdb.get_word_index()
&gt;&gt;&gt; index_word = {v:k for k,v in word_index.items()}
</code></pre>

<p>Then, I tried to restore original text like following.</p>

<p>

<pre><code>&gt;&gt;&gt; ' '.join(index_word.get(w) for w in X_train[5])
""the effort still been that usually makes for of finished sucking ended cbc's an because before if just though something know novel female i i slowly lot of above freshened with connect in of script their that out end his deceptively i i""
</code></pre>

<p>I’m not good at English, but I know this sentence is something strange.</p>

<p>Why is this happened? How can I restore original text?</p>
",7233229.0,,5974433.0,,2017-07-12 08:30:30,2021-03-13 22:24:13,Restore original text from Keras’s imdb dataset,<python><machine-learning><neural-network><nlp><keras>,9,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42821330
48508036,1,48512157,,2018-01-29 18:48:41,,42,76376,"<p>Working with Sklearn stratified kfold split, and when I attempt to split using multi-class, I received on error (see below).  When I tried and split using binary, it works no problem.</p>



<pre class=""lang-python prettyprint-override""><code>num_classes = len(np.unique(y_train))
y_train_categorical = keras.utils.to_categorical(y_train, num_classes)
kf=StratifiedKFold(n_splits=5, shuffle=True, random_state=999)

# splitting data into different folds
for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train_categorical)):
    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]
    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]

ValueError: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.
</code></pre>
",3866549.0,,4685471.0,,2019-04-13 15:46:03,2021-10-25 12:59:21,"Sklearn StratifiedKFold: ValueError: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead",<python><machine-learning><keras><scikit-learn><cross-validation>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48508036
48373845,1,48373959,,2018-01-22 02:15:34,,41,27141,"<p>In Keras, if you need to have a custom loss with additional parameters, we can use it like mentioned on <a href=""https://datascience.stackexchange.com/questions/25029/custom-loss-function-with-additional-parameter-in-keras"">https://datascience.stackexchange.com/questions/25029/custom-loss-function-with-additional-parameter-in-keras</a></p>

<pre><code>def penalized_loss(noise):
    def loss(y_true, y_pred):
        return K.mean(K.square(y_pred - y_true) - K.square(y_true - noise), axis=-1)
    return loss
</code></pre>

<p>The above method works when I am training the model. However, once the model is trained I am having difficulty in loading the model. When I try to use the custom_objects parameter in load_model like below</p>

<pre><code>model = load_model(modelFile, custom_objects={'penalized_loss': penalized_loss} )
</code></pre>

<p>it complains <code>ValueError: Unknown loss function:loss</code></p>

<p>Is there any way to pass in the loss function as one of the custom losses in <code>custom_objects</code> ? From what I can gather, the inner function is not in the namespace during load_model call. Is there any easier way to load the model or use a custom loss with additional parameters</p>
",9249320.0,,,,,2022-01-14 09:14:54,Loading model with custom loss + keras,<python><keras>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48373845
37657260,1,37663327,,2016-06-06 12:17:34,,41,77194,"<p>I get this error : </p>

<blockquote>
  <p>sum() got an unexpected keyword argument 'out'</p>
</blockquote>

<p>when I run this code:</p>

<pre><code>import pandas as pd, numpy as np
import keras
from keras.layers.core import Dense, Activation
from keras.models import Sequential

def AUC(y_true,y_pred):
    not_y_pred=np.logical_not(y_pred)
    y_int1=y_true*y_pred
    y_int0=np.logical_not(y_true)*not_y_pred
    TP=np.sum(y_pred*y_int1)
    FP=np.sum(y_pred)-TP
    TN=np.sum(not_y_pred*y_int0)
    FN=np.sum(not_y_pred)-TN
    TPR=np.float(TP)/(TP+FN)
    FPR=np.float(FP)/(FP+TN)
    return((1+TPR-FPR)/2)

# Input datasets

train_df = pd.DataFrame(np.random.rand(91,1000))
train_df.iloc[:,-2]=(train_df.iloc[:,-2]&gt;0.8)*1


model = Sequential()
model.add(Dense(output_dim=60, input_dim=91, init=""glorot_uniform""))
model.add(Activation(""sigmoid""))
model.add(Dense(output_dim=1, input_dim=60, init=""glorot_uniform""))
model.add(Activation(""sigmoid""))

model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=[AUC])


train_df.iloc[:,-1]=np.ones(train_df.shape[0]) #bias
X=train_df.iloc[:,:-1].values
Y=train_df.iloc[:,-1].values
print X.shape,Y.shape

model.fit(X, Y, batch_size=50,show_accuracy = False, verbose = 1)
</code></pre>

<p>Is it possible to implement a custom metric aside from doing a loop on batches and editing the source code?</p>
",5190014.0,,5974433.0,,2017-07-10 08:59:38,2020-01-06 17:17:12,how to implement custom metric in keras?,<python><neural-network><deep-learning><keras><metrics>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37657260
66964492,1,67599606,,2021-04-06 07:34:31,,41,154113,"<p>My notebook was working up till today. At the beginning of my colab notebook I install tf-nightly, but now it is giving me this error:</p>
<pre><code>---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-1-589c442233c5&gt; in &lt;module&gt;()
      7 import tensorflow as tf
      8 from tensorflow.keras import datasets, layers, models
----&gt; 9 from keras.preprocessing import image
     10 from keras_preprocessing.image import ImageDataGenerator #check underscore or not
     11 from tensorflow.keras.preprocessing import image_dataset_from_directory

2 frames
/usr/local/lib/python3.7/dist-packages/keras/backend.py in &lt;module&gt;()
     35 from tensorflow.python.distribute import distribute_coordinator as dc
     36 from tensorflow.python.distribute import distribute_coordinator_context as dc_context
---&gt; 37 from tensorflow.python.eager.context import get_config
     38 from tensorflow.python.framework import config
     39 from keras import backend_config

ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/context.py)
</code></pre>
<p>My code:</p>
<pre><code>!pip install tf-nightly

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from keras.preprocessing import image
from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image_dataset_from_directory
from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
</code></pre>
<p>Installing tensorflow==2.1.0 did not work either.</p>
",5111234.0,,365102.0,,2022-04-19 02:17:06,2022-10-31 07:13:59,ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context',<python><tensorflow><keras>,15,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/66964492
39674713,1,40005797,,2016-09-24 09:21:49,,41,30389,"<p>I am trying to implement an <a href=""https://keras.io/layers/recurrent/#lstm"" rel=""noreferrer"">LSTM with Keras</a>.</p>

<p>I know that LSTM's in Keras require a 3D tensor with shape <code>(nb_samples, timesteps, input_dim)</code> as an input. However, I am not entirely sure how the input should look like in my case, as I have just one sample of <code>T</code> observations for each input, not multiple samples, i.e. <code>(nb_samples=1, timesteps=T, input_dim=N)</code>. Is it better to split each of my inputs into samples of length <code>T/M</code>? <code>T</code> is around a few million observations for me, so how long should each sample in that case be, i.e., how would I choose <code>M</code>?</p>

<p>Also, am I right in that this tensor should look something like:</p>

<pre><code>[[[a_11, a_12, ..., a_1M], [a_21, a_22, ..., a_2M], ..., [a_N1, a_N2, ..., a_NM]], 
 [[b_11, b_12, ..., b_1M], [b_21, b_22, ..., b_2M], ..., [b_N1, b_N2, ..., b_NM]], 
 ..., 
 [[x_11, x_12, ..., a_1M], [x_21, x_22, ..., x_2M], ..., [x_N1, x_N2, ..., x_NM]]]
</code></pre>

<p>where M and N defined as before and x corresponds to the last sample that I would have obtained from splitting as discussed above? </p>

<p>Finally, given a pandas dataframe with <code>T</code> observations in each column, and <code>N</code> columns, one for each input, how can I create such an input to feed to Keras?</p>
",2151205.0,,7483494.0,,2018-05-02 09:48:08,2018-05-02 09:48:08,Neural Network LSTM input shape from dataframe,<python><pandas><keras><lstm>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/39674713
44788946,1,44789322,,2017-06-27 20:04:32,,41,16104,"<p>Since an LSTM RNN uses previous events to predict current sequences, why do we shuffle the training data? Don't we lose the temporal ordering of the training data? How is it still effective at making predictions after being trained on shuffled training data?</p>
",1444955.0,,,,,2017-06-28 22:48:31,Shuffling training data with LSTM RNN,<machine-learning><keras><lstm><recurrent-neural-network>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44788946
44674847,1,44684178,,2017-06-21 11:29:14,,40,5724,"<p>What are the differences between all these cross-entropy losses?</p>

<p>Keras is talking about</p>

<ul>
<li><strong>Binary cross-entropy</strong></li>
<li><strong>Categorical cross-entropy</strong></li>
<li><strong>Sparse categorical cross-entropy</strong></li>
</ul>

<p>While TensorFlow has</p>

<ul>
<li><strong>Softmax cross-entropy with logits</strong></li>
<li><strong>Sparse softmax cross-entropy with logits</strong></li>
<li><strong>Sigmoid cross-entropy with logits</strong></li>
</ul>

<p>What are the differences and relationships between them? What are the typical applications for them? What's the mathematical background? Are there other cross-entropy types that one should know? Are there any cross-entropy types without logits?</p>
",2612484.0,,3924118.0,,2020-01-06 13:30:36,2020-04-17 13:26:03,What are the differences between all these cross-entropy losses in Keras and TensorFlow?,<tensorflow><machine-learning><keras><loss-function><cross-entropy>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44674847
42264649,1,42275663,,2017-02-16 03:58:48,,40,35238,"<p>I'm following <a href=""http://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"" rel=""noreferrer"">this tutorial</a> (section 6: Tying it All Together), with my own dataset. I can get the example in the tutorial working, no problem, with the sample dataset provided.</p>

<p>I'm getting a binary cross-entropy error that is negative, and no improvements as epochs progress. I'm pretty sure binary cross-entropy should always be positive, and I should see some improvement in the loss. I've truncated the sample output (and code call) below to 5 epochs. Others seem to run into similar problems sometimes when training CNNs, but I didn't see a clear solution in my case. Does anyone know why this is happening?</p>

<p>Sample output:</p>

<pre><code>Creating TensorFlow device (/gpu:2) -&gt; (device: 2, name: GeForce GTX TITAN Black, pci bus id: 0000:84:00.0)
10240/10240 [==============================] - 2s - loss: -5.5378 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000
Epoch 2/5
10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000
Epoch 3/5
10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000
Epoch 4/5
10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000
Epoch 5/5
10240/10240 [==============================] - 0s - loss: -7.9712 - acc: 0.5000 - val_loss: -7.9712 - val_acc: 0.5000
</code></pre>

<p>My code:</p>

<pre><code>import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import History

history = History()
seed = 7
np.random.seed(seed)

dataset = np.loadtxt('train_rows.csv', delimiter="","")

#print dataset.shape (10240, 64)

# split into input (X) and output (Y) variables
X = dataset[:, 0:(dataset.shape[1]-2)] #0:62 (63 of 64 columns)
Y = dataset[:, dataset.shape[1]-1]  #column 64 counting from 0

#print X.shape (10240, 62)
#print Y.shape (10240,)

testset = np.loadtxt('test_rows.csv', delimiter="","")

#print testset.shape (2560, 64)

X_test = testset[:,0:(testset.shape[1]-2)]
Y_test = testset[:,testset.shape[1]-1]

#print X_test.shape (2560, 62)
#print Y_test.shape (2560,)

num_units_per_layer = [100, 50]

### create model
model = Sequential()
model.add(Dense(100, input_dim=(dataset.shape[1]-2), init='uniform', activation='relu'))
model.add(Dense(50, init='uniform', activation='relu'))
model.add(Dense(1, init='uniform', activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
## Fit the model
model.fit(X, Y, validation_data=(X_test, Y_test), nb_epoch=5, batch_size=128)
</code></pre>
",5171213.0,,,,,2019-06-06 11:48:32,Keras: Binary_crossentropy has negative values,<python><keras>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42264649
44931689,1,44931989,,2017-07-05 16:36:10,,40,29184,"<p>After each epoch I have printout like below:</p>

<pre><code>Train on 102 samples, validate on 26 samples
Epoch 1/1
Epoch 00000: val_acc did not improve
102/102 [==============================] - 3s - loss: 0.4934 - acc: 0.8997 - val_loss: 0.4984 - val_acc: 0.9231
</code></pre>

<p>I am not using built-in epochs, so I would like to disable these printouts and print something myself.</p>

<p>How to do that?</p>

<p>I am using tensorflow backend if it matters.</p>
",258483.0,,,,,2022-07-13 21:29:42,How to disable printing reports after each epoch in Keras?,<python><tensorflow><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44931689
54366935,1,54368176,,2019-01-25 14:09:14,,40,28934,"<p>I would like to make a deep copy of a keras model (called <code>model1</code>) of mine in order to be able to use it in a for a loop and then re-initialize for each for-loop iteration and perform <code>fit</code> with one additional sample to the model. I would  like to be able to initialize the model after each iteration since after performing the <code>fit</code> (my model is modified however, I want it keep it as it is when i am loading from the path using the load_weights).  </p>

<p>My code looks like:</p>

<pre><code>model1= create_Model()
model1.compile(optimizer='rmsprop', loss='categorical_crossentropy')
model1.load_weights('my_weights')

model_copy= create_Model()
model_copy.compile(optimizer='rmsprop', loss='categorical_crossentropy')

model_copy= keras.models.clone_model(model1)
for j in range(0, image_size):
      model_copy.fit(sample[j], sample_lbl[j])
      prediction= model_copy.predict(sample[j])
</code></pre>

<p>Also, it is not really efficient for me to load the model each time in the for-loop since that is time-consuming. How can I do properly the deep copy in my case? The code I posted give the following error that concerns the function .fit and my reference model model_copy:</p>

<blockquote>
  <p>RuntimeError: You must compile a model before training/testing. Use <code>model.compile(optimizer, loss)</code>.</p>
</blockquote>
",1194864.0,,1194864.0,,2019-01-25 14:41:20,2023-01-19 12:32:46,Make a deep copy of a keras model in python,<python><keras>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54366935
46663013,1,46667294,,2017-10-10 09:18:40,,40,36080,"<p>I want to implement my custom metric in Keras. According to the documentation, my custom metric should be defined as a function that takes as input two tensors, <code>y_pred</code> and <code>y_true</code>, and returns a single tensor value. </p>

<p>However, I'm confused to what exactly will be contained in these tensors <code>y_pred</code> and <code>y_true</code> when the optimization is running. Is it just one data point? Is it the whole batch? The whole epoch (probably not)? Is there a way to obtain these tensors' shapes?</p>

<p>Can someone point to a trustworthy place where I can get this information? Any help would be appreciated. Not sure if relevant, but I'm using TensorFlow backend.</p>

<hr>

<p>Things I tried so far, in order to answer this:</p>

<ul>
<li>Checking the <a href=""https://keras.io/metrics/"" rel=""noreferrer"">Keras metrics documentation</a> (no explanation there about what these tensors are).</li>
<li>Checking the <a href=""https://github.com/fchollet/keras/blob/master/keras/metrics.py"" rel=""noreferrer"">source code for the Keras metrics</a> and trying to understand these tensors by looking at the Keras implementation for other metrics (This seems to suggest that <code>y_true</code> and <code>y_pred</code> have the labels for an entire batch, but I'm not sure).</li>
<li>Reading these stackoverflow questions: <a href=""https://stackoverflow.com/questions/45961428/make-a-custom-loss-function-in-keras"">1</a>, <a href=""https://stackoverflow.com/questions/41458859/keras-custom-metric-for-single-class-accuracy"">2</a>, <a href=""https://stackoverflow.com/questions/43576922/keras-custom-metric-iteration"">3</a>, and others (none answer my question, most are centered on the OP not clearly understanding the difference between a tensor and the values computed using that tensor during the session).</li>
<li>Printing the values of <code>y_true</code> and <code>y_pred</code> during the optimization, by defining a metric like this:</li>
</ul>



<pre class=""lang-py prettyprint-override""><code>    def test_metric(y_true, y_pred):
        y_true = K.print_tensor(y_true)
        y_pred = K.print_tensor(y_pred)
        return y_true - y_pred
</code></pre>

<p>(unfortunately these don't print anything during the optimization).</p>
",2055373.0,,463213.0,,2017-10-11 00:17:55,2020-05-18 05:51:10,What is y_true and y_pred when creating a custom metric in Keras?,<tensorflow><keras>,3,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46663013
49161174,1,62286888,,2018-03-07 21:05:13,,40,88926,"<p>I am new in tensoflow and I want to adapt the MNIST tutorial <a href=""https://www.tensorflow.org/tutorials/layers"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/layers</a> with my own data (images of 40x40).
This is my model function : </p>

<pre><code>def cnn_model_fn(features, labels, mode):
        # Input Layer
        input_layer = tf.reshape(features, [-1, 40, 40, 1])

        # Convolutional Layer #1
        conv1 = tf.layers.conv2d(
                inputs=input_layer,
                filters=32,
                kernel_size=[5, 5],
                #  To specify that the output tensor should have the same width and height values as the input tensor
                # value can be ""same"" ou ""valid""
                padding=""same"",
                activation=tf.nn.relu)

        # Pooling Layer #1
        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

        # Convolutional Layer #2 and Pooling Layer #2
        conv2 = tf.layers.conv2d(
                inputs=pool1,
                filters=64,
                kernel_size=[5, 5],
                padding=""same"",
                activation=tf.nn.relu)
        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

        # Dense Layer
        pool2_flat = tf.reshape(pool2, [-1, 10 * 10 * 64])
        dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
        dropout = tf.layers.dropout(
                inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

        # Logits Layer
        logits = tf.layers.dense(inputs=dropout, units=2)

        predictions = {
            # Generate predictions (for PREDICT and EVAL mode)
            ""classes"":       tf.argmax(input=logits, axis=1),
            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the
            # `logging_hook`.
            ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")
        }

        if mode == tf.estimator.ModeKeys.PREDICT:
            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

        # Calculate Loss (for both TRAIN and EVAL modes)
        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

        # Configure the Training Op (for TRAIN mode)
        if mode == tf.estimator.ModeKeys.TRAIN:
            optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
            train_op = optimizer.minimize(
                    loss=loss,
                    global_step=tf.train.get_global_step())
            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

        # Add evaluation metrics (for EVAL mode)
        eval_metric_ops = {
            ""accuracy"": tf.metrics.accuracy(
                    labels=labels, predictions=predictions[""classes""])}
        return tf.estimator.EstimatorSpec(
                mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)
</code></pre>

<p>I have a shape size error between labels and logits : </p>

<p><strong>InvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [3,2] and labels shape [1]</strong> </p>

<p>filenames_array is an array of 16 string </p>

<pre><code>[""file1.png"", ""file2.png"", ""file3.png"", ...]
</code></pre>

<p>and labels_array is an array of 16 integer </p>

<pre><code>[0,0,1,1,0,1,0,0,0,...]
</code></pre>

<p>The main function is :</p>

<pre><code># Create the Estimator
mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=""/tmp/test_convnet_model"")

# Train the model
cust_train_input_fn = lambda: train_input_fn_custom(
        filenames_array=filenames, labels_array=labels, batch_size=1)

mnist_classifier.train(
        input_fn=cust_train_input_fn,
        steps=20000,
        hooks=[logging_hook])
</code></pre>

<p>I tried to reshape logits without success :</p>

<p>logits = tf.reshape(logits, [1, 2])</p>

<p>I need your help, thanks</p>

<hr>

<p><strong>EDIT</strong></p>

<p>After more time to search, in the first line of my model function</p>

<pre><code>input_layer = tf.reshape(features, [-1, 40, 40, 1])
</code></pre>

<p>the ""-1"" that signifies that the batch_size dimension will be dynamically calculated have here the value ""3"". The same ""3"" as in my error : <strong>logits and labels must have the same first dimension, got logits shape [3,2] and labels shape [1]</strong></p>

<p>If I force the value to ""1"" I have this new error :</p>

<p><strong>Input to reshape is a tensor with 4800 values, but the requested shape has 1600</strong></p>

<p>Maybe a problem with my features ?</p>

<hr>

<p><strong>EDIT2 :</strong> </p>

<p>the complete code is here : <a href=""https://gist.github.com/geoffreyp/cc8e97aab1bff4d39e10001118c6322e"" rel=""noreferrer"">https://gist.github.com/geoffreyp/cc8e97aab1bff4d39e10001118c6322e</a></p>

<hr>

<p><strong>EDIT3</strong></p>

<p>I updated the gist with </p>

<pre><code>logits = tf.layers.dense(inputs=dropout, units=1)
</code></pre>

<p><a href=""https://gist.github.com/geoffreyp/cc8e97aab1bff4d39e10001118c6322e"" rel=""noreferrer"">https://gist.github.com/geoffreyp/cc8e97aab1bff4d39e10001118c6322e</a></p>

<p>But I don't completely understand your answer about the batch size, how the batch size can be 3 here whereas I choose a batch size of 1 ? </p>

<p>If I choose a batch_size = 3 I have this error :
<strong>logits and labels must have the same first dimension, got logits shape [9,1] and labels shape [3]</strong></p>

<p>I tried to reshape labels : </p>

<pre><code>labels = tf.reshape(labels, [3, 1])
</code></pre>

<p>and I updated features and labels structure : </p>

<pre><code>    filenames_train = [['blackcorner-data/1.png', 'blackcorner-data/2.png', 'blackcorner-data/3.png',
                   'blackcorner-data/4.png', 'blackcorner-data/n1.png'],
                   ['blackcorner-data/n2.png',
                   'blackcorner-data/n3.png', 'blackcorner-data/n4.png',
                   'blackcorner-data/11.png', 'blackcorner-data/21.png'],
                   ['blackcorner-data/31.png',
                   'blackcorner-data/41.png', 'blackcorner-data/n11.png', 'blackcorner-data/n21.png',
                   'blackcorner-data/n31.png']
                   ]

labels = [[0, 0, 0, 0, 1], [1, 1, 1, 0, 0], [0, 0, 1, 1, 1]]
</code></pre>

<p>but without success...</p>
",4227291.0,,10375049.0,,2020-09-15 20:51:09,2022-08-05 22:31:48,Tensorflow : logits and labels must have the same first dimension,<python><tensorflow><keras><tensorflow-datasets><tensorflow-estimator>,7,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49161174
46771939,1,46772183,,2017-10-16 13:48:27,,40,9438,"<p>Can I use batch normalization layer right after input layer and not normalize my data? May I expect to get similar effect/performance?</p>

<p>In keras functional it would be something like this:</p>

<pre><code>x = Input (...)
x = Batchnorm(...)(x)
...
</code></pre>
",2146414.0,,712995.0,,2018-02-01 18:07:27,2018-10-06 02:02:36,Batch normalization instead of input normalization,<machine-learning><neural-network><keras><artificial-intelligence><batch-normalization>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46771939
43017017,1,43019294,,2017-03-25 13:35:59,,39,68041,"<p>I'd like to make a prediction for a single image with Keras. I've trained my model so I'm just loading the weights. </p>

<pre><code>from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
import numpy as np
import cv2

# dimensions of our images.
img_width, img_height = 150, 150



def create_model():
  if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
  else:
    input_shape = (img_width, img_height, 3)

  model = Sequential()
  model.add(Conv2D(32, (3, 3), input_shape=input_shape))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(32, (3, 3)))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(64, (3, 3)))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Flatten())
  model.add(Dense(64))
  model.add(Activation('relu'))
  model.add(Dropout(0.5))
  model.add(Dense(1))
  model.add(Activation('sigmoid'))

  return model


img = cv2.imread('./test1/1.jpg')
model = create_model()
model.load_weights('./weight.h5')
model.predict(img)
</code></pre>

<p>I'm loading the image using: </p>

<pre><code>img = cv2.imread('./test1/1.jpg')
</code></pre>

<p>And using the predict function of the model:</p>

<pre><code> model.predict(img)
</code></pre>

<p>But I get the error:</p>

<pre><code>ValueError: Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (499, 381, 3)
</code></pre>

<p>How should I proceed to have predictions on a single image ?</p>
",1236336.0,,,,,2020-11-09 06:05:24,Keras: model.predict for a single image,<deep-learning><keras>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43017017
47157526,1,47210349,,2017-11-07 12:03:24,,39,20095,"<p>I am new to machine learning and deep learning, and for learning purposes I tried to play with Resnet. I tried to overfit over small data (3 <em>different</em> images) and see if I can get almost 0 loss and 1.0 accuracy - and I did.</p>

<p>The problem is that predictions on the <strong>training</strong> images (i.e. the same 3 images used for training) are not correct..</p>

<p><strong>Training Images</strong></p>

<p><a href=""https://i.stack.imgur.com/e7rjH.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/e7rjH.jpg"" alt=""image 1""></a>  <a href=""https://i.stack.imgur.com/P1uJd.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/P1uJd.jpg"" alt=""image 2""></a>
  <a href=""https://i.stack.imgur.com/JGtlL.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/JGtlL.jpg"" alt=""image 3""></a></p>

<p><strong>Image labels</strong></p>

<p><code>[1,0,0]</code>, <code>[0,1,0]</code>, <code>[0,0,1]</code></p>

<p><strong>My python code</strong></p>



<pre class=""lang-python prettyprint-override""><code>#loading 3 images and resizing them
imgs = np.array([np.array(Image.open(""./Images/train/"" + fname)
                          .resize((197, 197), Image.ANTIALIAS)) for fname in
                 os.listdir(""./Images/train/"")]).reshape(-1,197,197,1)
# creating labels
y = np.array([[1,0,0],[0,1,0],[0,0,1]])
# create resnet model
model = ResNet50(input_shape=(197, 197,1),classes=3,weights=None)

# compile &amp; fit model
model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])

model.fit(imgs,y,epochs=5,shuffle=True)

# predict on training data
print(model.predict(imgs))
</code></pre>

<p>The model does overfit the data:</p>

<pre class=""lang-python prettyprint-override""><code>3/3 [==============================] - 22s - loss: 1.3229 - acc: 0.0000e+00
Epoch 2/5
3/3 [==============================] - 0s - loss: 0.1474 - acc: 1.0000
Epoch 3/5
3/3 [==============================] - 0s - loss: 0.0057 - acc: 1.0000
Epoch 4/5
3/3 [==============================] - 0s - loss: 0.0107 - acc: 1.0000
Epoch 5/5
3/3 [==============================] - 0s - loss: 1.3815e-04 - acc: 1.0000
</code></pre>

<p>but predictions are:</p>

<pre class=""lang-python prettyprint-override""><code> [[  1.05677405e-08   9.99999642e-01   3.95520459e-07]
 [  1.11955103e-08   9.99999642e-01   4.14905685e-07]
 [  1.02637095e-07   9.99997497e-01   2.43751242e-06]]
</code></pre>

<p>which means that all images got <code>label=[0,1,0]</code></p>

<p>why? and how can that happen?</p>
",3169750.0,,3169750.0,,2017-11-07 17:08:12,2022-11-17 17:20:54,"ResNet: 100% accuracy during training, but 33% prediction accuracy with the same data",<machine-learning><deep-learning><keras>,5,13,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47157526
45199047,1,45199301,,2017-07-19 19:03:31,,39,23717,"<p>There is <a href=""https://keras.io/models/about-keras-models/"" rel=""noreferrer"">model.summary() method</a> in Keras. It prints table to stdout. Is it possible to save this to file?</p>
",258483.0,,,,,2022-05-21 07:53:32,How to save model.summary() to file in Keras?,<python><keras><stdout>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45199047
46009619,1,46015144,,2017-09-02 01:12:58,,39,45699,"<p>I tried to implement a weighted binary crossentropy with Keras, but I am not sure if the code is correct. The training output seems to be a bit confusing. After a few epochs I just get an accuracy of ~0.15. I think thats much too less (even for a random guess).</p>

<p>There are in general about 11% ones in the output and 89% zeros, therefore the weights are w_zero=0.89 and w_one=0.11.</p>

<p>My code:</p>



<pre class=""lang-python prettyprint-override""><code>def create_weighted_binary_crossentropy(zero_weight, one_weight):

    def weighted_binary_crossentropy(y_true, y_pred):

        # Original binary crossentropy (see losses.py):
        # K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)

        # Calculate the binary crossentropy
        b_ce = K.binary_crossentropy(y_true, y_pred)

        # Apply the weights
        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight
        weighted_b_ce = weight_vector * b_ce

        # Return the mean error
        return K.mean(weighted_b_ce)

    return weighted_binary_crossentropy
</code></pre>

<p>Maybe someone sees whats wrong?</p>

<p>Thank you</p>
",916672.0,,4685471.0,,2017-09-07 14:39:16,2023-03-05 16:40:15,Keras: weighted binary crossentropy,<machine-learning><keras><keras-2>,7,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46009619
49785536,1,49785582,,2018-04-11 22:56:02,,39,49990,"<p>I cannot seem to get the value of learning rate. What I get is below. </p>

<p>I've tried the model for 200 epochs and want to see/change the learning rate. Is this not the correct way?</p>

<pre><code>&gt;&gt;&gt; print(ig_cnn_model.optimizer.lr)
&lt;tf.Variable 'lr_6:0' shape=() dtype=float32_ref&gt;
</code></pre>
",3657151.0,,7117003.0,,2018-04-12 10:20:30,2022-04-02 00:34:22,Get learning rate of keras model,<python><machine-learning><neural-network><keras>,7,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49785536
42532386,1,42539325,,2017-03-01 12:56:56,,39,48021,"<p>I'm trying to predict the water usage of a population.</p>

<p>I have 1 main input:</p>

<ul>
<li>Water volume</li>
</ul>

<p>and 2 secondary inputs:</p>

<ul>
<li>Temperature</li>
<li>Rainfall</li>
</ul>

<p>In theory they have a relation with the water supply. </p>

<p>It must be said that each rainfall and temperature data correspond with the water volume. So this is a time series problem.</p>

<p>The problem is that I don't know how to use 3 inputs from just one .csv file, with 3 columns, each one for each input, as the code below is made. When I have just one input (e.g.water volume) the network works more or less good with this code, but not when I have more than one. (So if you run this code with the csv file below, it will show a dimension error).</p>

<p>Reading some answers from:</p>

<ul>
<li><a href=""http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a></li>
<li><a href=""http://machinelearningmastery.com/time-series-forecast-study-python-annual-water-usage-baltimore/"" rel=""noreferrer"">Time Series Forecast Case Study with Python: Annual Water Usage in Baltimore</a></li>
</ul>

<p>it seems to be that many people have the same problem.</p>

<p>The code:</p>

<p><strong>EDIT:</strong> Code has been updated</p>

<pre><code>import numpy
import matplotlib.pyplot as plt
import pandas
import math

from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error


# convert an array of values into a dataset matrix

def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i + look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 2])
    return numpy.array(dataX), numpy.array(dataY)



# fix random seed for reproducibility
numpy.random.seed(7)


# load the dataset
dataframe = pandas.read_csv('datos.csv', engine='python') 
dataset = dataframe.values

# normalize the dataset
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

# split into train and test sets
train_size = int(len(dataset) * 0.67) 
test_size = len(dataset) - train_size
train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]

# reshape into X=t and Y=t+1
look_back = 3
trainX, trainY = create_dataset(train, look_back)  
testX, testY = create_dataset(test, look_back)

# reshape input to be  [samples, time steps, features]
trainX = numpy.reshape(trainX, (trainX.shape[0], look_back, 3))
testX = numpy.reshape(testX, (testX.shape[0],look_back, 3))

# create and fit the LSTM network

model = Sequential()
model.add(LSTM(4, input_dim=look_back))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
history= model.fit(trainX, trainY,validation_split=0.33, nb_epoch=200, batch_size=32)

# Plot training
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('pérdida')
plt.xlabel('época')
plt.legend(['entrenamiento', 'validación'], loc='upper right')
plt.show()

# make predictions
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

# Get something which has as many features as dataset
trainPredict_extended = numpy.zeros((len(trainPredict),3))
# Put the predictions there
trainPredict_extended[:,2] = trainPredict[:,0]
# Inverse transform it and select the 3rd column.
trainPredict = scaler.inverse_transform(trainPredict_extended) [:,2]  
print(trainPredict)
# Get something which has as many features as dataset
testPredict_extended = numpy.zeros((len(testPredict),3))
# Put the predictions there
testPredict_extended[:,2] = testPredict[:,0]
# Inverse transform it and select the 3rd column.
testPredict = scaler.inverse_transform(testPredict_extended)[:,2]   


trainY_extended = numpy.zeros((len(trainY),3))
trainY_extended[:,2]=trainY
trainY=scaler.inverse_transform(trainY_extended)[:,2]


testY_extended = numpy.zeros((len(testY),3))
testY_extended[:,2]=testY
testY=scaler.inverse_transform(testY_extended)[:,2]


# calculate root mean squared error
trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY, testPredict))
print('Test Score: %.2f RMSE' % (testScore))

# shift train predictions for plotting
trainPredictPlot = numpy.empty_like(dataset)
trainPredictPlot[:, :] = numpy.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, 2] = trainPredict

# shift test predictions for plotting
testPredictPlot = numpy.empty_like(dataset)
testPredictPlot[:, :] = numpy.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, 2] = testPredict



#plot

 serie,=plt.plot(scaler.inverse_transform(dataset)[:,2])  
prediccion_entrenamiento,=plt.plot(trainPredictPlot[:,2],linestyle='--')  
prediccion_test,=plt.plot(testPredictPlot[:,2],linestyle='--')
plt.title('Consumo de agua')
plt.ylabel('cosumo (m3)')
plt.xlabel('dia')
plt.legend([serie,prediccion_entrenamiento,prediccion_test],['serie','entrenamiento','test'], loc='upper right')
</code></pre>

<p>This is the csv file I have created, if it helps.</p>

<p><a href=""https://pastebin.com/qZv5HygU"" rel=""noreferrer"">datos.csv</a></p>

<p>After changing the code, I fixed all the errors, but I'm not really sure about the results. This is a zoom in the prediction plot:
<a href=""https://i.stack.imgur.com/gEJHZ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/gEJHZ.png"" alt=""Zoom on plot""></a></p>

<p>which shows that there is a ""displacement"" in the values predicted and in the real ones. When there is a max in the real time series, there is a min in the forecast for the same time, but it seems like it corresponds to the previous time step.</p>
",7553189.0,,463213.0,,2017-10-10 22:42:43,2019-01-03 16:54:45,How to work with multiple inputs for LSTM in Keras?,<python><neural-network><deep-learning><keras>,2,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42532386
44583254,1,44583919,,2017-06-16 07:23:45,,38,116429,"<p>I am trying for multi-class classification and here are the details of my training input and output:</p>

<blockquote>
  <p>train_input.shape= (1, 95000, 360) (95000 length input array with each
  element being an array of 360 length)</p>
  
  <p>train_output.shape = (1, 95000, 22) (22 Classes are there)</p>
</blockquote>

<pre><code>model = Sequential()

model.add(LSTM(22, input_shape=(1, 95000,360)))
model.add(Dense(22, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
model.fit(train_input, train_output, epochs=2, batch_size=500)
</code></pre>

<p>The error is:</p>

<blockquote>
  <p>ValueError: Input 0 is incompatible with layer lstm_13: expected ndim=3, found ndim=4
  in line:
  model.add(LSTM(22, input_shape=(1, 95000,360)))</p>
</blockquote>

<p>Please help me out, I am not able to solve it through other answers.</p>
",5697891.0,,,,,2021-10-27 05:26:06,"ValueError: Input 0 is incompatible with layer lstm_13: expected ndim=3, found ndim=4",<python><keras><lstm><recurrent-neural-network>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44583254
47057361,1,47060797,,2017-11-01 14:37:46,,38,27728,"<p>I am trying to implement a sequence-to-sequence task using LSTM by Keras with the TensorFlow backend. The inputs are English sentences with variable lengths. To construct a dataset with 2-D shape <code>[batch_number, max_sentence_length]</code>, I add <code>EOF</code> at the end of the line and pad each sentence with enough placeholders, e.g. <code>#</code>. And then each character in the sentence is transformed into a one-hot vector, so that the dataset has 3-D shape <code>[batch_number, max_sentence_length, character_number]</code>.  After LSTM encoder and decoder layers, softmax cross-entropy between output and target is computed. </p>

<p>To eliminate the padding effect in model training, masking could be used on input and loss function. Mask input in Keras can be done by using <code>layers.core.Masking</code>. In TensorFlow, masking on loss function can be done as follows: <a href=""https://i.stack.imgur.com/CwGRy.png"" rel=""noreferrer"">custom masked loss function in TensorFlow</a>.</p>

<p>However, I don't find a way to realize it in Keras, since a user-defined loss function in Keras only accepts parameters <code>y_true</code> and <code>y_pred</code>. So how to input true <code>sequence_lengths</code> to loss function and mask?</p>

<p>Besides, I find a function <code>_weighted_masked_objective(fn)</code> in <code>\keras\engine\training.py</code>. Its definition is </p>

<blockquote>
  <p>Adds support for masking and sample-weighting to an objective function.</p>
</blockquote>

<p>But it seems that the function can only accept <code>fn(y_true, y_pred)</code>. Is there a way to use this function to solve my problem?</p>

<p>To be specific, I modify the example of Yu-Yang.</p>

<pre><code>from keras.models import Model
from keras.layers import Input, Masking, LSTM, Dense, RepeatVector, TimeDistributed, Activation
import numpy as np
from numpy.random import seed as random_seed
random_seed(123)

max_sentence_length = 5
character_number = 3 # valid character 'a, b' and placeholder '#'

input_tensor = Input(shape=(max_sentence_length, character_number))
masked_input = Masking(mask_value=0)(input_tensor)
encoder_output = LSTM(10, return_sequences=False)(masked_input)
repeat_output = RepeatVector(max_sentence_length)(encoder_output)
decoder_output = LSTM(10, return_sequences=True)(repeat_output)
output = Dense(3, activation='softmax')(decoder_output)

model = Model(input_tensor, output)
model.compile(loss='categorical_crossentropy', optimizer='adam')
model.summary()

X = np.array([[[0, 0, 0], [0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0]],
          [[0, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0]]])
y_true = np.array([[[0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0]], # the batch is ['##abb','#babb'], padding '#'
          [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0]]])

y_pred = model.predict(X)
print('y_pred:', y_pred)
print('y_true:', y_true)
print('model.evaluate:', model.evaluate(X, y_true))
# See if the loss computed by model.evaluate() is equal to the masked loss
import tensorflow as tf
logits=tf.constant(y_pred, dtype=tf.float32)
target=tf.constant(y_true, dtype=tf.float32)
cross_entropy = tf.reduce_mean(-tf.reduce_sum(target * tf.log(logits),axis=2))
losses = -tf.reduce_sum(target * tf.log(logits),axis=2)
sequence_lengths=tf.constant([3,4])
mask = tf.reverse(tf.sequence_mask(sequence_lengths,maxlen=max_sentence_length),[0,1])
losses = tf.boolean_mask(losses, mask)
masked_loss = tf.reduce_mean(losses)
with tf.Session() as sess:
    c_e = sess.run(cross_entropy)
    m_c_e=sess.run(masked_loss)
    print(""tf unmasked_loss:"", c_e)
    print(""tf masked_loss:"", m_c_e)
</code></pre>

<p>The output in Keras and TensorFlow are compared as follows:</p>

<p><a href=""https://i.stack.imgur.com/iolvf.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/iolvf.png"" alt=""enter image description here""></a> </p>

<p>As shown above, masking is disabled after some kinds of layers. So how to mask the loss function in Keras when those layers are added?    </p>
",8699291.0,,3924118.0,,2019-12-29 23:12:40,2022-10-19 11:19:01,How do I mask a loss function in Keras with the TensorFlow backend?,<keras><lstm><masking><loss-function>,4,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47057361
47538391,1,47549590,,2017-11-28 18:19:00,,38,19645,"<p>The keras <a href=""https://keras.io/layers/normalization/"" rel=""noreferrer""><code>BatchNormalization</code> layer</a> uses <code>axis=-1</code> as a default value and states that the feature axis is typically normalized. Why is this the case?</p>

<p>I suppose this is surprising because I'm more familiar with using something like <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"" rel=""noreferrer""><code>StandardScaler</code></a>, which would be equivalent to using <code>axis=0</code>. This would normalize the features individually.</p>

<p>Is there a reason why samples are individually normalized by default (i.e. <code>axis=-1</code>) in keras as opposed to features?</p>

<p><strong>Edit: example for concreteness</strong></p>

<p>It's common to transform data such that each feature has zero mean and unit variance. Let's just consider the ""zero mean"" part with this mock dataset, where each row is a sample:</p>

<pre><code>&gt;&gt;&gt; data = np.array([[   1,   10,  100, 1000],
                     [   2,   20,  200, 2000],
                     [   3,   30,  300, 3000]])

&gt;&gt;&gt; data.mean(axis=0)
array([    2.,    20.,   200.,  2000.])

&gt;&gt;&gt; data.mean(axis=1)
array([ 277.75,  555.5 ,  833.25])
</code></pre>

<p>Wouldn't it make more sense to subtract the <code>axis=0</code> mean, as opposed to the <code>axis=1</code> mean? Using <code>axis=1</code>, the units and scales can be completely different.</p>

<p>Edit 2:</p>

<p>The first equation of section 3 in <a href=""https://arxiv.org/pdf/1502.03167.pdf"" rel=""noreferrer"">this paper</a> seems to imply that <code>axis=0</code> should be used for calculating expectations and variances for each feature individually, assuming you have an (m, n) shaped dataset where m is the number of samples and n is the number of features.</p>

<p>Edit 3: another example</p>

<p>I wanted to see the dimensions of the means and variances <code>BatchNormalization</code> was calculating on a toy dataset:</p>

<pre><code>import pandas as pd
import numpy as np
from sklearn.datasets import load_iris

from keras.optimizers import Adam
from keras.models import Model
from keras.layers import BatchNormalization, Dense, Input


iris = load_iris()
X = iris.data
y = pd.get_dummies(iris.target).values

input_ = Input(shape=(4, ))
norm = BatchNormalization()(input_)
l1 = Dense(4, activation='relu')(norm)
output = Dense(3, activation='sigmoid')(l1)

model = Model(input_, output)
model.compile(Adam(0.01), 'categorical_crossentropy')
model.fit(X, y, epochs=100, batch_size=32)

bn = model.layers[1]
bn.moving_mean  # &lt;tf.Variable 'batch_normalization_1/moving_mean:0' shape=(4,) dtype=float32_ref&gt;
</code></pre>

<p>The input X has shape (150, 4), and the <code>BatchNormalization</code> layer calculated 4 means, which means it operated over <code>axis=0</code>.</p>

<p>If <code>BatchNormalization</code> has a default of <code>axis=-1</code> then shouldn't there be 150 means?</p>
",1319915.0,,1319915.0,,2017-11-29 15:17:06,2019-08-16 23:15:19,keras BatchNormalization axis clarification,<python><machine-learning><deep-learning><keras>,3,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47538391
41648129,1,41648242,,2017-01-14 08:29:03,,38,21140,"<p>The keras </p>

<pre><code>ImageDataGenerator
</code></pre>

<p>can be used to ""<a href=""https://keras.io/preprocessing/image/"" rel=""noreferrer"">Generate batches of tensor image data with real-time data augmentation</a>""</p>

<p>The tutorial <a href=""https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"" rel=""noreferrer"">here</a> demonstrates how a small but balanced dataset can be augmented using the ImageDataGenerator. Is there an easy way to use this generator to augment a heavily unbalanced dataset, such that the resulting, generated dataset is balanced?</p>
",1934212.0,,6941400.0,,2020-03-02 15:53:44,2021-05-24 20:22:23,balancing an imbalanced dataset with keras image generator,<keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41648129
47877475,1,48393723,,2017-12-18 22:39:35,,38,17095,"<p>So I am using tensorboard within keras. In tensorflow one could use two different summarywriters for train and validation scalars so that tensorboard could plot them in a same figure. Something like the <strong>figure</strong> in </p>

<p><a href=""https://stackoverflow.com/questions/37146614/tensorboard-plot-training-and-validation-losses-on-the-same-graph"">TensorBoard - Plot training and validation losses on the same graph?</a></p>

<p>Is there a way to do this in keras?</p>

<p>Thanks. </p>
",9050461.0,,,,,2022-10-14 08:38:35,keras tensorboard: plot train and validation scalars in a same figure,<tensorflow><neural-network><keras><tensorboard>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47877475
46560313,1,46580957,,2017-10-04 08:27:54,,38,41139,"<p>I have been working with Keras and really liked the <code>model.summary()</code>
It gives a good overview of the size of the different layers and especially an overview of the number of parameters the model has.</p>

<p>Is there a similar function in Tensorflow? I could find nothing on Stackoverflow or the Tensorflow API documentation.</p>
",8258911.0,,,,,2020-01-04 10:48:12,Is there an easy way to get something like Keras model.summary in Tensorflow?,<tensorflow><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46560313
43833081,1,44615129,,2017-05-07 15:07:57,,38,29166,"<p>Im trying to use Keras (Sequential) but I get the following error when I try to import it:</p>

<pre><code>File ""kaggle_titanic_keras.py"", line 3, in &lt;module&gt;
    from keras.models import Sequential
  File ""/anaconda/lib/python2.7/site-packages/keras/__init__.py"", line 4, in &lt;module&gt;
    from . import applications
  File ""/anaconda/lib/python2.7/site-packages/keras/applications/__init__.py"", line 1, in &lt;module&gt;
    from .vgg16 import VGG16
  File ""/anaconda/lib/python2.7/site-packages/keras/applications/vgg16.py"", line 14, in &lt;module&gt;
    from ..models import Model
  File ""/anaconda/lib/python2.7/site-packages/keras/models.py"", line 14, in &lt;module&gt;
    from . import layers as layer_module
  File ""/anaconda/lib/python2.7/site-packages/keras/layers/__init__.py"", line 4, in &lt;module&gt;
    from ..engine import Layer
  File ""/anaconda/lib/python2.7/site-packages/keras/engine/__init__.py"", line 8, in &lt;module&gt;
    from .training import Model
  File ""/anaconda/lib/python2.7/site-packages/keras/engine/training.py"", line 24, in &lt;module&gt;
    from .. import callbacks as cbks
  File ""/anaconda/lib/python2.7/site-packages/keras/callbacks.py"", line 25, in &lt;module&gt;
    from tensorflow.contrib.tensorboard.plugins import projector
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/__init__.py"", line 30, in &lt;module&gt;
    from tensorflow.contrib import factorization
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/factorization/__init__.py"", line 24, in &lt;module&gt;
    from tensorflow.contrib.factorization.python.ops.gmm import *
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/factorization/python/ops/gmm.py"", line 27, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/__init__.py"", line 87, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn import *
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/__init__.py"", line 23, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn import *
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 25, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn import estimators
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py"", line 297, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 29, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 31, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 49, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py"", line 21, in &lt;module&gt;
    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data
  File ""/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py"", line 26, in &lt;module&gt;
    import dask.dataframe as dd
  File ""/anaconda/lib/python2.7/site-packages/dask/dataframe/__init__.py"", line 3, in &lt;module&gt;
    from .core import (DataFrame, Series, Index, _Frame, map_partitions,
  File ""/anaconda/lib/python2.7/site-packages/dask/dataframe/core.py"", line 38, in &lt;module&gt;
    pd.computation.expressions.set_use_numexpr(False)
AttributeError: 'module' object has no attribute 'computation'
</code></pre>

<p>Im running Python 2.7, TensorFlow 1.1 , Keras 2.0.3 and 'upgraded' to Pandas 0.20.1 yesterday which I suspect is causing the problem but the error message says nothing about it.</p>
",6094602.0,,3001761.0,,2017-05-07 15:08:38,2017-11-06 12:33:08,AttributeError: 'module' object has no attribute 'computation',<python><python-2.7><import><module><keras>,5,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43833081
48491737,1,48506964,,2018-01-28 21:53:12,,38,15134,"<h2>Sources</h2>
<p>There are several sources out there explaining stateful / stateless LSTMs and the role of batch_size which I've read already. I'll refer to them later in my post:</p>
<p>[<a href=""https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">1</a>] <a href=""https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/</a></p>
<p>[<a href=""https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/"" rel=""noreferrer"">2</a>] <a href=""https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/"" rel=""noreferrer"">https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/</a></p>
<p>[<a href=""http://philipperemy.github.io/keras-stateful-lstm/"" rel=""noreferrer"">3</a>] <a href=""http://philipperemy.github.io/keras-stateful-lstm/"" rel=""noreferrer"">http://philipperemy.github.io/keras-stateful-lstm/</a></p>
<p>[<a href=""https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"" rel=""noreferrer"">4</a>] <a href=""https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"" rel=""noreferrer"">https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/</a></p>
<p>And also other SO threads like <a href=""https://stackoverflow.com/questions/38714959/understanding-keras-lstms"">Understanding Keras LSTMs</a> and <a href=""https://stackoverflow.com/questions/39681046/keras-stateful-vs-stateless-lstms"">Keras - stateful vs stateless LSTMs</a> which didn't fully explain what I'm looking for however.</p>
<hr />
<h2>My Problem</h2>
<p>I am still not sure what is the correct approach for my task regarding statefulness and determining batch_size.</p>
<p>I have about 1000 independent time series (<code>samples</code>) that have a length of about 600 days (<code>timesteps</code>) each (actually variable length, but I thought about trimming the data to a constant timeframe) with 8 features (or <code>input_dim</code>) for each timestep (some of the features are identical to every sample, some individual per sample).</p>
<p><code>Input shape = (1000, 600, 8)</code></p>
<p>One of the features is the one I want to predict, while the others are (supposed to be) supportive for the prediction of this one “master feature”. I will do that for each of the 1000 time series. What would be the best strategy to model this problem?</p>
<p><code>Output shape = (1000, 600, 1)</code></p>
<hr />
<h2>What is a Batch?</h2>
<p>From [<a href=""https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"" rel=""noreferrer"">4</a>]:</p>
<blockquote>
<p>Keras uses fast symbolic mathematical libraries as a backend, such as TensorFlow and Theano.</p>
<p>A downside of using these libraries is that the shape and size of your data must be defined once up front and held constant regardless of whether you are training your network or making predictions.</p>
<p>[…]</p>
<p>This does become a problem when you wish to make fewer predictions than the batch size. For example, you may get the best results with a large batch size, but are required to make predictions for one observation at a time on something like a time series or sequence problem.</p>
</blockquote>
<p>This sounds to me like a “batch” would be splitting the data along the <code>timesteps</code>-dimension.</p>
<p>However, [<a href=""http://philipperemy.github.io/keras-stateful-lstm/"" rel=""noreferrer"">3</a>] states that:</p>
<blockquote>
<p>Said differently, whenever you train or test your LSTM, you first have to build your input matrix <code>X</code> of shape <code>nb_samples, timesteps, input_dim</code> where your batch size divides <code>nb_samples</code>. For instance, if <code>nb_samples=1024</code> and <code>batch_size=64</code>, it means that your model will receive blocks of 64 samples, compute each output (whatever the number of timesteps is for every sample), average the gradients and propagate it to update the parameters vector.</p>
</blockquote>
<p>When looking deeper into the examples of [<a href=""https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">1</a>] and [<a href=""https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"" rel=""noreferrer"">4</a>], Jason is always splitting his time series to several samples that only contain 1 timestep (the predecessor that in his example fully determines the next element in the sequence). So I think the batches are really split along the <code>samples</code>-axis. (However his approach of time series splitting doesn’t make sense to me for a long-term dependency problem.)</p>
<p><strong>Conclusion</strong></p>
<p>So let’s say I pick <code>batch_size=10</code>, that means during one epoch the weights are updated 1000 / 10 = 100 times with 10 randomly picked, complete time series containing 600 x 8 values, and when I later want to make predictions with the model, I’ll always have to feed it batches of 10 complete time series (or use <em>solution 3</em> from [<a href=""https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"" rel=""noreferrer"">4</a>], copying the weights to a new model with different batch_size).</p>
<p>Principles of batch_size understood – <em>however still not knowing what would be a <strong>good value for batch_size.</strong> and how to determine it</em></p>
<hr />
<h2>Statefulness</h2>
<p>The <a href=""https://keras.io/layers/recurrent/#rnn"" rel=""noreferrer"">KERAS documentation</a> tells us</p>
<blockquote>
<p>You can set RNN layers to be 'stateful', which means that the states computed for the samples in one batch will be reused as initial states for the samples in the next batch.</p>
</blockquote>
<p><em><strong>If I’m splitting my time series</strong> into several <code>samples</code> (like in the examples of [<a href=""https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">1</a>] and [<a href=""https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"" rel=""noreferrer"">4</a>]) so that the dependencies I’d like to model span across several batches, <strong>or the batch-spanning samples are otherwise correlated</strong> with each other, I may <strong>need a stateful net</strong>, otherwise not. Is that a correct and complete conclusion?</em></p>
<p>So for my problem I suppose I won’t need a stateful net. I’d build my training data as a 3D array of the shape <code>(samples, timesteps, features)</code> and then call <code>model.fit</code> with a batch_size yet to determine. Sample code could look like:</p>
<pre><code>model = Sequential()
model.add(LSTM(32, input_shape=(600, 8)))   # (timesteps, features)
model.add(LSTM(32))
model.add(LSTM(32))
model.add(LSTM(32))
model.add(Dense(1, activation='linear'))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(X, y, epochs=500, batch_size=batch_size, verbose=2)
</code></pre>
",3104974.0,,3104974.0,,2020-06-30 11:35:25,2020-06-30 11:35:25,Understanding Keras LSTMs: Role of Batch-size and Statefulness,<python><keras><lstm><recurrent-neural-network>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48491737
43457862,1,43459357,,2017-04-17 19:05:18,,37,42702,"<p>I was confused by this problem for several days...</p>

<p>My question is that why the training time has such massive difference between that I set the batch_size to be ""1"" and ""20"" for my generator.</p>

<p>If I set the <strong>batch_size</strong> to be <strong>1</strong>, the <strong>training time</strong> of <em><strong>1 epoch</strong></em> is approximately <strong>180 ~ 200 sec</strong>.
If I set the <strong>batch_size</strong> to be <strong>20</strong>, the <strong>training time</strong> of <strong>1 epoch</strong> is approximately <strong>3000 ~ 3200 sec</strong>. </p>

<p>However, this horrible difference between these training times seems to be abnormal..., since it should be the reversed result:
batch_size = 1, training time -> 3000 ~ 3200 sec.
batch_size = 20, training time -> 180 ~ 200 sec.</p>

<p>The input to my generator is not the file path, but the numpy arrays which are already loaded into the
memory via calling ""np.load()"".
So I think the I/O trade-off issue doesn't exist.</p>

<p>I'm using Keras-2.0.3 and my backend is tensorflow-gpu 1.0.1</p>

<p>I have seen the update of this merged <a href=""https://github.com/fchollet/keras/pull/5879/files"" rel=""noreferrer"">PR</a>,
but it seems that this change won't affect anything at all. (the usage is just the same with original one)</p>

<p>The <a href=""https://gist.github.com/HappyStorm/cb6c22ffec18a8fbb4912e9c79b6d87c"" rel=""noreferrer"">link</a> here is the gist of my self-defined generator and the part of my fit_generator.</p>
",3844231.0,,1140335.0,,2019-07-31 12:50:29,2020-12-29 13:16:11,"What's the difference between ""samples_per_epoch"" and ""steps_per_epoch"" in fit_generator",<keras>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43457862
53183865,1,53656253,,2018-11-07 05:09:17,,37,49088,"<p>I trained my CNN (VGG) through google colab and generated .h5 file. Now problem is, I can predict my output successfully through google colab but when i download that .h5 trained model file and try to predict output on my laptop, I am getting error when loading the model.</p>

<p>Here is the code:</p>

<pre><code>import tensorflow as tf
from tensorflow import keras
import h5py

# Initialization

loaded_model = keras.models.load_model('./train_personCount_model.h5')
</code></pre>

<p>And the error:</p>

<pre><code>ValueError: Unknown initializer: GlorotUniform
</code></pre>
",8614829.0,,4685471.0,,2018-11-07 11:10:48,2021-01-12 08:44:34,Unknown initializer: GlorotUniform when loading Keras model,<python><tensorflow><machine-learning><keras><google-colaboratory>,11,6,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53183865
44068899,1,44069109,,2017-05-19 11:29:29,,37,10662,"<p>Now that TensorFlow 1.1 supports the Keras API under <code>tf.contrib.keras</code>, which one should I use if I intend to use Keras with a TF backend?</p>

<p>Is the <code>tf.contrib.keras</code> version different in any way than a regular Keras distribution? (TF specific optimizations of internal data structures come to mind). Is there any benefit in terms of using Keras and TensorFlow Core together if I use one or the other?</p>

<p>Or is <code>tf.contrib.keras</code> simply a copy of the same codebase as Keras but under a different namespace?</p>
",72583.0,,1735003.0,,2019-04-03 08:55:09,2019-11-14 08:47:13,What is the difference between Keras and tf.keras in TensorFlow 1.1+?,<tensorflow><keras>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44068899
42475381,1,42476116,,2017-02-26 23:08:45,,37,17887,"<p>In <code>keras.applications</code>, there is a VGG16 model pre-trained on imagenet.</p>

<pre><code>from keras.applications import VGG16
model = VGG16(weights='imagenet')
</code></pre>

<p>This model has the following structure.</p>

<pre><code>
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 3, 224, 224)   0                                            
____________________________________________________________________________________________________
block1_conv1 (Convolution2D)     (None, 64, 224, 224)  1792        input_1[0][0]                    
____________________________________________________________________________________________________
block1_conv2 (Convolution2D)     (None, 64, 224, 224)  36928       block1_conv1[0][0]               
____________________________________________________________________________________________________
block1_pool (MaxPooling2D)       (None, 64, 112, 112)  0           block1_conv2[0][0]               
____________________________________________________________________________________________________
block2_conv1 (Convolution2D)     (None, 128, 112, 112) 73856       block1_pool[0][0]                
____________________________________________________________________________________________________
block2_conv2 (Convolution2D)     (None, 128, 112, 112) 147584      block2_conv1[0][0]               
____________________________________________________________________________________________________
block2_pool (MaxPooling2D)       (None, 128, 56, 56)   0           block2_conv2[0][0]               
____________________________________________________________________________________________________
block3_conv1 (Convolution2D)     (None, 256, 56, 56)   295168      block2_pool[0][0]                
____________________________________________________________________________________________________
block3_conv2 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv1[0][0]               
____________________________________________________________________________________________________
block3_conv3 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv2[0][0]               
____________________________________________________________________________________________________
block3_pool (MaxPooling2D)       (None, 256, 28, 28)   0           block3_conv3[0][0]               
____________________________________________________________________________________________________
block4_conv1 (Convolution2D)     (None, 512, 28, 28)   1180160     block3_pool[0][0]                
____________________________________________________________________________________________________
block4_conv2 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv1[0][0]               
____________________________________________________________________________________________________
block4_conv3 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv2[0][0]               
____________________________________________________________________________________________________
block4_pool (MaxPooling2D)       (None, 512, 14, 14)   0           block4_conv3[0][0]               
____________________________________________________________________________________________________
block5_conv1 (Convolution2D)     (None, 512, 14, 14)   2359808     block4_pool[0][0]                
____________________________________________________________________________________________________
block5_conv2 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv1[0][0]               
____________________________________________________________________________________________________
block5_conv3 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv2[0][0]               
____________________________________________________________________________________________________
block5_pool (MaxPooling2D)       (None, 512, 7, 7)     0           block5_conv3[0][0]               
____________________________________________________________________________________________________
flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                
____________________________________________________________________________________________________
fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    
____________________________________________________________________________________________________
fc2 (Dense)                      (None, 4096)          16781312    fc1[0][0]                        
____________________________________________________________________________________________________
predictions (Dense)              (None, 1000)          4097000     fc2[0][0]                        
====================================================================================================
Total params: 138,357,544
Trainable params: 138,357,544
Non-trainable params: 0
____________________________________________________________________________________________________

</code></pre>

<p>I would like to fine-tune this model with dropout layers between the dense layers (fc1, fc2 and predictions), while keeping all the pre-trained weights of the model intact. I know it's possible to access each layer individually with <code>model.layers</code>, but I haven't found anywhere how to add new layers between the existing layers.</p>

<p>What's the best practice of doing this?</p>
",1647057.0,,1647057.0,,2019-09-24 13:47:50,2020-03-06 21:45:32,Add dropout layers between pretrained dense layers in keras,<python><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42475381
52265978,1,52267075,,2018-09-10 21:52:11,,37,109204,"<p>I'm trying to delete a file that I uploaded on Google colab using the following code:</p>

<pre><code>from google.colab import files
uploaded = files.upload()
</code></pre>

<p>How to delete the file now? e.g If the file's name is 'sample.jpg' .</p>
",8185479.0,,,,,2022-11-26 10:04:19,How to delete a locally uploaded file on google colab?,<python-3.x><keras><jupyter-notebook><google-colaboratory>,11,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52265978
52570199,1,52570297,,2018-09-29 16:13:42,,37,14893,"<p>I am working on a Time Series Forecasting problem using LSTM. 
The input contains several features, so I am using a Multivariate LSTM.
The problem is that there are some missing values, for example:</p>

<pre><code>    Feature 1     Feature 2  ...  Feature n
 1    2               4             nan
 2    5               8             10
 3    8               8              5
 4    nan             7              7
 5    6              nan            12
</code></pre>

<p>Instead of interpolating the missing values, that can introduce bias in the results, because sometimes there are a lot of consecutive timestamps with missing values on the same feature, I would like to know if there is a way to let the LSTM learn with the missing values, for example, using a masking layer or something like that? Can someone explain to me what will be the best approach to deal with this problem?
I am using Tensorflow and Keras.</p>
",8901144.0,,2099607.0,,2018-09-29 17:59:55,2021-05-23 03:22:31,Multivariate LSTM with missing values,<tensorflow><neural-network><keras><lstm><missing-data>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52570199
43481490,1,43481605,,2017-04-18 20:19:49,,37,32629,"<p>I'd like to use class_weight argument in keras model.fit to handle the imbalanced training data. By looking at some documents, I understood we can pass a dictionary like this:</p>

<pre><code>class_weight = {0 : 1,
    1: 1,
    2: 5}
</code></pre>

<p>(In this example, class-2 will get higher penalty in the loss function.)</p>

<p>The problem is that my network's output has one-hot encoding i.e. class-0 = (1, 0, 0), class-1 = (0, 1, 0), and class-3 = (0, 0, 1).</p>

<p>How can we use the class_weight for one-hot encoded output?</p>

<p>By looking at <a href=""https://github.com/fchollet/keras/blob/d89afdfd82e6e27b850d910890f4a4059ddea331/keras/engine/training.py#L1307"" rel=""noreferrer"">some codes in Keras</a>, it looks like <code>_feed_output_names</code> contain a list of output classes, but in my case, <code>model.output_names</code>/<code>model._feed_output_names</code> returns <code>['dense_1']</code></p>

<p>Related: <a href=""https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras"">How to set class weights for imbalanced classes in Keras?</a></p>
",3109554.0,,,,,2023-01-11 19:26:24,Keras: class weights (class_weight) for one-hot encoding,<python><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43481490
47485216,1,53470422,,2017-11-25 11:03:49,,36,17853,"<p>I thought <code>mask_zero=True</code> will output 0's when the input value is 0, so the following layers could skip computation or something.</p>

<p>How does <code>mask_zero</code> works? </p>

<p>Example: </p>

<pre><code>data_in = np.array([
  [1, 2, 0, 0]
])
data_in.shape
&gt;&gt;&gt; (1, 4)

# model
x = Input(shape=(4,))
e = Embedding(5, 5, mask_zero=True)(x)

m = Model(inputs=x, outputs=e)
p = m.predict(data_in)
print(p.shape)
print(p)
</code></pre>

<p>The actual output is: (the numbers are random)</p>

<pre><code>(1, 4, 5)
[[[ 0.02499047  0.04617121  0.01586803  0.0338897   0.009652  ]
  [ 0.04782704 -0.04035913 -0.0341589   0.03020919 -0.01157228]
  [ 0.00451764 -0.01433611  0.02606953  0.00328832  0.02650392]
  [ 0.00451764 -0.01433611  0.02606953  0.00328832  0.02650392]]]
</code></pre>

<p>However, I thought the output will be:</p>

<pre><code>[[[ 0.02499047  0.04617121  0.01586803  0.0338897   0.009652  ]
  [ 0.04782704 -0.04035913 -0.0341589   0.03020919 -0.01157228]
  [ 0 0 0 0 0]
  [ 0 0 0 0 0]]]
</code></pre>
",1461746.0,,2099607.0,,2018-11-25 18:13:23,2020-04-08 13:50:35,How does mask_zero in Keras Embedding layer work?,<python><machine-learning><keras><word-embedding>,2,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47485216
47183159,1,47183890,,2017-11-08 15:10:59,,36,63483,"<p>I am having trouble with the Keras backend functions for setting values.  I am trying to convert a model from PyTorch to Keras and am trying to set the weights of the Keras model, but the weights do not appear to be getting set.  Note: I am not actually setting with np.ones just using that for an example.</p>

<p>I have tried...</p>

<p>Loading an existing model</p>

<pre><code>import keras
from keras.models import load_model, Model
model = load_model(model_dir+file_name)
keras_layer = [layer for layer in model.layers if layer.name=='conv2d_1'][0]
</code></pre>

<p>Creating a simple model</p>

<pre><code>img_input = keras.layers.Input(shape=(3,3,3))
x = keras.layers.Conv2D(1, kernel_size=1, strides=1, padding=""valid"", 
use_bias=False, name='conv1')(img_input)
model = Model(img_input, x)
keras_layer = [layer for layer in model.layers if layer.name=='conv1'][0]
</code></pre>

<p>Then using set_weights or set_value</p>

<pre><code>keras_layer.set_weights([np.ones((1, 1, 3, 1))])
</code></pre>

<p>or...</p>

<pre><code>K.batch_set_value([(weight,np.ones((1, 1, 3, 1))) for weight in keras_layer.weights])
</code></pre>

<p>afterwards I call either one of the following:</p>

<pre><code>K.batch_get_value([weight for weight in keras_layer.weights])
keras_layer.get_weights()
</code></pre>

<p>And None of the weights appear to have been set.  The same values as before are returned.</p>

<pre><code>[array([[[[  1.61547325e-06],
      [  2.97779252e-06],
      [  1.50160542e-06]]]], dtype=float32)]
</code></pre>

<p>How do I set the weights of a layer in Keras with a numpy array of values?</p>
",5129113.0,,6796042.0,,2020-03-05 10:23:24,2020-03-05 10:23:24,How to set weights in Keras with a numpy array?,<python><tensorflow><machine-learning><keras><deep-learning>,3,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47183159
43702481,1,43770736,,2017-04-30 02:56:34,,36,33235,"<p>When using a Keras LSTM to predict on time series data I've been getting errors when I'm trying to train the model using a batch size of 50, while then trying to predict on the same model using a batch size of 1 (ie just predicting the next value).  </p>

<p>Why am I not able to train and fit the model with multiple batches at once, and then use that model to predict for anything other than the same batch size.  It doesn't seem to make sense, but then I could easily be missing something about this.</p>

<p>Edit:  this is the model.  <code>batch_size</code> is 50, <code>sl</code> is sequence length, which is set at 20 currently.</p>

<pre><code>    model = Sequential()
    model.add(LSTM(1, batch_input_shape=(batch_size, 1, sl), stateful=True))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=2)
</code></pre>

<p>here is the line for predicting on the training set for RMSE</p>

<pre><code>    # make predictions
    trainPredict = model.predict(trainX, batch_size=batch_size)
</code></pre>

<p>here is the actual prediction of unseen time steps</p>

<pre><code>for i in range(test_len):
    print('Prediction %s: ' % str(pred_count))

    next_pred_res = np.reshape(next_pred, (next_pred.shape[1], 1, next_pred.shape[0]))
    # make predictions
    forecastPredict = model.predict(next_pred_res, batch_size=1)
    forecastPredictInv = scaler.inverse_transform(forecastPredict)
    forecasts.append(forecastPredictInv)
    next_pred = next_pred[1:]
    next_pred = np.concatenate([next_pred, forecastPredict])

    pred_count += 1
</code></pre>

<p>This issue is with the line:</p>

<p><code>forecastPredict = model.predict(next_pred_res, batch_size=batch_size)</code></p>

<p>The error when batch_size here is set to 1 is:</p>

<p><code>ValueError: Cannot feed value of shape (1, 1, 2) for Tensor 'lstm_1_input:0', which has shape '(10, 1, 2)'</code> which is the same error that throws when <code>batch_size</code> here is set to 50 like the other batch sizes as well.</p>

<p>The total error is:</p>

<pre><code>    forecastPredict = model.predict(next_pred_res, batch_size=1)
  File ""/home/entelechy/tf_keras/lib/python3.5/site-packages/keras/models.py"", line 899, in predict
    return self.model.predict(x, batch_size=batch_size, verbose=verbose)
  File ""/home/entelechy/tf_keras/lib/python3.5/site-packages/keras/engine/training.py"", line 1573, in predict
    batch_size=batch_size, verbose=verbose)
   File ""/home/entelechy/tf_keras/lib/python3.5/site-packages/keras/engine/training.py"", line 1203, in _predict_loop
    batch_outs = f(ins_batch)
  File ""/home/entelechy/tf_keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2103, in __call__
    feed_dict=feed_dict)
  File ""/home/entelechy/tf_keras/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/home/entelechy/tf_keras/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 944, in _run
    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (1, 1, 2) for Tensor 'lstm_1_input:0', which has shape '(10, 1, 2)'
</code></pre>

<p>Edit:  Once I set the model to <code>stateful=False</code> then I am able to use different batch sizes for fitting/training and prediction.  What is the reason for this?</p>
",5355831.0,,5355831.0,,2017-05-03 02:54:06,2021-10-08 16:27:47,Why does Keras LSTM batch size used for prediction have to be the same as fitting batch size?,<deep-learning><keras><lstm>,7,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43702481
40310035,1,40310928,,2016-10-28 17:11:59,,36,49697,"<p>I have installed Keras, and wanted to switch the backend to Theano. I checked out <a href=""https://stackoverflow.com/questions/40036748/keras-backend-importerror-cannot-import-name-ctc-ops"">this post</a>, but still have no idea where to put the created json file. Also, below is the error I got when running <code>import keras</code> in Python Shell:</p>

<blockquote>
  <p>Using TensorFlow backend.</p>
  
  <p>Traceback (most recent call last):   File """", line 1, in
  
      import keras   File ""C:\Python27\lib\site-packages\keras__init__.py"", line 2, in 
      from . import backend   File ""C:\Python27\lib\site-packages\keras\backend__init__.py"", line 64, in
  
      from .tensorflow_backend import *   File ""C:\Python27\lib\site-packages\keras\backend\tensorflow_backend.py"",
  line 1, in 
      import tensorflow as tf ImportError: No module named tensorflow</p>
</blockquote>

<p>When running <code>python -c ""import keras; print(keras.__version__)""</code> from Windows command line, I got:</p>

<blockquote>
  <p>Using TensorFlow backend. Traceback (most recent call last):   File
  """", line 1, in    File
  ""C:\Python27\lib\site-packages\keras__init__.py"", line 2, in 
      from . import backend   File ""C:\Python27\lib\site-packages\keras\backend__init__.py"", line 64, in
  
      from .tensorflow_backend import *   File ""C:\Python27\lib\site-packages\keras\backend\tensorflow_backend.py"",
  line 1, in 
      import tensorflow as tf ImportError: No module named tensorflow</p>
</blockquote>

<p>Can someone please help? Thanks!</p>
",4896087.0,,-1.0,,2017-05-23 12:18:26,2019-06-20 17:39:10,How to change Keras backend (where's the json file)?,<python><command-line><theano><keras>,12,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40310035
44704435,1,44704745,,2017-06-22 16:04:17,,36,74774,"<p>My input is simply a csv file with 339732 rows and two columns :</p>

<ul>
<li>the first being 29 feature values, i.e. X</li>
<li>the second being a binary label value, i.e. Y</li>
</ul>

<p>I am trying to train my data on a stacked LSTM model:</p>

<pre><code>data_dim = 29
timesteps = 8
num_classes = 2

model = Sequential()
model.add(LSTM(30, return_sequences=True,
               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 30
model.add(LSTM(30, return_sequences=True))  # returns a sequence of vectors of dimension 30
model.add(LSTM(30))  # return a single vector of dimension 30
model.add(Dense(1, activation='softmax'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

model.summary()
model.fit(X_train, y_train, batch_size = 400, epochs = 20, verbose = 1)
</code></pre>

<p>This throws the error:</p>

<blockquote>
  <p>Traceback (most recent call last):
    File ""first_approach.py"", line 80, in 
      model.fit(X_train, y_train, batch_size = 400, epochs = 20, verbose = 1)</p>
  
  <p>ValueError: Error when checking model input: expected lstm_1_input to
  have 3 dimensions, but got array with shape (339732, 29)</p>
</blockquote>

<p>I tried reshaping my input using <code>X_train.reshape((1,339732, 29))</code> but it did not work showing error:</p>

<blockquote>
  <p>ValueError: Error when checking model input: expected lstm_1_input to
  have shape (None, 8, 29) but got array with shape (1, 339732, 29)</p>
</blockquote>

<p>How can I feed in my input to the LSTM ?</p>
",5140684.0,,,,,2018-12-07 09:43:10,"Error when checking model input: expected lstm_1_input to have 3 dimensions, but got array with shape (339732, 29)",<python><keras><lstm><recurrent-neural-network><valueerror>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44704435
52133347,1,52141755,,2018-09-02 01:38:12,,36,57396,"<p>I have a problem when training a neural net with Keras in Jupyter Notebook. I created a sequential model with several hidden layers. After training the model and saving the results, I want to delete this model and create a new model in the same session, as I have a <code>for</code> loop that checks the results for different parameters. But as I understand the errors I get, when changing the parameters, when I loop over, I am just adding layers to the model (even though I initialise it again with <code>network = Sequential()</code> inside the loop). So my question is, how can I completely clear the previous model or how can I initialise a completely new model in the same session?</p>
",4959244.0,,,,,2022-04-07 00:10:22,How can I clear a model created with Keras and Tensorflow(as backend)?,<python><tensorflow><keras><jupyter-notebook>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52133347
49922252,1,49924566,,2018-04-19 13:23:36,,36,68679,"<p>If I want to train a model with train_generator, is there a significant difference between choosing</p>
<ul>
<li>10 Epochs with 500 Steps each</li>
</ul>
<p>and</p>
<ul>
<li>100 Epochs with 50 Steps each</li>
</ul>
<p>Currently I am training for 10 epochs, because each epoch takes a long time, but any graph showing improvement looks very &quot;jumpy&quot; because I only have 10 datapoints. I figure I can get a smoother graph if I use 100 Epochs, but I want to know first if there is any downside to this</p>
",9535607.0,,5662006.0,,2020-11-09 17:09:08,2022-08-08 17:31:05,Choosing number of Steps per Epoch,<tensorflow><machine-learning><keras><deep-learning><neural-network>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/49922252
44611006,1,44616780,,2017-06-18 01:41:08,,36,14458,"<p>I'm building a model that converts a string to another string using recurrent layers (GRUs). I have tried both a Dense and a TimeDistributed(Dense) layer as the last-but-one layer, but I don't understand the difference between the two when using return_sequences=True, especially as they seem to have the same number of parameters.</p>

<p>My simplified model is the following:</p>

<pre><code>InputSize = 15
MaxLen = 64
HiddenSize = 16

inputs = keras.layers.Input(shape=(MaxLen, InputSize))
x = keras.layers.recurrent.GRU(HiddenSize, return_sequences=True)(inputs)
x = keras.layers.TimeDistributed(keras.layers.Dense(InputSize))(x)
predictions = keras.layers.Activation('softmax')(x)
</code></pre>

<p>The summary of the network is:</p>

<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 15)            0         
_________________________________________________________________
gru_1 (GRU)                  (None, 64, 16)            1536      
_________________________________________________________________
time_distributed_1 (TimeDist (None, 64, 15)            255       
_________________________________________________________________
activation_1 (Activation)    (None, 64, 15)            0         
=================================================================
</code></pre>

<p>This makes sense to me as my understanding of TimeDistributed is that it applies the same layer at all timepoints, and so the Dense layer has 16*15+15=255 parameters (weights+biases).</p>

<p>However, if I switch to a simple Dense layer:</p>

<pre><code>inputs = keras.layers.Input(shape=(MaxLen, InputSize))
x = keras.layers.recurrent.GRU(HiddenSize, return_sequences=True)(inputs)
x = keras.layers.Dense(InputSize)(x)
predictions = keras.layers.Activation('softmax')(x)
</code></pre>

<p>I still only have 255 parameters:</p>

<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 64, 15)            0         
_________________________________________________________________
gru_1 (GRU)                  (None, 64, 16)            1536      
_________________________________________________________________
dense_1 (Dense)              (None, 64, 15)            255       
_________________________________________________________________
activation_1 (Activation)    (None, 64, 15)            0         
=================================================================
</code></pre>

<p>I wonder if this is because Dense() will only use the last dimension in the shape, and effectively treat everything else as a batch-like dimension. But then I'm no longer sure what the difference is between Dense and TimeDistributed(Dense).</p>

<p><strong>Update</strong> Looking at <a href=""https://github.com/fchollet/keras/blob/master/keras/layers/core.py"" rel=""noreferrer"">https://github.com/fchollet/keras/blob/master/keras/layers/core.py</a> it does seem that Dense uses the last dimension only to size itself:</p>

<pre class=""lang-python prettyprint-override""><code>def build(self, input_shape):
    assert len(input_shape) &gt;= 2
    input_dim = input_shape[-1]

    self.kernel = self.add_weight(shape=(input_dim, self.units),
</code></pre>

<p>It also uses keras.dot to apply the weights:</p>

<pre class=""lang-python prettyprint-override""><code>def call(self, inputs):
    output = K.dot(inputs, self.kernel)
</code></pre>

<p>The docs of keras.dot imply that it works fine on n-dimensional tensors. I wonder if its exact behavior means that Dense() will in effect be called at every time step. If so, the question still remains what TimeDistributed() achieves in this case.</p>
",7185570.0,,7185570.0,,2017-06-19 10:30:34,2020-10-16 09:55:40,TimeDistributed(Dense) vs Dense in Keras - Same number of parameters,<machine-learning><neural-network><keras><recurrent-neural-network><keras-layer>,2,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44611006
40028175,1,49154874,,2016-10-13 18:16:42,,35,42564,"<p>I'm trying to create a pb file from my Keras (tensorflow backend) model so I can build it on iOS. I'm using freeze.py and I need to pass the output nodes. How do i get the names of the output nodes of my Keras model?</p>

<p><a href=""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py"" rel=""noreferrer"">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py</a></p>
",4926741.0,,,,,2019-07-01 12:55:34,How do you get the name of the tensorflow output nodes in a Keras Model?,<python><tensorflow><keras>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40028175
53153790,1,53154110,,2018-11-05 11:46:59,,35,22784,"<p>I am fine-tuning a MobileNet with 14 new classes. When I add new layers by:</p>

<pre><code>x=mobile.layers[-6].output
x=Flatten(x)
predictions = Dense(14, activation='softmax')(x)
model = Model(inputs=mobile.input, outputs=predictions)
</code></pre>

<p>I get the error:</p>

<pre><code>'Tensor' object has no attribute 'lower'
</code></pre>

<p>Also using:</p>

<pre><code>model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])
model.fit_generator(train_batches, steps_per_epoch=18,
                validation_data=valid_batches, validation_steps=3, epochs=60, verbose=2)
</code></pre>

<p>I get the error:</p>

<pre><code>Error when checking target: expected dense_1 to have 4 dimensions, but got array with shape (10, 14)
</code></pre>

<p>What does <code>lower</code> mean? I saw other fine-tuning scripts and there were no other arguments other than the name of the model which is <code>x</code> in this case.</p>
",10607259.0,,2099607.0,,2020-04-25 05:16:37,2020-04-25 05:16:37,'Tensor' object has no attribute 'lower',<python><tensorflow><machine-learning><keras><conv-neural-network>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53153790
48893528,1,49073626,,2018-02-20 20:16:53,,35,8522,"<p>Which one is the recommended (or more future-proof) way to use Keras?</p>

<p>What are the advantages/disadvantages of each?</p>

<p>I guess there are more differences than simply saving one <code>pip install</code> step and writing <code>tensorflow.python.keras</code> instead of <code>keras</code>.</p>
",1866775.0,,,,,2019-10-29 11:43:23,keras vs. tensorflow.python.keras - which one to use?,<python><tensorflow><pip><deep-learning><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48893528
48547688,1,48552179,,2018-01-31 17:08:03,,34,32959,"<p>Using Keras from Tensorflow 1.4.1, how does one copy weights from one model to another?</p>

<p>As some background, I'm trying to implement a deep-q network (DQN) for Atari games following the DQN publication by DeepMind.  My understanding is that the implementation uses two networks, Q and Q'.  The weights of Q are trained using gradient descent, and then the weights are copied periodically to Q'.</p>

<p>Here's how I build Q and Q':</p>

<pre><code>ACT_SIZE   = 4
LEARN_RATE = 0.0025
OBS_SIZE   = 128

def buildModel():
  model = tf.keras.models.Sequential()

  model.add(tf.keras.layers.Lambda(lambda x: x / 255.0, input_shape=OBS_SIZE))
  model.add(tf.keras.layers.Dense(128, activation=""relu""))
  model.add(tf.keras.layers.Dense(128, activation=""relu""))
  model.add(tf.keras.layers.Dense(ACT_SIZE, activation=""linear""))
  opt = tf.keras.optimizers.RMSprop(lr=LEARN_RATE)

  model.compile(loss=""mean_squared_error"", optimizer=opt)

  return model
</code></pre>

<p>I call that twice to get Q and Q'.</p>

<p>I have an <code>updateTargetModel</code> method below that is my attempt at copying weights.  The code runs fine, but my overall DQN implementation is failing.  I'm really just trying to verify if this is a valid way of copying weights from one network to another.</p>

<pre><code>def updateTargetModel(model, targetModel):
  modelWeights       = model.trainable_weights
  targetModelWeights = targetModel.trainable_weights

  for i in range(len(targetModelWeights)):
    targetModelWeights[i].assign(modelWeights[i])
</code></pre>

<p>There's another question here that discusses saving and loading weights to and from disk (<a href=""https://stackoverflow.com/questions/38065448/tensorflow-copy-weights-issue"">Tensorflow Copy Weights Issue</a>), but there's no accepted answer.  There is also a question about loading weights from individual layers (<a href=""https://stackoverflow.com/questions/47667541/copying-weights-from-one-conv2d-layer-to-another"">Copying weights from one Conv2D layer to another</a>), but I'm wanting to copy the entire model's weights.</p>
",3977276.0,,5974433.0,,2018-04-24 11:35:57,2018-05-22 21:02:52,Tensorflow Keras Copy Weights From One Model to Another,<python-3.x><tensorflow><machine-learning><neural-network><keras>,1,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48547688
43178668,1,43186440,,2017-04-03 07:16:34,,34,21994,"<p>I want to compare the computation time between different models.
During the fit the computation time per epoch is printed to the console.</p>

<pre><code>Epoch 5/5
160000/160000 [==============================] - **10s** ......
</code></pre>

<p>I'm looking for a way to store these times in a similar way to the model metrics that are saved in each epoch and avaliable through the history object.</p>
",6293886.0,,5974433.0,,2017-07-12 21:00:30,2020-07-25 08:33:15,record the computation time for each epoch in Keras during model.fit(),<python><machine-learning><neural-network><deep-learning><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43178668
47079111,1,47081613,,2017-11-02 15:34:31,,34,22743,"<p>
I am building a simple Sequential model in Keras (tensorflow backend). During training I want to inspect the individual training batches and model predictions. Therefore, I am trying to create a custom <code>Callback</code> that saves the model predictions and targets for each training batch. However, the model is not using the current batch for prediction, but the entire training data.</p>

<p>How can I hand over only the current training batch to the <code>Callback</code>?</p>

<p>And how can I access the batches and targets that the <code>Callback</code> saves in self.predhis and self.targets?</p>

<p>My current version looks as follows:</p>

<pre class=""lang-py prettyprint-override""><code>callback_list = [prediction_history((self.x_train, self.y_train))]

self.model.fit(self.x_train, self.y_train, batch_size=self.batch_size, epochs=self.n_epochs, validation_data=(self.x_val, self.y_val), callbacks=callback_list)

class prediction_history(keras.callbacks.Callback):
    def __init__(self, train_data):
        self.train_data = train_data
        self.predhis = []
        self.targets = []

    def on_batch_end(self, epoch, logs={}):
        x_train, y_train = self.train_data
        self.targets.append(y_train)
        prediction = self.model.predict(x_train)
        self.predhis.append(prediction)
        tf.logging.info(""Prediction shape: {}"".format(prediction.shape))
        tf.logging.info(""Targets shape: {}"".format(y_train.shape))
</code></pre>
",7384906.0,,2464597.0,,2017-11-09 01:44:40,2022-02-03 15:13:27,Create keras callback to save model predictions and targets for each batch during training,<tensorflow><callback><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47079111
47787011,1,47790168,,2017-12-13 06:41:13,,34,33947,"<p>I am using dropout in neural network model in keras. Little bit code is like</p>

<pre><code>model.add(Dropout(0.5))
model.add(Dense(classes))
</code></pre>

<p>For testing, I am using <code>preds = model_1.predict_proba(image)</code>.</p>

<p>But while testing <strong>Dropout</strong> is also participating to predict the score which should not be happen. I search a lot to disable the dropout but didn't get any hint yet.</p>

<p>Do anyone have solution to disable the <strong>Dropout</strong> while testing in keras??</p>
",7334187.0,,10375049.0,,2021-03-16 19:40:17,2022-07-04 14:05:25,How to disable dropout while prediction in keras?,<tensorflow><machine-learning><keras><deep-learning><neural-network>,6,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47787011
34717241,1,34721948,,2016-01-11 08:44:13,,34,27452,"<p>This is my code that works if I use other activation layers like tanh:</p>

<pre><code>model = Sequential()
act = keras.layers.advanced_activations.PReLU(init='zero', weights=None)
model.add(Dense(64, input_dim=14, init='uniform'))
model.add(Activation(act))
model.add(Dropout(0.15))
model.add(Dense(64, init='uniform'))
model.add(Activation('softplus'))
model.add(Dropout(0.15))
model.add(Dense(2, init='uniform'))
model.add(Activation('softmax'))

sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='binary_crossentropy', optimizer=sgd)
model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)
</code></pre>

<p>In this case, it doesn't work and says ""TypeError: 'PReLU' object is not callable"" and the error is called at the model.compile line. Why is this the case? All the non-advanced activation functions works. However, neither of the advanced activation functions, including this one, works.</p>
",4984897.0,,,,,2018-02-01 17:09:33,How to use advanced activation layers in Keras?,<python><machine-learning><neural-network><keras><data-science>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/34717241
62465620,1,62482183,,2020-06-19 07:46:07,,34,99820,"<p>I just installed Visual Studio 2019 and Tensorflow, but I cannot import Keras because I get the following error message:</p>
<blockquote>
<p>Keras requires TensorFlow 2.2 or higher. Install TensorFlow via <code>pip install tensorflow</code></p>
</blockquote>
<p>The problem is that I had no choice but to install Tensorflow 1.15, because I have the following setup:</p>
<ul>
<li>Visual Studio 2019</li>
<li>Python 3.7</li>
<li>CPU i7 920 (no avs, only SSE)</li>
<li>OS Windows 7 64</li>
<li>Nvidia GPU</li>
<li>CUDA 10.1</li>
</ul>
<p>I had to download and install a wheel for that Python version, my CPU, and that CUDA version named &quot;tensorflow-1.15.0-cp37-cp37m-win_amd64&quot;.</p>
<p>Tensorflow seems to work (it detects my GPU and prints a &quot;hello world&quot; message) but the problem is that Visual Studio installs the newest version of Keras.</p>
<p>How can I specify an older, compatible version, and what is the newer version compatible?</p>
",9404261.0,,1945525.0,,2020-09-14 20:11:46,2022-01-20 18:57:26,"Error ""Keras requires TensorFlow 2.2 or higher""",<visual-studio><keras>,6,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/62465620
39815518,1,39851572,,2016-10-02 09:11:55,,33,27099,"<p>I am trying to replicate VGG16 model in keras, the following is my code:</p>

<pre><code>model = Sequential()
model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))
model.add(Convolution2D(64, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(64, 3, 3, activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(128, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(128, 3, 3, activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2))) ###This line gives error
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(256, 3, 3, activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, 3, 3, activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, 3, 3, activation='relu'))
model.add(ZeroPadding2D((1,1)))
model.add(Convolution2D(512, 3, 3, activation='relu'))
model.add(MaxPooling2D((2,2), strides=(2,2)))
model.add(Flatten())
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(4096, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1000, activation='softmax'))
</code></pre>

<p>The maxpooling2d layer gives an error at the line which is commented</p>

<p>The error says:</p>

<pre><code>ValueError: Negative dimension size caused by subtracting 2 from 1 for 'MaxPool_7' (op: 'MaxPool') with input shapes: [?,1,112,128].
</code></pre>

<p>What might be the reason behind this? How to solve this?</p>

<p>Edit:
A more detailed error log:</p>

<blockquote>
  <hr>
  
  <p>ValueError                                Traceback (most recent call
  last)  in ()
       12 model.add(Convolution2D(128, 3, 3, activation='relu'))
       13 
  ---> 14 model.add(MaxPooling2D((2,2), strides=(2,2)))
       15 
       16 model.add(ZeroPadding2D((1,1)))</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/keras/models.pyc in add(self,
  layer)
      306                  output_shapes=[self.outputs[0]._keras_shape])
      307         else:
  --> 308             output_tensor = layer(self.outputs[0])
      309             if type(output_tensor) is list:
      310                 raise Exception('All layers in a Sequential model '</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in
  <strong>call</strong>(self, x, mask)
      512         if inbound_layers:
      513             # this will call layer.build() if necessary
  --> 514             self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
      515             input_added = True
      516 </p>
  
  <p>/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in
  add_inbound_node(self, inbound_layers, node_indices, tensor_indices)
      570         # creating the node automatically updates self.inbound_nodes
      571         # as well as outbound_nodes on inbound layers.
  --> 572         Node.create_node(self, inbound_layers, node_indices, tensor_indices)
      573 
      574     def get_output_shape_for(self, input_shape):</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc in
  create_node(cls, outbound_layer, inbound_layers, node_indices,
  tensor_indices)
      147 
      148         if len(input_tensors) == 1:
  --> 149             output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
      150             output_masks = to_list(outbound_layer.compute_mask(input_tensors[0], input_masks[0]))
      151             # TODO: try to auto-infer shape if exception is raised by get_output_shape_for</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.pyc in
  call(self, x, mask)
      160                                         strides=self.strides,
      161                                         border_mode=self.border_mode,
  --> 162                                         dim_ordering=self.dim_ordering)
      163         return output
      164 </p>
  
  <p>/usr/local/lib/python2.7/dist-packages/keras/layers/pooling.pyc in
  _pooling_function(self, inputs, pool_size, strides, border_mode, dim_ordering)
      210                           border_mode, dim_ordering):
      211         output = K.pool2d(inputs, pool_size, strides,
  --> 212                           border_mode, dim_ordering, pool_mode='max')
      213         return output
      214 </p>
  
  <p>/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc
  in pool2d(x, pool_size, strides, border_mode, dim_ordering, pool_mode)
  1699     1700     if pool_mode == 'max':
  -> 1701         x = tf.nn.max_pool(x, pool_size, strides, padding=padding)    1702     elif pool_mode == 'avg':    1703<br>
  x = tf.nn.avg_pool(x, pool_size, strides, padding=padding)</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc
  in max_pool(value, ksize, strides, padding, data_format, name)    1391
  padding=padding,    1392<br>
  data_format=data_format,
  -> 1393                                 name=name)    1394     1395 </p>
  
  <p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.pyc
  in _max_pool(input, ksize, strides, padding, data_format, name)<br>
  1593   result = _op_def_lib.apply_op(""MaxPool"", input=input,
  ksize=ksize,    1594                                 strides=strides,
  padding=padding,
  -> 1595                                 data_format=data_format, name=name)    1596   return result    1597 </p>
  
  <p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc
  in apply_op(self, op_type_name, name, **keywords)
      747           op = g.create_op(op_type_name, inputs, output_types, name=scope,
      748                            input_types=input_types, attrs=attr_protos,
  --> 749                            op_def=op_def)
      750           outputs = op.outputs
      751           return _Restructure(ops.convert_n_to_tensor(outputs),</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc
  in create_op(self, op_type, inputs, dtypes, input_types, name, attrs,
  op_def, compute_shapes, compute_device)    2388<br>
  original_op=self._default_original_op, op_def=op_def)    2389     if
  compute_shapes:
  -> 2390       set_shapes_for_outputs(ret)    2391     self._add_op(ret)    2392<br>
  self._record_op_seen_by_control_dependencies(ret)</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc
  in set_shapes_for_outputs(op)    1783       raise RuntimeError(""No
  shape function registered for standard op: %s""    1784<br>
  % op.type)
  -> 1785   shapes = shape_func(op)    1786   if shapes is None:    1787     raise RuntimeError(</p>
  
  <p>/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc
  in call_cpp_shape_fn(op, input_tensors_needed, debug_python_shape_fn)
      594                                                              status)
      595   except errors.InvalidArgumentError as err:
  --> 596     raise ValueError(err.message)
      597 
      598   # Convert TensorShapeProto values in output_shapes.</p>
  
  <p>ValueError: Negative dimension size caused by subtracting 2 from 1 for
  'MaxPool_7' (op: 'MaxPool') with input shapes: [?,1,112,128].</p>
</blockquote>
",4516640.0,,147019.0,,2016-11-03 19:56:45,2020-08-26 05:43:32,Keras Maxpooling2d layer gives ValueError,<python><neural-network><tensorflow><deep-learning><keras>,7,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39815518
49546922,1,49554465,,2018-03-29 02:08:08,,33,35722,"<p>The code that I have (that I can't change) uses the Resnet with <code>my_input_tensor</code> as the input_tensor.</p>

<pre><code>model1 = keras.applications.resnet50.ResNet50(input_tensor=my_input_tensor, weights='imagenet')
</code></pre>

<p>Investigating the <a href=""https://github.com/keras-team/keras/blob/master/keras/applications/resnet50.py"" rel=""noreferrer"">source code</a>, ResNet50 function creates a new keras Input Layer with <code>my_input_tensor</code> and then create the rest of the model. This is the behavior that I want to copy with my own model. I load my model from h5 file.</p>

<pre><code>model2 = keras.models.load_model('my_model.h5')
</code></pre>

<p>Since this model already has an Input Layer, I want to replace it with a new Input Layer defined with <code>my_input_tensor</code>.</p>

<p>How can I replace an input layer?</p>
",6217326.0,,,,,2023-04-18 10:30:35,Keras replacing input layer,<python><tensorflow><deep-learning><keras>,7,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49546922
44176982,1,44191138,,2017-05-25 09:29:07,,33,65722,"<p>I am using the TensorFlow backend.</p>

<p>I am applying a convolution, max-pooling, flatten and a dense layer sequentially. The convolution requires a 3D input (height, width, color_channels_depth).</p>

<p>After the convolution, this becomes (height, width, Number_of_filters).</p>

<p>After applying max-pooling height and width changes. But, after applying the flatten layer, what happens exactly? For example, if the input before flatten is (24, 24, 32), then how it flattens it out?</p>

<p>Is it sequential like (24 * 24) for height, weight for each filter number sequentially, or in some other way? An example would be appreciated with actual values.</p>
",7990757.0,,3924118.0,,2019-10-15 16:57:47,2019-10-15 16:57:47,How does the Flatten layer work in Keras?,<tensorflow><neural-network><keras><keras-layer>,3,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44176982
42384602,1,42391339,,2017-02-22 06:54:33,,33,37590,"<p>I am implementing ApesNet in keras. It has an ApesBlock that has skip connections. How do I add this to a sequential model in keras? The ApesBlock has two parallel layers that merge at the end by element-wise addition.<img src=""https://i.stack.imgur.com/UrFP8.png"" alt=""enter image description here""></p>
",6691357.0,,6691357.0,,2017-02-22 07:35:17,2022-09-30 15:04:54,Implementing skip connections in keras,<keras><image-segmentation><resnet>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42384602
54255431,1,54255819,,2019-01-18 13:52:51,,33,61305,"<p>Can somebody explain, how does TensorFlow's eager mode work? I am trying to build a simple regression as follows:</p>

<pre><code>import tensorflow as tf

tfe = tf.contrib.eager
tf.enable_eager_execution()

import numpy as np


def make_model():
    net = tf.keras.Sequential()
    net.add(tf.keras.layers.Dense(4, activation='relu'))
    net.add(tf.keras.layers.Dense(1))
    return net

def compute_loss(pred, actual):
    return tf.reduce_mean(tf.square(tf.subtract(pred, actual)))

def compute_gradient(model, pred, actual):
    """"""compute gradients with given noise and input""""""
    with tf.GradientTape() as tape:
        loss = compute_loss(pred, actual)
    grads = tape.gradient(loss, model.variables)
    return grads, loss

def apply_gradients(optimizer, grads, model_vars):
    optimizer.apply_gradients(zip(grads, model_vars))

model = make_model()
optimizer = tf.train.AdamOptimizer(1e-4)

x = np.linspace(0,1,1000)
y = x+np.random.normal(0,0.3,1000)
y = y.astype('float32')
train_dataset = tf.data.Dataset.from_tensor_slices((y.reshape(-1,1)))

epochs = 2# 10
batch_size = 25
itr = y.shape[0] // batch_size
for epoch in range(epochs):
    for data in tf.contrib.eager.Iterator(train_dataset.batch(25)):
        preds = model(data)
        grads, loss = compute_gradient(model, preds, data)
        print(grads)
        apply_gradients(optimizer, grads, model.variables)
#         with tf.GradientTape() as tape:
#             loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(preds, data))))
#         grads = tape.gradient(loss, model.variables)
#         print(grads)
#         optimizer.apply_gradients(zip(grads, model.variables),global_step=None)
</code></pre>

<p><code>Gradient output: [None, None, None, None, None, None]</code>
The error is following:</p>

<pre><code>----------------------------------------------------------------------
ValueError                           Traceback (most recent call last)
&lt;ipython-input-3-a589b9123c80&gt; in &lt;module&gt;
     35         grads, loss = compute_gradient(model, preds, data)
     36         print(grads)
---&gt; 37         apply_gradients(optimizer, grads, model.variables)
     38 #         with tf.GradientTape() as tape:
     39 #             loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(preds, data))))

&lt;ipython-input-3-a589b9123c80&gt; in apply_gradients(optimizer, grads, model_vars)
     17 
     18 def apply_gradients(optimizer, grads, model_vars):
---&gt; 19     optimizer.apply_gradients(zip(grads, model_vars))
     20 
     21 model = make_model()

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py in apply_gradients(self, grads_and_vars, global_step, name)
    589     if not var_list:
    590       raise ValueError(""No gradients provided for any variable: %s."" %
--&gt; 591                        ([str(v) for _, v, _ in converted_grads_and_vars],))
    592     with ops.init_scope():
    593       self._create_slots(var_list)

ValueError: No gradients provided for any variable:
</code></pre>

<h3>Edit</h3>

<p>I updated my code. Now, the problem comes in gradients calculation, it is returning zero. I have checked the loss value that is non-zero.</p>
",9277245.0,,3924118.0,,2020-01-09 22:15:39,2020-01-09 22:15:39,InvalidArgumentError: cannot compute MatMul as input #0(zero-based) was expected to be a float tensor but is a double tensor [Op:MatMul],<python><tensorflow><keras><eager-execution>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54255431
58638701,1,58639060,,2019-10-31 07:35:28,,33,50924,"<p>Good day,</p>

<p>Here is the error. Can somebody help how can i solve it?</p>

<pre><code>ImportError                               Traceback (most recent call last)
&lt;ipython-input-18-c29f17706012&gt; in &lt;module&gt;
      7 import numpy as np
      8 import numpy.random as nr
----&gt; 9 from tensorflow import set_random_seed
     10 import matplotlib.pyplot as plt
     11 get_ipython().run_line_magic('matplotlib', 'inline')

ImportError: cannot import name 'set_random_seed' from 'tensorflow' (C:\Users\polon\Anaconda3\lib\site-packages\tensorflow\__init__.py)
</code></pre>

<p>Looked for similar problems on Stack, but nothing worked for me.</p>
",12301726.0,,,,,2021-06-11 18:07:26,ImportError: cannot import name 'set_random_seed' from 'tensorflow' (C:\Users\polon\Anaconda3\lib\site-packages\tensorflow\__init__.py),<python><tensorflow><keras>,6,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58638701
67018079,1,67018610,,2021-04-09 08:58:22,,33,91645,"<p>I have probem with this code , why ?</p>
<p>the code :</p>
<pre><code>import cv2
import numpy as np
from PIL import Image
import os
import numpy as np
import cv2
import os
import h5py
import dlib
from imutils import face_utils
from keras.models import load_model
import sys
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D,Dropout
from keras.layers import Dense, Activation, Flatten
from keras.utils import to_categorical
from keras import backend as K 
from sklearn.model_selection import train_test_split
from Model import model
from keras import callbacks

# Path for face image database
path = 'dataset'

recognizer = cv2.face.LBPHFaceRecognizer_create()
detector = cv2.CascadeClassifier(&quot;haarcascade_frontalface_default.xml&quot;);


def downsample_image(img):
    img = Image.fromarray(img.astype('uint8'), 'L')
    img = img.resize((32,32), Image.ANTIALIAS)
    return np.array(img)



# function to get the images and label data
def getImagesAndLabels(path):
    
    path = 'dataset'
    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     
    faceSamples=[]
    ids = []

    for imagePath in imagePaths:
        
        #if there is an error saving any jpegs
        try:
            PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale
        except:
            continue    
        img_numpy = np.array(PIL_img,'uint8')

        id = int(os.path.split(imagePath)[-1].split(&quot;.&quot;)[1])
        faceSamples.append(img_numpy)
        ids.append(id)
    return faceSamples,ids

print (&quot;\n [INFO] Training faces now.&quot;)
faces,ids = getImagesAndLabels(path)

K.clear_session()
n_faces = len(set(ids))
model = model((32,32,1),n_faces)
faces = np.asarray(faces)
faces = np.array([downsample_image(ab) for ab in faces])
ids = np.asarray(ids)
faces = faces[:,:,:,np.newaxis]
print(&quot;Shape of Data: &quot; + str(faces.shape))
print(&quot;Number of unique faces : &quot; + str(n_faces))


ids = to_categorical(ids)

faces = faces.astype('float32')
faces /= 255.

x_train, x_test, y_train, y_test = train_test_split(faces,ids, test_size = 0.2, random_state = 0)

checkpoint = callbacks.ModelCheckpoint('trained_model.h5', monitor='val_acc',
                                           save_best_only=True, save_weights_only=True, verbose=1)
                                    
model.fit(x_train, y_train,
             batch_size=32,
             epochs=10,
             validation_data=(x_test, y_test),
             shuffle=True,callbacks=[checkpoint])
             

# Print the numer of faces trained and end program
print(&quot;enter code here`\n [INFO] &quot; + str(n_faces) + &quot; faces trained. Exiting Program&quot;)
</code></pre>
<hr />
<pre><code>the output:
------------------
File &quot;D:\my hard sam\ماجستير\سنة ثانية\البحث\python\Real-Time-Face-Recognition-Using-CNN-master\Real-Time-Face-Recognition-Using-CNN-master\02_face_training.py&quot;, line 16, in &lt;module&gt;
    from keras.utils import to_categorical
ImportError: cannot import name 'to_categorical' from 'keras.utils' (C:\Users\omar\PycharmProjects\SnakGame\venv\lib\site-packages\keras\utils\__init__.py)
</code></pre>
",15558831.0,,9215780.0,,2021-04-09 09:01:26,2022-03-03 11:32:17,"Error in ""from keras.utils import to_categorical""",<python><keras>,4,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/67018079
49550182,1,49550620,,2018-03-29 07:20:01,,33,51733,"<p>1) I try to rename a model and the layers in Keras with TF backend, since I am using multiple models in one script.
Class Model seem to have the property model.name, but when changing it I get ""AttributeError: can't set attribute"".
What is the Problem here?</p>

<p>2) Additionally, I am using sequential API and I want to give a name to layers, which seems to be possibile with Functional API, but I found no solution for sequential API. Does anonye know how to do it for sequential API?</p>

<p>UPDATE TO 2): Naming the layers works, although it seems to be not documented. Just add the argument name, e.g. model.add(Dense(...,...,name=""hiddenLayer1""). <em>Watch out, Layers with same name share weights!</em></p>
",3921232.0,,3921232.0,,2018-03-29 07:44:52,2022-10-20 09:38:49,Keras rename model and layers,<python><keras>,9,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49550182
48127550,1,48139341,,2018-01-06 12:54:02,,33,12897,"<p>I wish to implement early stopping with Keras and sklean's <code>GridSearchCV</code>.</p>

<p>The working code example below is modified from <a href=""https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"" rel=""noreferrer"">How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras</a>. The data set may be <a href=""http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"" rel=""noreferrer"">downloaded from here</a>.</p>

<p>The modification adds the Keras <code>EarlyStopping</code> callback class to prevent over-fitting. For this to be effective it requires the <code>monitor='val_acc'</code> argument for monitoring validation accuracy. For <code>val_acc</code> to be available <code>KerasClassifier</code> requires the <code>validation_split=0.1</code> to generate validation accuracy, else <code>EarlyStopping</code> raises <code>RuntimeWarning: Early stopping requires val_acc available!</code>. Note the <code>FIXME:</code> code comment!</p>

<p>Note we could replace <code>val_acc</code> by <code>val_loss</code>! </p>

<p><strong>Question:</strong> How can I use the cross-validation data set generated by the <code>GridSearchCV</code> k-fold algorithm instead of wasting 10% of the training data for an early stopping validation set? </p>

<pre class=""lang-python prettyprint-override""><code># Use scikit-learn to grid search the learning rate and momentum
import numpy
from sklearn.model_selection import GridSearchCV
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.optimizers import SGD

# Function to create model, required for KerasClassifier
def create_model(learn_rate=0.01, momentum=0):
    # create model
    model = Sequential()
    model.add(Dense(12, input_dim=8, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    # Compile model
    optimizer = SGD(lr=learn_rate, momentum=momentum)
    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

# Early stopping
from keras.callbacks import EarlyStopping
stopper = EarlyStopping(monitor='val_acc', patience=3, verbose=1)

# fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# load dataset
dataset = numpy.loadtxt(""pima-indians-diabetes.csv"", delimiter="","")
# split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]
# create model
model = KerasClassifier(
    build_fn=create_model,
    epochs=100, batch_size=10,
    validation_split=0.1, # FIXME: Instead use GridSearchCV k-fold validation data.
    verbose=2)
# define the grid search parameters
learn_rate = [0.01, 0.1]
momentum = [0.2, 0.4]
param_grid = dict(learn_rate=learn_rate, momentum=momentum)
grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=2, n_jobs=1)

# Fitting parameters
fit_params = dict(callbacks=[stopper])
# Grid search.
grid_result = grid.fit(X, Y, **fit_params)

# summarize results
print(""Best: %f using %s"" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print(""%f (%f) with: %r"" % (mean, stdev, param))
</code></pre>
",3744784.0,,4685471.0,,2018-01-07 21:07:42,2021-10-10 00:31:04,Early stopping with Keras and sklearn GridSearchCV cross-validation,<machine-learning><scikit-learn><keras><cross-validation><grid-search>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48127550
43702323,1,43703139,,2017-04-30 02:26:05,,33,33749,"<p>I have a trained model that I've exported the weights and want to partially load into another model.
My model is built in Keras using TensorFlow as backend.</p>

<p>Right now I'm doing as follows:</p>

<pre><code>model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=input_shape, trainable=False))
model.add(Activation('relu', trainable=False))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3), trainable=False))
model.add(Activation('relu', trainable=False))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), trainable=True))
model.add(Activation('relu', trainable=True))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])


model.load_weights(""image_500.h5"")
model.pop()
model.pop()
model.pop()
model.pop()
model.pop()
model.pop()


model.add(Conv2D(1, (6, 6),strides=(1, 1), trainable=True))
model.add(Activation('relu', trainable=True))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
</code></pre>

<p>I'm sure it's a terrible way to do it, although it works.</p>

<p>How do I load just the first 9 layers?</p>
",3799743.0,,,,,2017-04-30 05:11:53,How to load only specific weights on Keras,<machine-learning><tensorflow><keras><conv-neural-network>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43702323
45328843,1,45329067,,2017-07-26 13:46:45,,33,15669,"<p>I'm a bit confused about the number of layers that are used in Keras models. The documentation is rather opaque on the matter.</p>

<p>According to Jason Brownlee the first layer technically consists of two layers, the input layer, specified by <code>input_dim</code> and a hidden layer. See the first questions on <a href=""http://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"" rel=""noreferrer"">his blog</a>.</p>

<p>In all of the Keras documentation the first layer is generally specified as
<code>model.add(Dense(number_of_neurons, input_dim=number_of_cols_in_input, activtion=some_activation_function))</code>.</p>

<p>The most basic model we could make would therefore be:</p>

<pre><code> model = Sequential()
 model.add(Dense(1, input_dim = 100, activation = None))
</code></pre>

<p>Does this model consist of a single layer, where 100 dimensional input is passed through a single input neuron, or does it consist of two layers, first a 100 dimensional input layer and second a 1 dimensional hidden layer?</p>

<p>Further, if I were to specify a model like this, how many layers does it have?</p>

<pre><code>model = Sequential()
model.add(Dense(32, input_dim = 100, activation = 'sigmoid'))
model.add(Dense(1)))
</code></pre>

<p>Is this a model with 1 input layer, 1 hidden layer, and 1 output layer or is this a model with 1 input layer and 1 output layer?</p>
",4577697.0,,,,,2022-03-17 12:11:18,Keras confusion about number of layers,<python><tensorflow><neural-network><deep-learning><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45328843
44806125,1,44827730,,2017-06-28 14:59:04,,32,78495,"<p>I'm trying to predict on the validation data with pre-trained and fine-tuned DL models. The code follows the example available in the Keras blog on ""building image classification models using very little data"". Here is the code:</p>

<pre><code>import numpy as np
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.models import Model
from keras.layers import Flatten, Dense
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import roc_auc_score
import itertools
from keras.optimizers import SGD
from sklearn.metrics import roc_curve, auc
from keras import applications
from keras import backend as K
K.set_image_dim_ordering('tf')

# Plotting the confusion matrix
def plot_confusion_matrix(cm, classes,
                          normalize=False, #if true all values in confusion matrix is between 0 and 1
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """"""
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """"""
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print(""Normalized confusion matrix"")
    else:
        print('Confusion matrix, without normalization')

    print(cm)
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment=""center"",
                 color=""white"" if cm[i, j] &gt; thresh else ""black"")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

#plot data
def generate_results(validation_labels, y_pred):
    fpr, tpr, _ = roc_curve(validation_labels, y_pred) ##(this implementation is restricted to a binary classification task)
    roc_auc = auc(fpr, tpr)
    plt.figure()
    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.05])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (FPR)')
    plt.ylabel('True Positive Rate (TPR)')
    plt.title('Receiver operating characteristic (ROC) curve')
    plt.show()
    print('Area Under the Curve (AUC): %f' % roc_auc)

img_width, img_height = 100,100
top_model_weights_path = 'modela.h5'
train_data_dir = 'data4/train'
validation_data_dir = 'data4/validation'
nb_train_samples = 20
nb_validation_samples = 20
epochs = 50
batch_size = 10
def save_bottleneck_features():
   datagen = ImageDataGenerator(rescale=1. / 255)
   model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(100,100,3))
   generator = datagen.flow_from_directory(
               train_data_dir,
               target_size=(img_width, img_height),
               batch_size=batch_size,
               class_mode='binary',
               shuffle=False)
   bottleneck_features_train = model.predict_generator(
               generator, nb_train_samples // batch_size)
   np.save(open('bottleneck_features_train', 'wb'),bottleneck_features_train)

   generator = datagen.flow_from_directory(
               validation_data_dir,
               target_size=(img_width, img_height),
               batch_size=batch_size,
               class_mode='binary',
               shuffle=False)
   bottleneck_features_validation = model.predict_generator(
               generator, nb_validation_samples // batch_size)
   np.save(open('bottleneck_features_validation', 'wb'),bottleneck_features_validation)

def train_top_model():
   train_data = np.load(open('bottleneck_features_train', 'rb'))
   train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))
   validation_data = np.load(open('bottleneck_features_validation', 'rb'))
   validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))
   model = Sequential()
   model.add(Flatten(input_shape=train_data.shape[1:]))
   model.add(Dense(512, activation='relu'))
   model.add(Dense(1, activation='sigmoid'))
   sgd = SGD(lr=1e-3, decay=0.00, momentum=0.99, nesterov=False) 
   model.compile(optimizer=sgd,
         loss='binary_crossentropy', metrics=['accuracy'])
   model.fit(train_data, train_labels,
          epochs=epochs,
          batch_size=batch_size,
   validation_data=(validation_data, validation_labels))
   model.save_weights(top_model_weights_path)
   print('Predicting on test data')
   y_pred = model.predict_classes(validation_data)
   print(y_pred.shape)
   print('Generating results')
   generate_results(validation_labels[:,], y_pred[:,])
   print('Generating the ROC_AUC_Scores') #Compute Area Under the Curve (AUC) from prediction scores
   print(roc_auc_score(validation_labels,y_pred)) #this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.
   target_names = ['class 0(Normal)', 'class 1(Abnormal)']
   print(classification_report(validation_labels,y_pred,target_names=target_names))
   print(confusion_matrix(validation_labels,y_pred))
   cnf_matrix = (confusion_matrix(validation_labels,y_pred))
   np.set_printoptions(precision=2)
   plt.figure()
   # Plot non-normalized confusion matrix
   plot_confusion_matrix(cnf_matrix, classes=target_names,
                      title='Confusion matrix')
   plt.show()
save_bottleneck_features()
train_top_model()

# path to the model weights files.
weights_path = '../keras/examples/vgg16_weights.h5'
top_model_weights_path = 'modela.h5'
# dimensions of our images.
img_width, img_height = 100, 100
train_data_dir = 'data4/train'
validation_data_dir = 'data4/validation'
nb_train_samples = 20
nb_validation_samples = 20
epochs = 50
batch_size = 10

# build the VGG16 network
base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(100,100,3))
print('Model loaded.')

train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1. / 255)
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary')
validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary') 
top_model = Sequential()
top_model.add(Flatten(input_shape=base_model.output_shape[1:]))
top_model.add(Dense(512, activation='relu'))
top_model.add(Dense(1, activation='softmax'))
top_model.load_weights(top_model_weights_path)
model = Model(inputs=base_model.input, outputs=top_model(base_model.output))
   # set the first 15 layers (up to the last conv block)
# to non-trainable (weights will not be updated)
for layer in model.layers[:15]: #up to the layer before the last convolution block
        layer.trainable = False
model.summary()
   # fine-tune the model
model.compile(loss='binary_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.99), metrics=['accuracy'])
model.fit_generator(train_generator,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples // batch_size,
    verbose=1)
model.save_weights(top_model_weights_path)
bottleneck_features_validation = model.predict_generator(validation_generator, nb_validation_samples // batch_size)
np.save(open('bottleneck_features_validation','wb'), bottleneck_features_validation)
validation_data = np.load(open('bottleneck_features_validation', 'rb'))
y_pred1 = model.predict_classes(validation_data)
</code></pre>

<p>The problem is that the pre-trained model is getting trained on the data and predicts the classes perfectly and gives the confusion matrix as well. As I proceed to fine-tuning the model, I could find that model.predict_classes is not working. Here is the error:</p>

<blockquote>
<pre><code>File ""C:/Users/rajaramans2/codes/untitled12.py"", line 220, in &lt;module&gt;
    y_pred1 = model.predict_classes(validation_data)

AttributeError: 'Model' object has no attribute 'predict_classes'
</code></pre>
</blockquote>

<p>I am confused because, <code>model.predict_classes</code> worked well with the pre-trained model, but not in the fine-tuning stage. The size of validation data is (20,1) and <code>float32</code> type. Any help would be appreciated. </p>
",7575552.0,,6626093.0,,2017-08-05 20:29:24,2021-12-29 07:02:10,AttributeError: 'Model' object has no attribute 'predict_classes',<compiler-errors><keras><prediction>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44806125
52020748,1,52215330,,2018-08-25 19:50:50,,32,2282,"<p>I have been developing feedforward neural networks (FNNs) and recurrent neural networks (RNNs) in Keras with structured data of the shape <code>[instances, time, features]</code>, and the performance of FNNs and RNNs has been the same (except that RNNs require more computation time).</p>

<p>I have also simulated tabular data (code below) where I expected a RNN to outperform a FNN because the next value in the series is dependent on the previous value in the series; however, both architectures predict correctly. </p>

<p>With NLP data, I have seen RNNs outperform FNNs, but not with tabular data. Generally, when would one expect a RNN to outperform a FNN with tabular data? Specifically, could someone post simulation code with tabular data demonstrating a RNN outperforming a FNN? </p>

<p>Thank you! If my simulation code is not ideal for my question, please adapt it or share a more ideal one!</p>

<pre><code>from keras import models
from keras import layers

from keras.layers import Dense, LSTM

import numpy as np
import matplotlib.pyplot as plt
</code></pre>

<p>Two features were simulated over 10 time steps, where the value of the second feature is dependent on the value of both features in the prior time step.</p>

<pre><code>## Simulate data.

np.random.seed(20180825)

X = np.random.randint(50, 70, size = (11000, 1)) / 100

X = np.concatenate((X, X), axis = 1)

for i in range(10):

    X_next = np.random.randint(50, 70, size = (11000, 1)) / 100

    X = np.concatenate((X, X_next, (0.50 * X[:, -1].reshape(len(X), 1)) 
        + (0.50 * X[:, -2].reshape(len(X), 1))), axis = 1)

print(X.shape)

## Training and validation data.

split = 10000

Y_train = X[:split, -1:].reshape(split, 1)
Y_valid = X[split:, -1:].reshape(len(X) - split, 1)
X_train = X[:split, :-2]
X_valid = X[split:, :-2]

print(X_train.shape)
print(Y_train.shape)
print(X_valid.shape)
print(Y_valid.shape)
</code></pre>

<p>FNN:</p>

<pre><code>## FNN model.

# Define model.

network_fnn = models.Sequential()
network_fnn.add(layers.Dense(64, activation = 'relu', input_shape = (X_train.shape[1],)))
network_fnn.add(Dense(1, activation = None))

# Compile model.

network_fnn.compile(optimizer = 'adam', loss = 'mean_squared_error')

# Fit model.

history_fnn = network_fnn.fit(X_train, Y_train, epochs = 10, batch_size = 32, verbose = False,
    validation_data = (X_valid, Y_valid))

plt.scatter(Y_train, network_fnn.predict(X_train), alpha = 0.1)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

plt.scatter(Y_valid, network_fnn.predict(X_valid), alpha = 0.1)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()
</code></pre>

<p>LSTM:</p>

<pre><code>## LSTM model.

X_lstm_train = X_train.reshape(X_train.shape[0], X_train.shape[1] // 2, 2)
X_lstm_valid = X_valid.reshape(X_valid.shape[0], X_valid.shape[1] // 2, 2)

# Define model.

network_lstm = models.Sequential()
network_lstm.add(layers.LSTM(64, activation = 'relu', input_shape = (X_lstm_train.shape[1], 2)))
network_lstm.add(layers.Dense(1, activation = None))

# Compile model.

network_lstm.compile(optimizer = 'adam', loss = 'mean_squared_error')

# Fit model.

history_lstm = network_lstm.fit(X_lstm_train, Y_train, epochs = 10, batch_size = 32, verbose = False,
    validation_data = (X_lstm_valid, Y_valid))

plt.scatter(Y_train, network_lstm.predict(X_lstm_train), alpha = 0.1)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

plt.scatter(Y_valid, network_lstm.predict(X_lstm_valid), alpha = 0.1)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()
</code></pre>
",9415043.0,,9415043.0,,2018-11-22 05:11:47,2018-11-22 05:11:47,Why Bother With Recurrent Neural Networks For Structured Data?,<python><keras><prediction><recurrent-neural-network>,1,10,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52020748
40866124,1,40870126,,2016-11-29 12:37:32,,32,12432,"<p>I was wondering what was the difference between Activation Layer and Dense layer in Keras.</p>

<p>Since Activation Layer seems to be a fully connected layer, and Dense have a parameter to pass an activation function, what is the best practice ?</p>

<p>Let's imagine a fictionnal network like this :
Input -> Dense -> Dropout -> Final Layer
Final Layer should be : Dense(activation=softmax) or Activation(softmax) ?
What is the cleanest and why ?</p>

<p>Thanks everyone!</p>
",3827807.0,,5974433.0,,2017-07-04 10:38:44,2020-10-03 17:03:06,Difference between Dense and Activation layer in Keras,<python><machine-learning><neural-network><deep-learning><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40866124
49113140,1,52101454,,2018-03-05 14:52:22,,32,34135,"<p>In Keras, </p>

<p>I'm trying to import <code>_obtain_input_shape</code> as follows: </p>

<pre><code>from keras.applications.imagenet_utils import _obtain_input_shape
</code></pre>

<p>However, I get the following error: </p>

<blockquote>
  <p>ImportError: cannot import name '_obtain_input_shape'</p>
</blockquote>

<p>The reason I'm trying to import _obtain_input_shape is so that I can determine the input shape(so as to load <a href=""http://www.vlfeat.org/matconvnet/pretrained/"" rel=""noreferrer"">VGG-Face</a> as follows : </p>

<p>I'm using it to determine the correct input shape of the input tensor as follow: </p>

<pre><code>input_shape = _obtain_input_shape(input_shape,
                                  default_size=224,
                                  min_size=48,
                                  data_format=K.image_data_format(),
                                  require_flatten=include_top)`
</code></pre>

<p>Please assist?
Thanks in advance. </p>
",5695374.0,,5695374.0,,2018-03-05 15:12:01,2021-07-01 20:29:13,ImportError: cannot import name '_obtain_input_shape' from keras,<keras><keras-layer><keras-2>,7,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49113140
58378374,1,58385156,,2019-10-14 13:58:18,,32,18583,"<p><a href=""https://i.stack.imgur.com/cCXBx.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cCXBx.png"" alt=""prediction speed keras""></a></p>

<p>In theory, the prediction should be constant as the weights have a fixed size. How do I get my speed back after compile (without the need to remove optimizer)?</p>

<p>See associated experiment: <a href=""https://nbviewer.jupyter.org/github/off99555/TensorFlowExperiments/blob/master/test-prediction-speed-after-compile.ipynb?flush_cache=true"" rel=""noreferrer"">https://nbviewer.jupyter.org/github/off99555/TensorFlowExperiments/blob/master/test-prediction-speed-after-compile.ipynb?flush_cache=true</a></p>
",2593810.0,,10133797.0,,2019-11-05 16:24:08,2020-01-15 06:13:27,Why does keras model predict slower after compile?,<python><performance><tensorflow><keras><jupyter-notebook>,2,7,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58378374
59380430,1,59381897,,2019-12-17 18:54:18,,32,57956,"<p>I have got this deprecation warning while using <code>Model.fit_generator</code> in tensorflow:</p>

<pre><code>WARNING:tensorflow: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
</code></pre>

<p>How can I use <code>Model.fit</code> instead of <code>Model.fit_generator</code>?</p>
",3134275.0,,,,,2021-05-09 20:04:18,How to use Model.fit which supports generators (after fit_generator deprecation),<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59380430
60837962,1,70205891,,2020-03-24 19:26:49,,32,10821,"<p>I have realized that I do not quite understand the difference between calling either the <code>__call__</code>, <code>call</code>, or <code>predict</code> method of a Keras' model.</p>

<p>For example, we have a trained keras model. After calling the code:</p>

<pre class=""lang-py prettyprint-override""><code># After training.
y_pred_1 = model(X_new)
y_pred_2 = model.call(X_new)
y_pred_3 = model.predict(X_new)
</code></pre>

<p>I expected that <code>y_pred_1</code>, <code>y_pred_2</code>, and <code>y_pred_3</code> are all the same.
But it turned out that they are not the same.</p>

<p>Could you please explain to me the difference?</p>
",1095202.0,,5739514.0,,2020-03-24 21:10:47,2021-12-18 11:26:09,Confusion about keras Model: __call__ vs. call vs. predict methods,<tensorflow><keras>,4,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/60837962
62436302,1,63198989,,2020-06-17 18:51:41,,32,44654,"<p>I am still learning tensorflow and keras, and I suspect this question has a very easy answer I'm just missing due to lack of familiarity.</p>
<p>I have a <code>PrefetchDataset</code> object:</p>
<pre><code>&gt; print(tf_test)
$ &lt;PrefetchDataset shapes: ((None, 99), (None,)), types: (tf.float32, tf.int64)&gt;
</code></pre>
<p>...made up of features and a target. I can iterate over it using a <code>for</code> loop:</p>
<pre><code>&gt; for example in tf_test:
&gt;     print(example[0].numpy())
&gt;     print(example[1].numpy())
&gt;     exit()
$ [[-0.31 -0.94 -1.12 ... 0.18 -0.27]
   [-0.22 -0.54 -0.14 ... 0.33 -0.55]
   [-0.60 -0.02 -1.41 ... 0.21 -0.63]
   ...
   [-0.03 -0.91 -0.12 ... 0.77 -0.23]
   [-0.76 -1.48 -0.15 ... 0.38 -0.35]
   [-0.55 -0.08 -0.69 ... 0.44 -0.36]]
  [0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0
   ...
   0 1 1 0]
</code></pre>
<p>However, this is very slow.  What I'd like to do is access the tensor corresponding to the class labels and turn that into a numpy array, or a list, or any sort of iterable that can be fed into scikit-learn's classification report and/or confusion matrix:</p>
<pre><code>&gt; y_pred = model.predict(tf_test)
&gt; print(y_pred)
$ [[0.01]
   [0.14]
   [0.00]
   ...
   [0.32]
   [0.03]
   [0.00]]
&gt; y_pred_list = [int(x[0]) for x in y_pred]             # assumes value &gt;= 0.5 is positive prediction
&gt; y_true = []                                           # what I need help with
&gt; print(sklearn.metrics.confusion_matrix(y_true, y_pred_list)
</code></pre>
<p>...OR access the data such that it could be used in tensorflow's confusion matrix:</p>
<pre><code>&gt; labels = []                                           # what I need help with
&gt; predictions = y_pred_list                             # could we just use a tensor?
&gt; print(tf.math.confusion_matrix(labels, predictions)
</code></pre>
<p>In both cases, the general ability to grab the target data from the original object in a manner that isn't computationally expensive would be very helpful (and might help with my underlying intuitions re: tensorflow and keras).</p>
<p>Any advice would be greatly appreciated.</p>
",3397173.0,,10908375.0,,2020-12-08 18:13:51,2022-12-07 15:39:01,Extract target from Tensorflow PrefetchDataset,<python><tensorflow><machine-learning><keras><prefetch>,8,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/62436302
58878421,1,58881339,,2019-11-15 13:50:35,,31,30321,"<p>Trying to run a trained keras model with the following python code:</p>

<pre class=""lang-py prettyprint-override""><code>from keras.preprocessing.image import img_to_array
from keras.models import load_model

from imutils.video import VideoStream
from threading import Thread
import numpy as np
import imutils
import time
import cv2
import os

MODEL_PATH = ""/home/pi/Documents/converted_keras/keras_model.h5""

print(""[info] loading model.."")
model = load_model(MODEL_PATH)


print(""[info] starting vid stream.."")
vs = VideoStream(usePiCamera=True).start()
time.sleep(2.0)

while True:
    frame = vs.Read()
    frame = imutils.resize(frame, width=400)

    image = cv2.resize(frame, (28, 28))
    image = image.astype(""float"") / 255.0
    image = img_to_array(image)
    image = np.expand_dims(image, axis=0)
    (fuel, redBall, whiteBall, none) = model.predict(image)[0]
    label = ""none""
    proba = none

    if fuel &gt; none and fuel &gt; redBall and fuel &gt; whiteBall:
        label = ""Fuel""
        proba = fuel
    elif redBall &gt; none and redBall &gt; fuel and redBall &gt; whiteBall:
        label = ""Red Ball""
        proba = redBall
    elif whiteBall &gt; none and whiteBall &gt; redBall and whiteBall &gt; fuel:
        label = ""white ball""
        proba = whiteBall
    else:
        label = ""none""
        proba = none

    label = ""{}:{:.2f%}"".format(label, proba * 100)
    frame = cv2.putText(frame, label, (10, 25),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.imshow(""Frame"", frame)
    key = cv2.waitKey(1) &amp; 0xFF

    if key == ord(""q""):
        break

print(""[info] cleaning up.."")
cv2.destroyAllWindows()
vs.stop()
</code></pre>

<p>When I run it with python3, I get the following error:
<code>TypeError: __init__() got an unexpected keyword argument 'ragged'</code></p>

<p>What's causing the error, and how do I get around it? </p>

<p>Versions:
Keras v2.3.1
tensorflow v1.13.1</p>

<p>Edit to add:</p>

<pre><code>Traceback (most recent call last):
  File ""/home/pi/Documents/converted_keras/keras-script.py"", line 18, in &lt;module&gt;
    model = load_model(MODEL_PATH)
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py"", line 492, in load_wrapper
    return load_function(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py"", line 584, in load_model
    model = _deserialize_model(h5dict, custom_objects, compile)
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py"", line 274, in _deserialize_model
    model = model_from_config(model_config, custom_objects=custom_objects)
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/saving.py"", line 627, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py"", line 168, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py"", line 147, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py"", line 301, in from_config
    custom_objects=custom_objects)
  File ""/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py"", line 168, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py"", line 147, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py"", line 301, in from_config
    custom_objects=custom_objects)
  File ""/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py"", line 168, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py"", line 147, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/network.py"", line 1056, in from_config
    process_layer(layer_data)
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/network.py"", line 1042, in process_layer
    custom_objects=custom_objects)
  File ""/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py"", line 168, in deserialize
    printable_module_name='layer')
  File ""/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py"", line 149, in deserialize_keras_object
    return cls.from_config(config['config'])
  File ""/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py"", line 1179, in from_config
    return cls(**config)
  File ""/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'ragged'
</code></pre>

<p><a href=""https://drive.google.com/file/d/1-8ADI40ujjmcLpv-Shn9b5qhvIZNqYcn/view?usp=sharing"" rel=""noreferrer"">h5 file link (google drive)</a></p>
",12378777.0,,12378777.0,,2019-11-15 14:26:18,2020-11-04 21:53:18,Unexpected keyword argument 'ragged' in Keras,<python><tensorflow><keras>,2,11,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58878421
54011173,1,54011300,,2019-01-02 18:11:33,,31,43785,"<p>I just read about the Keras weight initializers in <a href=""https://keras.io/initializers/"" rel=""noreferrer"">here</a>. In the documentation, only different initializers has been introduced. Such as:</p>

<pre><code>model.add(Dense(64, kernel_initializer='random_normal'))
</code></pre>

<p>I want to know what is the <strong>default weight</strong> when I don't specify the <code>kernel_initializer</code> argument. 
Is there a way to access it?</p>
",2512500.0,,2512500.0,,2022-09-09 06:13:34,2022-09-09 06:13:34,Where to find a documentation about default weight initializer in Keras?,<python><machine-learning><keras><neural-network>,1,2,0.0,2022-01-22 13:46:27,,CC BY-SA 4.0,https://stackoverflow.com/q/54011173
42521005,1,42524528,,2017-03-01 00:09:45,,31,19376,"<p>I have the following code.</p>

<pre><code>x = keras.layers.Input(batch_shape = (None, 4096))
hidden = keras.layers.Dense(512, activation = 'relu')(x)
hidden = keras.layers.BatchNormalization()(hidden)
hidden = keras.layers.Dropout(0.5)(hidden)
predictions = keras.layers.Dense(80, activation = 'sigmoid')(hidden)
mlp_model = keras.models.Model(input = [x], output = [predictions])
mlp_model.summary()
</code></pre>

<p>And this is the model summary:</p>

<pre><code>____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_3 (InputLayer)             (None, 4096)          0                                            
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 512)           2097664     input_3[0][0]                    
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 512)           2048        dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 512)           0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 80)            41040       dropout_1[0][0]                  
====================================================================================================
Total params: 2,140,752
Trainable params: 2,139,728
Non-trainable params: 1,024
____________________________________________________________________________________________________
</code></pre>

<p>The size of the input for the BatchNormalization (BN) layer is 512. According to <a href=""https://keras.io/layers/normalization/"" rel=""noreferrer"">Keras documentation</a>, shape of the output for BN layer is same as input which is 512.</p>

<p>Then how the number of parameters associated with BN layer is 2048?</p>
",5352399.0,,,,,2022-12-01 21:09:09,How the number of parameters associated with BatchNormalization layer is 2048?,<keras><batch-normalization>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42521005
61550026,1,61550151,,2020-05-01 20:09:59,,31,107023,"<p>I have a 3 dimensional dataset of audio files where <code>X.shape</code> is <code>(329,20,85)</code>. I want to have a simpl bare-bones model running, so please don't nitpick and address only the issue at hand. Here is the code:</p>
<pre><code>model = tf.keras.models.Sequential()
model.add(tf.keras.layers.LSTM(32, return_sequences=True, stateful=False, input_shape = (20,85,1)))
model.add(tf.keras.layers.LSTM(20))
model.add(tf.keras.layers.Dense(nb_classes, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[&quot;accuracy&quot;])
model.summary()
print(&quot;Train...&quot;)
model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=50, validation_data=(X_test, y_test))
</code></pre>
<p>But then I had the error mentioned in the title:
<code>ValueError: Shapes (None, 1) and (None, 3) are incompatible</code></p>
<p>Here is the <code>model.summary()</code></p>
<pre><code>Model: &quot;sequential_13&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_21 (LSTM)               (None, 20, 32)            15104     
_________________________________________________________________
lstm_22 (LSTM)               (None, 20)                4240      
_________________________________________________________________
dense_8 (Dense)              (None, 3)                 63        
=================================================================
Total params: 19,407
Trainable params: 19,407
Non-trainable params: 0
_________________________________________________________________
Train...
</code></pre>
<p>For this, I followed <a href=""https://stackoverflow.com/questions/61267737/valueerror-shapes-none-50-and-none-1-are-incompatible-in-tensorflow-and-c"">this</a> post and updated Tensorflow to the latest version, but the issue persists. <a href=""https://stackoverflow.com/questions/43901767/valueerror-shapes-2-1-and-are-incompatible"">This</a> post is completely unrelated and highly unreliable.<a href=""https://stackoverflow.com/questions/60789274/tf-estimator-add-metrics-ends-in-shapes-none-12-and-none-are-incompatible"">This</a> post although a bit relatable is unanswered for a while now.</p>
<p><strong>Update 1.0:</strong></p>
<p>I strongly think the problem has something to do with the final <code>Dense</code> layer where I pass nb_classes as 3, since I am classifying for 3 categories in <code>y</code>.</p>
<p>So I changed the <code>Dense</code> layer's <code>nb_classes</code> to 1, which ran the model and gives me this output, which I am positive is wrong.</p>
<pre><code>Train...
9/9 [==============================] - 2s 177ms/step - loss: 0.0000e+00 - accuracy: 0.1520 - val_loss: 0.0000e+00 - val_accuracy: 0.3418

&lt;tensorflow.python.keras.callbacks.History at 0x7f50f1dcebe0&gt;
</code></pre>
<p><strong>Update 2.0:</strong></p>
<p>I one hot encoded the <code>y</code>s and resolved the shape issue. But now the above output with <code>&lt;tensorflow.python.keras.callbacks.History at 0x7f50f1dcebe0&gt;</code> persists. Any help with this? Or should I post a new question for this? Thanks for all the help.</p>
<p>How should I proceed, or what should I be changing?</p>
",4060622.0,,10908375.0,,2021-01-18 12:41:45,2023-03-15 20:35:42,"ValueError: Shapes (None, 1) and (None, 3) are incompatible",<python><tensorflow><keras>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/61550026
45799474,1,45834857,,2017-08-21 14:20:51,,30,31822,"<p>I am training a simple model in keras for NLP task with following code. Variable names are self explanatory for train, test and validation set. This dataset has 19 classes so final layer of the network has 19 outputs. Labels are also one-hot encoded.</p>



<pre class=""lang-python prettyprint-override""><code>nb_classes = 19
model1 = Sequential()
model1.add(Embedding(nb_words,
                     EMBEDDING_DIM,
                     weights=[embedding_matrix],
                     input_length=MAX_SEQUENCE_LENGTH,
                     trainable=False))
model1.add(LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))
model1.add(Dropout(rate_drop_dense))
model1.add(BatchNormalization())
model1.add(Dense(num_dense, activation=act))
model1.add(Dropout(rate_drop_dense))
model1.add(BatchNormalization())

model1.add(Dense(nb_classes, activation = 'sigmoid'))


model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#One hot encode all labels
ytrain_enc = np_utils.to_categorical(train_labels)
yval_enc = np_utils.to_categorical(val_labels)
ytestenc = np_utils.to_categorical(test_labels)

model1.fit(train_data, ytrain_enc,
             validation_data=(val_data, yval_enc),
             epochs=200,
             batch_size=384,
             shuffle=True,
             verbose=1)
</code></pre>

<p>After first epoch, this gives me these outputs.</p>

<pre class=""lang-python prettyprint-override""><code>Epoch 1/200
216632/216632 [==============================] - 2442s - loss: 0.1427 - acc: 0.9443 - val_loss: 0.0526 - val_acc: 0.9826
</code></pre>

<p>Then I evaluate my model on testing dataset and this also shows me accuracy around 0.98.</p>

<pre class=""lang-python prettyprint-override""><code>model1.evaluate(test_data, y = ytestenc, batch_size=384, verbose=1)
</code></pre>

<p>However, the labels are one-hot encoded, so I need prediction vector of classes so that I can generate confusion matrix etc. So I use,</p>

<pre class=""lang-python prettyprint-override""><code>PREDICTED_CLASSES = model1.predict_classes(test_data, batch_size=384, verbose=1)
temp = sum(test_labels == PREDICTED_CLASSES)
temp/len(test_labels)
0.83
</code></pre>

<p>This shows that total predicted classes were 83% accurate however <code>model1.evaluate</code> shows 98% accuracy!! What am I doing wrong here? Is my loss function okay with categorical class labels? Is my choice of <code>sigmoid</code> activation function for prediction layer okay? or there is difference in the way keras evaluates a model? Please suggest on what can be wrong. This is my first try to make a deep model so I don't have much understanding of what's wrong here.</p>
",7280300.0,,4685471.0,,2017-09-05 13:46:37,2017-09-05 13:46:37,Keras: model.evaluate vs model.predict accuracy difference in multi-class NLP task,<machine-learning><deep-learning><keras>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45799474
44119207,1,44120068,,2017-05-22 17:54:26,,30,34705,"<p>I am looking for a proper or best way to get variable importance in a Neural Network created with Keras. The way I currently do it is I just take the weights (not the biases) of the variables in the first layer with the assumption that more important variables will have higher weights in the first layer. Is there another/better way of doing it?</p>
",1367204.0,,562769.0,,2017-10-18 14:40:38,2020-10-09 18:29:17,Is there any way to get variable importance with Keras?,<tensorflow><deep-learning><keras><keras-layer><keras-2>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44119207
49527159,1,49527269,,2018-03-28 06:01:53,,30,56482,"<p>I have the following code in Keras (Basically I am modifying this code for my use) and I get this error:</p>

<p>'ValueError: Error when checking target: expected conv3d_3 to have 5 dimensions, but got array with shape (10, 4096)'</p>

<p>Code:</p>

<pre><code>from keras.models import Sequential
from keras.layers.convolutional import Conv3D
from keras.layers.convolutional_recurrent import ConvLSTM2D
from keras.layers.normalization import BatchNormalization
import numpy as np
import pylab as plt
from keras import layers

# We create a layer which take as input movies of shape
# (n_frames, width, height, channels) and returns a movie
# of identical shape.

model = Sequential()
model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                   input_shape=(None, 64, 64, 1),
                   padding='same', return_sequences=True))
model.add(BatchNormalization())

model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                   padding='same', return_sequences=True))
model.add(BatchNormalization())

model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                   padding='same', return_sequences=True))
model.add(BatchNormalization())

model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),
                   padding='same', return_sequences=True))
model.add(BatchNormalization())

model.add(Conv3D(filters=1, kernel_size=(3, 3, 3),
               activation='sigmoid',
               padding='same', data_format='channels_last'))
model.compile(loss='binary_crossentropy', optimizer='adadelta')
</code></pre>

<p>the data I feed is in the following format: [1, 10, 64, 64, 1].
So I would like to know where I am wrong and also how to see the output_shape of each layer.</p>
",8234464.0,,,,,2022-06-17 17:54:07,How to get the output shape of a layer in Keras?,<python><keras><lstm><recurrent-neural-network>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49527159
40396042,1,40397312,,2016-11-03 07:34:56,,30,20613,"<p>I have the following code, using <a href=""https://github.com/fchollet/keras/blob/master/keras/wrappers/scikit_learn.py"">Keras Scikit-Learn Wrapper</a>:</p>

<pre><code>from keras.models import Sequential
from sklearn import datasets
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
import pickle
import numpy as np
import json

def classifier(X, y):
    """"""
    Description of classifier
    """"""
    NOF_ROW, NOF_COL =  X.shape

    def create_model():
        # create model
        model = Sequential()
        model.add(Dense(12, input_dim=NOF_COL, init='uniform', activation='relu'))
        model.add(Dense(6, init='uniform', activation='relu'))
        model.add(Dense(1, init='uniform', activation='sigmoid'))
        # Compile model
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        return model

    # evaluate using 10-fold cross validation
    seed = 7
    np.random.seed(seed)
    model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10, verbose=0)
    return model


def main():
    """"""
    Description of main
    """"""

    iris = datasets.load_iris()
    X, y = iris.data, iris.target
    X = preprocessing.scale(X)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)
    model_tt = classifier(X_train, y_train)
    model_tt.fit(X_train,y_train)

    #--------------------------------------------------
    # This fail
    #-------------------------------------------------- 
    filename = 'finalized_model.sav'
    pickle.dump(model_tt, open(filename, 'wb'))
    # load the model from disk
    loaded_model = pickle.load(open(filename, 'rb'))
    result = loaded_model.score(X_test, Y_test)
    print(result)

    #--------------------------------------------------
    # This also fail
    #--------------------------------------------------
    # from keras.models import load_model       
    # model_tt.save('test_model.h5')


    #--------------------------------------------------
    # This works OK 
    #-------------------------------------------------- 
    # print model_tt.score(X_test, y_test)
    # print model_tt.predict_proba(X_test)
    # print model_tt.predict(X_test)


# Output of predict_proba
# 2nd column is the probability that the prediction is 1
# this value is used as final score, which can be used
# with other method as comparison
# [   [ 0.25311464  0.74688536]
#     [ 0.84401423  0.15598579]
#     [ 0.96047372  0.03952631]
#     ...,
#     [ 0.25518912  0.74481088]
#     [ 0.91467732  0.08532269]
#     [ 0.25473493  0.74526507]]

# Output of predict
# [[1]
# [0]
# [0]
# ...,
# [1]
# [0]
# [1]]


if __name__ == '__main__':
    main()
</code></pre>

<p>As stated in the code there it fails at this line:</p>

<pre><code>pickle.dump(model_tt, open(filename, 'wb'))
</code></pre>

<p>With this error:</p>

<pre><code>pickle.PicklingError: Can't pickle &lt;function create_model at 0x101c09320&gt;: it's not found as __main__.create_model
</code></pre>

<p>How can I get around it?</p>
",67405.0,,67405.0,,2016-11-04 01:04:11,2023-05-10 08:44:29,How to save Scikit-Learn-Keras Model into a Persistence File (pickle/hd5/json/yaml),<python><scikit-learn><persistence><pickle><keras>,5,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40396042
48187283,1,48187516,,2018-01-10 12:14:45,,30,16113,"<p>I've checked the source code for both functions, and it seems that LSTM() makes the LSTM network in general, while LSTMCell() only returns one cell. </p>

<p>However, in most cases people only use one LSTM Cell in their program. Does this mean when you have only one LSTM Cell (ex. in simple Seq2Seq), calling LSTMCell() and LSTM() would make no difference?</p>
",6017074.0,,,,,2019-09-24 16:10:58,What's the difference between LSTM() and LSTMCell()?,<machine-learning><keras>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48187283
49665757,1,49675283,,2018-04-05 06:45:15,,30,34038,"<p>I'm trying to train a neural net on a GPU using Keras and am getting a ""Resource exhausted: OOM when allocating tensor"" error.  The specific tensor it's trying to allocate isn't very big, so I assume some previous tensor consumed almost all the VRAM.  The error message comes with a hint that suggests this:</p>

<blockquote>
  <p>Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.</p>
</blockquote>

<p>That sounds good, but how do I do it?  RunOptions appears to be a Tensorflow thing, and what little documentation I can find for it associates it with a ""session"".  I'm using Keras, so Tensorflow is hidden under a layer of abstraction and its sessions under another layer below that.</p>

<p>How do I dig underneath everything to set this option in such a way that it will take effect?</p>
",1944458.0,,,,,2022-06-16 16:21:51,How to add report_tensor_allocations_upon_oom to RunOptions in Keras,<python><tensorflow><keras><gpu>,5,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49665757
39930952,1,39931939,,2016-10-08 09:46:36,,30,131004,"<p>I'm trying to setup <code>keras</code> deep learning library for <code>Python3.5</code> on Ubuntu 16.04 LTS and use <code>Tensorflow</code> as a backend. I have <code>Python2.7</code> and <code>Python3.5</code> installed. I have installed <code>Anaconda</code> and with help of it  <code>Tensorflow</code>, <code>numpy</code>, <code>scipy</code>, <code>pyyaml</code>. Afterwards I have installed <code>keras</code> with command</p>

<blockquote>
  <p>sudo python setup.py install</p>
</blockquote>

<p>Although I can see <code>/usr/local/lib/python3.5/dist-packages/Keras-1.1.0-py3.5.egg</code> directory, I cannot use <code>keras</code> library. When I try to import it in python it says</p>

<blockquote>
  <p>ImportError: No module named 'keras'</p>
</blockquote>

<p>I have tried to install <code>keras</code> using<code>pip3</code>, but got the same result. </p>

<p>What am I doing wrong? Any Ideas?</p>
",1928515.0,,,,,2019-04-29 09:22:08,Cannot import keras after installation,<python><ubuntu><tensorflow><anaconda><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39930952
50184144,1,50187160,,2018-05-04 23:08:18,,30,45846,"<p>In the <code>model.fit</code> of <code>keras</code>, there is a <code>shuffle</code> parameter,</p>

<pre><code>shuffle: Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). 'batch' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not  None.
</code></pre>

<p>Assume the training set is a list with <code>50000</code> elements, so the whole list will be randomly permuted before each epoch? Of if the batch size is <code>250</code>, only the elements belonging to each batch get permuted? What should be the correct understanding?</p>
",297850.0,,,,,2020-09-29 05:21:33,shuffle in the model.fit of keras,<tensorflow><deep-learning><keras>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50184144
36886711,1,36890526,,2016-04-27 10:08:21,,30,40273,"<p>I'm using Anaconda Python 2.7 on windows 10</p>

<p>I was planning on doing Keras visualization so (whilst spyder was open) I opened the Anaconda command prompt and pip installed graphviz and pydot. Now when I try run the following:</p>

<pre><code>from keras.models import Sequential
</code></pre>

<p>or any sort of ""from keras."" ,  I get the error:</p>

<pre><code>ImportError: cannot import name gof
</code></pre>

<p>I have uninstalled and reinstalled Keras, Graphviz and pydot. i am using the development version of theano. I cannot find a fix. </p>

<p><strong>P.S</strong></p>

<p>If I uninstall graphviz and pydot, keras works again</p>

<p><strong>EDIT</strong></p>

<p>After uninstalling anaconda and reinstalling it including theano, keras, <strong>graphviz and pydot</strong> I now get the following error:</p>

<pre><code>from keras.utils.visualize_util import plot

Using Theano backend.
Using gpu device 0: GeForce GTX 970M (CNMeM is disabled, cuDNN not available)
Traceback (most recent call last):

  File ""&lt;ipython-input-1-65016ddab3cd&gt;"", line 1, in &lt;module&gt;
  from keras.utils.visualize_util import plot

  File ""C:\Anaconda2\lib\site-packages\keras\utils\visualize_util.py"", line  8, in &lt;module&gt;
  raise RuntimeError('Failed to import pydot. You must install pydot'

RuntimeError: Failed to import pydot. You must install pydot and graphviz  for `pydotprint` to work.
</code></pre>

<p>I used <code>pip install graphviz</code> and <code>pip install git+https://github.com/nlhepler/pydot.git</code></p>
",5310324.0,,5310324.0,,2016-04-27 12:51:07,2023-03-31 03:05:51,"Keras: ""RuntimeError: Failed to import pydot."" after installing graphviz and pydot",<python><graphviz><theano><keras><pydot>,13,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36886711
50715928,1,50716411,,2018-06-06 08:43:08,,30,32421,"<p>I'm building a model in Keras using some tensorflow function (reduce_sum and l2_normalize) in the last layer while encountered this problem. I have searched for a solution but all of it related to ""Keras tensor"".</p>

<p>Here is my code:</p>

<pre><code>import tensorflow as tf;
from tensorflow.python.keras import backend as K

vgg16_model = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape);

fire8 = extract_layer_from_model(vgg16_model, layer_name = 'block4_pool');

pool8 = MaxPooling2D((3,3), strides = (2,2), name = 'pool8')(fire8.output);

fc1 = Conv2D(64, (6,6), strides= (1, 1), padding = 'same', name = 'fc1')(pool8);

fc1 = Dropout(rate = 0.5)(fc1);

fc2 = Conv2D(3, (1, 1), strides = (1, 1), padding = 'same', name = 'fc2')(fc1);

fc2 = Activation('relu')(fc2);

fc2 = Conv2D(3, (15, 15), padding = 'valid', name = 'fc_pooling')(fc2);

fc2_norm = K.l2_normalize(fc2, axis = 3);

est = tf.reduce_sum(fc2_norm, axis = (1, 2));
est = K.l2_normalize(est);

FC_model = Model(inputs = vgg16_model.input, outputs = est);
</code></pre>

<p>and then the error: </p>

<blockquote>
  <p>ValueError: Output tensors to a Model must be the output of a
  TensorFlow <code>Layer</code> (thus holding past layer metadata). Found:
  Tensor(""l2_normalize_3:0"", shape=(?, 3), dtype=float32)</p>
</blockquote>

<p>I noticed that without passing fc2 layer to these functions, the model works fine:</p>

<pre><code>FC_model = Model(inputs = vgg16_model.input, outputs = fc2);
</code></pre>

<p>Can someone please explain to me this problem and some suggestion on how to fix it?</p>
",4902934.0,,4902934.0,,2018-08-01 15:13:31,2019-10-16 11:25:40,ValueError: Output tensors to a Model must be the output of a TensorFlow `Layer`,<python><tensorflow><machine-learning><keras><tensor>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50715928
45930750,1,45940876,,2017-08-29 04:35:18,,29,27415,"<p>Caffe can not only print overall accuracy, but also per-class accuracy.</p>
<p>In Keras log, there's only overall accuracy. It's hard for me to calculate the separate class accuracy.</p>
<pre><code>Epoch 168/200

0s - loss: 0.0495 - acc: 0.9818 - val_loss: 0.0519 - val_acc: 0.9796

Epoch 169/200

0s - loss: 0.0519 - acc: 0.9796 - val_loss: 0.0496 - val_acc: 0.9815

Epoch 170/200

0s - loss: 0.0496 - acc: 0.9815 - val_loss: 0.0514 - val_acc: 0.9801
</code></pre>
<p>Anybody who knows how to output per-class accuracy in keras?</p>
",8481526.0,,4685471.0,,2021-07-19 08:18:01,2022-01-24 17:00:48,How to output per-class accuracy in Keras？,<python><machine-learning><keras><neural-network><conv-neural-network>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45930750
44972565,1,44972728,,2017-07-07 13:52:02,,29,37504,"<p>According to the keras <a href=""https://keras.io/models/sequential/"" rel=""noreferrer"">documentation</a>:</p>

<pre><code>predict_on_batch(self, x)
Returns predictions for a single batch of samples.
</code></pre>

<p>However, there does not seem to be any difference with the standard <code>predict</code> method when called on a batch, whether it being with one or multiple elements.</p>

<pre><code>model.predict_on_batch(np.zeros((n, d_in)))
</code></pre>

<p>is the same as </p>

<pre><code>model.predict(np.zeros((n, d_in)))
</code></pre>

<p>(a <code>numpy.ndarray</code> of shape <code>(n, d_out</code>)</p>
",3860928.0,,,,,2020-04-18 11:16:10,What is the difference between the predict and predict_on_batch methods of a Keras model?,<python><deep-learning><keras>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44972565
49404993,1,49405175,,2018-03-21 11:21:18,,29,25656,"<p>Is it possible to have two fit_generator?</p>

<p>I'm creating a model with two inputs,
The model configuration is shown below.</p>

<p><a href=""https://i.stack.imgur.com/FDY0W.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/FDY0W.png"" alt=""enter image description here""></a></p>

<p>Label Y uses the same labeling for X1 and X2 data.</p>

<p>The following error will continue to occur.</p>

<blockquote>
  <p><em>Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected
  to see 2 array(s), but instead got the following list of 1 arrays:
  [array([[[[0.75686276, 0.75686276, 0.75686276],
           [0.75686276, 0.75686276, 0.75686276],
           [0.75686276, 0.75686276, 0.75686276],
           ...,
           [0.65882355, 0.65882355, 0.65882355...</em></p>
</blockquote>

<p>My code looks like this:</p>



<pre class=""lang-python prettyprint-override""><code>def generator_two_img(X1, X2, Y,batch_size):
    generator = ImageDataGenerator(rotation_range=15,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

    genX1 = generator.flow(X1, Y, batch_size=batch_size)
    genX2 = generator.flow(X2, Y, batch_size=batch_size)

    while True:
        X1 = genX1.__next__()
        X2 = genX2.__next__()
        yield [X1, X2], Y
  """"""
      .................................
  """"""
hist = model.fit_generator(generator_two_img(x_train, x_train_landmark, 
                y_train, batch_size),
                steps_per_epoch=len(x_train) // batch_size, epochs=nb_epoch,
                callbacks = callbacks,
                validation_data=(x_validation, y_validation),
                validation_steps=x_validation.shape[0] // batch_size, 
                `enter code here`verbose=1)
</code></pre>
",9527246.0,,11573842.0,,2021-03-06 10:46:18,2022-01-27 09:29:58,How to use fit_generator with multiple inputs,<python><machine-learning><neural-network><keras><generator>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/49404993
46947842,1,47061543,,2017-10-26 07:07:32,,29,4321,"<p><strong>Preamble</strong></p>

<p>I am currently working on a Machine Learning problem where we are tasked with using past data on product sales in order to predict sales volumes going forward (so that shops can better plan their stocks). We essentially have time series data, where for each and every product we know how many units were sold on which days. We also have information like what the weather was like, whether there was a public holiday, if any of the products were on sales etc. </p>

<p>We've been able to model this with some success using an MLP with dense layers, and just using a sliding window approach to include sales volumes from the surrounding days. However, we believe we'll be able to get much better results with a time-series approach such as an LSTM.</p>

<p><strong>Data</strong></p>

<p>The data we have essentially is as follows:</p>

<p><a href=""https://i.stack.imgur.com/fOr4z.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/fOr4z.jpg"" alt=""enter image description here""></a></p>

<p>(<strong>EDIT:</strong> for clarity the ""Time"" column in the picture above is not correct. We have inputs once per day, not once per month. But otherwise the structure is the same!)</p>

<p>So the X data is of shape:</p>

<pre><code>(numProducts, numTimesteps, numFeatures) = (50 products, 1096 days, 90 features)
</code></pre>

<p>And the Y data is of shape:</p>

<pre><code>(numProducts, numTimesteps, numTargets) =  (50 products, 1096 days, 3 binary targets)
</code></pre>

<p><a href=""https://i.stack.imgur.com/uaSl5.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/uaSl5.jpg"" alt=""enter image description here""></a></p>

<p>So we have data for three years (2014, 2015, 2016) and want to train on this in order to make predictions for 2017. (That's of course not 100% true, since we actually have data up to Oct 2017, but let's just ignore that for now)</p>

<p><strong>Problem</strong></p>

<p>I would like to build an LSTM in Keras that allows me to make these predictions. There are a few places where I am getting stuck though. So I have six concrete questions (I know one is supposed to try to limit a Stackoverflow post to one question, but these are all intertwined).</p>

<p>Firstly, <strong>how would I slice up my data for the batches</strong>? Since I have three full years, does it make sense to simply push through three batches, each time of size one year? Or does it make more sense to make smaller batches (say 30 days) and also to using sliding windows? I.e. instead of 36 batches of 30 days each, I use 36 * 6 batches of 30 days each, each time sliding with 5 days? Or is this not really the way LSTMs should be used? (Note that there is quite a bit of seasonality in the data, to I need to catch that kind of long-term trend as well).</p>

<p>Secondly, <strong>does it make sense to use</strong> <code>return_sequences=True</code> here? In other words, I keep my Y data as is <code>(50, 1096, 3)</code> so that (as far as I've understood it) there is a prediction at every time step for which a loss can be calculated against the target data? Or would I be better off with <code>return_sequences=False</code>, so that only the final value of each batch is used to evaluate the loss (i.e. if using yearly batches, then in 2016 for product 1, we evaluate against the Dec 2016 value of <code>(1,1,1)</code>).</p>

<p>Thirdly <strong>how should I deal with the 50 different products?</strong> They are different, but still strongly correlated and we've seen with other approaches (for example an MLP with simple time-windows) that the results are better when all products are considered in the same model. Some ideas that are currently on the table are:</p>

<ul>
<li>change the target variable to be not just 3 variables, but 3 * 50 = 150; i.e. for each product there are three targets, all of which are trained simultaneously. </li>
<li>split up the results after the LSTM layer into 50 dense networks, which take as input the ouputs from the LSTM, plus some features that are specific to each product - i.e. we get a multi-task network with 50 loss functions, which we then optimise together. Would that be crazy?</li>
<li>consider a product as a single observation, and include product specific features already at the LSTM layer. Use just this one layer followed by an ouput layer of size 3 (for the three targets). Push through each product in a separate batch.</li>
</ul>

<p>Fourthly, <strong>how do I deal with validation data</strong>? Normally I would just keep out a randomly selected sample to validate against, but here we need to keep the time ordering in place. So I guess the best is to just keep a few months aside?</p>

<p>Fifthly, and this is the part that is probably the most unclear to me - <strong>how can I use the actual results to perform predictions</strong>? Let's  say I used <code>return_sequences=False</code> and I trained on all three years in three batches (each time up to Nov) with the goal of training the model to predict the next value (Dec 2014, Dec 2015, Dec 2016). If I want to use these results in 2017, how does this actually work? If I understood it correctly, the only thing I can do in this instance is to then feed the model all the data points for Jan to Nov 2017 and it will give me back a prediction for Dec 2017. Is that correct? However, if I were to use <code>return_sequences=True</code>, then trained on all data up to Dec 2016, would I then be able to get a prediction for Jan 2017 just by giving the model the features observed at Jan 2017? Or do I need to also give it the 12 months before Jan 2017? What about Feb 2017, do I in addition need to give the value for 2017, plus a further 11 months before that? (If it sounds like I'm confused, it's because I am!)</p>

<p>Lastly, depending on what structure I should use, <strong>how do I do this in Keras</strong>? What I have in mind at the moment is something along the following lines: (though this would be for only one product, so doesn't solve having all products in the same model):</p>

<p><strong>Keras code</strong></p>

<pre><code>trainX = trainingDataReshaped #Data for Product 1, Jan 2014 to Dec 2016
trainY = trainingTargetReshaped
validX = validDataReshaped #Data for Product 1, for ??? Maybe for a few months?
validY = validTargetReshaped    

numSequences = trainX.shape[0]
numTimeSteps = trainX.shape[1]
numFeatures = trainX.shape[2]

numTargets = trainY.shape[2]

model = Sequential()
model.add(LSTM(100, input_shape=(None, numFeatures), return_sequences=True)) 
model.add(Dense(numTargets, activation=""softmax""))    

model.compile(loss=stackEntry.params[""loss""],
      optimizer=""adam"",
      metrics=['accuracy'])

history = model.fit(trainX, trainY,
            batch_size=30,
            epochs=20,
            verbose=1,
            validation_data=(validX, validY))               

predictX  = predictionDataReshaped #Data for Product 1, Jan 2017 to Dec 2017

prediction=model.predict(predictX)
</code></pre>
",141789.0,,5974433.0,,2017-12-30 13:34:51,2017-12-30 13:34:51,"Building a mutlivariate, multi-task LSTM with Keras",<tensorflow><machine-learning><neural-network><keras><lstm>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46947842
42596057,1,42596310,,2017-03-04 12:31:47,,29,35273,"<p>I got the following error when I tried to train an MLP model in keras(I am using keras version <code>1.2.2</code>)</p>

<blockquote>
  <p>Error when checking model input: the list of Numpy arrays that you
  are passing to your model is not the size the model expected. Expected
  to see 1 arrays but instead got the following list of 12859 arrays:</p>
</blockquote>

<p>This is the summary of the model</p>

<pre><code>____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
dense_1 (Dense)                  (None, 20)            4020        dense_input_1[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 2)             42          dense_1[0][0]
====================================================================================================
Total params: 4,062
Trainable params: 4,062
Non-trainable params: 0
____________________________________________________________________________________________________
None
</code></pre>

<p>This is the first line of model</p>

<pre><code> model.add(Dense(20, input_shape=(200,), init='lecun_uniform', activation='tanh'))
</code></pre>

<p>For training:</p>

<pre><code>model.fit(X,Y,nb_epoch=100,verbose=1)
</code></pre>

<p>where X is a list of elements and each element in turn is a list of 200 values.</p>

<p>Edit :</p>

<p>I also tried</p>

<pre><code>model.add(Dense(20, input_shape=(12859,200), init='lecun_uniform', activation='tanh'))
</code></pre>

<p>but I am getting the same error</p>
",6354442.0,,5974433.0,,2017-03-04 17:43:02,2019-03-21 10:08:20,Keras error : Expected to see 1 array,<python><machine-learning><neural-network><deep-learning><keras>,2,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42596057
51731207,1,51731446,,2018-08-07 16:10:34,,29,36860,"<p>I have been practicing building and comparing neural networks using Keras and Tensorflow in python, but when I look to plot the models for comparisons I am receiving an error:</p>

<pre><code>TypeError: 'History' object is not subscriptable
</code></pre>

<p>Here is my code for the three models:</p>

<pre><code>############################## Initiate model 1 ###############################
# Model 1 has no hidden layers
from keras.models import Sequential
model1 = Sequential()

# Get layers
from keras.layers import Dense
# Add first layer
n_cols = len(X.columns)
model1.add(Dense(units=n_cols, activation='relu', input_shape=(n_cols,)))
# Add output layer
model1.add(Dense(units=2, activation='softmax'))

# Compile the model
model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics= 
['accuracy']) 

# Define early_stopping_monitor
from keras.callbacks import EarlyStopping
early_stopping_monitor = EarlyStopping(patience=2)

# Fit model
model1.fit(X, y, validation_split=0.33, epochs=30, callbacks= 
[early_stopping_monitor], verbose=False)


############################## Initiate model 2 ###############################
# Model 2 has 1 hidden layer that has the mean number of nodes of input and output layer
model2 = Sequential()

# Add first layer
model2.add(Dense(units=n_cols, activation='relu', input_shape=(n_cols,)))
# Add hidden layer
import math
model2.add(Dense(units=math.ceil((n_cols+2)/2), activation='relu'))
# Add output layer
model2.add(Dense(units=2, activation='softmax'))

# Compile the model
model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics= 
['accuracy']) 

# Fit model
model2.fit(X, y, validation_split=0.33, epochs=30, callbacks= 
[early_stopping_monitor], verbose=False)

############################## Initiate model 3 ###############################
# Model 3 has 1 hidden layer that is 2/3 the size of the input layer plus the size of the output layer
model3 = Sequential()

# Add first layer
model3.add(Dense(units=n_cols, activation='relu', input_shape=(n_cols,)))
# Add hidden layer
model3.add(Dense(units=math.ceil((n_cols*(2/3))+2), activation='relu'))
# Add output layer
model3.add(Dense(units=2, activation='softmax'))

# Compile the model
model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics= 
['accuracy']) 

# Fit model
model3.fit(X, y, validation_split=0.33, epochs=30, callbacks= 
[early_stopping_monitor], verbose=False)


# Plot the models
plt.plot(model1.history['val_loss'], 'r', model2.history['val_loss'], 'b', 
model3.history['val_loss'], 'g')
plt.xlabel('Epochs')
plt.ylabel('Validation score')
plt.show()
</code></pre>

<p>I have no problems with running any of my models, getting predicted probabilities, plotting ROC curves, or plotting PR curves. However, when I attempt to plot the three curves together I am getting an error from this area of my code:</p>

<pre><code>model1.history['val_loss']

TypeError: 'History' object is not subscriptable
</code></pre>

<p>Does anyone have experience with this type of error and can lead me to what I am doing wrong?</p>

<p>Thank you in advance.</p>
",6875778.0,,,,,2022-06-06 23:13:42,Python: Neural Network - TypeError: 'History' object is not subscriptable,<python><tensorflow><neural-network><keras>,4,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51731207
44172165,1,44451189,,2017-05-25 04:15:30,,29,23890,"<p>I am using a multiple output model in Keras</p>

<pre><code>model1 = Model(input=x, output=[y2, y3])

model1.compile((optimizer='sgd', loss=cutom_loss_function)
</code></pre>

<p>my <code>custom_loss</code> function is</p>

<pre><code>def custom_loss(y_true, y_pred):
   y2_pred = y_pred[0]
   y2_true = y_true[0]

   loss = K.mean(K.square(y2_true - y2_pred), axis=-1)
   return loss
</code></pre>

<p>I only want to train the network on output <code>y2</code>.</p>

<p>What is the shape/structure of the <code>y_pred</code> and <code>y_true</code> argument in loss function when multiple outputs are used?
Can I access them as above? Is it <code>y_pred[0]</code> or <code>y_pred[:,0]</code>?</p>
",4101250.0,,3924118.0,,2019-12-29 21:06:12,2021-02-10 21:55:13,How to train the network only on one output when there are multiple outputs?,<model><keras><prediction><loss><multipleoutputs>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/44172165
69471749,1,69472316,,2021-10-06 19:36:38,,29,82098,"<p>i have an import problem when executing my code:</p>
<pre><code>from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
</code></pre>
<pre><code>2021-10-06 22:27:14.064885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-10-06 22:27:14.064974: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File &quot;C:\Data\breast-cancer-classification\train_model.py&quot;, line 10, in &lt;module&gt;
    from cancernet.cancernet import CancerNet
  File &quot;C:\Data\breast-cancer-classification\cancernet\cancernet.py&quot;, line 2, in &lt;module&gt;
    from keras.layers.normalization import BatchNormalization
ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (C:\Users\Catalin\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\layers\normalization\__init__.py)
</code></pre>
<ul>
<li>Keras version: 2.6.0</li>
<li>Tensorflow: 2.6.0</li>
<li>Python version: 3.9.7</li>
</ul>
<p>The library it is installed also with</p>
<pre><code>pip install numpy opencv-python pillow tensorflow keras imutils scikit-learn matplotlib
</code></pre>
<p>Do you have any ideas?</p>
<p><a href=""https://i.stack.imgur.com/Qup45.png"" rel=""noreferrer"">library path</a></p>
",8483107.0,,4685471.0,,2021-10-09 23:36:29,2021-11-13 07:14:12,ImportError: cannot import name 'BatchNormalization' from 'keras.layers.normalization',<python><tensorflow><keras>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/69471749
51337558,1,51337967,,2018-07-14 10:24:22,,29,60656,"<p>I want to import keras.engine.topology in Tensorflow.
I used to add the word tensorflow at the beginning of every Keras import if I want to use the Tensorflow  version of Keras.</p>

<p>For example: instead of writing:</p>

<pre><code>from keras.layers import Dense, Dropout, Input
</code></pre>

<p>I just write the following code and it works fine :</p>

<pre><code>from tensorflow.keras.layers import Dense, Dropout, Input
</code></pre>

<p>But that's not the case for this specific import:</p>

<pre><code>from tensorflow.keras.engine.topology import Layer, InputSpec
</code></pre>

<p>And I m getting the following error message:</p>

<pre><code>No module named 'tensorflow.keras.engine'
</code></pre>
",4713057.0,,,,,2023-05-20 03:53:40,How to import keras.engine.topology in Tensorflow?,<python><tensorflow><keras>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51337558
44274701,1,44349081,,2017-05-31 02:31:49,,28,13230,"<p>I have a model trained using Keras with Tensorflow as my backend, but now I need to turn my model into a tensorflow graph for a certain application. I attempted to do this and make predictions to insure that it is working correctly, but when comparing to the results gathered from model.predict() I get very different values. For instance:</p>

<pre><code>from keras.models import load_model
import tensorflow as tf

model = load_model('model_file.h5')

x_placeholder = tf.placeholder(tf.float32, shape=(None,7214,1))
y = model(x_placeholder)

x = np.ones((1,7214,1))


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(""Predictions from:\ntf graph:      ""+str(sess.run(y, feed_dict={x_placeholder:x})))
    print(""keras predict: ""+str(model.predict(x)))
</code></pre>

<p>returns:</p>

<pre><code>Predictions from:
tf graph:      [[-0.1015993   0.07432419  0.0592984 ]]
keras predict: [[ 0.39339241  0.57949686 -3.67846966]]
</code></pre>

<p>The values from keras predict are correct, but the tf graph results are not.</p>

<p>If it helps to know the final intended application, I am creating a jacobian matrix with the tf.gradients() function, but currently it does not return the correct results when comparing to theano's jacobian function, which gives the correct jacobian. Here is my tensorflow jacobian code:</p>

<pre><code>x = tf.placeholder(tf.float32, shape=(None,7214,1))
y = tf.reshape(model(x)[0],[-1])
y_list = tf.unstack(y)

jacobian_list = [tf.gradients(y_, x)[0] for y_ in y_list]
jacobian = tf.stack(jacobian_list)
</code></pre>

<p>EDIT: Model code</p>

<pre><code>import numpy as np

from keras.models import Sequential
from keras.layers import Dense, InputLayer, Flatten
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ReduceLROnPlateau

# activation function used following every layer except for the output layers
activation = 'relu'

# model weight initializer
initializer = 'he_normal'

# shape of input data that is fed into the input layer
input_shape = (None,7214,1)

# number of filters used in the convolutional layers
num_filters = [4,16]

# length of the filters in the convolutional layers
filter_length = 8

# length of the maxpooling window 
pool_length = 4

# number of nodes in each of the hidden fully connected layers
num_hidden_nodes = [256,128]

# number of samples fed into model at once during training
batch_size = 64

# maximum number of interations for model training
max_epochs = 30

# initial learning rate for optimization algorithm
lr = 0.0007

# exponential decay rate for the 1st moment estimates for optimization algorithm
beta_1 = 0.9

# exponential decay rate for the 2nd moment estimates for optimization algorithm
beta_2 = 0.999

# a small constant for numerical stability for optimization algorithm
optimizer_epsilon = 1e-08

model = Sequential([

    InputLayer(batch_input_shape=input_shape),

    Conv1D(kernel_initializer=initializer, activation=activation, padding=""same"", filters=num_filters[0], kernel_size=filter_length),

    Conv1D(kernel_initializer=initializer, activation=activation, padding=""same"", filters=num_filters[1], kernel_size=filter_length),

    MaxPooling1D(pool_size=pool_length),

    Flatten(),

    Dense(units=num_hidden_nodes[0], kernel_initializer=initializer, activation=activation),

    Dense(units=num_hidden_nodes[1], kernel_initializer=initializer, activation=activation),

    Dense(units=3, activation=""linear"", input_dim=num_hidden_nodes[1]),
]) 

# compile model
loss_function = mean squared error
early_stopping_min_delta = 0.0001
early_stopping_patience = 4
reduce_lr_factor = 0.5
reuce_lr_epsilon = 0.0009
reduce_lr_patience = 2
reduce_lr_min = 0.00008

optimizer = Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=optimizer_epsilon, decay=0.0)

early_stopping = EarlyStopping(monitor='val_loss',     min_delta=early_stopping_min_delta, 
                                   patience=early_stopping_patience, verbose=2, mode='min')

reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, epsilon=reuce_lr_epsilon, 
                              patience=reduce_lr_patience,     min_lr=reduce_lr_min, mode='min', verbose=2)

model.compile(optimizer=optimizer, loss=loss_function)

model.fit(train_x, train_y, validation_data=(cv_x, cv_y),
      epochs=max_epochs, batch_size=batch_size, verbose=2,
      callbacks=[reduce_lr,early_stopping])

model.save('model_file.h5')
</code></pre>
",7687401.0,,7687401.0,,2017-05-31 20:52:44,2017-10-15 00:42:47,Make predictions using a tensorflow graph from a keras model,<python><machine-learning><tensorflow><keras>,1,8,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44274701
57144586,1,75347426,,2019-07-22 10:59:50,,28,32627,"<p>When training my network I am occasionally met with the warning: </p>

<p><code>W0722 11:47:35.101842 140641577297728 optimizer_v2.py:928] Gradients does not exist for variables ['model/conv1d_x/Variable:0'] when minimizing the loss.
</code></p>

<p>This happens sporadically at infrequent intervals (maybe once in every 20 successful steps). My model basically has two paths which join together with concatenations at various positions in the network. To illustrate this, here is a simplified example of what I mean.</p>

<pre><code>class myModel(tf.keras.Model):

  def __init__(self):

    self.conv1 = Conv2D(32)
    self.conv2 = Conv2D(32)
    self.conv3 = Conv2D(16)

  def call(self, inputs):

    net1 = self.conv1(inputs)
    net2 = self.conv2(inputs)
    net = tf.concat([net1, net2], axis=2)
    net = self.conv3(net)
    end_points = tf.nn.softmax(net)

model = myModel()

with tf.GradientTape() as tape:

  predicition = model(image)
  loss = myloss(labels, prediction)

gradients = tape.gradient(loss, model.trainable_variables)
optimizer.apply_gradients(zip(gradients, model.trainable_variables))
</code></pre>

<p>In reality my network is much larger, but the variables that generally don't have gradients tend to be the ones at the top of the network. Before each <code>Conv2D</code> layer I also have a custom gradient. Sometimes when I the error appears I can notice that the gradient function for that layer has not been called.</p>

<p>My question is how can the gradient tape sometimes take what appears to be different paths when propagating backwards through my network. My secondary question, is this caused by having two separate routes through my network (i.e. conv1 AND conv2). Is there a fundamental flaw in this network architecture?</p>

<p>Ideally, could I define to the <code>GradientTape()</code> that it must find the gradients for each of the top layers? </p>
",8058705.0,,,,,2023-02-04 18:36:14,"Tensorflow GradientTape ""Gradients does not exist for variables"" intermittently",<python><tensorflow><keras>,9,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/57144586
48493755,1,48494469,,2018-01-29 02:55:27,,28,74836,"<p>I'm running a Keras neural network model in Jupyter Notebook (Python 3.6)</p>

<p>I get the following error</p>

<blockquote>
  <p>AttributeError: 'list' object has no attribute 'ndim'</p>
</blockquote>

<p>after calling the .fit() method from Keras.model</p>

<pre><code>model  = Sequential()
model.add(Dense(5, input_dim=len(X_data[0]), activation='sigmoid' ))
model.add(Dense(1, activation = 'sigmoid'))
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])
model.fit(X_data, y_data, epochs=20, batch_size=10)
</code></pre>

<p>I checked the requirements.txt file for Keras (in Anaconda3) and the numpy, scipy, and six module versions are all up to date.</p>

<p>What can explain this AttributeError?</p>

<p>The full error message is the following (seems to be somewhat related to Numpy):</p>

<blockquote>
  <p>--------------------------------------------------------------------------- AttributeError                            Traceback (most recent call
  last)  in ()
        3 model.add(Dense(1, activation = 'sigmoid'))
        4 model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])
  ----> 5 model.fit(X_data, y_data, epochs=20, batch_size=10)</p>
  
  <p>~\Anaconda3\lib\site-packages\keras\models.py in fit(self, x, y,
  batch_size, epochs, verbose, callbacks, validation_split,
  validation_data, shuffle, class_weight, sample_weight, initial_epoch,
  steps_per_epoch, validation_steps, **kwargs)
      963                               initial_epoch=initial_epoch,
      964                               steps_per_epoch=steps_per_epoch,
  --> 965                               validation_steps=validation_steps)
      966 
      967     def evaluate(self, x=None, y=None,</p>
  
  <p>~\Anaconda3\lib\site-packages\keras\engine\training.py in fit(self, x,
  y, batch_size, epochs, verbose, callbacks, validation_split,
  validation_data, shuffle, class_weight, sample_weight, initial_epoch,
  steps_per_epoch, validation_steps, **kwargs)    1591<br>
  class_weight=class_weight,    1592             check_batch_axis=False,
  -> 1593             batch_size=batch_size)    1594         # Prepare validation data.    1595         do_validation = False</p>
  
  <p>~\Anaconda3\lib\site-packages\keras\engine\training.py in
  _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)    1424<br>
  self._feed_input_shapes,    1425<br>
  check_batch_axis=False,
  -> 1426                                     exception_prefix='input')    1427         y = _standardize_input_data(y, self._feed_output_names,<br>
  1428                                     output_shapes,</p>
  
  <p>~\Anaconda3\lib\site-packages\keras\engine\training.py in
  _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
       68     elif isinstance(data, list):
       69         data = [x.values if x.<strong>class</strong>.<strong>name</strong> == 'DataFrame' else x for x in data]
  ---> 70         data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]
       71     else:
       72         data = data.values if data.<strong>class</strong>.<strong>name</strong> == 'DataFrame' else data</p>
  
  <p>~\Anaconda3\lib\site-packages\keras\engine\training.py in
  (.0)
       68     elif isinstance(data, list):
       69         data = [x.values if x.<strong>class</strong>.<strong>name</strong> == 'DataFrame' else x for x in data]
  ---> 70         data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]
       71     else:
       72         data = data.values if data.<strong>class</strong>.<strong>name</strong> == 'DataFrame' else data</p>
  
  <p>AttributeError: 'list' object has no attribute 'ndim'</p>
</blockquote>
",7201349.0,,7201349.0,,2018-01-29 03:22:32,2019-02-15 10:55:52,Keras AttributeError: 'list' object has no attribute 'ndim',<python><tensorflow><machine-learning><keras><jupyter-notebook>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48493755
49035200,1,49055577,,2018-02-28 17:19:12,,28,48565,"<p>I am training a Keras (Tensorflow backend, Python, on MacBook) and am getting an error in the early stopping callback in fit_generator function.  The error is as follows:</p>

<pre><code>RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are:
  (self.monitor, ','.join(list(logs.keys()))),
RuntimeWarning: Can save best model only with val_acc available, skipping.

'skipping.' % (self.monitor), RuntimeWarning
[local-dir]/lib/python3.6/site-packages/keras/callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are:
  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning
[local-dir]/lib/python3.6/site-packages/keras/callbacks.py:406: RuntimeWarning: Can save best model only with val_acc available, skipping.
  'skipping.' % (self.monitor), RuntimeWarning)
Traceback (most recent call last):
  :
  [my-code]
  :
  File ""[local-dir]/lib/python3.6/site-packages/keras/legacy/interfaces.py"", line 91, in wrapper
return func(*args, **kwargs)
  File ""[local-dir]/lib/python3.6/site-packages/keras/engine/training.py"", line 2213, in fit_generator
callbacks.on_epoch_end(epoch, epoch_logs)
  File ""[local-dir]/lib/python3.6/site-packages/keras/callbacks.py"", line 76, in on_epoch_end
callback.on_epoch_end(epoch, logs)
  File ""[local-dir]/lib/python3.6/site-packages/keras/callbacks.py"", line 310, in on_epoch_end
self.progbar.update(self.seen, self.log_values, force=True)
AttributeError: 'ProgbarLogger' object has no attribute 'log_values'
</code></pre>

<p>My code is as follows (which looks OK):</p>

<pre><code>:
ES = EarlyStopping(monitor=""val_loss"", min_delta=0.001, patience=3, mode=""min"", verbose=1)
:
self.model.fit_generator(
        generator        = train_batch,
        validation_data  = valid_batch,
        validation_steps = validation_steps,
        steps_per_epoch  = steps_per_epoch,
        epochs           = epochs,
        callbacks        = [ES],
        verbose          = 1,
        workers          = 3,
        max_queue_size   = 8)
</code></pre>

<p>The error message appears to relate to the early stopping callback but the callback looks OK.  Also the error states that the val_loss is not appropriate, but I am not sure why... one more unusual thing about this is that the error only occurs when I use smaller data sets.</p>

<p>Any help is appreciated.</p>
",3011570.0,,,,,2022-09-14 17:42:53,"Keras early stopping callback error, val_loss metric not available",<python><tensorflow><keras>,13,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49035200
50125844,1,50134698,,2018-05-02 01:06:12,,28,33150,"<p>I am working on a signal classification problem and would like to scale the dataset matrix first, but my data is in a 3D format (batch, length, channels).<br>
I tried to use Scikit-learn Standard Scaler:</p>

<pre><code>from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
</code></pre>

<p>But I've got this error message:</p>

<blockquote>
  <p>Found array with dim 3. StandardScaler expected &lt;= 2</p>
</blockquote>

<p>I think one solution would be to split the matrix by each channel in multiples 2D matrices, scale them separately and then put back in 3D format, but I wonder if there is a better solution.<br>
Thank you very much.</p>
",9028779.0,,10375049.0,,2020-10-07 09:43:05,2023-02-08 14:01:14,How to standard scale a 3D matrix?,<python><machine-learning><keras><scikit-learn><deep-learning>,8,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50125844
44466066,1,46210187,,2017-06-09 20:16:05,,28,35174,"<p>I have a trained Tensorflow model and weights vector which have been exported to protobuf and weights files respectively.</p>

<p>How can I convert these to JSON or YAML and HDF5 files which can be used by Keras?</p>

<p>I have the code for the Tensorflow model, so it would also be acceptable to convert the <code>tf.Session</code> to a keras model and save that in code.</p>
",5605365.0,,5605365.0,,2017-06-09 21:18:55,2018-12-10 09:38:43,How can I convert a trained Tensorflow model to Keras?,<tensorflow><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44466066
43784921,1,49363251,,2017-05-04 13:56:45,,28,20178,"<p>I'm working on a segmentation problem in Keras and I want to display segmentation results at the end of every training epoch.</p>

<p>I want something similar to <a href=""https://stackoverflow.com/questions/38543850/tensorflow-how-to-display-custom-images-in-tensorboard-e-g-matplotlib-plots""><em>Tensorflow: How to Display Custom Images in Tensorboard (e.g. Matplotlib Plots)</em></a>, but using Keras. I know that Keras has the <a href=""https://keras.io/callbacks/#tensorboard"" rel=""noreferrer""><code>TensorBoard</code></a> callback but it seems limited for this purpose.</p>

<p>I know this would break the Keras backend abstraction, but I'm interested in using TensorFlow backend anyway.</p>

<p>Is it possible to achieve that with Keras + TensorFlow?</p>
",604734.0,,604734.0,,2018-09-27 07:24:23,2020-09-29 23:09:20,How to display custom images in TensorBoard using Keras?,<tensorflow><keras><deep-learning><tensorboard>,8,6,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43784921
55233377,1,55234203,,2019-03-19 03:50:45,,28,63443,"<p>I am making a MLP model which takes two inputs and produces a single output.</p>

<p>I have two input arrays (one for each input) and 1 output array. The neural network has 1 hidden layer with 2 neurons. Each array has 336 elements.</p>

<pre><code>model0 = keras.Sequential([
keras.layers.Dense(2, input_dim=2, activation=keras.activations.sigmoid, use_bias=True),
keras.layers.Dense(1, activation=keras.activations.relu, use_bias=True),
])

# Compile the neural network #
model0.compile(
    optimizer = keras.optimizers.RMSprop(lr=0.02,rho=0.9,epsilon=None,decay=0),
    loss = 'mean_squared_error',
    metrics=['accuracy']
)
</code></pre>

<p>I tried two ways, both of them are giving errors.</p>

<pre><code>model0.fit(numpy.array([array_1, array_2]),output, batch_size=16, epochs=100)
</code></pre>

<blockquote>
  <p>ValueError: Error when checking input: expected dense_input to have shape (2,) but got array with shape (336,)</p>
</blockquote>

<p>The second way:</p>

<pre><code>model0.fit([array_1, array_2],output, batch_size=16, epochs=100)
</code></pre>

<blockquote>
  <p>ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays:</p>
</blockquote>

<p><a href=""https://stackoverflow.com/questions/53017177/multiple-inputs-to-keras-sequential-model"">Similar question</a>. But not using sequential model.</p>
",7303913.0,,,,,2022-03-12 08:07:01,Keras Sequential model with multiple inputs,<python><arrays><tensorflow><keras>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55233377
46036522,1,46040835,,2017-09-04 11:55:48,,28,22676,"<p>Can somebody tell me what include_top= True means when defining a model in keras?</p>

<p>I read the meaning of this line in Keras Documentation. It says include_top: whether to include the fully-connected layer at the top of the network.</p>

<p>I am still looking for an intuitive explanation for this line of code. </p>

<pre><code>ResNet50(include_top=True)
</code></pre>

<p>Thanks!</p>
",4724057.0,,,,,2019-07-20 21:40:24,Defining model in keras (include_top = True),<python><neural-network><keras><convolution>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46036522
48775305,1,48788577,,2018-02-13 20:43:55,,28,28354,"<p>How is Accuracy defined when the loss function is mean square error? Is it <a href=""https://en.wikipedia.org/wiki/Mean_absolute_percentage_error"" rel=""noreferrer"">mean absolute percentage error</a>?</p>



<p>The model I use has output activation linear and is compiled with <code>loss= mean_squared_error</code></p>

<pre class=""lang-python prettyprint-override""><code>model.add(Dense(1))
model.add(Activation('linear'))  # number

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>and the output looks like this:</p>

<pre class=""lang-python prettyprint-override""><code>Epoch 99/100
1000/1000 [==============================] - 687s 687ms/step - loss: 0.0463 - acc: 0.9689 - val_loss: 3.7303 - val_acc: 0.3250
Epoch 100/100
1000/1000 [==============================] - 688s 688ms/step - loss: 0.0424 - acc: 0.9740 - val_loss: 3.4221 - val_acc: 0.3701
</code></pre>

<p>So what does e.g. val_acc: 0.3250 mean? Mean_squared_error should be a scalar not a percentage - shouldnt it? So is val_acc - mean squared error, or mean percentage error or another function?</p>

<p>From definition of MSE on wikipedia:<a href=""https://en.wikipedia.org/wiki/Mean_squared_error"" rel=""noreferrer"">https://en.wikipedia.org/wiki/Mean_squared_error</a></p>

<blockquote>
  <p>The MSE is a measure of the quality of an estimator—it is always
  non-negative, and values closer to zero are better.</p>
</blockquote>

<p>Does that mean a value of <code>val_acc: 0.0</code> is better than <code>val_acc: 0.325</code>?</p>

<p>edit: more examples of the output of accuracy metric when I train - where the accuracy is increase as I train more. While the loss function - mse should decrease. Is Accuracy well defined for mse - and how is it defined in Keras?</p>

<pre class=""lang-python prettyprint-override""><code>lAllocator: After 14014 get requests, put_count=14032 evicted_count=1000 eviction_rate=0.0712657 and unsatisfied allocation rate=0.071714
1000/1000 [==============================] - 453s 453ms/step - loss: 17.4875 - acc: 0.1443 - val_loss: 98.0973 - val_acc: 0.0333
Epoch 2/100
1000/1000 [==============================] - 443s 443ms/step - loss: 6.6793 - acc: 0.1973 - val_loss: 11.9101 - val_acc: 0.1500
Epoch 3/100
1000/1000 [==============================] - 444s 444ms/step - loss: 6.3867 - acc: 0.1980 - val_loss: 6.8647 - val_acc: 0.1667
Epoch 4/100
1000/1000 [==============================] - 445s 445ms/step - loss: 5.4062 - acc: 0.2255 - val_loss: 5.6029 - val_acc: 0.1600
Epoch 5/100
783/1000 [======================&gt;.......] - ETA: 1:36 - loss: 5.0148 - acc: 0.2306
</code></pre>
",2707144.0,,4685471.0,,2019-01-31 09:34:48,2022-07-25 15:00:21,What function defines accuracy in Keras when the loss is mean squared error (MSE)?,<machine-learning><keras><regression><loss-function><mean-square-error>,3,11,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48775305
38155836,1,39062323,,2016-07-02 02:04:02,,28,19145,"<p>I'm fitting full convolutional network on some image data for semantic segmentation using Keras.  However, I'm having some problems overfitting. I don't have that much data and I want to do data augmentation.  However, as I want to do pixel-wise classification, I need any augmentations like flips, rotations, and shifts to apply to both feature images and the label images. Ideally I'd like to use the Keras ImageDataGenerator for on-the-fly transformations. However, as far as I can tell, you cannot do equivalent transformations on both the feature and label data.</p>

<p>Does anyone know if this is the case and if not, does anyone have any ideas? Otherwise, I'll use other tools to create a larger dataset and just feed it in all at once.</p>

<p>Thanks!</p>
",4631796.0,,,,,2017-05-11 09:36:49,Data Augmentation Image Data Generator Keras Semantic Segmentation,<computer-vision><deep-learning><image-segmentation><keras>,2,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38155836
42322698,1,45843766,,2017-02-19 01:35:17,,28,18205,"<p>I'm attempting to train multiple <code>keras</code> models with different parameter values using multiple threads (and the <code>tensorflow</code> backend). I've seen a few examples of using the same model within multiple threads, but in this particular case, I run into various errors regarding conflicting graphs, etc. Here's a simple example of what I'd like to be able to do:</p>

<pre class=""lang-py prettyprint-override""><code>from concurrent.futures import ThreadPoolExecutor
import numpy as np
import tensorflow as tf
from keras import backend as K
from keras.layers import Dense
from keras.models import Sequential


sess = tf.Session()


def example_model(size):
    model = Sequential()
    model.add(Dense(size, input_shape=(5,)))
    model.add(Dense(1))
    model.compile(optimizer='sgd', loss='mse')
    return model


if __name__ == '__main__':
    K.set_session(sess)
    X = np.random.random((10, 5))
    y = np.random.random((10, 1))
    models = [example_model(i) for i in range(5, 10)]

    e = ThreadPoolExecutor(4)
    res_list = [e.submit(model.fit, X, y) for model in models]

    for res in res_list:
        print(res.result())
</code></pre>

<p>The resulting error is <code>ValueError: Tensor(""Variable:0"", shape=(5, 5), dtype=float32_ref) must be from the same graph as Tensor(""Variable_2/read:0"", shape=(), dtype=float32).</code>. I've also tried initializing the models within the threads which gives a similar failure. </p>

<p>Any thoughts on the best way to go about this? I'm not at all attached to this exact structure, but I'd prefer to be able to use multiple threads rather than processes so all the models are trained within the same GPU memory allocation.</p>
",233293.0,,214686.0,,2017-02-21 17:25:09,2019-03-02 00:20:02,TensorFlow/Keras multi-threaded model fitting,<multithreading><concurrency><tensorflow><keras><python-multithreading>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42322698
40317243,1,54146623,,2016-10-29 08:08:03,,28,3974,"<p>I am trying to get Theano to run with Keras on a Raspberry Pi 3 (B) without success. I tried Ubuntu MATE and Raspbian as operating systems, without success. To install Theano and Keras, I have taken following steps:</p>

<ol>
<li>Install miniconda (armv7 distribution)</li>
<li>Install all Theano dependencies (as shown <a href=""http://deeplearning.net/software/theano/install_ubuntu.html"" rel=""noreferrer"">here</a>) through Conda (if possible), <code>pip</code> and <code>apt-get</code></li>
<li>Install Theano </li>
<li>Install Keras</li>
</ol>

<p>The aforementioned steps work without any issues. In the next step, I built a little test script (test.py) which loads an already built model via </p>

<pre><code>from keras.models import load_model
model = load_model('model.hdf5')
</code></pre>

<p>When the model is being loaded, I get the following error</p>

<pre><code>Segmentation fault (core dumped)
</code></pre>

<p>Then I tried to investigate the issue further, following this answer on SO (<a href=""https://stackoverflow.com/questions/10035541/what-causes-a-python-segmentation-fault"">What causes a Python segmentation fault?</a>):</p>

<pre><code>gdb python
&gt; run test.py
</code></pre>

<p>When I run this I get:</p>

<pre><code>Program received SIGSEV, Segmentation fault.
0x76fd9822 in ?? () from /lib/ld-linux-armhf.so.3
</code></pre>

<p>In the next step I ran in the gdb shell:</p>

<pre><code>&gt; backtrace
</code></pre>

<p>and got</p>

<pre><code>#0  0x76fd9822 in ?? () from /lib/ld-linux-armhf.so.3
#1  0x76fd983a in ?? () from /lib/ld-linux-armhf.so.3
</code></pre>

<p>this is the point where I don't know any further and I would like to ask, if anyone could point me into a direction on how to fix this issue and get keras + theano to run on a Raspberry Pi.</p>

<p>(I have also tried TensorFlow as an alternative, but getting the same issue)</p>

<p>Thanks a lot.</p>

<hr>

<p>EDIT</p>

<p>I have done some more investigations. If I <a href=""https://github.com/samjabrahams/tensorflow-on-raspberry-pi"" rel=""noreferrer"">run Keras with TensorFlow</a> the problem seems to change a little bit. I ran gdb again, but the error happens now in numpy, especially in libopenblas.so.0</p>

<pre><code>Program received signal SIGSEV, Segmentation fault.
0x75ead7cc in inner_thread()
from /home/&lt;path&gt;/numpy/core/../../../../libopenblas.so.0
</code></pre>

<p>Does this help?</p>

<hr>

<p>EDIT 2</p>

<p>I have installed everything without using Miniconda and Keras works now with TensorFlow (but not with Theano yet). </p>
",1756010.0,,3574081.0,,2018-05-30 15:08:13,2019-03-10 04:57:33,Theano with Keras on Raspberry Pi,<python><raspberry-pi><keras><theano>,3,8,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40317243
47824598,1,47839270,,2017-12-15 01:33:29,,28,15839,"<p>I'm training the Keras object detection model linked at the bottom of this question, although I believe my problem has to do neither with Keras nor with the specific model I'm trying to train (SSD), but rather with the way the data is passed to the model during training.</p>

<p>Here is my problem (see image below):
My training loss is decreasing overall, but it shows sharp regular spikes: </p>

<p><a href=""https://i.stack.imgur.com/7zmbx.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/7zmbx.png"" alt=""Training loss""></a></p>

<p>The unit on the x-axis is not training epochs, but tens of training steps. The spikes occur precisely once every 1390 training steps, which is exactly the number of training steps for one full pass over my training dataset.</p>

<p>The fact that the spikes always occur after each full pass over the training dataset makes me suspect that the problem is not with the model itself, but with the data it is being fed during the training.</p>

<p>I'm using the <a href=""https://github.com/pierluigiferrari/ssd_keras/blob/master/ssd_batch_generator.py"" rel=""noreferrer"">batch generator provided in the repository</a> to generate batches during training. I checked the source code of the generator and it does shuffle the training dataset before each pass using <code>sklearn.utils.shuffle</code>.</p>

<p>I'm confused for two reasons:</p>

<ol>
<li>The training dataset is being shuffled before each pass.</li>
<li>As you can see in <a href=""https://github.com/pierluigiferrari/ssd_keras/blob/master/train_ssd7.ipynb"" rel=""noreferrer"">this Jupyter notebook</a>, I'm using the generator's ad-hoc data augmentation features, so the dataset should theoretically never be same for any pass: All the augmentations are random.</li>
</ol>

<p>I made some test predictions to see if the model is actually learning anything, and it is! The predictions get better over time, but of course the model is learning very slowly since those spikes seem to mess up the gradient every 1390 steps.</p>

<p>Any hints as to what this might be are greatly appreciated! I'm using the exact same Jupyter notebook that is linked above for my training, the only variable I changed is the batch size from 32 to 16. Other than that, the linked notebook contains the exact training process I'm following.</p>

<p>Here is a link to the repository that contains the model:</p>

<p><a href=""https://github.com/pierluigiferrari/ssd_keras"" rel=""noreferrer"">https://github.com/pierluigiferrari/ssd_keras</a></p>
",7517192.0,,7517192.0,,2019-11-18 13:07:54,2021-11-12 13:27:20,Why does my training loss have regular spikes?,<deep-learning><keras>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47824598
46202519,1,46205217,,2017-09-13 16:24:47,,28,12184,"<pre><code>&gt;&gt;&gt; t = Tokenizer(num_words=3)
&gt;&gt;&gt; l = [""Hello, World! This is so&amp;#$ fantastic!"", ""There is no other world like this one""]
&gt;&gt;&gt; t.fit_on_texts(l)
&gt;&gt;&gt; t.word_index
{'fantastic': 6, 'like': 10, 'no': 8, 'this': 2, 'is': 3, 'there': 7, 'one': 11, 'other': 9, 'so': 5, 'world': 1, 'hello': 4}
</code></pre>

<p>I'd have expected <code>t.word_index</code> to have just the top 3 words. What am I doing wrong?</p>
",3508752.0,,5974433.0,,2018-05-11 16:16:12,2021-05-12 03:30:06,Keras Tokenizer num_words doesn't seem to work,<machine-learning><neural-network><keras><deep-learning><tokenize>,4,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46202519
63006575,1,63008981,,2020-07-21 02:44:40,,27,13191,"<p>I just started working with <a href=""/questions/tagged/keras"" class=""post-tag"" title=""show questions tagged &#39;keras&#39;"" rel=""tag"">keras</a> and noticed that there are two layers with very similar names for max-pooling: <code>MaxPool</code> and <code>MaxPooling</code>. I was surprised that I couldn't find the difference between these two on Google; so I am wondering what the difference is between the two if any.</p>
",11502399.0,,10375049.0,,2022-01-13 08:47:18,2022-08-10 18:27:55,What is the difference between MaxPool and MaxPooling layers in Keras?,<python><tensorflow><machine-learning><keras><deep-learning>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/63006575
52162004,1,52176182,,2018-09-04 08:28:48,,27,101991,"<p>I am trying to apply a Keras' image classifier to my project, but down the road I got stuck with this. Though previously, with the same code I could use OpenCV to read and train images, but after switching to a new batch of images it got caught with the error. So my speculation is that there's something wrong with my file type:</p>
<p>This is from the batch that got the error:</p>
<blockquote>
<p>traf.204.jpg: JPEG image data, JFIF standard 1.01, aspect ratio,
density 1x1, segment length 16, baseline, precision 8, 480x294, frames
1</p>
</blockquote>
<p>This is from the batch that didn't get caught with the error:</p>
<blockquote>
<p>bear.290.jpg: JPEG image data, JFIF standard 1.01, aspect ratio,
density 1x1, segment length 16, baseline, precision 8, 224x224, frames
3</p>
</blockquote>
<p>But the file type seems to be exactly the same (except for the resolution). How can I fix this problem?</p>
",7809118.0,,63550.0,,2021-05-18 11:37:37,2022-07-12 07:29:35,I am having trouble with this error (-215:Assertion failed) !ssize.empty() in function 'resize' in OpenCV,<python><opencv><keras>,9,1,0.0,2021-06-14 03:00:21,,CC BY-SA 4.0,https://stackoverflow.com/q/52162004
63390725,1,63481422,,2020-08-13 08:04:12,,27,8269,"<p>I'm learning keras API in tensorflow(2.3). In this <a href=""https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_losses"" rel=""noreferrer"">guide</a> on tensorflow website, I found an example of custom loss funciton:</p>
<pre><code>    def custom_mean_squared_error(y_true, y_pred):
        return tf.math.reduce_mean(tf.square(y_true - y_pred))
</code></pre>
<p>The <code>reduce_mean</code> function in this custom loss function will return an scalar.</p>
<p>Is it right to define loss function like this? As far as I know, the first dimension of the shapes of <code>y_true</code> and <code>y_pred</code> is the batch size. I think the loss function should return loss values for every sample in the batch. So the loss function shoud give an array of shape <code>(batch_size,)</code>. But the above function gives a single value for the whole batch.</p>
<p>Maybe the above example is wrong? Could anyone give me some help on this problem?</p>
<hr />
<p>p.s. <strong>Why do I think the loss function should return an array rather than a single value?</strong></p>
<p>I read the source code of <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/engine/training.py#L159-L2634"" rel=""noreferrer"">Model</a> class. When you provide a loss function (please note it's a <strong>function</strong>, not a loss <strong>class</strong>) to <code>Model.compile()</code> method, ths loss function is used to construct a <code>LossesContainer</code> object, which is stored in <code>Model.compiled_loss</code>. This loss function passed to the constructor of <code>LossesContainer</code> class is used once again to construct a <code>LossFunctionWrapper</code> object, which is stored in <code>LossesContainer._losses</code>.</p>
<p><strong>According to the source code of <a href=""https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/losses.py"" rel=""noreferrer"">LossFunctionWrapper</a> class, the overall loss value for a training batch is calculated by the <code>LossFunctionWrapper.__call__()</code> method (inherited from <code>Loss</code> class), i.e. it returns a single loss value for the whole batch.</strong> But the <code>LossFunctionWrapper.__call__()</code> first calls the <code>LossFunctionWrapper.call()</code> method to obtain an array of losses for every sample in the training batch. Then these losses are fianlly averaged to get the single loss value for the whole batch. It's in the <code>LossFunctionWrapper.call()</code> method that the loss function provided to the <code>Model.compile()</code> method is called.</p>
<p>That's why I think the custom loss funciton should return an array of losses, insead of a single scalar value. Besides, if we write a custom <code>Loss</code> class for the <code>Model.compile()</code> method, the <code>call()</code> method of our custom <code>Loss</code> class should also return an array, rather than a signal value.</p>
<hr />
<p>I opened an <a href=""https://github.com/tensorflow/tensorflow/issues/42446"" rel=""noreferrer"">issue</a> on github. It's confirmed that custom loss function is required to return one loss value per sample. The example will need to be updated to reflect this.</p>
",4151926.0,,2099607.0,,2020-08-19 07:04:41,2022-12-19 12:56:21,Should the custom loss function in Keras return a single loss value for the batch or an arrary of losses for every sample in the training batch?,<tensorflow><machine-learning><keras><tensorflow2.0><loss-function>,7,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/63390725
42353056,1,43266817,,2017-02-20 19:46:46,,27,8406,"<p>I'm trying to fit an RNN in Keras using sequences that have varying time lengths. My data is in a Numpy array with format <code>(sample, time, feature) = (20631, max_time, 24)</code> where <code>max_time</code> is determined at run-time as the number of time steps available for the sample with the most time stamps. I've padded the beginning of each time series with <code>0</code>, except for the longest one, obviously.</p>

<p>I've initially defined my model like so...</p>

<pre><code>model = Sequential()
model.add(Masking(mask_value=0., input_shape=(max_time, 24)))
model.add(LSTM(100, input_dim=24))
model.add(Dense(2))
model.add(Activation(activate))
model.compile(loss=weibull_loglik_discrete, optimizer=RMSprop(lr=.01))
model.fit(train_x, train_y, nb_epoch=100, batch_size=1000, verbose=2, validation_data=(test_x, test_y))
</code></pre>

<p>For completeness, here's the code for the loss function:</p>

<pre><code>def weibull_loglik_discrete(y_true, ab_pred, name=None):
    y_ = y_true[:, 0]
    u_ = y_true[:, 1]
    a_ = ab_pred[:, 0]
    b_ = ab_pred[:, 1]

    hazard0 = k.pow((y_ + 1e-35) / a_, b_)
    hazard1 = k.pow((y_ + 1) / a_, b_)

    return -1 * k.mean(u_ * k.log(k.exp(hazard1 - hazard0) - 1.0) - hazard1)
</code></pre>

<p>And here's the code for the custom activation function:</p>

<pre><code>def activate(ab):
    a = k.exp(ab[:, 0])
    b = k.softplus(ab[:, 1])

    a = k.reshape(a, (k.shape(a)[0], 1))
    b = k.reshape(b, (k.shape(b)[0], 1))

    return k.concatenate((a, b), axis=1)
</code></pre>

<p>When I fit the model and make some test predictions, <em>every sample in the test set gets exactly the same prediction</em>, which seems fishy.</p>

<p>Things get better if I remove the masking layer, which makes me think there's something wrong with the masking layer, but as far as I can tell, I've followed the documentation exactly.</p>

<p>Is there something mis-specified with the masking layer? Am I missing something else?</p>
",2751997.0,,2751997.0,,2017-02-20 19:57:16,2019-02-26 15:32:54,Keras Masking for RNN with Varying Time Steps,<python><numpy><neural-network><keras><recurrent-neural-network>,2,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42353056
41758385,1,41759831,,2017-01-20 07:39:05,,27,38102,"<p>The Keras <code>ImageDataGenerator</code> class provides the two flow methods <code>flow(X, y)</code> and <code>flow_from_directory(directory)</code> (<a href=""https://keras.io/preprocessing/image/"" rel=""noreferrer"">https://keras.io/preprocessing/image/</a>).</p>

<p>Why is the parameter </p>

<blockquote>
  <p>target_size: tuple of integers, default: (256, 256). The dimensions to which all images found will be resized</p>
</blockquote>

<p>Only provided by <em>flow_from_directory(directory)</em> ? And what is the most concise way to add reshaping of images to the preprocessing pipeline using <em>flow(X, y)</em> ?</p>
",1934212.0,,5215538.0,,2017-01-20 08:59:49,2021-05-13 14:38:34,Resizing images in Keras ImageDataGenerator flow methods,<image-processing><keras>,5,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41758385
48265926,1,48267194,,2018-01-15 15:25:11,,27,19772,"<p>Is there a way to get the number of layers (not parameters) in a Keras model?</p>

<p><code>model.summary()</code> is very informative, but it is not straightforward to get the number of layers from it.</p>
",673592.0,,712995.0,,2018-12-15 23:49:49,2023-04-20 13:07:08,Keras: find out the number of layers,<python><machine-learning><keras><deep-learning><keras-layer>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48265926
61425296,1,61578364,,2020-04-25 12:02:09,,27,6703,"<p>I made a LSTM (RNN) neural network with supervised learning for data stock prediction. The problem is why it predicts wrong on its own training data? (note: <strong>reproducible example</strong> below)</p>

<p>I created simple model to predict next 5 days stock price:</p>

<pre><code>model = Sequential()
model.add(LSTM(32, activation='sigmoid', input_shape=(x_train.shape[1], x_train.shape[2])))
model.add(Dense(y_train.shape[1]))
model.compile(optimizer='adam', loss='mse')

es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
model.fit(x_train, y_train, batch_size=64, epochs=25, validation_data=(x_test, y_test), callbacks=[es])
</code></pre>

<p>The correct results are in <code>y_test</code> (5 values), so model trains, looking back 90 previous days and then restore weights from best (<code>val_loss=0.0030</code>) result with <code>patience=3</code>:</p>

<pre><code>Train on 396 samples, validate on 1 samples
Epoch 1/25
396/396 [==============================] - 1s 2ms/step - loss: 0.1322 - val_loss: 0.0299
Epoch 2/25
396/396 [==============================] - 0s 402us/step - loss: 0.0478 - val_loss: 0.0129
Epoch 3/25
396/396 [==============================] - 0s 397us/step - loss: 0.0385 - val_loss: 0.0178
Epoch 4/25
396/396 [==============================] - 0s 399us/step - loss: 0.0398 - val_loss: 0.0078
Epoch 5/25
396/396 [==============================] - 0s 391us/step - loss: 0.0343 - val_loss: 0.0030
Epoch 6/25
396/396 [==============================] - 0s 391us/step - loss: 0.0318 - val_loss: 0.0047
Epoch 7/25
396/396 [==============================] - 0s 389us/step - loss: 0.0308 - val_loss: 0.0043
Epoch 8/25
396/396 [==============================] - 0s 393us/step - loss: 0.0292 - val_loss: 0.0056
</code></pre>

<p>Prediction result is pretty awesome, isn't it?</p>

<p><a href=""https://i.stack.imgur.com/5z91q.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/5z91q.png"" alt=""enter image description here""></a></p>

<p>That's because algorithm restored best weights from #5 epoch. Okey, let's now save this model to <code>.h5</code> file, move back -10 days and predict last 5 days (at first example we made model and validate on 17-23 April including day off weekends, now let's test on 2-8 April). Result:</p>

<p><a href=""https://i.stack.imgur.com/vXIvp.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/vXIvp.png"" alt=""enter image description here""></a></p>

<p>It shows absolutely wrong direction. As we see that's because model was trained and took #5 epoch best for validation set on 17-23 April, but not on 2-8. If I try train more, playing with what epoch to choose, whatever I do, there are always a lot of time intervals in the past that have wrong prediction.</p>

<p>Why does model show wrong results on its own trained data? I trained data, it must remember how to predict data on this piece of set, but predicts wrong. What I also tried:</p>

<ul>
<li>Use large data sets with 50k+ rows, 20 years stock prices, adding more or less features</li>
<li>Create different types of model, like adding more hidden layers, different batch_sizes, different layers activations, dropouts, batchnormalization</li>
<li>Create custom EarlyStopping callback, get average val_loss from many validation data sets and choose the best</li>
</ul>

<p>Maybe I miss something? What can I improve?</p>

<p>Here is very simple and <strong>reproducible</strong> example. <code>yfinance</code> downloads S&amp;P 500 stock data.</p>

<pre><code>""""""python 3.7.7
tensorflow 2.1.0
keras 2.3.1""""""


import numpy as np
import pandas as pd
from keras.callbacks import EarlyStopping, Callback
from keras.models import Model, Sequential, load_model
from keras.layers import Dense, Dropout, LSTM, BatchNormalization
from sklearn.preprocessing import MinMaxScaler
import plotly.graph_objects as go
import yfinance as yf
np.random.seed(4)


num_prediction = 5
look_back = 90
new_s_h5 = True # change it to False when you created model and want test on other past dates


df = yf.download(tickers=""^GSPC"", start='2018-05-06', end='2020-04-24', interval=""1d"")
data = df.filter(['Close', 'High', 'Low', 'Volume'])

# drop last N days to validate saved model on past
df.drop(df.tail(0).index, inplace=True)
print(df)


class EarlyStoppingCust(Callback):
    def __init__(self, patience=0, verbose=0, validation_sets=None, restore_best_weights=False):
        super(EarlyStoppingCust, self).__init__()
        self.patience = patience
        self.verbose = verbose
        self.wait = 0
        self.stopped_epoch = 0
        self.restore_best_weights = restore_best_weights
        self.best_weights = None
        self.validation_sets = validation_sets

    def on_train_begin(self, logs=None):
        self.wait = 0
        self.stopped_epoch = 0
        self.best_avg_loss = (np.Inf, 0)

    def on_epoch_end(self, epoch, logs=None):
        loss_ = 0
        for i, validation_set in enumerate(self.validation_sets):
            predicted = self.model.predict(validation_set[0])
            loss = self.model.evaluate(validation_set[0], validation_set[1], verbose = 0)
            loss_ += loss
            if self.verbose &gt; 0:
                print('val' + str(i + 1) + '_loss: %.5f' % loss)

        avg_loss = loss_ / len(self.validation_sets)
        print('avg_loss: %.5f' % avg_loss)

        if self.best_avg_loss[0] &gt; avg_loss:
            self.best_avg_loss = (avg_loss, epoch + 1)
            self.wait = 0
            if self.restore_best_weights:
                print('new best epoch = %d' % (epoch + 1))
                self.best_weights = self.model.get_weights()
        else:
            self.wait += 1
            if self.wait &gt;= self.patience or self.params['epochs'] == epoch + 1:
                self.stopped_epoch = epoch
                self.model.stop_training = True
                if self.restore_best_weights:
                    if self.verbose &gt; 0:
                        print('Restoring model weights from the end of the best epoch')
                    self.model.set_weights(self.best_weights)

    def on_train_end(self, logs=None):
        print('best_avg_loss: %.5f (#%d)' % (self.best_avg_loss[0], self.best_avg_loss[1]))


def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step, single_step=False):
    data = []
    labels = []
    start_index = start_index + history_size
    if end_index is None:
        end_index = len(dataset) - target_size
    for i in range(start_index, end_index):
        indices = range(i-history_size, i, step)
        data.append(dataset[indices])
        if single_step:
            labels.append(target[i+target_size])
        else:
            labels.append(target[i:i+target_size])
    return np.array(data), np.array(labels)


def transform_predicted(pr):
    pr = pr.reshape(pr.shape[1], -1)
    z = np.zeros((pr.shape[0], x_train.shape[2] - 1), dtype=pr.dtype)
    pr = np.append(pr, z, axis=1)
    pr = scaler.inverse_transform(pr)
    pr = pr[:, 0]
    return pr


step = 1

# creating datasets with look back
scaler = MinMaxScaler()
df_normalized = scaler.fit_transform(df.values)
dataset = df_normalized[:-num_prediction]
x_train, y_train = multivariate_data(dataset, dataset[:, 0], 0,len(dataset) - num_prediction + 1, look_back, num_prediction, step)
indices = range(len(dataset)-look_back, len(dataset), step)
x_test = np.array(dataset[indices])
x_test = np.expand_dims(x_test, axis=0)
y_test = np.expand_dims(df_normalized[-num_prediction:, 0], axis=0)

# creating past datasets to validate with EarlyStoppingCust
number_validates = 50
step_past = 5
validation_sets = [(x_test, y_test)]
for i in range(1, number_validates * step_past + 1, step_past):
    indices = range(len(dataset)-look_back-i, len(dataset)-i, step)
    x_t = np.array(dataset[indices])
    x_t = np.expand_dims(x_t, axis=0)
    y_t = np.expand_dims(df_normalized[-num_prediction-i:len(df_normalized)-i, 0], axis=0)
    validation_sets.append((x_t, y_t))


if new_s_h5:
    model = Sequential()
    model.add(LSTM(32, return_sequences=False, activation = 'sigmoid', input_shape=(x_train.shape[1], x_train.shape[2])))
    # model.add(Dropout(0.2))
    # model.add(BatchNormalization())
    # model.add(LSTM(units = 16))
    model.add(Dense(y_train.shape[1]))
    model.compile(optimizer = 'adam', loss = 'mse')

    # EarlyStoppingCust is custom callback to validate each validation_sets and get average
    # it takes epoch with best ""best_avg"" value
    # es = EarlyStoppingCust(patience = 3, restore_best_weights = True, validation_sets = validation_sets, verbose = 1)

    # or there is keras extension with built-in EarlyStopping, but it validates only 1 set that you pass through fit()
    es = EarlyStopping(monitor = 'val_loss', patience = 3, restore_best_weights = True)

    model.fit(x_train, y_train, batch_size = 64, epochs = 25, shuffle = True, validation_data = (x_test, y_test), callbacks = [es])
    model.save('s.h5')
else:
    model = load_model('s.h5')



predicted = model.predict(x_test)
predicted = transform_predicted(predicted)
print('predicted', predicted)
print('real', df.iloc[-num_prediction:, 0].values)
print('val_loss: %.5f' % (model.evaluate(x_test, y_test, verbose=0)))


fig = go.Figure()
fig.add_trace(go.Scatter(
    x = df.index[-60:],
    y = df.iloc[-60:,0],
    mode='lines+markers',
    name='real',
    line=dict(color='#ff9800', width=1)
))
fig.add_trace(go.Scatter(
    x = df.index[-num_prediction:],
    y = predicted,
    mode='lines+markers',
    name='predict',
    line=dict(color='#2196f3', width=1)
))
fig.update_layout(template='plotly_dark', hovermode='x', spikedistance=-1, hoverlabel=dict(font_size=16))
fig.update_xaxes(showspikes=True)
fig.update_yaxes(showspikes=True)
fig.show()
</code></pre>
",1802225.0,,4685471.0,,2020-04-25 12:24:46,2020-05-04 13:15:13,Why neural network predicts wrong on its own training data?,<python><tensorflow><machine-learning><keras><neural-network>,8,8,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/61425296
55324762,1,55325491,,2019-03-24 14:21:18,,26,67928,"<p>I am new to machine learning. I was following this <a href=""https://www.youtube.com/watch?v=oDHpqu52soI&amp;t=2s"" rel=""noreferrer"">tutorial</a> on fine-tuning VGG16 models.</p>
<p>The model loaded fine with this code:</p>
<pre><code>vgg_model = tensorflow.keras.applications.vgg16.VGG16()
</code></pre>
<p>but gets this ERROR:</p>
<pre><code>TypeError: The added layer must be an instance of class Layer. Found: &lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001FA104CBB70&gt;
</code></pre>
<p>When running this code:</p>
<pre><code>model = Sequential()
for layer in vgg_model.layers[:-1]:
    model.add(layer)
</code></pre>
<p>Dependencies:</p>
<ul>
<li>Keras 2.2.3</li>
<li>Tensorflow 1.12.0</li>
<li>tensorflow-gpu1.12.0</li>
<li>Python 3.6.0</li>
</ul>
<p>I am following this <a href=""https://github.com/vbookshelf/Skin-Lesion-Analyzer/blob/master/skin-lesion-analyzer-jupyter-notebook%20version%202.ipynb"" rel=""noreferrer"">blog</a> but instead, I want to use VGG16.</p>
<p>Any help to fix this would be appreciated. Thank you so much.</p>
",11037865.0,,6414102.0,,2020-11-13 14:58:19,2021-12-06 11:29:37,The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.engine.input_layer.InputLayer>,<python><tensorflow><keras><transfer-learning><vgg-net>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55324762
43765381,1,43769694,,2017-05-03 16:22:25,,26,10867,"<p>Where can I find the API documentation of the class <code>keras.layers.Input</code>? I couldn't find it at <a href=""https://keras.io/"" rel=""noreferrer"">https://keras.io/</a>.</p>
",6521119.0,,3924118.0,,2019-02-22 20:05:10,2019-02-22 20:05:10,Where can I find the API documentation of the class Input?,<keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/43765381
52476191,1,52478034,,2018-09-24 09:23:38,,26,16261,"<p>I'm a little bit confused about <code>initial_epoch</code> value in <code>fit</code> and <code>fit_generator</code> methods. Here is the <a href=""https://keras.io/api/models/model_training_apis/"" rel=""noreferrer"">doc</a>:</p>
<blockquote>
<p><strong>initial_epoch</strong>: Integer. Epoch at which to start training (useful for resuming a previous training run).</p>
</blockquote>
<p>I understand, it is not useful if you start training from scratch. It is useful if you trained your dataset and want to improve accuracy or other values (<em>correct me if I'm wrong</em>). But I'm not sure what it really does.</p>
<p>So after all this, I have 2 questions:</p>
<ol>
<li>What does <code>initial_epoch</code> do and what is it for?</li>
<li>When can I use <code>initial_epoch</code>?</li>
</ol>
<ul>
<li>When I change my dataset?</li>
<li>When I change the learning rate, optimizer or loss function?</li>
<li>Both of them?</li>
</ul>
",2057653.0,,11256688.0,,2021-02-01 10:15:56,2021-05-27 05:37:35,What does initial_epoch in Keras mean?,<machine-learning><keras><deep-learning>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52476191
62484597,1,62487089,,2020-06-20 10:28:25,,26,12985,"<p>The Keras documentation of <code>ImageDataGenerator class</code> says—</p>
<blockquote>
<p><strong>width_shift_range:</strong> Float, 1-D array-like or int - float: fraction of total width, if &lt; 1, or pixels if &gt;= 1. - 1-D array-like: random elements from the array. - int: integer number of pixels from interval <code>(-width_shift_range, +width_shift_range)</code> - With <code>width_shift_range=2</code> possible values are integers <code>[-1, 0, +1]</code>, same as with <code>width_shift_range=[-1, 0, +1]</code>, while with <code>width_shift_range=1.0</code> possible values are floats in the interval [-1.0, +1.0).</p>
</blockquote>
<blockquote>
<p><strong>height_shift_range:</strong> Float, 1-D array-like or int - float: fraction of total height, if &lt; 1, or pixels if &gt;= 1. - 1-D array-like: random elements from the array. - int: integer number of pixels from interval <code>(-height_shift_range, +height_shift_range)</code> - With <code>height_shift_range=2</code> possible values are integers <code>[-1, 0, +1]</code>, same as with <code>height_shift_range=[-1, 0, +1]</code>, while with <code>height_shift_range=1.0</code> possible values are floats in the interval [-1.0, +1.0).</p>
</blockquote>
<p>I’m new in Keras and machine learning, and I just have started learning it.</p>
<p>I am struggling to understand the documentation and use of these two arguments of Keras  <a href=""https://keras.io/api/preprocessing/image/#imagedatagenerator-class"" rel=""noreferrer""><code>ImageDataGenerator class</code></a>, named <code>width_shift_range</code> and <code>height_shift_range</code>. I have searched out a lot, but couldn't find any good documentation other than the official. What exactly do these two arguments do? When have to use them?</p>
<p>This talk may seem inappropriate here, but since there is no discussion anywhere on the internet, I think it would be nice to have the discussion here.</p>
<p>If anyone helps me understanding these, I would be grateful. Thank you very much.</p>
",7829174.0,,7829174.0,,2020-06-29 07:55:59,2020-07-16 04:25:59,Understanding `width_shift_range` and `height_shift_range` arguments in Keras's ImageDataGenerator class,<python><python-3.x><machine-learning><keras><data-generation>,1,1,,,,CC BY-SA 4.0,https://stackoverflow.com/q/62484597
59439128,1,61860175,,2019-12-21 19:11:17,,26,39900,"<pre><code>train_image_gen = image_gen.flow_from_directory('/Users/harshpanwar/Desktop/Folder/train',
                                               target_size=image_shape[:2],
                                               batch_size=batch_size,
                                               class_mode='binary')
</code></pre>

<p>In the above code snippet what does class_mode='binary' signify. I think it is for the number of categories of images. I am using this code for training a image recognition classifier in Keras to classify between 2 different categories like dog and cat. So if class_mode='binary' is for signifying two categories how do we make it for three or more?</p>
",12339371.0,,,,,2021-03-31 07:28:11,what does class_mode parameter in Keras image_gen.flow_from_directory() signify?,<tensorflow><image-processing><keras><neural-network><training-data>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59439128
46421258,1,46422627,,2017-09-26 08:19:48,,26,21832,"<p>I have a shared machine with 64 cores on which I have a big pipeline of Keras functions that I want to run. The thing is that it seems that Keras automatically uses all the cores available and I can't do that. </p>

<p>I use Python and I want to run 67 neural networks in a for loop. I would like to use half of the available cores. </p>

<p>I can't find any way of limiting the number of cores in Keras... Do you have any clue? </p>
",7171976.0,,7117003.0,,2017-09-26 08:39:14,2022-08-03 02:28:11,Limit number of cores used in Keras,<python><tensorflow><keras><cpu-cores>,2,9,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46421258
48226783,1,48228379,,2018-01-12 12:58:39,,26,12000,"<p>I noticed in a number of places that people use something like this, usually in fully convolutional networks, autoencoders, and similar:</p>

<pre><code>model.add(UpSampling2D(size=(2,2)))
model.add(Conv2DTranspose(kernel_size=k, padding='same', strides=(1,1))
</code></pre>

<p>I am wondering what is the difference between that and simply:</p>

<pre><code>model.add(Conv2DTranspose(kernel_size=k, padding='same', strides=(2,2))
</code></pre>

<p>Links towards any papers that explain this difference are welcome.</p>
",5985209.0,,1033581.0,,2020-02-23 09:46:49,2021-06-07 01:31:59,What is the difference between performing upsampling together with strided transpose convolution and transpose convolution with stride 1 only?,<deep-learning><keras><conv-neural-network><convolution><deconvolution>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48226783
61706535,1,61707324,,2020-05-10 02:46:16,,26,15996,"<p>I am trying to train a simple 2 layer Fully Connected neural net for Binary Classification in Tensorflow keras. I have split my data into Training and Validation sets with a 80-20 split using sklearn's <code>train_test_split()</code>.</p>

<p>When I call <code>model.fit(X_train, y_train, validation_data=[X_val, y_val])</code>, <strong>it shows 0 validation loss and accuracy for all epochs</strong>, but it trains just fine.</p>

<p><a href=""https://i.stack.imgur.com/aJVoW.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/aJVoW.png"" alt=""Screenshot of model.fit call and verbose log""></a></p>

<p>Also, when I try to evaluate it on the validation set, the output is non-zero.</p>

<p><a href=""https://i.stack.imgur.com/8C34g.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8C34g.png"" alt=""Screenshot of model.evaluate function call""></a></p>

<p>Can someone please explain why I am facing this 0 loss 0 accuracy error on validation. Thanks for your help.</p>

<p>Here is the complete sample code (MCVE) for this error: <a href=""https://colab.research.google.com/drive/1P8iCUlnD87vqtuS5YTdoePcDOVEKpBHr?usp=sharing"" rel=""noreferrer"">https://colab.research.google.com/drive/1P8iCUlnD87vqtuS5YTdoePcDOVEKpBHr?usp=sharing</a></p>
",4182274.0,,4685471.0,,2020-05-10 12:17:53,2022-08-26 18:16:27,Keras - Validation Loss and Accuracy stuck at 0,<python><tensorflow><machine-learning><keras><tf.keras>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/61706535
45480820,1,45483109,,2017-08-03 09:56:04,,25,24654,"<p>I'm trying to write my custom loss function: I want to apply <code>categorical_crossentropy</code> to the parts of input vector and then sum.</p>

<p>Assume y_true, y_pred are 1D vectors.</p>

<p>Code:</p>

<pre><code>def custom_loss(y_true, y_pred):

    loss_sum= 0.0
    for i in range(0,y_true.shape[0],dictionary_dims):
        loss_sum+= keras.backend.categorical_crossentropy(y_true[i*dictionary_dims:(i+1)*dictionary_dims], y_pred[i*dictionary_dims:(i+1)*dictionary_dims])

    return loss_sum
</code></pre>

<p>But I get an error:</p>

<pre><code>    for i in range(0,y_true.shape[0],dictionary_dims):
TypeError: __index__ returned non-int (type NoneType)
</code></pre>

<p>So how to access shape of input tensors to get subset of tensor?</p>

<p><strong>Update:</strong>
Also tried to write loss via tensorflow directly:</p>

<pre><code>def custom_loss_tf(y_true, y_pred):

    print('tf.shape(y_true)',tf.shape(y_true)) #
    print('type(tf.shape(y_true))',type(tf.shape(y_true))) #

    sys.exit()

    loss_sum= 0.0
    for i in range(0,y_true.shape[0],dictionary_dims):
        loss_sum+= keras.backend.categorical_crossentropy(y_true[i*dictionary_dims:(i+1)*dictionary_dims], y_pred[i*dictionary_dims:(i+1)*dictionary_dims])

    return loss_sum
</code></pre>

<p>Output:</p>

<pre><code>tf.shape(y_true) Tensor(""Shape:0"", shape=(2,), dtype=int32)
type(tf.shape(y_true)) &lt;class 'tensorflow.python.framework.ops.Tensor'&gt;
</code></pre>

<p>Not sure what is <code>shape=(2,)</code> mean, but this is not what I'm expecting, because <code>model.summary()</code> shows that last layer is <code>(None, 26)</code>:</p>

<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 80, 120, 3)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 80, 120, 32)       896
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 40, 60, 32)        0
_________________________________________________________________
activation_1 (Activation)    (None, 40, 60, 32)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 40, 60, 32)        9248
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 20, 30, 32)        0
_________________________________________________________________
activation_2 (Activation)    (None, 20, 30, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 20, 30, 64)        18496
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 10, 15, 64)        0
_________________________________________________________________
activation_3 (Activation)    (None, 10, 15, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 10, 15, 64)        36928
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 5, 7, 64)          0
_________________________________________________________________
activation_4 (Activation)    (None, 5, 7, 64)          0
_________________________________________________________________
flatten_1 (Flatten)          (None, 2240)              0
_________________________________________________________________
head (Dense)                 (None, 26)                58266
=================================================================
</code></pre>
",1179925.0,,5974433.0,,2018-01-23 20:19:41,2018-01-23 20:19:41,Keras: how to get tensor dimensions inside custom loss?,<python><tensorflow><neural-network><deep-learning><keras>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45480820
36986815,1,36989864,,2016-05-02 16:07:50,,25,21447,"<p>I built a simple generator that yields a <code>tuple(inputs, targets)</code> with only single items in the <code>inputs</code> and <code>targets</code> lists. Basically, it is crawling the data set, one sample item at a time.</p>

<p>I pass this generator into: </p>

<pre><code>  model.fit_generator(my_generator(),
                      nb_epoch=10,
                      samples_per_epoch=1,
                      max_q_size=1  # defaults to 10
                      )
</code></pre>

<p>I get that:</p>

<ul>
<li><code>nb_epoch</code> is the number of times the training batch will be run</li>
<li><code>samples_per_epoch</code> is the number of samples trained with per epoch</li>
</ul>

<p>But what is <code>max_q_size</code> for and why would it default to 10?  I thought the purpose of using a generator was to batch data sets into reasonable chunks, so why the additional queue? </p>
",722263.0,,1079075.0,,2018-07-11 19:44:30,2020-08-11 14:23:43,"What is the parameter ""max_q_size"" used for in ""model.fit_generator""?",<python><machine-learning><generator><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/36986815
38080035,1,38086903,,2016-06-28 15:13:05,,25,37703,"<p>Is there a way to calculate the total number of parameters in a LSTM network.</p>

<p>I have found a example but I'm unsure of how correct <a href=""https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"">this</a> is or If I have understood it correctly.</p>

<p>For eg consider the following example:-</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.layers import Embedding
from keras.layers import LSTM
model = Sequential()
model.add(LSTM(256, input_dim=4096, input_length=16))
model.summary()
</code></pre>

<h1>Output</h1>

<pre><code>____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to                     
====================================================================================================
lstm_1 (LSTM)                      (None, 256)         4457472     lstm_input_1[0][0]               
====================================================================================================
Total params: 4457472
____________________________________________________________________________________________________
</code></pre>

<p>As per My understanding <code>n</code> is the input vector lenght.
And <code>m</code> is the number of time steps. and in this example they consider the number of hidden layers to be 1.</p>

<p>Hence according to the formula in <a href=""https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"">the post.</a> <code>4(nm+n^2)</code> in my example <code>m=16</code>;<code>n=4096</code>;<code>num_of_units=256</code></p>

<pre><code>4*((4096*16)+(4096*4096))*256 = 17246978048
</code></pre>

<p>Why is there such a difference? 
Did I misunderstand the example or was the formula wrong ?</p>
",2527680.0,,5974433.0,,2017-07-04 10:37:04,2020-06-21 09:48:01,How to calculate the number of parameters of an LSTM network?,<machine-learning><neural-network><deep-learning><keras><lstm>,6,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38080035
40850089,1,43393252,,2016-11-28 17:25:10,,25,12712,"<p>I'm using Python and Keras (currently using Theano backend, but I have no qualms with switching). I have a neural network that I load and process multiple sources of information with in parallel. Currently, I've been running each one in a separate process and it loads its own copy of the network from the file. This seems like a waste of RAM, so I was thinking it would be more efficient to have a single multi-threaded process with one instance of the network that is used by all threads. However, I'm wondering if Keras is thread safe with either backend. If I run <code>.predict(x)</code> on two different inputs at the same time in different threads, will I run into race conditions or other issues?</p>

<p>Thanks</p>
",1107282.0,,,,,2023-03-01 17:00:53,Is Keras thread safe?,<python><multithreading><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40850089
51344839,1,51345413,,2018-07-15 02:46:18,,25,52077,"<p>I have used LSTM from Keras to build a model that can detect if two questions on Stack overflow are duplicate or not. When I run the model I see the following output in the epochs.</p>
<pre><code>Epoch 23/200
727722/727722 [==============================] - 67s - loss: 0.3167 - acc: 0.8557 - val_loss: 0.3473 - val_acc: 0.8418
Epoch 24/200
727722/727722 [==============================] - 67s - loss: 0.3152 - acc: 0.8573 - val_loss: 0.3497 - val_acc: 0.8404
Epoch 25/200
727722/727722 [==============================] - 67s - loss: 0.3136 - acc: 0.8581 - val_loss: 0.3518 - val_acc: 0.8391
</code></pre>
<p>I am trying to understand the meaning of each of these terms. Which of the above values is the accuracy of my model. I am comparatively new to machine learning, so any explanation would help.</p>
",6837337.0,,6837337.0,,2022-01-03 23:13:13,2022-01-03 23:13:13,What is the difference between the terms accuracy and validation accuracy,<python><keras><lstm>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51344839
40393629,1,40455745,,2016-11-03 03:57:38,,25,12871,"<p>I have the following code, using <a href=""https://github.com/fchollet/keras/blob/master/keras/wrappers/scikit_learn.py"" rel=""noreferrer"">Keras Scikit-Learn Wrapper</a>, which work fine:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense
from sklearn import datasets
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
import numpy as np


def create_model():
    # create model
    model = Sequential()
    model.add(Dense(12, input_dim=4, init='uniform', activation='relu'))
    model.add(Dense(6, init='uniform', activation='relu'))
    model.add(Dense(1, init='uniform', activation='sigmoid'))
    # Compile model
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model


def main():
    """"""
    Description of main
    """"""


    iris = datasets.load_iris()
    X, y = iris.data, iris.target

    NOF_ROW, NOF_COL =  X.shape

    # evaluate using 10-fold cross validation
    seed = 7
    np.random.seed(seed)
    model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10, verbose=0)
    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)
    results = cross_val_score(model, X, y, cv=kfold)

    print(results.mean())
    # 0.666666666667


if __name__ == '__main__':
    main()
</code></pre>

<p>The <code>pima-indians-diabetes.data</code>  can be downloaded <strong><a href=""http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"" rel=""noreferrer"">here</a></strong>.</p>

<p>Now what I want to do is to pass a value <code>NOF_COL</code> into a parameter of <code>create_model()</code> function the following way</p>

<pre><code>model = KerasClassifier(build_fn=create_model(input_dim=NOF_COL), nb_epoch=150, batch_size=10, verbose=0)
</code></pre>

<p>With the <code>create_model()</code> function that looks like this:</p>

<pre><code>def create_model(input_dim=None):
    # create model
    model = Sequential()
    model.add(Dense(12, input_dim=input_dim, init='uniform', activation='relu'))
    model.add(Dense(6, init='uniform', activation='relu'))
    model.add(Dense(1, init='uniform', activation='sigmoid'))
    # Compile model
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model
</code></pre>

<p>But it fails giving this error:</p>

<pre><code>TypeError: __call__() takes at least 2 arguments (1 given)
</code></pre>

<p>What's the right way to do it?</p>
",67405.0,,67405.0,,2016-11-03 07:47:44,2021-05-03 14:28:35,How to pass a parameter to Scikit-Learn Keras model function,<python><function><scikit-learn><keras><callable>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40393629
45492318,1,45762340,,2017-08-03 18:50:43,,25,6025,"<p>Imagine a fully-connected neural network with its last two layers of the following structure:</p>

<pre><code>[Dense]
    units = 612
    activation = softplus

[Dense]
    units = 1
    activation = sigmoid
</code></pre>

<p>The output value of the net is 1, but I'd like to know what the input x to the sigmoidal function was (must be some high number, since sigm(x) is 1 here).</p>

<p>Folllowing <a href=""https://stackoverflow.com/a/41712013/1922302"">indraforyou's</a> answer I managed to retrieve the output and weights of Keras layers:</p>

<pre><code>outputs = [layer.output for layer in model.layers[-2:]]
functors = [K.function( [model.input]+[K.learning_phase()], [out] ) for out in outputs]

test_input = np.array(...)
layer_outs = [func([test_input, 0.]) for func in functors]

print layer_outs[-1][0]  # -&gt; array([[ 1.]])

dense_0_out = layer_outs[-2][0]                           # shape (612, 1)
dense_1_weights = model.layers[-1].weights[0].get_value() # shape (1, 612)
dense_1_bias = model.layers[-1].weights[1].get_value()

x = np.dot(dense_0_out, dense_1_weights) + dense_1_bias
print x # -&gt; -11.7
</code></pre>

<p>How can x be a negative number? In that case the last layers output should be a number closer to 0.0 than 1.0. Are <code>dense_0_out</code> or <code>dense_1_weights</code> the wrong outputs or weights?</p>
",1922302.0,,1922302.0,,2017-08-03 19:23:24,2021-10-10 17:53:01,Keras retrieve value of node before activation function,<python><neural-network><keras><keras-layer><sigmoid>,6,8,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45492318
59336899,1,59433454,,2019-12-14 16:15:51,,25,34687,"<p>I am training a multi-label classification model for detecting attributes of clothes. I am using transfer learning in Keras, retraining the last few layers of the vgg-19 model.</p>

<p>The total number of attributes is 1000 and about 99% of them are 0s. Metrics like accuracy, precision, recall, etc., all fail, as the model can predict all zeroes and still achieve a very high score. Binary cross-entropy, hamming loss, etc., haven't worked in the case of loss functions.</p>

<p>I am using the deep fashion dataset. </p>

<p>So, which metrics and loss functions can I use to measure my model correctly?</p>
",12537339.0,,3924118.0,,2020-03-01 17:59:32,2021-09-26 23:07:57,Which loss function and metrics to use for multi-label classification with very high ratio of negatives to positives?,<python><machine-learning><keras><multilabel-classification><vgg-net>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59336899
49603498,1,49770553,,2018-04-01 23:14:53,,25,12659,"<p>Are <code>1</code> and <code>2</code> the same?</p>

<ol>
<li>Use <code>Convolution2D</code> layers and <code>LSTM</code> layers </li>
<li>Use <code>ConvLSTM2D</code></li>
</ol>

<p>If there is any difference, could you explain it for me?</p>
",4088201.0,,7224320.0,,2018-04-13 16:40:43,2018-04-13 16:40:43,Convolution2D + LSTM versus ConvLSTM2D,<python><tensorflow><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49603498
59069058,1,59069122,,2019-11-27 11:20:39,,25,21850,"<p>I'm using keras defined as submodule in tensorflow v2. I'm training my model using <code>fit_generator()</code> method. I want to save my model every 10 epochs. How can I achieve this?</p>

<p>In Keras (not as a submodule of tf), I can give <code>ModelCheckpoint(model_savepath,period=10)</code>. But in tf v2, they've changed this to <code>ModelCheckpoint(model_savepath, save_freq)</code> where <code>save_freq</code> can be <code>'epoch'</code> in which case model is saved every epoch. If <code>save_freq</code> is integer, model is saved after so many samples have been processed. But I want it to be after 10 epochs. How can I achieve this?</p>
",3337089.0,,,,,2022-07-18 07:41:04,Save model every 10 epochs tensorflow.keras v2,<python><keras><deep-learning><tensorflow2.0><tf.keras>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59069058
38656566,1,38673493,,2016-07-29 10:30:23,,25,13281,"<p>really finding it hard to understand the input dimensions to the convolutional 1d <a href=""http://keras.io/layers/convolutional/#convolution1d"" rel=""noreferrer"">layer</a> in keras:</p>

<p>Input shape</p>

<p>3D tensor with shape: (samples, steps, input_dim).</p>

<p>Output shape</p>

<p>3D tensor with shape: (samples, new_steps, nb_filter). steps value might have changed due to padding.</p>

<p>I want my network to take in a time series of prices (101, in order) and output 4 probabilities. My current non-convolutional network which does this fairly well (with a training set of 28000) looks like this:</p>

<pre><code>standardModel = Sequential()
standardModel.add(Dense(input_dim=101, output_dim=100, W_regularizer=l2(0.5), activation='sigmoid'))
standardModel.add(Dense(4, W_regularizer=l2(0.7), activation='softmax'))
</code></pre>

<p>To improve this, I want to make a feature map from the input layer which has a local receptive field of length 10. (and therefore has 10 shared weights and 1 shared bias). I then want to use max pooling and feed this in to a hidden layer of 40 or so neurons and then output this with 4 neurons with softmax in the outer layer. </p>

<p><a href=""http://i.stack.imgur.com/Kx8yT.png"" rel=""noreferrer"">picture (it's quite awful sorry!)</a></p>

<p>So ideally, the convolutional layer would take a 2d tensor of dimensions:</p>

<p>(minibatch_size, 101)</p>

<p>and output a 3d tensor of dimensions</p>

<p>(minibatch_size, 91, no_of_featuremaps)</p>

<p>However, the keras layer seems to require a dimension in the input called step. I've tried understanding this and still don't quite get it. In my case, should step be 1 as each step in the vector is an increase in the time by 1? Also, what is new_step? </p>

<p>In addition, how do you turn the output of the pooling layers (a 3d tensor) into input suitable for the standard hidden layer (i.e a Dense keras layer) in the form of a 2d tensor?</p>

<p>Update: After the very helpful suggestions given, I tried making a convolutional network like so:</p>

<pre><code>conv = Sequential()
conv.add(Convolution1D(64, 10, input_shape=(1,101)))
conv.add(Activation('relu'))
conv.add(MaxPooling1D(2))
conv.add(Flatten())
conv.add(Dense(10))
conv.add(Activation('tanh'))
conv.add(Dense(4))
conv.add(Activation('softmax'))
</code></pre>

<p>The line conv.Add(Flatten()) throws a range exceeds valid bounds error. Interestingly, this error is <strong>not</strong> thrown for just this code:</p>

<pre><code>conv = Sequential()
conv.add(Convolution1D(64, 10, input_shape=(1,101)))
conv.add(Activation('relu'))
conv.add(MaxPooling1D(2))
conv.add(Flatten())
</code></pre>

<p>doing </p>

<pre><code>print conv.input_shape
print conv.output_shape
</code></pre>

<p>results in </p>

<pre><code>(None, 1, 101
(None, -256)
</code></pre>

<p>being returned</p>

<p>Update 2:</p>

<p>Changed </p>

<pre><code>conv.add(Convolution1D(64, 10, input_shape=(1,101)))
</code></pre>

<p>to</p>

<pre><code>conv.add(Convolution1D(10, 10, input_shape=(101,1))
</code></pre>

<p>and it started working. However, is there any important different between 
inputting (None, 101, 1) to a 1d conv layer or (None, 1, 101) that I should be aware of? Why does (None, 1, 101) not work?</p>
",6555213.0,,6555213.0,,2016-08-01 10:09:39,2016-09-29 05:49:47,input dimensions to a one dimensional convolutional network in keras,<python><neural-network><theano><conv-neural-network><keras>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/38656566
45806669,1,45814333,,2017-08-21 23:03:43,,25,80308,"<p>I'm very new to Keras. I trained a model and would like to predict some images stored in subfolders (like for training). For testing, I want to predict 2 images from 7 classes (subfolders). The test_generator below sees 14 images, but I get 196 predictions. Where is the mistake? Thanks a lot!</p>

<pre><code>test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(200, 200),
        color_mode=""rgb"",
        shuffle = ""false"",
        class_mode='categorical')

filenames = test_generator.filenames
nb_samples = len(filenames)

predict = model.predict_generator(test_generator,nb_samples)
</code></pre>
",5794690.0,,4685471.0,,2021-05-08 17:07:14,2021-05-27 05:52:21,How to use predict_generator with ImageDataGenerator?,<python><machine-learning><keras><deep-learning><generator>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45806669
69783897,1,69788484,,2021-10-31 04:13:28,,25,31438,"<p>The classifier script I wrote is working fine and recently added weight balancing to the fitting. Since I added the weight estimate function using 'sklearn' library I get the following error :</p>
<pre><code>compute_class_weight() takes 1 positional argument but 3 were given
</code></pre>
<p>This error does not make sense per documentation. The script should have three inputs but not sure why it says expecting only one variable. Full error and code information is shown below. Apparently, this is failing only in VS code. I tested in the Jupyter notebook and working fine. So it seems an issue with VS code compiler. Any one notice? ( I am using Python 3.8 with other latest other libraries)</p>
<pre><code>from sklearn.utils import compute_class_weight

train_classes = train_generator.classes

class_weights = compute_class_weight(
                                        &quot;balanced&quot;,
                                        np.unique(train_classes),
                                        train_classes                                                    
                                    )
class_weights = dict(zip(np.unique(train_classes), class_weights)),
class_weights
</code></pre>
<p>In Jupyter Notebook,</p>
<p><a href=""https://i.stack.imgur.com/r35GZ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/r35GZ.png"" alt=""enter image description here"" /></a></p>
<p><a href=""https://i.stack.imgur.com/zBnqH.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/zBnqH.png"" alt=""enter image description here"" /></a></p>
",7788402.0,,7788402.0,,2021-10-31 16:06:10,2023-01-25 20:39:20,"Compute class weight function issue in 'sklearn' library when used in 'Keras' classification (Python 3.8, only in VS code)",<python><keras><scikit-learn><classification>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/69783897
47731935,1,47738812,,2017-12-09 18:45:37,,25,8480,"<p>I am training a model with keras using the <code>model.fit()</code> method. 
I would like to use multiple validation sets that should be validated on separately after each training epoch so that i get one loss value for each validation set. If possible they should be both displayed during training and as well be returned by the <code>keras.callbacks.History()</code> callback.</p>

<p>I am thinking of something like this:</p>

<pre><code>history = model.fit(train_data, train_targets,
                    epochs=epochs,
                    batch_size=batch_size,
                    validation_data=[
                        (validation_data1, validation_targets1), 
                        (validation_data2, validation_targets2)],
                    shuffle=True)
</code></pre>

<p>I currently have no idea how to implement this. Is it possible to achieve this by writing my own <code>Callback</code>? Or how else would you approach this problem?</p>
",9077324.0,,,,,2023-03-23 13:53:08,Using multiple validation sets with keras,<validation><keras><monitoring>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47731935
51006505,1,51006816,,2018-06-24 02:28:07,,25,85943,"<p>I am currently training my data using neural network and using fit function. </p>

<pre><code>history=model.fit(X, encoded_Y, batch_size=50, nb_epoch=500, validation_split = 0.2, verbose=1)
</code></pre>

<p>Now I have used validation_split as 20%. What I understood is that my training data will be 80% and testing data will be 20%. I am confused how this data is dealt on back end. Is it like top 80% samples will be taken for training and below 20% percent for testing or the samples are randomly picked from inbetween? If I want to give separate training and testing data, how will I do that using fit()??</p>

<p>Moreover, my second concern is how to check if data is fitting well on model? I can see from the results that training accuracy is around 90% while the validation accuracy is around 55%. Does this mean it is the case of over-fitting or Under-fitting?</p>

<p>My last question is what does evaluate returns? Document says it returns the loss but I am already getting loss and accuracy during each epoch (as a return of fit() (in history)). What does accuracy and score returned by evaluate shows? If the accuracy returned by evaluate returns 90%, can I say my data is fitting well, regardless of what individual accuracy and loss was for each epoch?</p>

<p>Below is my Code:</p>

<pre><code>import numpy
import pandas
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from keras.utils import np_utils
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix
import itertools

seed = 7
numpy.random.seed(seed)

dataframe = pandas.read_csv(""INPUTFILE.csv"", skiprows=range(0, 0))

dataset = dataframe.values
X = dataset[:,0:50].astype(float) # number of cols-1
Y = dataset[:,50]

encoder = LabelEncoder()
encoder.fit(Y)
encoded_Y = encoder.transform(Y)

encoded_Y = np_utils.to_categorical(encoded_Y)
print(""encoded_Y="", encoded_Y) 
# baseline model
def create_baseline():
    # create model
    model = Sequential()
    model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))
    model.add(Dense(5, kernel_initializer='normal', activation='relu'))
    #model.add(Dense(2, kernel_initializer='normal', activation='sigmoid'))

    model.add(Dense(2, kernel_initializer='normal', activation='softmax'))

    # Compile model
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # for binayr classification
        #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # for multi class
    return model


model=create_baseline();
history=model.fit(X, encoded_Y, batch_size=50, nb_epoch=500, validation_split = 0.2, verbose=1)

print(history.history.keys())
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()


pre_cls=model.predict_classes(X)    
cm1 = confusion_matrix(encoder.transform(Y),pre_cls)
print('Confusion Matrix : \n')
print(cm1)


score, acc = model.evaluate(X,encoded_Y)
print('Test score:', score)
print('Test accuracy:', acc)
</code></pre>
",2955608.0,,9983880.0,,2018-06-24 09:20:54,2020-12-31 12:50:18,How training and test data is split - Keras on Tensorflow,<validation><tensorflow><machine-learning><neural-network><keras>,1,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51006505
47843265,1,51945256,,2017-12-16 06:44:52,,25,14359,"<p>I have saved a <code>keras</code> model as a <code>h5py</code> file and now want to load it from disk.</p>
<p>When training the model I use:</p>
<pre><code>from keras.models import Sequential

model = Sequential()
H = model.fit(....)
</code></pre>
<p>When the model is trained, I want to load it from disk with</p>
<pre><code>model = load_model()
</code></pre>
<p>How can I get <code>H</code> from the <code>model</code> variable? It unfortunately does not have a <code>history</code> parameter that I can just call. Is it because the <code>save_model</code> function doesn't save history?</p>
",3116573.0,,8162025.0,,2021-06-11 03:30:38,2021-07-23 12:46:51,How can I get a Keras models' history after loading it from a file in Python?,<python><keras>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47843265
45046525,1,45048910,,2017-07-12 00:40:45,,25,22150,"<p>I am setting <code>trainable=False</code> in all my layers, implemented through the <code>Model</code> API, but I want to verify whether that is working. <code>model.count_params()</code> returns the total number of parameters, but is there any way in which I can get the total number of trainable parameters, other than looking at the last few lines of <code>model.summary()</code>?</p>
",8021672.0,,3924118.0,,2019-10-23 20:53:24,2020-10-20 15:35:07,How can I get the number of trainable parameters of a model in Keras?,<python><keras>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45046525
58276337,1,58277760,,2019-10-07 19:57:53,,24,8728,"<p>Let's suppose I have a sequence of integers:</p>

<p><code>0,1,2, ..</code></p>

<p>and want to predict the next integer given the last 3 integers, e.g.:</p>

<p><code>[0,1,2]-&gt;5</code>, <code>[3,4,5]-&gt;6</code>, etc</p>

<p>Suppose I setup my model like so:</p>

<pre><code>batch_size=1
time_steps=3
model = Sequential()
model.add(LSTM(4, batch_input_shape=(batch_size, time_steps, 1), stateful=True))
model.add(Dense(1))
</code></pre>

<p>It is my understanding that model has the following structure (please excuse the crude drawing):</p>

<p><a href=""https://i.stack.imgur.com/Eqenl.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Eqenl.png"" alt=""enter image description here""></a></p>

<p><strong>First Question: is my understanding correct?</strong></p>

<p>Note I have drawn the previous states <code>C_{t-1}, h_{t-1}</code> entering the picture as this is exposed when specifying <code>stateful=True</code>.  In this simple ""next integer prediction"" problem, the performance should improve by providing this extra information (as long as the previous state results from the previous 3 integers).</p>

<p><strong>This brings me to my main question:</strong>  It seems the standard practice (for example see this <a href=""https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"" rel=""noreferrer"">blog post</a> and the <a href=""https://keras.io/preprocessing/sequence/"" rel=""noreferrer"">TimeseriesGenerator</a> keras preprocessing utility), is to feed a staggered set of inputs to the model during training.</p>

<p>For example:</p>

<pre><code>batch0: [[0, 1, 2]]
batch1: [[1, 2, 3]]
batch2: [[2, 3, 4]]
etc
</code></pre>

<p>This has me confused because it seems this is requires the output of the 1st Lstm Cell (corresponding to the 1st time step).  See this figure:</p>

<p><img src=""https://i.stack.imgur.com/lM2RC.png"" width=""550""></p>

<p>From the tensorflow <a href=""https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"" rel=""noreferrer"">docs</a>:</p>

<blockquote>
  <p><strong>stateful</strong>: Boolean (default False). If True, the last state for each
  sample at index i in a batch will be used as initial state for the
  sample of index i in the following batch.</p>
</blockquote>

<p>it seems this ""internal"" state isn't available and all that is available is the final state.  See this figure:</p>

<p><img src=""https://i.stack.imgur.com/l8cUb.png"" width=""550""></p>

<p>So, if my understanding is correct (which it's clearly not), shouldn't we be feeding non-overlapped windows of samples to the model when using <code>stateful=True</code>?  E.g.:</p>

<pre><code>batch0: [[0, 1, 2]]
batch1: [[3, 4, 5]]
batch2: [[6, 7, 8]]
etc
</code></pre>
",2066786.0,,10133797.0,,2019-10-07 21:26:52,2019-10-08 00:29:12,Proper way to feed time-series data to stateful LSTM?,<python><tensorflow><machine-learning><keras><lstm>,1,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/58276337
39289285,1,39291033,,2016-09-02 09:42:25,,24,34145,"<p>I have 10000 BMP images of some handwritten digits. If i want to feed the datas to a neural network what do i need to do ? For MNIST dataset i just had to write</p>

<pre><code>(X_train, y_train), (X_test, y_test) = mnist.load_data()
</code></pre>

<p>I am using Keras library in python . How can i create such dataset ?</p>
",6655645.0,,,,,2020-12-06 13:06:02,How to create a Image Dataset just like MNIST dataset?,<python><image-processing><dataset><neural-network><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/39289285
47414651,1,47414680,,2017-11-21 13:45:06,,24,11804,"<p>There is already an answer wrt to Tensorflow.
But the problem is that
In my IDE
Conv2D is a class
while Convolution2D is a variable?</p>
",8913947.0,,,,,2020-03-08 12:49:44,Difference between Conv2D and Convolution2D in Keras,<machine-learning><neural-network><keras><convolution><keras-layer>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47414651
51405517,1,59093579,,2018-07-18 15:13:04,,24,9431,"<p>I'm using keras with tensorflow backend. My goal is to query the <code>batchsize</code> of the current batch in a <strong>custom loss</strong> function. This is needed to compute values of the custom loss functions which depend on the index of particular observations. I like to make this clearer given the minimum reproducible examples below.</p>

<p>(BTW: Of course I could use the batch size defined for the training procedure and plugin it's value when defining the custom loss function, but there are some reasons why this can vary, especially if <code>epochsize % batchsize</code> (epochsize modulo batchsize) is unequal zero, then the last batch of an epoch has different size. I didn't found a suitable approach in stackoverflow, especially e. g.
<a href=""https://stackoverflow.com/q/46200080/10099959"">Tensor indexing in custom loss function</a> and   <a href=""https://stackoverflow.com/q/48524836/10099959"">Tensorflow custom loss function in Keras - loop over tensor</a> and <a href=""https://stackoverflow.com/q/43327668/10099959"">Looping over a tensor</a> because obviously the shape of any tensor can't be inferred when building the graph which is the case for a loss function - shape inference is only possible when evaluating given the data, which is only possible given the graph. Hence I need to tell the custom loss function to do something with particular elements along a certain dimension without knowing the length of the dimension.</p>

<h1>(this is the same in all examples)</h1>

<pre><code>from keras.models import Sequential
from keras.layers import Dense, Activation

# Generate dummy data
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(2, size=(1000, 1))

model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(1, activation='sigmoid'))
</code></pre>

<h1>example 1: nothing special without issue, no custom loss</h1>

<pre><code>model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])    

# Train the model, iterating on the data in batches of 32 samples
model.fit(data, labels, epochs=10, batch_size=32)
</code></pre>

<p><em>(Output omitted, this runs perfectily fine)</em></p>

<h1>example 2: nothing special, with a fairly simple custom loss</h1>

<pre><code>def custom_loss(yTrue, yPred):
    loss = np.abs(yTrue-yPred)
    return loss

model.compile(optimizer='rmsprop',
              loss=custom_loss,
              metrics=['accuracy'])

# Train the model, iterating on the data in batches of 32 samples
model.fit(data, labels, epochs=10, batch_size=32)
</code></pre>

<p><em>(Output omitted, this runs perfectily fine)</em></p>

<h1>example 3: the issue</h1>

<pre><code>def custom_loss(yTrue, yPred):
    print(yPred) # Output: Tensor(""dense_2/Sigmoid:0"", shape=(?, 1), dtype=float32)
    n = yPred.shape[0]
    for i in range(n): # TypeError: __index__ returned non-int (type NoneType)
        loss = np.abs(yTrue[i]-yPred[int(i/2)])
    return loss

model.compile(optimizer='rmsprop',
              loss=custom_loss,
              metrics=['accuracy'])

# Train the model, iterating on the data in batches of 32 samples
model.fit(data, labels, epochs=10, batch_size=32)
</code></pre>

<p>Of course the tensor has not shape info yet which can't be inferred when building the graph, only at training time. Hence <code>for i in range(n)</code> rises an error. Is there any way to perform this?</p>

<p><strong>The traceback of the output:</strong>
<a href=""https://i.stack.imgur.com/b9eCa.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/b9eCa.png"" alt=""enter image description here""></a></p>

<h1>-------</h1>

<p>BTW here's my true custom loss function in case of any questions. I skipped it above for clarity and simplicity.</p>

<pre><code>def neg_log_likelihood(yTrue,yPred):
    yStatus = yTrue[:,0]
    yTime = yTrue[:,1]    
    n = yTrue.shape[0]    
    for i in range(n):
        s1 = K.greater_equal(yTime, yTime[i])
        s2 = K.exp(yPred[s1])
        s3 = K.sum(s2)
        logsum = K.log(y3)
        loss = K.sum(yStatus[i] * yPred[i] - logsum)
    return loss
</code></pre>

<p>Here's an image of the partial negative log-likelihood of the cox proportional harzards model. </p>

<p><a href=""https://i.stack.imgur.com/jxmXd.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/jxmXd.png"" alt=""enter image description here""></a></p>

<p>This is to clarify a question in the comments to avoid confusion. I don't think it is necessary to understand this in detail to answer the question. </p>
",10099959.0,,1699075.0,,2019-10-06 21:05:10,2019-11-28 17:13:17,How to iterate through tensors in custom loss function?,<python><tensorflow><keras><loss-function>,1,9,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51405517
43151775,1,43173316,,2017-04-01 01:22:22,,24,24986,"<p>I am a little new to neural networks and keras. I have some images with size 6*7 and the size of the filter is 15. I want to have several filters and train a convolutional layer separately on each and then combine them. I have looked at one example here:</p>

<pre><code>model = Sequential()
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],
                    border_mode='valid',
                    input_shape=input_shape))
model.add(Activation('relu'))
model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=pool_size))
model.add(Dropout(0.25))
model.add(Flatten(input_shape=input_shape))
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('tanh'))
</code></pre>

<p>This model works with one filter. Can anybody give me some hints on how to modify the model to work with parallel convolutional layers.</p>

<p>Thanks</p>
",2462485.0,,,,,2021-07-12 03:58:36,How to have parallel convolutional layers in keras?,<neural-network><keras><conv-neural-network><keras-layer>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43151775
61505749,1,61510447,,2020-04-29 15:38:04,,24,26127,"<p>I have an issue with <code>tf.callbacks.ModelChekpoint</code>. As you can see in my log file, the warning comes always before the last iteration where the <code>val_acc</code> is calculated. Therefore, <code>Modelcheckpoint</code> never finds the <code>val_acc</code></p>
<pre><code>Epoch 1/30
1/8 [==&gt;...........................] - ETA: 19s - loss: 1.4174 - accuracy: 0.3000
2/8 [======&gt;.......................] - ETA: 8s - loss: 1.3363 - accuracy: 0.3500 
3/8 [==========&gt;...................] - ETA: 4s - loss: 1.3994 - accuracy: 0.2667
4/8 [==============&gt;...............] - ETA: 3s - loss: 1.3527 - accuracy: 0.3250
6/8 [=====================&gt;........] - ETA: 1s - loss: 1.3042 - accuracy: 0.3333
WARNING:tensorflow:Can save best model only with val_acc available, skipping.
8/8 [==============================] - 4s 482ms/step - loss: 1.2846 - accuracy: 0.3375 - val_loss: 1.3512 - val_accuracy: 0.5000

Epoch 2/30
1/8 [==&gt;...........................] - ETA: 0s - loss: 1.0098 - accuracy: 0.5000
3/8 [==========&gt;...................] - ETA: 0s - loss: 0.8916 - accuracy: 0.5333
5/8 [=================&gt;............] - ETA: 0s - loss: 0.9533 - accuracy: 0.5600
6/8 [=====================&gt;........] - ETA: 0s - loss: 0.9523 - accuracy: 0.5667
7/8 [=========================&gt;....] - ETA: 0s - loss: 0.9377 - accuracy: 0.5714
WARNING:tensorflow:Can save best model only with val_acc available, skipping.
8/8 [==============================] - 1s 98ms/step - loss: 0.9229 - accuracy: 0.5750 - val_loss: 1.2507 - val_accuracy: 0.5000
</code></pre>
<p>This is my code for training the CNN.</p>
<pre><code>callbacks = [
        TensorBoard(log_dir=r'C:\Users\reda\Desktop\logs\{}'.format(Name),
                    histogram_freq=1),
        ModelCheckpoint(filepath=r&quot;C:\Users\reda\Desktop\checkpoints\{}&quot;.format(Name), monitor='val_acc',
                        verbose=2, save_best_only=True, mode='max')]
history = model.fit_generator(
        train_data_gen, 
        steps_per_epoch=total_train // batch_size,
        epochs=epochs,
        validation_data=val_data_gen,
        validation_steps=total_val // batch_size,
        callbacks=callbacks)
</code></pre>
",9802019.0,,9802019.0,,2022-01-18 08:15:30,2023-02-11 18:52:48,"tensorflow:Can save best model only with val_acc available, skipping",<python><tensorflow><machine-learning><keras><deep-learning>,10,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/61505749
46464549,1,46465774,,2017-09-28 08:34:19,,24,11429,"<p>In Keras (with Tensorflow backend), is the current input pattern available to my custom loss function?</p>

<p>The current input pattern is defined as the input vector used to produce the prediction. For example, consider the following: <code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)</code>. Then the current input pattern is the current X_train vector associated with the y_train (which is termed y_true in the loss function).</p>

<p>When designing a custom loss function, I intend to optimize/minimize a value that requires access to the current input pattern, not just the current prediction.</p>

<p>I've taken a look through <a href=""https://github.com/fchollet/keras/blob/master/keras/losses.py"" rel=""noreferrer"">https://github.com/fchollet/keras/blob/master/keras/losses.py</a></p>

<p>I've also looked through ""<a href=""https://github.com/fchollet/keras/issues/7379"" rel=""noreferrer"">Cost function that isn't just y_pred, y_true?</a>""</p>

<p>I am also familiar with previous examples to produce a customized loss function:</p>

<pre><code>import keras.backend as K

def customLoss(y_true,y_pred):
    return K.sum(K.log(y_true) - K.log(y_pred))
</code></pre>

<p>Presumably <code>(y_true,y_pred)</code> are defined elsewhere. I've taken a look through the source code without success and I'm wondering whether I need to define the current input pattern myself or whether this is already accessible to my loss function.</p>
",216295.0,,10375049.0,,2021-04-06 11:59:24,2021-04-06 11:59:24,Keras custom loss function: Accessing current input pattern,<python><tensorflow><machine-learning><keras><deep-learning>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46464549
47416861,1,47417083,,2017-11-21 15:34:59,,24,28523,"<p>can anyone tell me how is backpropagation done in Keras? I read that it is really easy in Torch and complex in Caffe, but I can't find anything about doing it with Keras. I am implementing my own layers in Keras (A very beginner) and would like to know how to do the backward propagation. </p>

<p>Thank you in advance</p>
",7855502.0,,,,,2022-04-01 12:11:04,Backward propagation in Keras?,<python><deep-learning><keras><keras-layer>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47416861
41749398,1,41774345,,2017-01-19 18:44:52,,24,12946,"<p>I want to use the <code>flow_from_directory</code> method of the <code>ImageDataGenerator</code>
to generate training data for a regression model, where the target value can be any float value between 1 and -1. <code>flow_from_directory</code> has a &quot;class_mode&quot; parameter with the description</p>
<blockquote>
<p>class_mode: one of &quot;categorical&quot;, &quot;binary&quot;, &quot;sparse&quot; or None. Default:
&quot;categorical&quot;. Determines the type of label arrays that are returned:
&quot;categorical&quot; will be 2D one-hot encoded labels, &quot;binary&quot; will be 1D
binary labels, &quot;sparse&quot; will be 1D integer labels.</p>
</blockquote>
<p>Which of these values should I take? None of them seems to really fit...</p>
",1934212.0,,2423278.0,,2022-09-06 09:17:45,2022-09-06 09:19:50,Using Keras ImageDataGenerator in a regression model,<machine-learning><neural-network><regression><keras>,4,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41749398
53212672,1,53214077,,2018-11-08 17:00:41,,24,43838,"<p>I have cloned human pose estimation keras model from this link <a href=""https://github.com/michalfaber/keras_Realtime_Multi-Person_Pose_Estimation"" rel=""noreferrer"">human pose estimation keras</a> </p>

<p>When I try to load the model on google colab, I get the following error</p>

<p>code</p>

<pre><code>from keras.models import load_model
model = load_model('model.h5')
</code></pre>

<p>error</p>

<pre><code>ValueError                                Traceback (most recent call 

last)
&lt;ipython-input-29-bdcc7d8d338b&gt; in &lt;module&gt;()
      1 from keras.models import load_model
----&gt; 2 model = load_model('model.h5')

/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py in load_model(filepath, custom_objects, compile)
    417     f = h5dict(filepath, 'r')
    418     try:
--&gt; 419         model = _deserialize_model(f, custom_objects, compile)
    420     finally:
    421         if opened_new_file:

/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py in _deserialize_model(f, custom_objects, compile)
    219         return obj
    220 
--&gt; 221     model_config = f['model_config']
    222     if model_config is None:
    223         raise ValueError('No model found in config.')

/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py in __getitem__(self, attr)
    300             else:
    301                 if self.read_only:
--&gt; 302                     raise ValueError('Cannot create group in read only mode.')
    303                 val = H5Dict(self.data.create_group(attr))
    304         return val

ValueError: Cannot create group in read only mode.
</code></pre>

<p>Can someone please help me understand this read-only mode? How do I load this model?</p>
",7576115.0,,,,,2020-01-29 17:04:25,Read only mode in keras,<python><tensorflow><keras><deep-learning>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53212672
49503748,1,49504376,,2018-03-27 03:06:03,,24,26249,"<p>I have a set of fairly complicated models that I am training and I am looking for a way to save and load the model optimizer states. The ""trainer models"" consist of different combinations of several other ""weight models"", of which some have shared weights, some have frozen weights depending on the trainer, etc. It is a bit too complicated of an example to share, but in short, I am not able to use <code>model.save('model_file.h5')</code> and <code>keras.models.load_model('model_file.h5')</code> when stopping and starting my training. </p>

<p>Using <code>model.load_weights('weight_file.h5')</code> works fine for testing my model if the training has finished, but if I attempt to continue training the model using this method, the loss does not come even close to returning to its last location. I have read that this is because the optimizer state is not saved using this method which makes sense. However, I need a method for saving and loading the states of the optimizers of my trainer models. It seems as though keras once had a <code>model.optimizer.get_sate()</code> and <code>model.optimizer.set_sate()</code> that would accomplish what I am after, but that does not seem to be the case anymore (at least for the Adam optimizer). Are there any other solutions with the current Keras?</p>
",7687401.0,,,,,2023-02-10 01:13:02,Save and load model optimizer state,<python><tensorflow><machine-learning><keras>,7,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49503748
51235118,1,51235358,,2018-07-08 18:53:29,,24,15308,"<p>I'm currently working with a Keras model which has a embedding layer as first layer. In order to visualize the relationships and similarity of words between each other I need a function that returns the mapping of words and vectors of every element in the vocabulary (e.g. 'love' - [0.21, 0.56, ..., 0.65, 0.10]).</p>

<p>Is there any way to do it?</p>
",7714720.0,,2099607.0,,2018-09-05 18:42:56,2021-01-12 11:32:53,How to get word vectors from Keras Embedding Layer,<python><dictionary><keras><keras-layer><word-embedding>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51235118
63068639,1,63085142,,2020-07-24 07:14:19,,24,44091,"<p>I made a CNN in colab and saved the models at every epoch. I exported the h5 file and now am trying to run the model on some test images. Here's the main error:</p>
<pre><code>ValueError: Unknown layer: Functional
</code></pre>
<p>Here's the code I used to run the model and save at each epoch:</p>
<pre><code>epochs = 50

callbacks = [
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
    keras.callbacks.ModelCheckpoint(&quot;save_at_{epoch}.h5&quot;),
]
model.compile(
    optimizer=keras.optimizers.Adam(1e-3),
    loss=&quot;binary_crossentropy&quot;,
    metrics=[&quot;accuracy&quot;],
)
model.fit(
    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,
)
</code></pre>
<p>After the model ran I just downloaded the h5 file from the colab sidebar locally. I re-uploaded the file from the local disk, and here's how I'm trying to load the model:</p>
<pre><code># load and evaluate a saved model
from tensorflow.keras.models import load_model

# load model#
loaded_model = load_model('save_at_47.h5')
loaded_model.layers[0].input_shape
</code></pre>
<p>Here's the full traceback:</p>
<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-4-6af7396280fa&gt; in &lt;module&gt;()
      3 
      4 # load model#
----&gt; 5 loaded_model = load_model('save_at_47.h5')
      6 loaded_model.layers[0].input_shape

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    182     if (h5py is not None and (
    183         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--&gt; 184       return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
    185 
    186     if sys.version_info &gt;= (3, 4) and isinstance(filepath, pathlib.Path):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    176     model_config = json.loads(model_config.decode('utf-8'))
    177     model = model_config_lib.model_from_config(model_config,
--&gt; 178                                                custom_objects=custom_objects)
    179 
    180     # set weights

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)
     53                     '`Sequential.from_config(config)`?')
     54   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
---&gt; 55   return deserialize(config, custom_objects=custom_objects)
     56 
     57 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    107       module_objects=globs,
    108       custom_objects=custom_objects,
--&gt; 109       printable_module_name='layer')

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    360     config = identifier
    361     (cls, cls_config) = class_and_config_for_serialized_keras_object(
--&gt; 362         config, module_objects, custom_objects, printable_module_name)
    363 
    364     if hasattr(cls, 'from_config'):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
    319   cls = get_registered_object(class_name, custom_objects, module_objects)
    320   if cls is None:
--&gt; 321     raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
    322 
    323   cls_config = config['config']

ValueError: Unknown layer: Functional
</code></pre>
<p>It seems there have been several similar <a href=""https://stackoverflow.com/questions/53051274/i-trained-a-keras-model-on-google-colab-now-not-able-to-load-it-locally-on-my-s"">questions here</a>,and <a href=""https://stackoverflow.com/questions/53183865/unknown-initializer-glorotuniform-when-loading-keras-model"">here</a>. Changing the import method hasn't helped yet, and trying to make some <a href=""https://stackoverflow.com/questions/54286368/valueerror-unknown-layername-when-loading-a-keras-model"">kind of custom</a> object has not worked either.</p>
",10777776.0,,10777776.0,,2020-07-24 07:33:42,2022-04-06 06:38:54,ValueError: Unknown layer: Functional,<python><tensorflow><keras>,7,8,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/63068639
43782409,1,43782410,,2017-05-04 12:04:24,,24,14343,"<p>Is it possible to use custom <a href=""https://keras.io/metrics/"" rel=""noreferrer"">metrics</a> in the <a href=""https://keras.io/callbacks/#modelcheckpoint"" rel=""noreferrer""><code>ModelCheckpoint</code></a> callback?</p>
",604734.0,,604734.0,,2018-09-27 07:25:03,2018-10-18 15:40:27,How to use ModelCheckpoint with custom metrics in Keras?,<keras><deep-learning>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43782409
52026652,1,54746150,,2018-08-26 13:20:35,,24,27998,"<p>I am facing a problem now, unable to run any program in the cluster. It gives error.</p>
<pre><code>OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 64 current, 64 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 64 current, 64 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 64 current, 64 max
OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable
OpenBLAS blas_thread_init: RLIMIT_NPROC 64 current, 64 max
Traceback (most recent call last):
  File &quot;hello-world.py&quot;, line 1, in &lt;module&gt;
    from keras.models import Sequential
  File &quot;/home/amalli2s/anaconda3/lib/python3.6/site-packages/keras/__init__.py&quot;, line 3, in &lt;module&gt;
    from . import utils
  File &quot;/home/amalli2s/anaconda3/lib/python3.6/site-packages/keras/utils/__init__.py&quot;, line 2, in &lt;module&gt;
    from . import np_utils
  File &quot;/home/amalli2s/anaconda3/lib/python3.6/site-packages/keras/utils/np_utils.py&quot;, line 6, in &lt;module&gt;
    import numpy as np
  File &quot;/home/amalli2s/.local/lib/python3.6/site-packages/numpy/__init__.py&quot;, line 142, in &lt;module&gt;
    from . import add_newdocs
  File &quot;/home/amalli2s/.local/lib/python3.6/site-packages/numpy/add_newdocs.py&quot;, line 13, in &lt;module&gt;
    from numpy.lib import add_newdoc
  File &quot;/home/amalli2s/.local/lib/python3.6/site-packages/numpy/lib/__init__.py&quot;, line 8, in &lt;module&gt;
    from .type_check import *
  File &quot;/home/amalli2s/.local/lib/python3.6/site-packages/numpy/lib/type_check.py&quot;, line 11, in &lt;module&gt;
    import numpy.core.numeric as _nx
  File &quot;/home/amalli2s/.local/lib/python3.6/site-packages/numpy/core/__init__.py&quot;, line 16, in &lt;module&gt;
    from . import multiarray
SystemError: initialization of multiarray raised unreported exception
</code></pre>
<p>This problem, i assume to be same as this one <a href=""https://stackoverflow.com/questions/51256738/multiple-instances-of-python-running-simultaneously-limited-to-35"">Multiple instances of Python running simultaneously limited to 35</a></p>
<p>So according to the solution when I set
<code>export OPENBLAS_NUM_THREADS=1</code></p>
<p>then I end up getting following error:</p>
<pre><code>terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
Aborted
</code></pre>
<p>Is there anybody else facing same issue or has idea on how to solve this ? Thank you.</p>
<p>EDIT:
Ok, Seems like this happened because of some config restrictions the admins were trying to implement. Now it works again.</p>
",1578967.0,,1578967.0,,2020-09-26 16:35:48,2021-06-14 21:12:52,OpenBLAS blas_thread_init: pthread_create: Resource temporarily unavailable,<python-3.x><keras><openblas>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52026652
42411891,1,42412124,,2017-02-23 09:38:27,,23,24405,"<p>I'm running a simple feed-forward network using <em>Keras</em> . 
Having just one hidden layer I would like to make some inference regarding the relevance of each input to each output and I would like to extract the weights. </p>

<p>This is the model: </p>

<pre><code>def build_model(input_dim, output_dim):
    n_output_layer_1 = 150
    n_output = output_dim
    model = Sequential()
    model.add(Dense(n_output_layer_1, input_dim=input_dim, activation='relu'))
    model.add(Dropout(0.25))
    model.add(Dense(n_output))
</code></pre>

<p>To extract the weight I wrote: </p>

<pre><code>for layer in model.layers:
    weights = layer.get_weights() 


weights = np.array(weights[0])     #this is hidden to output
first = model.layers[0].get_weights() #input to hidden
first = np.array(first[0])
</code></pre>

<p>Unfortunately I don't get the biases columns in the matrices, which I know Keras automatically puts in it. </p>

<p><strong>Do you know how to retrieve the biases weights?</strong></p>

<p>Thank you in advance for your help !</p>
",4338302.0,,,,,2020-01-20 18:18:58,How to extract bias weights in Keras sequential model?,<python><tensorflow><neural-network><keras>,1,0,0.0,2017-07-18 16:11:09,,CC BY-SA 3.0,https://stackoverflow.com/q/42411891
48085182,1,48087663,,2018-01-03 21:11:05,,23,46567,"<p>I'm implementing a Multilayer Perceptron in Keras and using scikit-learn to perform cross-validation. For this, I was inspired by the code found in the issue <a href=""https://github.com/keras-team/keras/issues/1711#issuecomment-185801662"" rel=""noreferrer"">Cross Validation in Keras</a></p>

<pre class=""lang-python prettyprint-override""><code>from sklearn.cross_validation import StratifiedKFold

def load_data():
    # load your data using this function

def create model():
    # create your model using this function

def train_and_evaluate__model(model, data[train], labels[train], data[test], labels[test)):
    # fit and evaluate here.

if __name__ == &quot;__main__&quot;:
    X, Y = load_model()
    kFold = StratifiedKFold(n_splits=10)
    for train, test in kFold.split(X, Y):
        model = None
        model = create_model()
        train_evaluate(model, X[train], Y[train], X[test], Y[test])
</code></pre>
<p>In my studies on neural networks, I learned that the knowledge representation of the neural network is in the synaptic weights and during the network tracing process, the weights that are updated to thereby reduce the network error rate and improve its performance. (In my case, I'm using Supervised Learning)</p>
<p>For better training and assessment of neural network performance, a common method of being used is cross-validation that returns partitions of the data set for training and evaluation of the model.</p>
<p>My doubt is...</p>
<p>In this code snippet:</p>
<pre class=""lang-python prettyprint-override""><code>for train, test in kFold.split(X, Y):
    model = None
    model = create_model()
    train_evaluate(model, X[train], Y[train], X[test], Y[test])
</code></pre>
<p>We define, train and evaluate a new neural net for each of the generated partitions?</p>
<p>If my goal is to fine-tune the network for the entire dataset, why is it not correct to define a single neural network and train it with the generated partitions?</p>
<p>That is, why is this piece of code like this?</p>
<pre class=""lang-python prettyprint-override""><code>for train, test in kFold.split(X, Y):
    model = None
    model = create_model()
    train_evaluate(model, X[train], Y[train], X[test], Y[test])
</code></pre>
<p>and not so?</p>
<pre class=""lang-python prettyprint-override""><code>model = None
model = create_model()
for train, test in kFold.split(X, Y):
    train_evaluate(model, X[train], Y[train], X[test], Y[test])
</code></pre>
<p>Is my understanding of how the code works wrong? Or my theory?</p>
",9169838.0,,4685471.0,,2021-07-12 13:39:05,2021-07-12 13:39:05,Cross Validation in Keras,<machine-learning><keras><scikit-learn><neural-network><cross-validation>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/48085182
51180234,1,51180353,,2018-07-04 20:07:09,,23,21535,"<p>What's the difference between those two? It would also help to explain in the more general context of convolutional networks.</p>

<p>Also, as a side note, what is channels? In other words, please break down the 3 terms for me: channels vs filters vs kernel.</p>
",2475195.0,,,,,2019-11-19 19:35:37,Keras Conv2D: filters vs kernel_size,<python><neural-network><keras><deep-learning><conv-neural-network>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51180234
48488549,1,48489090,,2018-01-28 16:27:08,,23,9369,"<p>I have a callback that computes a couple of additional metrics in <code>on_epoch_end</code> for validation data and every 10 epochs for test data.</p>

<p>I also have a <code>CSVLogger</code> callback that saves normal metrics to a log file.</p>

<p>Is there an easy way from my callback to add a column or two to the logs that gets properly written by <code>CSVLogger</code>?</p>
",5629339.0,,5629339.0,,2018-01-28 17:34:54,2018-09-09 02:43:42,"Keras, append to logs from callback",<logging><callback><keras>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48488549
47594861,1,47719094,,2017-12-01 13:49:13,,23,18648,"<p>I want to predict certain values that are weekly predictable (low SNR). I need to predict the whole time series of a year formed by the weeks of the year (52 values - Figure 1)</p>

<p><a href=""https://i.stack.imgur.com/5qMLH.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/5qMLH.png"" alt=""Figure 1: Year time series by week""></a></p>

<p>My first idea was to develop a many-to-many LSTM model (Figure 2) using Keras over TensorFlow. I'm training the model with a 52 input layer (the given time series of previous year) and 52 predicted output layer (the time series of next year). The shape of train_X is (X_examples, 52, 1), in other words, X_examples to train, 52 timesteps of 1 feature each. I understand that Keras will consider the 52 inputs as a time series of the same domain. The shape of the train_Y are the same (y_examples, 52, 1). 
I added a TimeDistributed layer. My thought was that the algorithm will predict the values as a time series instead of isolated values (am I correct?)</p>

<p>The model's code in Keras is:</p>

<pre><code>y = y.reshape(y.shape[0], 52, 1)
X = X.reshape(X.shape[0], 52, 1)
# design network
model = Sequential()
model.add(LSTM(n_neurons, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(TimeDistributed(Dense(1)))
model.compile(loss='mean_squared_error', optimizer='adam')
# fit network
model.fit(X, y, epochs=n_epochs, batch_size=n_batch, verbose=2)
</code></pre>

<p><a href=""https://i.stack.imgur.com/jZfab.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/jZfab.jpg"" alt=""Figure 2: Many-to-many LSTM architecture""></a></p>

<p>The problem is that the algorithm is not learning the example. It is predicting values very similar to the attributes' values. Am I modeling the problem correctly? </p>

<p>Second question:
Another idea is to train the algorithm with 1 input and 1 output, but then during the test how will I predict the whole 2015 time series without looking to the '1 input'? The test data will have a different shape than the training data.</p>
",1445225.0,,374437.0,,2018-12-18 14:14:09,2019-04-30 17:41:46,Predicting a multiple forward time step of a time series using LSTM,<time-series><keras><lstm><prediction><forward>,3,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47594861
42918446,1,44387553,,2017-03-21 04:26:37,,23,43872,"<p>I'm currently using this code that i get from <a href=""https://github.com/fchollet/keras/issues/4962"" rel=""noreferrer"">one discussion on github</a>
Here's the code of the attention mechanism:</p>

<pre><code>_input = Input(shape=[max_length], dtype='int32')

# get the embedding layer
embedded = Embedding(
        input_dim=vocab_size,
        output_dim=embedding_size,
        input_length=max_length,
        trainable=False,
        mask_zero=False
    )(_input)

activations = LSTM(units, return_sequences=True)(embedded)

# compute importance for each step
attention = Dense(1, activation='tanh')(activations)
attention = Flatten()(attention)
attention = Activation('softmax')(attention)
attention = RepeatVector(units)(attention)
attention = Permute([2, 1])(attention)


sent_representation = merge([activations, attention], mode='mul')
sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units,))(sent_representation)

probabilities = Dense(3, activation='softmax')(sent_representation)
</code></pre>

<p>Is this the correct way to do it? i was sort of expecting the existence of time distributed layer since attention mechanism is distributed in every time step of the RNN. I need someone to confirm that this implementation(the code) is a correct implementation of attention mechanism. Thank you.</p>
",7676016.0,,249341.0,,2018-07-03 15:37:37,2020-12-09 14:25:59,How to add an attention mechanism in keras?,<python><keras>,5,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42918446
43459317,1,43461480,,2017-04-17 20:46:43,,23,21126,"<p>In Keras (using TensorFlow as a backend) I am building a model which is working with a huge dataset that is having highly imbalanced classes (labels). To be able to run the training process, I created a generator which feeds chunks of data to the <code>fit_generator</code>.</p>

<p>According to the documentation for the <a href=""https://keras.io/models/sequential/#fit_generator"" rel=""noreferrer"">fit_generator</a>, the output of the generator can either be the tuple <code>(inputs, targets)</code> or the tuple <code>(inputs, targets, sample_weights)</code>. Having that in mind, here are a few questions:</p>

<ol>
<li>My understanding is that 
the <code>class_weight</code> regards the weights of all classes for the entire dataset whereas
the <code>sample_weights</code> regards the weights of all classes for each individual chunk
created by the generator. Is that correct? If not, can someone elaborate on the matter?</li>
<li>Is it necessary to give both the <code>class_weight</code> to the <code>fit_generator</code> and then the <code>sample_weights</code> as an output for each chunk? If yes, then why? If not then which one is better to give?</li>
<li>If I should give the <code>sample_weights</code> for each chunk, how do I map the weights if some of the classes are missing from a specific chunk? Let me give an example. In my overall dataset, I have 7 possible classes (labels). Because these classes are highly imbalanced, when I create smaller chunks of data as an output from the <code>fit_generator</code>, some of the classes are missing from the specific chunk. How should I create the <code>sample_weights</code> for these chunks?</li>
</ol>
",2480410.0,,4978581.0,,2017-04-17 21:55:09,2017-04-18 12:13:31,Keras - class_weight vs sample_weights in the fit_generator,<tensorflow><keras>,1,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43459317
50746096,1,50748868,,2018-06-07 16:26:13,,23,13100,"<p>I'm studying deep learning. Trained an image classification algorithm. The problem is, however, that to train images I used:</p>

<pre><code>test_image = image.load_img('some.png', target_size = (64, 64))
test_image = image.img_to_array(test_image)
</code></pre>

<p>While for actual application I use:</p>

<pre><code>test_image = cv2.imread('trick.png')
test_image = cv2.resize(test_image, (64, 64))
</code></pre>

<p>But I found that those give a different ndarray (different data):</p>

<p>Last entries from load_image:</p>

<pre><code>  [ 64.  71.  66.]
  [ 64.  71.  66.]
  [ 62.  69.  67.]]]
</code></pre>

<p>Last entries from cv2.imread:</p>

<pre><code>  [ 15  23  27]
  [ 16  24  28]
  [ 14  24  28]]]
</code></pre>

<p>, so the system is not working. Is there a way to match results of one to another?</p>
",4363045.0,,4363045.0,,2018-06-07 17:00:29,2019-09-27 04:28:44,How to match cv2.imread to the keras image.img_load output,<python-3.x><numpy><opencv><image-processing><keras>,3,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50746096
43327464,1,43328647,,2017-04-10 15:38:53,,23,34703,"<p>I have install tensorflow-gpu in my Anaconda environment. They both work well. </p>

<p>Now I am trying to install Keras with Tensorflow backend. According to the <a href=""https://keras.io/#installation"" rel=""noreferrer"">instruction</a> I just run:</p>

<pre><code>pip install keras
</code></pre>

<p>But it doesn't install keras, then I tried:</p>

<pre><code>conda install -c conda-forge keras=2.0.2
</code></pre>

<p>Then I am now able import keras in python. But the problem is, it always use the Theano backend. I am trying to change this, but not knowing how to do it.</p>

<p>I also tried edit the file <strong>~/.keras</strong>, but actually default backend was tensorflow already.</p>

<p>Please help.. Thank you so much!</p>
",4352606.0,,,,,2020-03-10 07:41:42,How to make Keras use Tensorflow backend in Anaconda?,<python><tensorflow><anaconda><backend><keras>,11,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43327464
43086548,1,43092197,,2017-03-29 07:02:58,,23,13499,"<p><strong>Problem:</strong> I am training a model for multilabel image recognition. My images are therefore associated with multiple y labels. This is conflicting with the convenient keras method ""flow_from_directory"" of the ImageDataGenerator, where each image is supposed to be in the folder of the corresponding label (<a href=""https://keras.io/preprocessing/image/"" rel=""noreferrer"">https://keras.io/preprocessing/image/</a>).</p>

<p><strong>Workaround:</strong> Currently, I am reading all images into a numpy array and use the ""flow"" function from there. But this results in heavy memory loads and a slow read-in process. </p>

<p><strong>Question:</strong> Is there a way to use the ""flow_from_directory"" method and to supply manually the (multiple) class labels?</p>

<hr>

<p><strong>Update</strong>: I ended up extending the DirectoryIterator class for the multilabel case. You can now set the attribute ""class_mode"" to the value ""multilabel"" and provide a dictionary ""multlabel_classes"" which maps filenames to their labels. Code: <a href=""https://github.com/tholor/keras/commit/29ceafca3c4792cb480829c5768510e4bdb489c5"" rel=""noreferrer"">https://github.com/tholor/keras/commit/29ceafca3c4792cb480829c5768510e4bdb489c5</a></p>
",1325071.0,,1325071.0,,2017-04-03 08:23:33,2020-11-18 15:41:54,How to manually specify class labels in keras flow_from_directory?,<python><image-processing><deep-learning><keras><multilabel-classification>,3,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43086548
41947039,1,48521460,,2017-01-30 23:08:16,,23,18166,"<p>I would like to model RNN with LSTM cells in order to predict multiple output time series based on multiple input time series. To be specific, I have 4 output time series, y1[t], y2[t], y3[t], y4[t], each has a length 3,000 (t=0,...,2999). I also have 3 input time series, x1[t], x2[t], x3[t], and each has a length 3,000 sec (t=0,...,2999). The goal is to predict y1[t],.. y4[t] using all the input time series up to this current time point i.e.:</p>

<pre><code>  y1[t] = f1(x1[k],x2[k],x3[k], k = 0,...,t)
  y2[t] = f2(x1[k],x2[k],x3[k], k = 0,...,t)
  y3[t] = f3(x1[k],x2[k],x3[k], k = 0,...,t)
  y4[t] = f3(x1[k],x2[k],x3[k], k = 0,...,t)
</code></pre>

<p>For a model to have a long term memory, I created a stateful RNN model by following. <a href=""http://philipperemy.github.io/keras-stateful-lstm/"" rel=""noreferrer"">keras-stateful-lstme</a>. The main difference between my case and <a href=""http://philipperemy.github.io/keras-stateful-lstm/"" rel=""noreferrer"">keras-stateful-lstme</a> is that I have:</p>

<ul>
<li>more than 1 output time series</li>
<li>more than 1 input time series</li>
<li>the goal is the prediction of continuous time series</li>
</ul>

<p>My code is running. However the model's prediction result is bad even with a simple data. So I would like to ask you if I am getting anything wrong.</p>

<p>Here is my code with a toy example.</p>

<p>In toy example, our input time series are simple cosign and sign waves:</p>

<pre><code>import numpy as np
def random_sample(len_timeseries=3000):
    Nchoice = 600
    x1 = np.cos(np.arange(0,len_timeseries)/float(1.0 + np.random.choice(Nchoice)))
    x2 = np.cos(np.arange(0,len_timeseries)/float(1.0 + np.random.choice(Nchoice)))
    x3 = np.sin(np.arange(0,len_timeseries)/float(1.0 + np.random.choice(Nchoice)))
    x4 = np.sin(np.arange(0,len_timeseries)/float(1.0 + np.random.choice(Nchoice)))
    y1 = np.random.random(len_timeseries)
    y2 = np.random.random(len_timeseries)
    y3 = np.random.random(len_timeseries)
    for t in range(3,len_timeseries):
        ## the output time series depend on input as follows: 
        y1[t] = x1[t-2] 
        y2[t] = x2[t-1]*x3[t-2]
        y3[t] = x4[t-3]
    y = np.array([y1,y2,y3]).T
    X = np.array([x1,x2,x3,x4]).T
    return y, X
def generate_data(Nsequence = 1000):
    X_train = []
    y_train = []
    for isequence in range(Nsequence):
        y, X = random_sample()
        X_train.append(X)
        y_train.append(y)
    return np.array(X_train),np.array(y_train)
</code></pre>

<p>Please notice that y1 at time point t is simply the value of x1 at t - 2.
Please also notice that y3 at time point t is simply the value of x1 in the two previous step.</p>

<p>Using these functions, I generated 100 sets of time series y1,y2,y3,x1,x2,x3,x4. Half of them go to training data and the remaining half go to testing data.</p>

<pre><code>Nsequence = 100
prop = 0.5
Ntrain = Nsequence*prop
X, y = generate_data(Nsequence)
X_train = X[:Ntrain,:,:]
X_test  = X[Ntrain:,:,:]
y_train = y[:Ntrain,:,:]
y_test  = y[Ntrain:,:,:] 
</code></pre>

<p>X, y are both 3 dimensional and each contains:</p>

<pre><code>#X.shape = (N sequence, length of time series, N input features)
#y.shape = (N sequence, length of time series, N targets)
print X.shape, y.shape
&gt; (100, 3000, 4) (100, 3000, 3)
</code></pre>

<p>The example of the time series y1, .. y4 and x1, .., x3 are shown as below:</p>

<p><a href=""https://i.stack.imgur.com/u100N.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/u100N.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/PtOvt.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/PtOvt.png"" alt=""enter image description here""></a></p>

<p>I standardize these data as:</p>

<pre><code>def standardize(X_train,stat=None):
    ## X_train is 3 dimentional e.g. (Nsample,len_timeseries, Nfeature)
    ## standardization is done with respect to the 3rd dimention
    if stat is None:
        featmean = np.array([np.nanmean(X_train[:,:,itrain]) for itrain in range(X_train.shape[2])]).reshape(1,1,X_train.shape[2])
        featstd = np.array([np.nanstd(X_train[:,:,itrain]) for itrain in range(X_train.shape[2])]).reshape(1,1,X_train.shape[2])
        stat = {""featmean"":featmean,""featstd"":featstd}
    else:
        featmean = stat[""featmean""]
        featstd = stat[""featstd""]
    X_train_s = (X_train - featmean)/featstd
    return X_train_s, stat 

X_train_s, X_stat = standardize(X_train,stat=None)
X_test_s, _ = standardize(X_test,stat=X_stat)
y_train_s, y_stat = standardize(y_train,stat=None)
y_test_s, _ = standardize(y_test,stat=y_stat)
</code></pre>

<p><strong>Create a stateful RNN model with 10 LSTM hidden neurons</strong></p>

<pre><code>from keras.models import Sequential
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
def create_stateful_model(hidden_neurons):
    # create and fit the LSTM network

    model = Sequential()
    model.add(LSTM(hidden_neurons, 
                   batch_input_shape=(1, 1, X_train.shape[2]), 
                   return_sequences=False, 
                   stateful=True))
    model.add(Dropout(0.5))
    model.add(Dense(y_train.shape[2]))
    model.add(Activation(""linear""))
    model.compile(loss='mean_squared_error', optimizer=""rmsprop"",metrics=['mean_squared_error'])
    return model
 model = create_stateful_model(10)
</code></pre>

<p>Now following code is used to train and validate the RNN model:</p>

<pre><code>def get_R2(y_pred,y_test):
        ## y_pred_s_batch: (Nsample, len_timeseries, Noutput)
        ## the relative percentage error is computed for each output
        overall_mean = np.nanmean(y_test)
        SSres = np.nanmean( (y_pred - y_test)**2 ,axis=0).mean(axis=0)
        SStot = np.nanmean( (y_test - overall_mean)**2 ,axis=0).mean(axis=0)
        R2 = 1 - SSres / SStot 
        print ""&lt;R2 testing&gt; target 1:"",R2[0],""target 2:"",R2[1],""target 3:"",R2[2]
        return R2


def reshape_batch_input(X_t,y_t=None):
    X_t = np.array(X_t).reshape(1,1,len(X_t)) ## (1,1,4) dimention
    if y_t is not None:
        y_t = np.array([y_t]) ## (1,3)
    return X_t,y_t
def fit_stateful(model,X_train,y_train,X_test,y_test,nb_epoch=8):
    '''
    reference: http://philipperemy.github.io/keras-stateful-lstm/

    X_train: (N_time_series, len_time_series, N_features) = (10,000, 3,600 (max), 2), 
    y_train: (N_time_series, len_time_series, N_output) =   (10,000, 3,600 (max), 4)

    '''
    max_len = X_train.shape[1]

    print ""X_train.shape(Nsequence ="",X_train.shape[0],""len_timeseries ="",X_train.shape[1],""Nfeats ="",X_train.shape[2],"")""
    print ""y_train.shape(Nsequence ="",y_train.shape[0],""len_timeseries ="",y_train.shape[1],""Ntargets ="",y_train.shape[2],"")""
    print('Train...')
    for epoch in range(nb_epoch):
        print('___________________________________')
        print ""epoch"", epoch+1, ""out of "",nb_epoch
        ## ---------- ##
        ##  training  ##
        ## ---------- ##
        mean_tr_acc = []
        mean_tr_loss = []
        for s in range(X_train.shape[0]):
            for t in range(max_len):
                X_st = X_train[s][t]
                y_st = y_train[s][t]
                if np.any(np.isnan(y_st)):
                    break
                X_st,y_st = reshape_batch_input(X_st,y_st)
                tr_loss, tr_acc = model.train_on_batch(X_st,y_st)
                mean_tr_acc.append(tr_acc)
                mean_tr_loss.append(tr_loss)
            model.reset_states()

        ##print('accuracy training = {}'.format(np.mean(mean_tr_acc)))
        print('&lt;loss (mse) training&gt; {}'.format(np.mean(mean_tr_loss)))
        ## ---------- ##
        ##  testing   ##
        ## ---------- ##
        y_pred = predict_stateful(model,X_test)
        eva =  get_R2(y_pred,y_test)
    return model, eva, y_pred

def predict_stateful(model,X_test):
    y_pred = []
    max_len = X_test.shape[1]
    for s in range(X_test.shape[0]):
        y_s_pred = []
        for t in range(max_len):
            X_st = X_test[s][t]
            if np.any(np.isnan(X_st)):
                ## the rest of y is NA
                y_s_pred.extend([np.NaN]*(max_len-len(y_s_pred)))
                break
            X_st,_ = reshape_batch_input(X_st)
            y_st_pred = model.predict_on_batch(X_st)
            y_s_pred.append(y_st_pred[0].tolist())

        y_pred.append(y_s_pred)
        model.reset_states()

    y_pred = np.array(y_pred)
    return y_pred




  model, train_metric, y_pred = fit_stateful(model,
                                        X_train_s,y_train_s,
                                        X_test_s,y_test_s,nb_epoch=15)
</code></pre>

<p>The output is the following:</p>

<pre><code>X_train.shape(Nsequence = 15 len_timeseries = 3000 Nfeats = 4 )
y_train.shape(Nsequence = 15 len_timeseries = 3000 Ntargets = 3 )
Train...
___________________________________
epoch 1 out of  15
&lt;loss (mse) training&gt; 0.414115458727
&lt;R2 testing&gt; target 1: 0.664464304688 target 2: -0.574523052322 target 3: 0.526447813052
___________________________________
epoch 2 out of  15
&lt;loss (mse) training&gt; 0.394549429417
&lt;R2 testing&gt; target 1: 0.361516087033 target 2: -0.724583671831 target 3: 0.795566178787
___________________________________
epoch 3 out of  15
&lt;loss (mse) training&gt; 0.403199136257
&lt;R2 testing&gt; target 1: 0.09610702779 target 2: -0.468219774909 target 3: 0.69419269042
___________________________________
epoch 4 out of  15
&lt;loss (mse) training&gt; 0.406423777342
&lt;R2 testing&gt; target 1: 0.469149270848 target 2: -0.725592048946 target 3: 0.732963522766
___________________________________
epoch 5 out of  15
&lt;loss (mse) training&gt; 0.408153116703
&lt;R2 testing&gt; target 1: 0.400821776652 target 2: -0.329415365214 target 3: 0.2578432553
___________________________________
epoch 6 out of  15
&lt;loss (mse) training&gt; 0.421062678099
&lt;R2 testing&gt; target 1: -0.100464591586 target 2: -0.232403824523 target 3: 0.570606489959
___________________________________
epoch 7 out of  15
&lt;loss (mse) training&gt; 0.417774856091
&lt;R2 testing&gt; target 1: 0.320094445321 target 2: -0.606375769083 target 3: 0.349876223119
___________________________________
epoch 8 out of  15
&lt;loss (mse) training&gt; 0.427440851927
&lt;R2 testing&gt; target 1: 0.489543715713 target 2: -0.445328806611 target 3: 0.236463139804
___________________________________
epoch 9 out of  15
&lt;loss (mse) training&gt; 0.422931671143
&lt;R2 testing&gt; target 1: -0.31006468223 target 2: -0.322621276474 target 3: 0.122573123871
___________________________________
epoch 10 out of  15
&lt;loss (mse) training&gt; 0.43609803915
&lt;R2 testing&gt; target 1: 0.459111316554 target 2: -0.313382405804 target 3: 0.636854743292
___________________________________
epoch 11 out of  15
&lt;loss (mse) training&gt; 0.433844655752
&lt;R2 testing&gt; target 1: -0.0161015052703 target 2: -0.237462995323 target 3: 0.271788109459
___________________________________
epoch 12 out of  15
&lt;loss (mse) training&gt; 0.437297314405
&lt;R2 testing&gt; target 1: -0.493665758658 target 2: -0.234236263092 target 3: 0.047264439493
___________________________________
epoch 13 out of  15
&lt;loss (mse) training&gt; 0.470605045557
&lt;R2 testing&gt; target 1: 0.144443089961 target 2: -0.333210874982 target 3: -0.00432615142135
___________________________________
epoch 14 out of  15
&lt;loss (mse) training&gt; 0.444566756487
&lt;R2 testing&gt; target 1: -0.053982119103 target 2: -0.0676577449316 target 3: -0.12678037186
___________________________________
epoch 15 out of  15
&lt;loss (mse) training&gt; 0.482106208801
&lt;R2 testing&gt; target 1: 0.208482181828 target 2: -0.402982670798 target 3: 0.366757778713
</code></pre>

<p>As you can see, the training loss is NOT decreasing!!</p>

<p>As the target time series 1 and 3 have very simple relations with the input time series (y1[t] = x1[t-2] , y3[t] = x4[t-3]), I would expect perfect prediction performance. However, testing R2 at every epoch shows that that is not the case. R2 at the final epoch is just about 0.2 and 0.36. Clearly, the algorithm is not converging. I am very puzzled with this result. Please do let me know what I am missing, and why the algorithm is not converging. </p>
",1639886.0,,,,,2018-03-31 12:07:32,Keras RNN with LSTM cells for predicting multiple output time series based on multiple intput time series,<python><neural-network><keras><recurrent-neural-network>,1,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41947039
62044838,1,62307678,,2020-05-27 13:54:37,,23,17268,"<p>I want to train my RNN model using Cudnn:</p>

<pre><code>max_length &lt;- 140 
embedding_dim &lt;- 128

model &lt;- keras_model_sequential()

# define model
model %&gt;% 
  # layer input
  layer_embedding(
    name = ""input"",
    input_dim = num_words,
    input_length = max_length,
    output_dim = embedding_dim, 
    embeddings_initializer = initializer_random_uniform(minval = -0.05, maxval = 0.05, seed = 2)
  ) %&gt;%
  # layer dropout
  layer_spatial_dropout_1d(
    name = ""embedding_dropout"",
    rate = 0.2
  ) %&gt;%
  # layer lstm 1
  bidirectional(layer_lstm(
    name = ""lstm"",
    units = 64,
    unroll = FALSE,
    dropout = 0.2,
    use_bias = TRUE,
    recurrent_dropout = 0,
    return_sequences = TRUE
  )) %&gt;% 
  layer_batch_normalization() %&gt;%
  # layer output
  layer_dense(
    name = ""output"",
    units = 3,
    activation = ""softmax""
  )
</code></pre>

<p>when I run this I get this warming:</p>

<blockquote>
  <p>WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it
  doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel
  as fallback when running on GPU</p>
</blockquote>

<p>I think I have followed all the <a href=""https://www.tensorflow.org/guide/keras/rnn#performance_optimization_and_cudnn_kernels_in_tensorflow_20"" rel=""noreferrer"">requirements</a>, not sure what I'm missing. </p>

<p>SessionInfo:</p>

<pre><code>R version 4.0.0 (2020-04-24)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] keras_2.3.0.0

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6     lattice_0.20-41  zeallot_0.1.0    rappdirs_0.3.1  
 [5] grid_4.0.0       R6_2.4.1         jsonlite_1.6.1   magrittr_1.5    
 [9] tfruns_1.4       whisker_0.4      Matrix_1.2-18    reticulate_1.15 
[13] generics_0.0.2   tools_4.0.0      xfun_0.14        compiler_4.0.0  
[17] base64enc_0.1-3  tensorflow_2.2.0 knitr_1.28   
</code></pre>
",2475569.0,,2475569.0,,2020-05-27 14:06:55,2020-11-02 17:16:15,using cuDNN kernel for LSTM,<r><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/62044838
48235169,1,48364708,,2018-01-12 22:58:41,,22,118999,"<p>I have updated numpy to 1.14.0. I use Windows 10. I tried to run my code and I got this error:</p>

<blockquote>
  <p>AttributeError: module 'numpy' has no attribute 'square'</p>
</blockquote>

<p>Here are my imports:</p>

<pre><code>%matplotlib inline
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from sklearn.metrics import confusion_matrix
import math
</code></pre>
",7561641.0,,5660517.0,,2018-01-12 23:16:07,2018-01-21 07:46:26,How to fix AttributeError: module 'numpy' has no attribute 'square',<python><python-3.x><numpy><keras><attributeerror>,1,4,0.0,2018-01-21 07:52:52,,CC BY-SA 3.0,https://stackoverflow.com/q/48235169
38972380,1,41872896,,2016-08-16 10:22:33,,22,23297,"<p>In a Keras model with the Functional API I need to call fit_generator to train on augmented images data using an ImageDataGenerator.<br />
The problem is my model has two outputs: the mask I'm trying to predict and a binary value.<br />
I obviously only want to augment the input and the mask output and not the binary value.<br />
How can I achieve this?</p>
",1490721.0,,1490721.0,,2021-02-19 14:32:05,2021-02-19 14:32:05,Keras: How to use fit_generator with multiple outputs of different type,<python><deep-learning><keras>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/38972380
51140950,1,51144278,,2018-07-02 17:19:50,,22,14793,"<p>I am attempting to debug a <code>keras</code> model that I have built.  It seems that my gradients are exploding, or there is a division by 0 or some such.  It would be convenient to be able to inspect the various gradients as they back-propagate through the network.  Something like the following would be ideal:</p>

<pre><code>model.evaluate(np.array([[1,2]]), np.array([[1]])) #gives the loss
model.evaluate_gradient(np.array([[1,2]]), np.array([[1]]), layer=2) #gives the doutput/dloss at layer 2 for the given input
model.evaluate_weight_gradient(np.array([[1,2]]), np.array([[1]]), layer=2) #gives the dweight/dloss at layer 2 for the given input
</code></pre>
",2886575.0,,,,,2018-12-15 11:56:23,How to obtain the gradients in keras?,<python><keras>,1,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51140950
50720670,1,50721621,,2018-06-06 12:40:46,,22,13856,"<p>In Keras you can specify a dropout layer like this:</p>



<pre class=""lang-python prettyprint-override""><code>model.add(Dropout(0.5))
</code></pre>

<p>But with a GRU cell you can specify the dropout as a parameter in the constructor:</p>

<pre class=""lang-python prettyprint-override""><code>model.add(GRU(units=512,
        return_sequences=True,
        dropout=0.5,
        input_shape=(None, features_size,)))
</code></pre>

<p>What's the difference? Is one preferable to the other?</p>

<p>In <a href=""https://keras.io/getting-started/sequential-model-guide/"" rel=""noreferrer"">Keras' documentation</a>  it adds it as a separate dropout layer (see ""Sequence classification with LSTM"")</p>
",1408483.0,,8563649.0,,2018-06-08 07:16:46,2018-06-08 07:16:46,Using Dropout with Keras and LSTM/GRU cell,<keras><lstm><dropout>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50720670
54589669,1,54595455,,2019-02-08 09:46:19,,22,63691,"<p>I am getting a</p>

<pre><code>Classification metrics can't handle a mix of multilabel-indicator and multiclass targets
</code></pre>

<p>error when I try to use confusion matrix.</p>

<p>I am doing my first deep learning project. I am new to it. I am using the mnist dataset provided by keras. I have trained and tested my model successfully. </p>

<p>However, when I try to use the scikit learn confusion matrix I get the error stated above. I have searched for an answer and while there are answers on this error, none of them worked for me. From what I found online it probably has something to do with the loss function (I use the <code>categorical_crossentropy</code> in my code). I tried changing it to <code>sparse_categorical_crossentropy</code> but that just gave me the </p>

<pre><code>Error when checking target: expected dense_2 to have shape (1,) but got array with shape (10,)
</code></pre>

<p>when I run the <code>fit()</code> function on the model. </p>

<p>This is the code. (I have left out the imports for the sake of brevity)</p>

<pre><code>model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))
model.add(Dense(10, activation='softmax')) 

model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255

test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

model.fit(train_images, train_labels, epochs=10, batch_size=128)

rounded_predictions = model.predict_classes(test_images, batch_size=128, verbose=0)

cm = confusion_matrix(test_labels, rounded_predictions)
</code></pre>

<p>How can i fix this? </p>
",9033081.0,,4685471.0,,2020-04-30 01:29:18,2023-05-18 18:16:50,"confusion matrix error ""Classification metrics can't handle a mix of multilabel-indicator and multiclass targets""",<python><machine-learning><keras><scikit-learn><confusion-matrix>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54589669
55235230,1,56262468,,2019-03-19 06:58:16,,22,15878,"<p>I get this warning most of the time when i define a model using Keras. It seems to somehow come from tensorflow though:</p>

<pre><code>WARNING:tensorflow:From C:\Users\lenik\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
</code></pre>

<p>Is this warning something to worry about?
If yes, how do i solve this problem?</p>
",8104036.0,,,,,2019-05-22 17:56:08,tensorflow: Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`,<python><tensorflow><keras><deep-learning>,2,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55235230
41588383,1,41597238,,2017-01-11 10:29:30,,22,31271,"<p>I'm using Keras with Tensorflow backend on a cluster (creating neural networks). How can I run it in a multi-threaded way on the cluster (on several cores) or is this done automatically by Keras? For example in Java one can create several threads, each thread running on a core.</p>

<p>If possible, how many cores should be used?</p>
",3591044.0,,3591044.0,,2017-01-11 10:59:31,2020-10-25 09:45:28,How to run Keras on multiple cores?,<python><multithreading><python-3.x><tensorflow><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41588383
54416322,1,54416792,,2019-01-29 08:01:35,,22,52874,"<p>I'm new with Keras and I'm trying to implement a Sequence to Sequence LSTM. 
Particularly, I have a dataset with 9 features and I want to predict 5 continuous values. </p>

<p>I split the training and the test set and their shape are respectively:</p>

<pre><code>X TRAIN (59010, 9)

X TEST (25291, 9)

Y TRAIN (59010, 5)

Y TEST (25291, 5)
</code></pre>

<p>The LSTM is extremely simple at the moment:</p>

<pre><code>model = Sequential()
model.add(LSTM(100, input_shape=(9,), return_sequences=True))
model.compile(loss=""mean_absolute_error"", optimizer=""adam"", metrics= ['accuracy'])

history = model.fit(X_train,y_train,epochs=100, validation_data=(X_test,y_test))
</code></pre>

<p>But I have the following error:</p>

<blockquote>
  <p>ValueError: Input 0 is incompatible with layer lstm_1: expected
  ndim=3, found ndim=2</p>
</blockquote>

<p>Can anyone help me?</p>
",10242641.0,,5884955.0,,2019-01-29 08:31:26,2020-09-01 08:34:11,"expected ndim=3, found ndim=2",<python><tensorflow><keras><lstm>,1,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54416322
47137061,1,51282062,,2017-11-06 12:28:10,,22,13208,"<p>I'm using <code>tf.estimator</code> in TensorFlow 1.4 and <code>tf.estimator.train_and_evaluate</code> is great but I need early stopping. What's the prefered way of adding that?</p>

<p>I assume there is some <code>tf.train.SessionRunHook</code> somewhere for this. I saw that there was an old contrib package with a <code>ValidationMonitor</code> that seemed to have early stopping, but it doesn't seem to be around anymore in 1.4. Or will the preferred way in the future be to rely on <code>tf.keras</code> (with which early stopping is really easy) instead of <code>tf.estimator/tf.layers/tf.data</code>, perhaps?</p>
",7287271.0,,712995.0,,2018-06-16 06:54:14,2019-09-03 16:33:24,"Early stopping with tf.estimator, how?",<python><tensorflow><neural-network><keras><tensorflow-estimator>,4,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/47137061
61083004,1,61083136,,2020-04-07 14:57:47,,22,16275,"<p>I am trying to make a fully connected model using tensorflow.keras, here is my code</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Flatten

def load_model(input_shape):
  input = Input(shape = input_shape)
  dense_shape = input_shape[0]
  x = Flatten()(input)
  x = Dense(dense_shape, activation='relu')(x)
  x = Dense(dense_shape, activation='relu')(x)
  x = Dense(dense_shape, activation='relu')(x)
  x = Dense(dense_shape, activation='relu')(x)
  x = Dense(dense_shape, activation='relu')(x)
  output = Dense(10, activation='softmax')

  model  = Model(input , output)
  model.summary()
  return model
</code></pre>
<p>but when I call the model</p>
<pre class=""lang-py prettyprint-override""><code>model = load_model((120,))
</code></pre>
<p>I have this error</p>
<pre><code>'Dense' object has no attribute 'op'
</code></pre>
<p>How can I fix this?</p>
",7257452.0,,4685471.0,,2021-04-05 00:26:09,2021-04-05 00:26:09,'Dense' object has no attribute 'op',<python><tensorflow><machine-learning><keras><deep-learning>,1,1,,2021-04-05 12:25:46,,CC BY-SA 4.0,https://stackoverflow.com/q/61083004
44861149,1,44890471,,2017-07-01 12:52:23,,22,11166,"<p>For the keras functions <code>fit()</code> and <code>fit_generator()</code> there is the possibility of tensorboard visualization by passing a <code>keras.callbacks.TensorBoard</code> object to the functions. For the <code>train_on_batch()</code> function there obviously are no callback available. Are there other options in keras to create a Tensorboard in this case?</p>
",4391129.0,,,,,2021-05-03 13:56:46,Keras: use Tensorboard with train_on_batch(),<keras><tensorboard>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44861149
46572674,1,46574294,,2017-10-04 19:25:20,,22,21425,"<p>When creating a Sequential model in Keras, I understand you provide the input shape in the first layer. Does this input shape then make an <em>implicit</em> input layer?</p>

<p>For example, the model below explicitly specifies 2 Dense layers, but is this actually a model with 3 layers consisting of one input layer implied by the input shape, one hidden dense layer with 32 neurons, and then one output layer with 10 possible outputs?</p>



<pre class=""lang-py prettyprint-override""><code>model = Sequential([
    Dense(32, input_shape=(784,)),
    Activation('relu'),
    Dense(10),
    Activation('softmax'),
])
</code></pre>
",8328970.0,,4685471.0,,2019-10-11 22:56:19,2020-05-07 05:17:27,Keras Sequential model input layer,<python><machine-learning><keras><neural-network><deep-learning>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46572674
46127625,1,46132439,,2017-09-09 05:59:16,,22,33714,"<p>I load a <code>Keras</code> model from <strong>.json</strong> and <strong>.hdf5</strong> files. When I call <code>model.evaluate()</code>, it returns an error:</p>

<blockquote>
  <p>You must compile a model before training/testing. Use `model.compile(optimizer, loss)</p>
</blockquote>

<p>Why do I need to compile to run <code>evaluate()</code>? </p>

<p>To add, the model can be passed <code>predict()</code> with no problem. </p>
",1058511.0,,9215780.0,,2021-07-18 19:30:38,2022-05-16 09:51:11,Need To Compile Keras Model Before `model.evaluate()`,<tensorflow><keras>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46127625
53503389,1,53512269,,2018-11-27 15:52:34,,22,47556,"<p>I am new to Keras and I am building a model. I want to freeze the weights of the last few layers of the model while training the previous layers. I tried to set the trainable property of the lateral model to be False, but it dosen't seem to work. Here is the code and the model summary:</p>

<pre><code>opt = optimizers.Adam(1e-3)
domain_layers = self._build_domain_regressor()
domain_layers.trainble = False
feature_extrator = self._build_common()
img_inputs = Input(shape=(160, 160, 3))
conv_out = feature_extrator(img_inputs)
domain_label = domain_layers(conv_out)
self.domain_regressor = Model(img_inputs, domain_label)
self.domain_regressor.compile(optimizer = opt, loss='binary_crossentropy', metrics=['accuracy'])
self.domain_regressor.summary()
</code></pre>

<p>The model summary: <a href=""https://i.stack.imgur.com/nWR8q.png"" rel=""noreferrer"">model summary</a>.</p>

<p>As you can see, <code>model_1</code> is trainable. But according to the code, it is set to be non-trainable.</p>
",10712335.0,,3924118.0,,2019-10-23 15:46:57,2019-11-08 18:13:59,How to set parameters in keras to be non-trainable?,<python><keras><deep-learning>,4,5,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53503389
62280161,1,62326857,,2020-06-09 10:12:33,,22,22327,"<p>I am trying to save a Keras model in a H5 file. The Keras model has a <strong>custom layer</strong>.
When I try to <strong>restore the model</strong>, I get the following error:</p>

<pre class=""lang-py prettyprint-override""><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-5-0fbff9b56a9d&gt; in &lt;module&gt;()
      1 model.save('model.h5')
      2 del model
----&gt; 3 model = tf.keras.models.load_model('model.h5')

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
    319   cls = get_registered_object(class_name, custom_objects, module_objects)
    320   if cls is None:
--&gt; 321     raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
    322 
    323   cls_config = config['config']

ValueError: Unknown layer: CustomLayer
</code></pre>

<p>Could you please tell me how I am supposed to save and load weights of all the custom Keras layers too? (Also, there was no warning when saving, will it be possible to load models from H5 files which I have already saved but can't load back now?)</p>

<p>Here is the minimal working code sample (MCVE) for this error, as well as the full expanded message: <a href=""https://colab.research.google.com/drive/18r5TDlVZR8SC1WBOXuYKk9f17edZN6y6?usp=sharing"" rel=""noreferrer"">Google Colab Notebook</a></p>

<p>Just for completeness, this is the code I used to make my custom layer.
<code>get_config</code> and <code>from_config</code> are both working fine.</p>

<pre class=""lang-py prettyprint-override""><code>class CustomLayer(tf.keras.layers.Layer):
    def __init__(self, k, name=None):
        super(CustomLayer, self).__init__(name=name)
        self.k = k

    def get_config(self):
        return {'k': self.k}

    def call(self, input):
        return tf.multiply(input, 2)

model = tf.keras.models.Sequential([
    tf.keras.Input(name='input_layer', shape=(10,)),
    CustomLayer(10, name='custom_layer'),
    tf.keras.layers.Dense(1, activation='sigmoid', name='output_layer')
])
model.save('model.h5')
model = tf.keras.models.load_model('model.h5')
</code></pre>
",4182274.0,,4182274.0,,2020-06-09 12:00:38,2021-10-14 12:03:46,Saving Keras models with Custom Layers,<python><tensorflow><keras><save>,2,6,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/62280161
56860180,1,56879016,,2019-07-02 21:21:35,,21,33581,"<p>I use the Tensorflow v 1.14.0. I work on Windows 10. And here is how relevant <strong>environment variables</strong> look in the <code>PATH</code>:</p>

<pre><code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp
C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common
C:\Users\sinthes\AppData\Local\Programs\Python\Python37
C:\Users\sinthes\AppData\Local\Programs\Python\Python37\Scripts
C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\cuda\bin
</code></pre>

<p>Maybe also worth to mention, just in case it might be relevant.. I use Sublime Text 3 for development and I do not use Anaconda. I find it a bit cumbersome to make updates on tensorflow in the conda environment so I just use Sublime Text right now. (I was using Anaconda (Spyder) previously but I uninstalled it from my computer.) </p>

<p>Things seem to work fine except with some occasional strange warnings. But one consistent warning I get is the following whenever I run the <code>fit</code> function.</p>

<pre><code>E tensorflow/core/platform/default/device_tracer.cc:68] CUPTI error: CUPTI could not be loaded or symbol could not be found.
</code></pre>

<p>And here is how I call the fit function:</p>

<pre><code>history = model.fit(x=train_x,
                    y=train_y,
                    batch_size=BATCH_SIZE,
                    epochs=110,
                    verbose=2,
                    callbacks=[tensorboard, checkpoint, reduce_lr_on_plateau],
                    validation_data=(dev_x, dev_y),
                    shuffle=True,
                    class_weight=class_weight,
                    steps_per_epoch=None,
                    validation_steps=None)
</code></pre>

<p>I just wonder why I see the <strong><code>CUPTI Error</code></strong> message during the run time? It is only printed out once. Is that something that I need to fix or is it something that can be ignored? This message does not tell anything concrete to me to be able to take any action.</p>
",9328846.0,,681865.0,,2019-07-02 21:41:34,2021-07-04 17:37:40,Tensorflow CUDA - CUPTI error: CUPTI could not be loaded or symbol could not be found,<python><tensorflow><keras><nvidia>,8,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/56860180
53972814,1,53974172,,2018-12-29 19:41:39,,21,13610,"<p>I am facing an issue when trying to use CuDNNLSTM instead of keras.layers.LSTM.</p>
<p>This is the error I am getting:</p>
<blockquote>
<p>Failed to call ThenRnnForward with model config: [rnn_mode,
rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers,
input_size, num_units, dir_count, seq_length, batch_size]: [1, 300,
512, 1, 5521, 128]     [[{{node bidirectional_1/CudnnRNN_1}} =
CudnnRNN[T=DT_FLOAT, _class=[&quot;loc:@train...NNBackprop&quot;],
direction=&quot;unidirectional&quot;, dropout=0, input_mode=&quot;linear_input&quot;,
is_training=true, rnn_mode=&quot;lstm&quot;, seed=87654321, seed2=0,
_device=&quot;/job:localhost/replica:0/task:0/device:GPU:0&quot;](bidirectional_1/transpose_1,
bidirectional_1/ExpandDims_1, bidirectional_1/ExpandDims_1,
bidirectional_1/concat_1)]]    [[{{node loss/mul/_75}} =
_Recvclient_terminated=false, recv_device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;,
send_device=&quot;/job:localhost/replica:0/task:0/device:GPU:0&quot;,
send_device_incarnation=1, tensor_name=&quot;edge_1209_loss/mul&quot;,
tensor_type=DT_FLOAT,
_device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;]]</p>
</blockquote>
<p>Also, I got this error in one of the runs:</p>
<blockquote>
<p>InternalError: GPU sync failed</p>
</blockquote>
<p>And the kernel kept dying after each run.</p>
<p>I only started getting this error when I tried to run it on a VM instance on google cloud with CuDNNLSTM.</p>
<p>my code is:</p>
<pre><code>MAX_LEN = max(len(article) for article in X_train_tokens)
EMBEDDING_DIM=300
vocab_size = len(word_to_id)
classes = 2 
# Text input
text_input = Input(shape=(MAX_LEN,))
embedding = Embedding(vocab_size, EMBEDDING_DIM, input_length=MAX_LEN)(text_input)
x = Bidirectional(LSTM(512, return_sequences=False))(embedding)
pred = Dense(2, activation='softmax')(x)
model = Model(inputs=[text_input],outputs=pred)
model.compile(loss='categorical_crossentropy', optimizer='RMSprop',     metrics=['accuracy'])
batch_size = 128
generator = text_training_generator(batch_size)
steps = len(X_train)/ batch_size 

model.fit_generator(generator, steps_per_epoch=steps, verbose=True, epochs=10)
</code></pre>
<p>The model summary:</p>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 5521)              0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 5521, 300)         8099100   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 1024)              3330048   
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 2050      
=================================================================
Total params: 11,431,198
Trainable params: 11,431,198
Non-trainable params: 0
_________________________________________________________________
</code></pre>
",3084192.0,,2650249.0,,2021-02-12 18:08:18,2023-01-13 01:52:35,CuDNNLSTM: Failed to call ThenRnnForward,<tensorflow><keras><google-cloud-platform><gpu><lstm>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53972814
49840968,1,49841111,,2018-04-15 10:38:39,,21,55001,"<p>I am building a prediction model for the sequence data using conv1d layer provided by Keras. This is how I did</p>

<pre><code>model= Sequential()
model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(None,64,1)))
model.add(Conv1D(80,10, strides=1, activation='relu',padding='causal'))
model.add(Dropout(0.25))
model.add(Conv1D(100,5, strides=1, activation='relu',padding='causal'))
model.add(MaxPooling1D(1))
model.add(Dropout(0.25))
model.add(Dense(300,activation='relu'))
model.add(Dense(1,activation='relu'))
print(model.summary())
</code></pre>

<p>However, the debugging information has</p>

<pre><code>Traceback (most recent call last):
File ""processing_2a_1.py"", line 96, in &lt;module&gt;
model.add(Conv1D(60,32, strides=1, activation='relu',padding='causal',input_shape=(None,64,1)))
File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 442, in add
File ""build/bdist.linux-x86_64/egg/keras/engine/topology.py"", line 558, in __call__
File ""build/bdist.linux-x86_64/egg/keras/engine/topology.py"", line 457, in assert_input_compatibility
ValueError: Input 0 is incompatible with layer conv1d_1: expected ndim=3, found ndim=4
</code></pre>

<p>The training data and validation data shape are as follows</p>

<pre><code>('X_train shape ', (1496000, 64, 1))
('Y_train shape ', (1496000, 1))
('X_val shape ', (374000, 64, 1))
('Y_val shape ', (374000, 1))
</code></pre>

<p>I think the <code>input_shape</code> in the first layer was not setup right. How to set it up?</p>

<hr>

<p><strong>Update</strong>: After using <code>input_shape=(64,1)</code>, I got the following error message, even though the model summary runs through</p>

<pre><code>________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv1d_1 (Conv1D)            (None, 64, 60)            1980
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 64, 80)            48080
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 80)            0
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 64, 100)           40100
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 64, 100)           0
_________________________________________________________________
dropout_2 (Dropout)          (None, 64, 100)           0
_________________________________________________________________
dense_1 (Dense)              (None, 64, 300)           30300
_________________________________________________________________
dense_2 (Dense)              (None, 64, 1)             301
=================================================================
Total params: 120,761
Trainable params: 120,761
Non-trainable params: 0
_________________________________________________________________
None
Traceback (most recent call last):
  File ""processing_2a_1.py"", line 125, in &lt;module&gt;
    history=model.fit(X_train, Y_train, batch_size=batch_size, validation_data=(X_val,Y_val), epochs=nr_of_epochs,verbose=2)
  File ""build/bdist.linux-x86_64/egg/keras/models.py"", line 871, in fit
  File ""build/bdist.linux-x86_64/egg/keras/engine/training.py"", line 1524, in fit
  File ""build/bdist.linux-x86_64/egg/keras/engine/training.py"", line 1382, in _standardize_user_data
  File ""build/bdist.linux-x86_64/egg/keras/engine/training.py"", line 132, in _standardize_input_data
ValueError: Error when checking target: expected dense_2 to have 3 dimensions, but got array with shape (1496000, 1)
</code></pre>
",288609.0,,712995.0,,2018-04-15 16:52:30,2021-06-08 13:38:42,"ValueError: Input 0 is incompatible with layer conv1d_1: expected ndim=3, found ndim=4",<machine-learning><neural-network><deep-learning><keras><conv-neural-network>,3,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49840968
44131295,1,44131602,,2017-05-23 09:46:15,,21,47979,"<p>I recently got the deep learning docker from <a href=""https://github.com/floydhub/dl-docker"" rel=""noreferrer"">https://github.com/floydhub/dl-docker</a> running and while trying out the tutorials, received an error when importing the keras layers module. </p>

<pre><code>from __future__ import print_function
import keras
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D

---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-13-3a12c6f32fcf&gt; in &lt;module&gt;()
      5 from keras.models import Sequential
      6 from keras.layers import Dense, Dropout, Activation, Flatten
----&gt; 7 from keras.layers import Conv2D, MaxPooling2D

ImportError: cannot import name Conv2D
</code></pre>

<p>I am running with ubuntu 14.04, python version 2.7.6 on the ipython notebook and the following versions of the deep learning libraries on docker.</p>

<pre><code>ARG THEANO_VERSION=rel-0.8.2
ARG TENSORFLOW_VERSION=0.12.1 
ARG TENSORFLOW_ARCH=cpu
ARG KERAS_VERSION=1.2.0
ARG LASAGNE_VERSION=v0.1
ARG TORCH_VERSION=latest
ARG CAFFE_VERSION=master
</code></pre>

<p>Im not sure if the problem lies with the version because it seems that there no related issues on the github thread.</p>
",6467567.0,,5359882.0,,2018-03-13 07:55:42,2020-04-01 05:55:19,keras - cannot import name Conv2D,<python><tensorflow><neural-network><keras><theano>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44131295
41378461,1,41386444,,2016-12-29 11:07:28,,21,17801,"<p>I want to get pretrained VGG16 model in Keras, remove its output layer, and then put a new output layer with the number of classes suited for my problem, and then to fit it on new data. For this reason, I am trying to use the model here: <a href=""https://keras.io/applications/#vgg16"" rel=""noreferrer"">https://keras.io/applications/#vgg16</a>, but since it is not Sequential, I cannot just <code>model.pop()</code>. Popping from layers and adding it also does not work, because in the predictions it still expects the old shape. How would I do that? Is there a way to convert this type of model to <code>Sequential</code>?</p>
",6636290.0,,249341.0,,2017-06-09 12:26:45,2018-07-05 10:07:28,How to use models from keras.applications for transfer learnig?,<python><deep-learning><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41378461
46204569,1,46206061,,2017-09-13 18:31:44,,21,23937,"<p>I am trying to perform the usual classification on the MNIST database but with randomly cropped digits. 
Images are cropped the following way : removed randomly first/last and/or row/column.</p>

<p>I would like to use a Convolutional Neural Network using Keras (and Tensorflow backend) to perform convolution and then the usual classification.</p>

<p>Inputs are of variable size and i can't manage to get it to work.</p>

<p>Here is how I cropped digits</p>

<pre><code>import numpy as np
from keras.utils import to_categorical
from sklearn.datasets import load_digits

digits = load_digits()

X = digits.images
X = np.expand_dims(X, axis=3)

X_crop = list()
for index in range(len(X)):
    X_crop.append(X[index, np.random.randint(0,2):np.random.randint(7,9), np.random.randint(0,2):np.random.randint(7,9), :])
X_crop = np.array(X_crop)

y = to_categorical(digits.target)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_crop, y, train_size=0.8, test_size=0.2)
</code></pre>

<p>And here is the architecture of the model I want to use</p>

<pre><code>from keras.layers import Dense, Dropout
from keras.layers.convolutional import Conv2D
from keras.models import Sequential

model = Sequential()

model.add(Conv2D(filters=10, 
                 kernel_size=(3,3), 
                 input_shape=(None, None, 1), 
                 data_format='channels_last'))

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(10, activation='softmax'))


model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

model.summary()

model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))
</code></pre>

<ol>
<li><p>Does someone have an idea on how to handle variable sized input in my neural network? </p></li>
<li><p>And how to perform classification?</p></li>
</ol>
",8036988.0,,5974433.0,,2017-10-29 19:37:38,2017-10-29 19:37:38,How to handle variable sized input in CNN with Keras?,<python><machine-learning><neural-network><deep-learning><keras>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46204569
54689096,1,54689291,,2019-02-14 11:12:25,,21,69351,"<p>I installed Tensorflow for GPU using: <code>pip install tensorflow-gpu</code> 
But when I tried the same for <strong>Keras</strong> <code>pip install keras-gpu</code>, it pulled me an error: <em>could not find the version that satisfies the requirements</em>.</p>
",9222818.0,,3924118.0,,2019-10-15 14:13:50,2022-02-11 00:03:53,How to install Keras with gpu support?,<tensorflow><keras><pip><anaconda><gpu>,4,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54689096
62948332,1,62949137,,2020-07-17 06:28:31,,21,10024,"<p>I am developing a Bi-LSTM model and want to add a attention layer to it. But I am not getting how to add it.</p>
<p>My current code for the model is</p>
<pre><code>model = Sequential()
model.add(Embedding(max_words, 1152, input_length=max_len, weights=[embeddings]))
model.add(BatchNormalization())
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Bidirectional(LSTM(32)))
model.add(BatchNormalization())
model.add(Activation('tanh'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))
model.summary()
</code></pre>
<p>And the model summary is</p>
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 1152, 1152)        278396928 
_________________________________________________________________
batch_normalization_1 (Batch (None, 1152, 1152)        4608      
_________________________________________________________________
activation_1 (Activation)    (None, 1152, 1152)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 1152, 1152)        0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, 64)                303360    
_________________________________________________________________
batch_normalization_2 (Batch (None, 64)                256       
_________________________________________________________________
activation_2 (Activation)    (None, 64)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 65        
=================================================================
Total params: 278,705,217
Trainable params: 278,702,785
Non-trainable params: 2,432
</code></pre>
",10097229.0,,10375049.0,,2020-10-06 16:44:40,2021-06-24 18:02:36,How to add attention layer to a Bi-LSTM,<python-3.x><tensorflow><machine-learning><keras><nlp>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/62948332
49135929,1,49137346,,2018-03-06 16:43:16,,21,19145,"<p>I've implemented a basic MLP in Keras with tensorflow and I'm trying to solve a binary classification problem. For binary classification, it seems that sigmoid is the recommended activation function and I'm not quite understanding why, and how Keras deals with this.</p>

<p>I understand the sigmoid function will produce values in a range between 0 and 1. My understanding is that for classification problems using sigmoid, there will be a certain threshold used to determine the class of an input (typically 0.5). In Keras, I'm not seeing any way to specify this threshold, so I assume it's done implicitly in the back-end? If this is the case, how is Keras distinguishing between the use of sigmoid in a binary classification problem, or a regression problem? With binary classification, we want a binary value, but with regression a nominal value is needed. All I can see that could be indicating this is the loss function. Is that informing Keras on how to handle the data?</p>

<p>Additionally, assuming Keras is implicitly applying a threshold, why does it output nominal values when I use my model to predict on new data?</p>

<p>For example:</p>

<pre><code>y_pred = model.predict(x_test)
print(y_pred)
</code></pre>

<p>gives:</p>

<blockquote>
  <p>[7.4706882e-02] [8.3481872e-01] [2.9314638e-04] [5.2297767e-03]
  [2.1608515e-01] ... [4.4894204e-03] [5.1120580e-05] [7.0263929e-04]</p>
</blockquote>

<p>I can apply a threshold myself when predicting to get a binary output, however surely Keras must be doing that anyway in order to correctly classify? Perhaps Keras is applying a threshold when training the model, but when I use it to predict new values, the threshold isn't used as the loss function isn't used in predicting? Or is not applying a threshold at all, and the nominal values outputted happen to be working well with my model? I've checked this is happening on the Keras example for binary classification, so I don't think I've made any errors with my code, especially as it's predicting accurately.</p>

<p>If anyone could explain how this is working, I would greatly appreciate it.</p>

<p>Here's my model as a point of reference:</p>

<pre><code>model = Sequential()
model.add(Dense(124, activation='relu', input_shape = (2,)))
model.add(Dropout(0.5))
model.add(Dense(124, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(loss='binary_crossentropy',
              optimizer=SGD(lr = 0.1, momentum = 0.003),
              metrics=['acc'])

history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
</code></pre>
",7470093.0,,,,,2022-05-22 20:21:42,Keras Binary Classification - Sigmoid activation function,<python><tensorflow><neural-network><keras><sigmoid>,2,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49135929
42184863,1,44771313,,2017-02-12 06:33:52,,21,16320,"<p><strong>What is an example of how to use a TensorFlow TFRecord with a Keras Model and tf.session.run() while keeping the dataset in tensors w/ queue runners?</strong></p>

<p>Below is a snippet that works but it needs the following improvements:</p>

<ul>
<li>Use the <a href=""https://keras.io/models/model/"" rel=""nofollow noreferrer"">Model API</a></li>
<li>specify an Input()</li>
<li>Load a dataset from a TFRecord</li>
<li>Run through a dataset in parallel (such as with a queuerunner)</li>
</ul>

<p>Here is the snippet, there are several TODO lines indicating what is needed:</p>



<pre class=""lang-python prettyprint-override""><code>from keras.models import Model
import tensorflow as tf
from keras import backend as K
from keras.layers import Dense, Input
from keras.objectives import categorical_crossentropy
from tensorflow.examples.tutorials.mnist import input_data

sess = tf.Session()
K.set_session(sess)

# Can this be done more efficiently than placeholders w/ TFRecords?
img = tf.placeholder(tf.float32, shape=(None, 784))
labels = tf.placeholder(tf.float32, shape=(None, 10))

# TODO: Use Input() 
x = Dense(128, activation='relu')(img)
x = Dense(128, activation='relu')(x)
preds = Dense(10, activation='softmax')(x)
# TODO: Construct model = Model(input=inputs, output=preds)

loss = tf.reduce_mean(categorical_crossentropy(labels, preds))

# TODO: handle TFRecord data, is it the same?
mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

sess.run(tf.global_variables_initializer())

# TODO remove default, add queuerunner
with sess.as_default():
    for i in range(1000):
        batch = mnist_data.train.next_batch(50)
        train_step.run(feed_dict={img: batch[0],
                                  labels: batch[1]})
    print(loss.eval(feed_dict={img:    mnist_data.test.images, 
                               labels: mnist_data.test.labels}))
</code></pre>

<p><strong>Why is this question relevant?</strong></p>

<ul>
<li>For high performance training without going back to python

<ul>
<li>no <a href=""https://stackoverflow.com/questions/36026892/how-can-i-convert-tfrecords-into-numpy-arrays"">TFRecord to numpy</a> to tensor conversions</li>
</ul></li>
<li><a href=""https://github.com/fchollet/keras/issues/5358"" rel=""nofollow noreferrer"">Keras will soon be part of tensorflow</a></li>
<li>Demonstrate how Keras Model() classes can accept tensors for input data correctly.</li>
</ul>

<p><strong>Here is some starter information for a semantic segmentation problem example:</strong></p>

<ul>
<li>example unet Keras model <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/models/unet.py"" rel=""nofollow noreferrer"">unet.py</a>, happens to be for semantic segmentation.</li>
<li><a href=""https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"" rel=""nofollow noreferrer"">Keras + Tensorflow Blog Post</a></li>
<li>An <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/recipes/pascal_voc/FCNs/densenet_fcn.py#L78"" rel=""nofollow noreferrer"">attempt at running the unet model a tf session with TFRecords and a Keras model</a> (not working)</li>
<li>Code to create the TFRecords: <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/utils/tf_records.py"" rel=""nofollow noreferrer"">tf_records.py</a></li>
<li>An attempt at running the unet model a tf session with TFRecords and a Keras model is in <a href=""https://github.com/ahundt/tf-image-segmentation/blob/cd7df53e6f59ef9e3dff1ed0119e12922ae98a3a/tf_image_segmentation/recipes/pascal_voc/FCNs/densenet_fcn.py#L78"" rel=""nofollow noreferrer"">densenet_fcn.py</a> (not working)</li>
</ul>
",99379.0,,10133797.0,,2019-07-11 07:25:32,2019-07-11 07:25:32,How do you make TensorFlow + Keras fast with a TFRecord dataset?,<machine-learning><tensorflow><deep-learning><keras><keras-layer>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42184863
57985406,1,57985905,,2019-09-18 05:05:16,,21,42056,"<p>I'm using Oracle Linux 7.7, and I installed python3.6 using yum (epel repos). Then I install tensorflow 1.5(since if it goes newer ver I got core dumped) and keras. If I'm importing tensorflow, I got nothing.
But when I import keras, I got </p>

<pre><code>ImportError: cannot import name 'tf_utils'
</code></pre>

<p>Here's the full output:</p>

<pre><code>$ python
Python 3.6.8 (default, Aug  7 2019, 08:02:28) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-39.0.1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import tensorflow
&gt;&gt;&gt; import keras
Using TensorFlow backend.
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/reyhan/project/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/__init__.py"", line 3, in &lt;module&gt;
from . import utils
  File ""/home/reyhan/project/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/utils/__init__.py"", line 6, in &lt;module&gt;
from . import conv_utils
  File ""/home/reyhan/project/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/utils/conv_utils.py"", line 9, in &lt;module&gt;
from .. import backend as K
  File ""/home/reyhan/project/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/backend/__init__.py"", line 1, in &lt;module&gt;
from .load_backend import epsilon
  File ""/home/reyhan/project/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/backend/load_backend.py"", line 90, in &lt;module&gt;
from .tensorflow_backend import *
  File ""/home/reyhan/project/.virtualenvs/keras_tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 13, in &lt;module&gt;
from tensorflow.python.keras.utils import tf_utils
ImportError: cannot import name 'tf_utils'
</code></pre>

<p>I was using python 3.6 by building it from source before and keras worked fine but since I can't install tkinter for pyplot I uninstall it and using the one from yum instead.</p>
",11332292.0,,,,,2020-06-16 08:40:11,Cannot import name 'tf_utils' when using importing keras,<python><tensorflow><keras><oraclelinux>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/57985406
36992855,1,37009670,,2016-05-02 22:51:32,,21,15025,"<p>I'm having trouble with preparing input data for RNN on Keras.</p>

<p>Currently, my training data dimension is: <code>(6752, 600, 13)</code></p>

<ul>
<li>6752: number of training data </li>
<li>600: number of time steps </li>
<li>13: size of feature vectors (the vector is in float)</li>
</ul>

<p><code>X_train</code> and <code>Y_train</code> are both in this dimension.</p>

<p>I want to prepare this data to be fed into <code>SimpleRNN</code> on Keras.
Suppose that we're going through time steps, from step #0 to step #599.
Let's say I want to use <code>input_length = 5</code>, which means that I want to use recent 5 inputs. (e.g. step #10, #11,#12,#13,#14 @ step #14).</p>

<p>How should I reshape <code>X_train</code>?</p>

<p>should it be <code>(6752, 5, 600, 13)</code> or should it be <code>(6752, 600, 5, 13)</code>?</p>

<p>And what shape should <code>Y_train</code> be in?</p>

<p>Should it be <code>(6752, 600, 13)</code> or <code>(6752, 1, 600, 13)</code> or <code>(6752, 600, 1, 13)</code>?</p>
",5513231.0,,10375049.0,,2020-08-28 11:34:33,2021-03-01 14:51:48,Keras : How should I prepare input data for RNN?,<tensorflow><keras><deep-learning><lstm><recurrent-neural-network>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/36992855
63279168,1,63300341,,2020-08-06 07:55:53,,21,60295,"<p>I keep on getting this error related to input shape. Any help would be highly appreciated. Thanks!</p>
<pre><code>import tensorflow as tf

(xtrain, ytrain), (xtest, ytest) = tf.keras.datasets.mnist.load_data()

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
    ])

model.compile(loss='categorical_crossentropy', 
              optimizer='adam',
              metrics='accuracy')

history = model.fit(xtrain, ytrain,
                    validation_data=(xtest, ytest),
                    epochs=10, batch_size=8)
</code></pre>
<blockquote>
<p>ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [8, 28, 28]</p>
</blockquote>
",11144416.0,,10908375.0,,2021-01-13 14:58:57,2022-03-01 15:29:45,"ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: [8, 28, 28]",<python><tensorflow><keras><deep-learning>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/63279168
40708169,1,41688653,,2016-11-20 19:04:29,,21,38192,"<p>I am trying to build a synthetic model in Keras, and I need to assign values for the weights and biases. Assigning the weights is easy, I am using the instructions provided here: <a href=""https://keras.io/initializations/"" rel=""noreferrer"">https://keras.io/initializations/</a>.
However, I could not find any instructions on how to assign the biases. Any ideas?</p>
",6640916.0,,,,,2018-11-29 19:18:51,How to initialize biases in a Keras model?,<python><neural-network><deep-learning><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/40708169
43876770,1,43877033,,2017-05-09 17:55:53,,21,41470,"<p>I'm trying to perform a sentiment analysis in Python using Keras. To do so, I need to do a word embedding of my texts. The problem appears when I try to fit the data to my model:</p>

<pre><code>model_1 = Sequential()
model_1.add(Embedding(1000,32, input_length = X_train.shape[0]))
model_1.add(Flatten())
model_1.add(Dense(250, activation='relu'))
model_1.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
</code></pre>

<p>The shape of my train data is</p>

<pre><code>(4834,)
</code></pre>

<p>And is a Pandas series object. When I try to fit my model and validate it with some other data I get this error:</p>

<pre><code>model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=64, verbose=2)
</code></pre>

<blockquote>
  <p>ValueError: Error when checking model input: expected
  embedding_1_input to have shape (None, 4834) but got array with shape
  (4834, 1)</p>
</blockquote>

<p>How can I reshape my data to make it suited for Keras? I've been trying with np.reshape but I cannot place None elements with that function.</p>

<p>Thanks in advance</p>
",6588261.0,,,,,2021-02-26 20:15:26,Pandas DataFrame and Keras,<python><pandas><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43876770
42260265,1,42262632,,2017-02-15 21:19:09,,21,18939,"<p>I would like my <code>keras</code> model to resize the input image using OpenCV or similar.</p>
<p>I have seen the use of <code>ImageGenerator</code>, but I would prefer to write my own generator and simply resize the image in the first layer with <code>keras.layers.core.Lambda</code>.</p>
<p>How would I do this?</p>
",1158977.0,,2602877.0,,2022-07-23 15:29:26,2022-07-23 15:29:26,Resizing an input image in a Keras Lambda layer,<python><keras><keras-layer>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/42260265
41327601,1,46004661,,2016-12-26 07:02:29,,21,18012,"<p>I'm learning how to create convolutional neural networks using Keras. I'm trying to get a high accuracy for the MNIST dataset.</p>

<p>Apparently <code>categorical_crossentropy</code> is for more than 2 classes and <code>binary_crossentropy</code> is for 2 classes. Since there are 10 digits, I should be using <code>categorical_crossentropy</code>. However, after training and testing dozens of models, <code>binary_crossentropy</code> consistently outperforms <code>categorical_crossentropy</code> significantly.</p>

<p>On Kaggle, I got 99+% accuracy using <code>binary_crossentropy</code> and 10 epochs. Meanwhile, I can't get above 97% using <code>categorical_crossentropy</code>, even using 30 epochs (which isn't much, but I don't have a GPU, so training takes forever).</p>

<p>Here's what my model looks like now:</p>



<pre class=""lang-python prettyprint-override""><code>model = Sequential()
model.add(Convolution2D(100, 5, 5, border_mode='valid', input_shape=(28, 28, 1), init='glorot_uniform', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Convolution2D(100, 3, 3, init='glorot_uniform', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(100, init='glorot_uniform', activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(100, init='glorot_uniform', activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(10, init='glorot_uniform', activation='softmax'))
model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['accuracy'])
</code></pre>
",599184.0,,4685471.0,,2019-02-11 08:27:50,2019-02-11 08:27:50,Why is binary_crossentropy more accurate than categorical_crossentropy for multiclass classification in Keras?,<machine-learning><keras><neural-network><deep-learning><conv-neural-network>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41327601
37984304,1,43415459,,2016-06-23 06:57:01,,21,11366,"<p>I have a scikit-learn pipline with kerasRegressor in it:</p>

<pre><code>estimators = [
    ('standardize', StandardScaler()),
    ('mlp', KerasRegressor(build_fn=baseline_model, nb_epoch=5, batch_size=1000, verbose=1))
    ]
pipeline = Pipeline(estimators)
</code></pre>

<p>After, training the pipline, I am trying to save to disk using joblib...</p>

<pre><code>joblib.dump(pipeline, filename , compress=9)
</code></pre>

<p>But I am getting an error:</p>

<blockquote>
  <p>RuntimeError: maximum recursion depth exceeded</p>
</blockquote>

<p>How would you save the pipeline to disk?</p>
",314548.0,,,,,2020-09-02 22:05:49,how to save a scikit-learn pipline with keras regressor inside to disk?,<python><machine-learning><scikit-learn><keras><joblib>,2,2,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/37984304
41161021,1,48639586,,2016-12-15 09:47:05,,21,8353,"<p>I would like to do something similar to the Fully Convolutional Networks paper (<a href=""https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf"" rel=""noreferrer"">https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf</a>) using Keras.  I have a network which ends up flattening the feature maps and runs them through several dense layers.  I would like to load the weights from a network like this into one where the dense layers are replaced with equivalent convolutions.</p>

<p>The VGG16 network which comes with Keras could be used as an example, where the 7x7x512 output of the last MaxPooling2D() is flattened and then goes into a Dense(4096) layer.  In this case the Dense(4096) would be replaced with a 7x7x4096 convolution.  </p>

<p>My real network is slightly different, there is a GlobalAveragePooling2D() layer instead of MaxPooling2D() and Flatten().  The output of GlobalAveragePooling2D() is a 2D tensor, and there is no need to additionally flatten it, so all the dense layers including the first would be replaced with 1x1 convolutions. </p>

<p>I've seen this question: <a href=""https://stackoverflow.com/questions/36966392/python-keras-how-to-transform-a-dense-layer-into-a-convolutional-layer"">Python keras how to transform a dense layer into a convolutional layer</a> which seems very similar if not identical.  The trouble is I can't get the suggested solution to work, because (a) I'm using TensorFlow as the backend, so the weights rearrangement/filter ""rotation"" isn't right, and (b) I can't figure out how to load the weights.  Loading the old weights file into the new network with <code>model.load_weights(by_name=True)</code> doesn't work, because the names don't match (and even if they did the dimensions differ).  </p>

<p>What should the rearrangement be when using TensorFlow?</p>

<p>How do I load the weights?  Do I create one of each model, call model.load_weights() on both to load the identical weights and then copy some of the extra weights that need rearrangement?</p>
",1828289.0,,2786884.0,,2018-10-09 06:33:31,2022-02-23 12:02:34,How to convert a dense layer to an equivalent convolutional layer in Keras?,<python><neural-network><keras><conv-neural-network>,2,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41161021
45645276,1,45647715,,2017-08-12 00:02:55,,21,55878,"<p>I got this error message when declaring the input layer in Keras.</p>

<blockquote>
  <p>ValueError: Negative dimension size caused by subtracting 3 from 1 for
  'conv2d_2/convolution' (op: 'Conv2D') with input shapes: [?,1,28,28],
  [3,3,28,32].</p>
</blockquote>

<p>My code is like this</p>

<pre><code>model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1,28,28)))
</code></pre>

<p>Sample application: <a href=""https://github.com/IntellijSys/tensorflow/blob/master/Keras.ipynb"" rel=""noreferrer"">https://github.com/IntellijSys/tensorflow/blob/master/Keras.ipynb</a></p>
",1922589.0,,472495.0,,2018-09-03 19:40:52,2022-11-24 11:12:52,Negative dimension size caused by subtracting 3 from 1 for 'conv2d_2/convolution',<python><tensorflow><neural-network><keras><keras-layer>,6,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/45645276
51923048,1,51923884,,2018-08-20 01:09:10,,21,19699,"<p>I saw two ways of saving the weights of a keras model.</p>

<p>First way;</p>

<pre><code>checkpointer = ModelCheckpoint(filepath=""weights.hdf5"", verbose=1, save_best_only=True)
model.fit(x_train, y_train,
                    nb_epoch=number_of_epoch,
                    batch_size=128,
                    verbose=1,
                    validation_data=(x_test, y_test),
                    callbacks=[reduce_lr, checkpointer],
                    shuffle=True)
</code></pre>

<p>Second way;</p>

<pre><code>model.save_weights(""model_weights.h5"")
</code></pre>

<p>What is the difference between the two ways? Any difference in prediction performance between loading <code>weights.hdf5</code> and <code>model_weights.h5</code>?</p>
",7518091.0,,12130775.0,,2020-02-27 16:06:15,2021-01-07 19:53:22,What is the difference between these two ways of saving keras machine learning model weights?,<python><machine-learning><neural-network><keras>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51923048
50955798,1,50979587,,2018-06-20 19:34:15,,21,18969,"<p>So I have got my keras model to work with a tf.Dataset through the following code:</p>

<pre><code># Initialize batch generators(returns tf.Dataset)
batch_train = build_features.get_train_batches(batch_size=batch_size)

# Create TensorFlow Iterator object
iterator = batch_train.make_one_shot_iterator()
dataset_inputs, dataset_labels = iterator.get_next()

# Create Model
logits = .....(some layers)
keras.models.Model(inputs=dataset_inputs, outputs=logits)

# Train network
model.compile(optimizer=train_opt, loss=model_loss, target_tensors=[dataset_labels])
model.fit(epochs=epochs, steps_per_epoch=num_batches, callbacks=callbacks, verbose=1)
</code></pre>

<p>however when I try to pass <code>validation_data</code> parameter to the model. fit it tells me that I cannot use it with the generator. Is there a way to use validation while using tf.Dataset</p>

<p><strong>for example in tensorflow I could do the following</strong>:</p>

<pre><code># initialize batch generators
batch_train = build_features.get_train_batches(batch_size=batch_size)
batch_valid = build_features.get_valid_batches(batch_size=batch_size)

# create TensorFlow Iterator object
iterator = tf.data.Iterator.from_structure(batch_train.output_types,
                                           batch_train.output_shapes)

# create two initialization ops to switch between the datasets
init_op_train = iterator.make_initializer(batch_train)
init_op_valid = iterator.make_initializer(batch_valid)
</code></pre>

<p>then just use <code>sess.run(init_op_train)</code> and <code>sess.run(init_op_valid)</code> to switch between the datasets</p>

<p>I tried implementing a callback that does just that (switch to validation set, predict and back) but it tells me I can't use model.predict in a callback</p>

<p>can someone help me get validation working with Keras+Tf.Dataset</p>

<h2>edit: incorporate answer into the code</h2>

<p><strong>so FINALLY what worked for me, thanks to the selected answer is:</strong></p>

<pre><code># Initialize batch generators(returns tf.Dataset)
batch_train = # returns tf.Dataset
batch_valid = # returns tf.Dataset

# Create TensorFlow Iterator object and wrap it in a generator
itr_train = make_iterator(batch_train)
itr_valid = make_iterator(batch_train)

# Create Model
logits = # the keras model
keras.models.Model(inputs=dataset_inputs, outputs=logits)

# Train network
model.compile(optimizer=train_opt, loss=model_loss, target_tensors=[dataset_labels])
model.fit_generator(
    generator=itr_train, validation_data=itr_valid, validation_steps=batch_size,
    epochs=epochs, steps_per_epoch=num_batches, callbacks=cbs, verbose=1, workers=0)

def make_iterator(dataset):
    iterator = dataset.make_one_shot_iterator()
    next_val = iterator.get_next()

    with K.get_session().as_default() as sess:
        while True:
            *inputs, labels = sess.run(next_val)
            yield inputs, labels
</code></pre>

<p>This doesn't introduce any <strong>overhead</strong></p>
",6205813.0,,6205813.0,,2018-06-22 15:16:37,2019-04-16 11:04:07,Keras model.fit() with tf.dataset API + validation_data,<python><tensorflow><keras>,2,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50955798
35169491,1,35180313,,2016-02-03 05:54:02,,21,40392,"<p>I am trying to implement a LSTM based speech recognizer. So far I could set up bidirectional LSTM (i think it is working as a bidirectional LSTM) by following the example in Merge layer. Now I want to try it with another bidirectional LSTM layer, which make it a deep bidirectional LSTM. But I am unable to figure out how to connect the output of the previously merged two layers into a second set of LSTM layers. I don't know whether it is possible with Keras. Hope someone can help me with this.</p>

<p>Code for my single layer bidirectional LSTM is as follows</p>

<pre><code>left = Sequential()
left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',
               forget_bias_init='one', return_sequences=True, activation='tanh',
               inner_activation='sigmoid', input_shape=(99, 13)))
right = Sequential()
right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',
               forget_bias_init='one', return_sequences=True, activation='tanh',
               inner_activation='sigmoid', input_shape=(99, 13), go_backwards=True))

model = Sequential()
model.add(Merge([left, right], mode='sum'))

model.add(TimeDistributedDense(nb_classes))
model.add(Activation('softmax'))

sgd = SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd)
print(""Train..."")
model.fit([X_train, X_train], Y_train, batch_size=1, nb_epoch=nb_epoches, validation_data=([X_test, X_test], Y_test), verbose=1, show_accuracy=True)
</code></pre>

<p>Dimensions of my x and y values are as follows.</p>

<pre><code>(100, 'train sequences')
(20, 'test sequences')
('X_train shape:', (100, 99, 13))
('X_test shape:', (20, 99, 13))
('y_train shape:', (100, 99, 11))
('y_test shape:', (20, 99, 11))
</code></pre>
",3609599.0,,,,,2019-03-26 13:56:50,How to implement a deep bidirectional LSTM with Keras?,<deep-learning><keras><lstm>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/35169491
43235531,1,43236878,,2017-04-05 15:26:25,,21,34738,"<p>I am trying to create a CNN to classify data. My Data is X[N_data, N_features]
I want to create a neural net capable of classifying it. My problem is concerning the input shape of a Conv1D for the keras back end. </p>

<p>I want to repeat a filter over.. let say 10 features and then keep the same weights for the next ten features. 
For each data my convolutional layer would create N_features/10 New neurones.
How can i do so? What should I put in input_shape?  </p>

<pre><code>def cnn_model():
model = Sequential()                                               
model.add(Conv1D(filters=1, kernel_size=10 ,strides=10,     
                  input_shape=(1, 1,N_features),kernel_initializer= 'uniform',      
                  activation= 'relu')) 
model.flatten()
model.add(Dense(N_features/10, init= 'uniform' , activation= 'relu' ))
</code></pre>

<p>Any advice?
thank you!</p>
",7821557.0,,5974433.0,,2017-07-12 08:35:12,2018-10-19 17:32:36,Convolutional neural network Conv1d input shape,<input><machine-learning><neural-network><keras><conv-neural-network>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/43235531
55445712,1,55530654,,2019-03-31 21:41:41,,21,15583,"<p>I am trying to create the custom loss function using Keras. I want to compute the loss function based on the input and predicted the output of the neural network. </p>

<p>I tried using the customloss function in Keras. I think y_true is the output that we give for training and y_pred is the predicted output of the neural network. The below loss function is same as ""mean_squared_error"" loss in Keras.   </p>

<pre><code>def customloss(y_true, y_pred):
    return K.mean(K.square(y_pred - y_true), axis=-1)
</code></pre>

<p>I would like to use the input to the neural network also to compute the custom loss function in addition to mean_squared_error loss. Is there a way to send an input to the neural network as an argument to the customloss function. </p>

<p>Thank you.</p>
",3443033.0,,,,,2023-01-26 12:50:42,Custom loss function in Keras based on the input data,<keras>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55445712
51522848,1,51523029,,2018-07-25 15:38:14,,21,38439,"<p>I have this code:</p>

<pre><code># Declare the layers
inp1 = Input(shape=input_shape, name=""input1"")
inp2 = Input(shape=input_shape, name=""input2"")


# 128 -&gt; 64
conv1_inp1 = Conv2D(start_neurons * 1, 3, activation=""relu"", padding=""same"")(inp1)
conv1_inp2 = Conv2D(start_neurons * 1, 3, activation=""relu"", padding=""same"")(inp2)
conv1 = Concatenate()([conv1_inp1, conv1_inp2])
conv1 = Conv2D(start_neurons * 1, 3, activation=""relu"", padding=""same"")(conv1)
conv1 = MaxPooling2D((2, 2))(conv1)
conv1 = Dropout(0.25)(conv1)

# 64 -&gt; 32
conv2 = Conv2D(start_neurons * 2, (3, 3), activation=""relu"", padding=""same"")(conv1)
conv2 = Conv2D(start_neurons * 2, (3, 3), activation=""relu"", padding=""same"")(conv2)
pool2 = MaxPooling2D((2, 2))(conv2)
pool2 = Dropout(0.5)(pool2)

# 32 -&gt; 16
conv3 = Conv2D(start_neurons * 4, (3, 3), activation=""relu"", padding=""same"")(pool2)
conv3 = Conv2D(start_neurons * 4, (3, 3), activation=""relu"", padding=""same"")(conv3)
pool3 = MaxPooling2D((2, 2))(conv3)
pool3 = Dropout(0.5)(pool3)

# 16 -&gt; 8
conv4 = Conv2D(start_neurons * 8, (3, 3), activation=""relu"", padding=""same"")(pool3)
conv4 = Conv2D(start_neurons * 8, (3, 3), activation=""relu"", padding=""same"")(conv4)
pool4 = MaxPooling2D((2, 2))(conv4)
pool4 = Dropout(0.5)(pool4)

# Middle
convm = Conv2D(start_neurons * 16, (3, 3), activation=""relu"", padding=""same"")(pool4)
convm = Conv2D(start_neurons * 16, (3, 3), activation=""relu"", padding=""same"")(convm)

# 8 -&gt; 16
deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=""same"")(convm)
uconv4 = Concatenate()([deconv4, conv4])
uconv4 = Dropout(0.5)(uconv4)
uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=""relu"", padding=""same"")(uconv4)
uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=""relu"", padding=""same"")(uconv4)

# 16 -&gt; 32
deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=""same"")(uconv4)
uconv3 = Concatenate()([deconv3, conv3])
uconv3 = Dropout(0.5)(uconv3)
uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=""relu"", padding=""same"")(uconv3)
uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=""relu"", padding=""same"")(uconv3)

# 32 -&gt; 64
deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=""same"")(uconv3)
uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=""relu"", padding=""same"")(uconv2)
uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=""relu"", padding=""same"")(uconv2)

# 64 -&gt; 128
deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=""same"")(uconv2)
uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=""relu"", padding=""same"")(deconv1)
uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=""relu"", padding=""same"")(uconv1)

uncov1 = Dropout(0.5)(uconv1)
output_layer = Conv2D(1, (1,1), padding=""same"", activation=""sigmoid"")(uconv1)



# Declare the model and add the layers
model = Model(inputs = [inp1, inp2], outputs = output_layer)

model.summary()
model.compile(optimizer='adam',loss='binary_crossentropy')
</code></pre>

<p>And it generates this error :</p>

<pre><code>Graph disconnected: cannot obtain value for tensor Tensor(""input_28:0"", shape=(?, 128, 128, 1), dtype=float32) at layer ""input_28"". The following previous layers were accessed without issue: []
</code></pre>

<p>The inputs have the same shape and in some forums, they say that the problem comes from the fact that the inputs are coming from 2 different sources therefore breaking the link that you had before.</p>

<p>I don't really know how to fix that.</p>

<p>Can anyone help me?</p>

<p>Thanks in advance.</p>
",7723396.0,,9190768.0,,2018-07-25 17:28:30,2020-02-12 20:18:42,Graph disconnected: cannot obtain value for tensor Tensor Input Keras Python,<python><input><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51522848
41958566,1,41970980,,2017-01-31 13:14:12,,21,9836,"<p>I'm trying to design a neural network using Keras with priority on prediction performance, and I cannot get sufficiently high accuracy by further reducing the number of layers and nodes per layer. I have noticed that very large portion of my weights are effectively zero (>95%). Is there a way to prune dense layers in hope of reducing prediction time?</p>
",1901114.0,,,,,2021-03-15 04:31:06,Pruning in Keras,<python-3.x><neural-network><keras><pruning>,4,5,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41958566
45979848,1,45981666,,2017-08-31 10:59:28,,21,39190,"<p>I a trying to merge 2 sequential models in keras. Here is the code:</p>

<pre><code>model1 = Sequential(layers=[
    # input layers and convolutional layers
    Conv1D(128, kernel_size=12, strides=4, padding='valid', activation='relu', input_shape=input_shape),
    MaxPooling1D(pool_size=6),
    Conv1D(256, kernel_size=12, strides=4, padding='valid', activation='relu'),
    MaxPooling1D(pool_size=6),
    Dropout(.5),

])

model2 = Sequential(layers=[
    # input layers and convolutional layers
    Conv1D(128, kernel_size=20, strides=5, padding='valid', activation='relu', input_shape=input_shape),
    MaxPooling1D(pool_size=5),
    Conv1D(256, kernel_size=20, strides=5, padding='valid', activation='relu'),
    MaxPooling1D(pool_size=5),
    Dropout(.5),

])

model = merge([model1, model2], mode = 'sum')
Flatten(),
Dense(256, activation='relu'),
Dropout(.5),
Dense(128, activation='relu'),
Dropout(.35),
# output layer
Dense(5, activation='softmax')
return model
</code></pre>

<p>Here is the error log:</p>

<blockquote>
  <p>File
  ""/nics/d/home/dsawant/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"",
  line 392, in is_keras_tensor
      raise ValueError('Unexpectedly found an instance of type <code>' + str(type(x)) + '</code>. ' ValueError: Unexpectedly found an instance of
  type <code>&lt;class 'keras.models.Sequential'&gt;</code>. Expected a symbolic tensor
  instance.</p>
</blockquote>

<p>Some more log:</p>

<blockquote>
  <p>ValueError: Layer merge_1 was called with an input that isn't a
  symbolic tensor. Received type: class 'keras.models.Sequential'.
  Full input: [keras.models.Sequential object at 0x2b32d518a780,
  keras.models.Sequential object at 0x2b32d521ee80]. All inputs to the
  layer should be tensors.</p>
</blockquote>

<p>How can I merge these 2 Sequential models that use different window sizes and apply functions like 'max', 'sum' etc to them?</p>
",7309225.0,,,,,2021-11-05 13:13:16,Merge 2 sequential models in Keras,<python><machine-learning><neural-network><keras><conv-neural-network>,1,4,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45979848
41855512,1,41855937,,2017-01-25 15:33:34,,21,29012,"<p>I see that the imageDataGenerator allows me to specify different styles of data normalization, e.g. featurewise_center, samplewise_center, etc.</p>

<p>I see from the examples that if I specify one of these options, then I need to call the fit method on the generator in order to allow the generator to compute statistics like the mean image on the generator.</p>

<pre><code>(X_train, y_train), (X_test, y_test) = cifar10.load_data()
Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True)

# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
datagen.fit(X_train)

# fits the model on batches with real-time data augmentation:
model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),
                samples_per_epoch=len(X_train), nb_epoch=nb_epoch)
</code></pre>

<p>My question is, how does prediction work if I have specified data normalization during training? I can't see how in the framework I would even pass knowledge of the training set mean/std deviation along to predict to allow me to normalize my test data myself, but I also don't see in the training code where this information is stored.</p>

<p>Are the image statistics needed for normalization stored in the model so that they can be used during prediction?</p>
",2221270.0,,5974433.0,,2017-01-25 19:38:55,2017-05-12 06:14:28,How does data normalization work in keras during prediction?,<python><machine-learning><tensorflow><neural-network><keras>,4,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/41855512
45585104,1,46268055,,2017-08-09 08:11:31,,20,8890,"<p>I'm working on training a LSTM network on Google Cloud Machine Learning Engine using Keras with TensorFlow backend. I managed it to deploy my model and perform a successful training task after some adjustments to the gcloud and my python script. </p>

<p>I then tried to make my model save checkpoints after every epoch using Keras <a href=""https://keras.io/callbacks/#modelcheckpoint"" rel=""noreferrer"">modelCheckpoint callback</a>. Running a local training job with Google Cloud works perfectly as expected. The weights are getting stored in the specified path after each epoch. But when I try to run the same job online on Google Cloud Machine Learning Engine the <code>weights.hdf5</code> does not get written to my Google Cloud Bucket. Instead I get the following error:</p>

<pre><code>...
File ""h5f.pyx"", line 71, in h5py.h5f.open (h5py/h5f.c:1797)
IOError: Unable to open file (Unable to open file: name = 
'gs://.../weights.hdf5', errno = 2, error message = 'no such file or
directory', flags = 0, o_flags = 0)
</code></pre>

<p>I investigated this issue and it turned out, that there is no Problem with the the Bucket itself, as Keras <a href=""https://keras.io/callbacks/#tensorboard"" rel=""noreferrer"">Tensorboard callback</a> does work fine and writes the expected output to the same bucket. I also made sure that <code>h5py</code> gets included by providing it in the <code>setup.py</code> located at:</p>

<pre><code>├── setup.py
    └── trainer
    ├── __init__.py
    ├── ...
</code></pre>

<p>The actual include in <code>setup.py</code> is shown below:</p>

<pre><code># setup.py
from setuptools import setup, find_packages

setup(name='kerasLSTM',
      version='0.1',
      packages=find_packages(),
      author='Kevin Katzke',
      install_requires=['keras','h5py','simplejson'],
      zip_safe=False)
</code></pre>

<p>I guess the problem comes down to the fact that GCS cannot be accessed with Pythons <code>open</code> for I/O since it instead provides a custom implementation:</p>

<pre><code>import tensorflow as tf
from tensorflow.python.lib.io import file_io

with file_io.FileIO(""gs://..."", 'r') as f:
    f.write(""Hi!"")
</code></pre>

<p>After checking how Keras modelCheckpoint callback implements the actual file writing and it turned out, that it is using <a href=""http://docs.h5py.org/en/latest/high/file.html?highlight=open"" rel=""noreferrer"">h5py.File()</a> for I/O:</p>

<pre><code> with h5py.File(filepath, mode='w') as f:
    f.attrs['keras_version'] = str(keras_version).encode('utf8')
    f.attrs['backend'] = K.backend().encode('utf8')
    f.attrs['model_config'] = json.dumps({
        'class_name': model.__class__.__name__,
        'config': model.get_config()
 }, default=get_json_type).encode('utf8')
</code></pre>

<p>And as the <code>h5py package</code> is a Pythonic interface to the <code>HDF5 binary data format</code> the <code>h5py.File()</code> seems to call an underlying <code>HDF5</code> functionality written in Fortran as far as I can tell: <a href=""https://github.com/mokus0/hdf5/blob/master/fortran/examples/h5_rdwt.f90"" rel=""noreferrer"">source</a>, <a href=""https://support.hdfgroup.org/HDF5/doc/RM/RM_H5F.html#File-Open"" rel=""noreferrer"">documentation</a>.</p>

<p>How can I fix this and make the modelCheckpoint callback write to my GCS Bucket? Is there a way for ""monkey patching"" to somehow overwrite how a hdf5 file is opened to make it use GCS's <code>file_io.FileIO()</code>?</p>
",1280289.0,,,,,2021-09-18 09:01:12,Save Keras ModelCheckpoints in Google Cloud Bucket,<tensorflow><google-cloud-platform><keras><hdf5><h5py>,8,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45585104
59394947,1,59395251,,2019-12-18 15:12:04,,20,54907,"<p>I wanna make a model with multiple inputs. So, I try to build a model like this.</p>
<pre><code># define two sets of inputs
inputA = Input(shape=(32,64,1))
inputB = Input(shape=(32,1024))
 
# CNN
x = layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu')(inputA)
x = layers.Conv2D(32, (3,3), activation='relu')(x)
x = layers.MaxPooling2D(pool_size=(2,2))(x)
x = layers.Dropout(0.2)(x)
x = layers.Flatten()(x)
x = layers.Dense(500, activation = 'relu')(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(500, activation='relu')(x)
x = Model(inputs=inputA, outputs=x)
 
# DNN
y = layers.Flatten()(inputB)
y = Dense(64, activation=&quot;relu&quot;)(y)
y = Dense(250, activation=&quot;relu&quot;)(y)
y = Dense(500, activation=&quot;relu&quot;)(y)
y = Model(inputs=inputB, outputs=y)
 
# Combine the output of the two models
combined = concatenate([x.output, y.output])
 

# combined outputs
z = Dense(300, activation=&quot;relu&quot;)(combined)
z = Dense(100, activation=&quot;relu&quot;)(combined)
z = Dense(1, activation=&quot;softmax&quot;)(combined)

model = Model(inputs=[x.input, y.input], outputs=z)

model.summary()

opt = Adam(lr=1e-3, decay=1e-3 / 200)
model.compile(loss = 'sparse_categorical_crossentropy', optimizer = opt,
    metrics = ['accuracy'])
</code></pre>
<p>and the summary
:
_</p>
<p>But, when i try to train this model,</p>
<pre><code>history = model.fit([trainimage, train_product_embd],train_label,
    validation_data=([validimage,valid_product_embd],valid_label), epochs=10, 
    steps_per_epoch=100, validation_steps=10)
</code></pre>
<p>the problem happens....
:</p>
<pre><code> ResourceExhaustedError                    Traceback (most recent call
 last) &lt;ipython-input-18-2b79f16d63c0&gt; in &lt;module&gt;()
 ----&gt; 1 history = model.fit([trainimage, train_product_embd],train_label,
 validation_data=([validimage,valid_product_embd],valid_label),
 epochs=10, steps_per_epoch=100, validation_steps=10)

 4 frames
 /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py
 in __call__(self, *args, **kwargs)    1470         ret =
 tf_session.TF_SessionRunCallable(self._session._session,    1471      
 self._handle, args,
 -&gt; 1472                                                run_metadata_ptr)    1473         if run_metadata:    1474          
 proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)
 
 ResourceExhaustedError: 2 root error(s) found.   (0) Resource
 exhausted: OOM when allocating tensor with shape[800000,32,30,62] and
 type float on /job:localhost/replica:0/task:0/device:GPU:0 by
 allocator GPU_0_bfc     [[{{node conv2d_1/convolution}}]] Hint: If you
 want to see a list of allocated tensors when OOM happens, add
 report_tensor_allocations_upon_oom to RunOptions for current
 allocation info.
 
     [[metrics/acc/Mean_1/_185]] Hint: If you want to see a list of
 allocated tensors when OOM happens, add
 report_tensor_allocations_upon_oom to RunOptions for current
 allocation info.
 
   (1) Resource exhausted: OOM when allocating tensor with
 shape[800000,32,30,62] and type float on
 /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc    
 [[{{node conv2d_1/convolution}}]] Hint: If you want to see a list of
 allocated tensors when OOM happens, add
 report_tensor_allocations_upon_oom to RunOptions for current
 allocation info.
 
 0 successful operations. 0 derived errors ignored.
</code></pre>
<p>Thanks for reading and hopefully helping me :)</p>
",12182110.0,,,user12304080,2020-11-09 09:26:33,2023-04-19 06:23:30,"How to fix ""ResourceExhaustedError: OOM when allocating tensor""",<python><tensorflow><machine-learning><keras><deep-learning>,5,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/59394947
54347963,1,54348035,,2019-01-24 13:38:19,,20,45622,"<p>I have a <code>Keras</code> model that I am trying to export and use in a different python code.</p>

<p>Here is my code:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Dropout, Lambda
from keras.layers.embeddings import Embedding
import tensorflow as tf


EMBEDDING_DIM = 100

model = Sequential()
model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))
model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_val_pad, y_val), verbose=2)
model.save('my_model.h5') 
</code></pre>

<hr>

<p>In <strong>another file</strong>, when I import <code>my_model.h5</code> :</p>

<pre><code>from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf


def learning(test_samples):
    model = load_model('my_model.h5')
    #ERROR HERE
    #rest of the code
</code></pre>

<p>The error is the following:</p>

<pre><code>  in &lt;lambda&gt;
    model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))
NameError: name 'tf' is not defined
</code></pre>

<p>After research, I got that the fact that <strong>I used <code>lambda</code> in my model</strong> is the reason for this problem, but I added these references and it didn't help:</p>

<pre><code>from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf
</code></pre>

<p>What could be the problem?</p>

<p>Thank you</p>
",2378622.0,,,,,2020-09-02 15:42:44,'tf' is not defined on load_model() - using lambda,<python><tensorflow><lambda><keras>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54347963
55852831,1,59492947,,2019-04-25 15:28:03,,20,4733,"<p>I'm trying to decide whether to use the existing keras.utils.sequence module or to switch to tf.data. From what I understand, tf.data optimizes performance by <a href=""https://www.tensorflow.org/guide/performance/datasets"" rel=""noreferrer"">overlapping training on GPU with pre-processing on the CPU</a>. But how does that compare to keras.utils.sequence and the keras data generator? From what I read <a href=""https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"" rel=""noreferrer"">here</a> it seems that it's doing the same thing. Is there anything to gain by switching to tf.data ?</p>
",3217278.0,,,,,2019-12-26 20:01:39,tf.data vs keras.utils.sequence performance,<python><tensorflow><keras>,1,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55852831
41458859,1,41717938,,2017-01-04 07:58:47,,20,9248,"<p>I am building a custom metric to measure the accuracy of one class in my multi-class dataset during training. I am having trouble selecting the class. </p>

<p>The targets are one hot (e.g: the class <code>0</code> label is <code>[1 0 0 0 0]</code>):</p>

<pre><code>from keras import backend as K

def single_class_accuracy(y_true, y_pred):
    idx = bool(y_true[:, 0])              # boolean mask for class 0 
    class_preds = y_pred[idx]
    class_true = y_true[idx]
    class_acc = K.mean(K.equal(K.argmax(class_true, axis=-1), K.argmax(class_preds, axis=-1)))  # multi-class accuracy  
    return class_acc
</code></pre>

<p>The trouble is, we have to use Keras functions to index tensors. How do you create a boolean mask for a tensor?</p>
",4013781.0,,3924118.0,,2020-01-22 14:40:24,2022-11-07 16:58:41,How do you create a boolean mask for a tensor in Keras?,<python><tensorflow><neural-network><keras>,2,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/41458859
48987959,1,48991515,,2018-02-26 11:54:55,,20,70455,"<p>I have created an ANN with numerical inputs and a single categorical output which is one hot encoded to be 1 of 19 categories. I set my output layer to have 19 units. I don't know how to perform the confusion matrix now nor how to classifier.predict() in light of this rather than a single binary output. I keep getting an error saying classification metrics can't handle a mix of continuous-multioutput and multi-label-indicator targets. Not sure how to proceed.</p>

<pre><code>#Importing Datasets
dataset=pd.read_csv('Data.csv')
x = dataset.iloc[:,1:36].values # lower bound independent variable to upper bound in a matrix (in this case only 1 column 'NC')
y = dataset.iloc[:,36:].values # dependent variable vector
print(x.shape)
print(y.shape)

#One Hot Encoding fuel rail column
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_y= LabelEncoder()
y[:,0]=labelencoder_y.fit_transform(y[:,0])
onehotencoder= OneHotEncoder(categorical_features=[0])
y = onehotencoder.fit_transform(y).toarray()
print(y[:,0:])

print(x.shape)
print (y.shape)


#splitting data into Training and Test Data
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.1,random_state=0)

#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
#x_train = sc.fit_transform(x_train)
#x_test=sc.transform(x_test)
y_train = sc.fit_transform(y_train)
y_test=sc.transform(y_test)

# PART2 - Making ANN, deep neural network

#Importing the Keras libraries and packages
import keras
from keras.models import Sequential
from keras.layers import Dense


#Initialising ANN
classifier = Sequential()
#Adding the input layer and first hidden layer
classifier.add(Dense(activation= 'relu', input_dim =35, units=2, kernel_initializer=""uniform""))#rectifier activation function, include all input with one hot encoding
#Adding second hidden layer
classifier.add(Dense(activation= 'relu', units=2, kernel_initializer=""uniform"")) #rectifier activation function
#Adding the Output Layer
classifier.add(Dense(activation='softmax', units=19, kernel_initializer=""uniform"")) 
#Compiling ANN - stochastic gradient descent
classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])#stochastic gradient descent

#Fit ANN to training set

#PART 3 - Making predictions and evaluating the model
#Fitting classifier to the training set
classifier.fit(x_train, y_train, batch_size=10, epochs=100)#original batch is 10 and epoch is 100

#Predicting the Test set rules
y_pred = classifier.predict(x_test)
y_pred = (y_pred &gt; 0.5) #greater than 0.50 on scale 0 to 1
print(y_pred)

#Making confusion matrix that checks accuracy of the model
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
</code></pre>
",8512104.0,,8512104.0,,2018-02-26 14:00:55,2021-05-11 16:58:40,classification metrics can't handle a mix of continuous-multioutput and multi-label-indicator targets,<python><keras>,2,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48987959
42441431,1,42446706,,2017-02-24 14:42:49,,20,18405,"<p>In my <a href=""https://stackoverflow.com/questions/41672114/add-tensorflow-pre-processing-to-existing-keras-model-for-use-in-tensorflow-ser"">previous question</a>, I used Keras' <code>Layer.set_input()</code> to connect my Tensorflow pre-processing output tensor to my Keras model's input. However, <a href=""https://github.com/fchollet/keras/commit/92e8a20761bedbde8fd56a02a165884e8132f045"" rel=""noreferrer"">this method has been removed</a> after Keras version <code>1.1.1</code>.</p>

<p>How can I achieve this in newer Keras versions?</p>

<p><strong>Example:</strong></p>

<pre><code># Tensorflow pre-processing
raw_input = tf.placeholder(tf.string)
### some TF operations on raw_input ###
tf_embedding_input = ...    # pre-processing output tensor

# Keras model
model = Sequential()
e = Embedding(max_features, 128, input_length=maxlen)

### THIS DOESN'T WORK ANYMORE ###
e.set_input(tf_embedding_input)
################################

model.add(e)
model.add(LSTM(128, activation='sigmoid'))
model.add(Dense(num_classes, activation='softmax'))
</code></pre>
",2106858.0,,-1.0,,2017-05-23 12:09:57,2018-02-01 02:34:25,How to set the input of a Keras layer with a Tensorflow tensor?,<tensorflow><keras><keras-layer>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42441431
50808593,1,50809012,,2018-06-12 02:50:40,,20,17168,"<p>In a CNN for binary classification of images, should the shape of output be (number of images, 1) or (number of images, 2)? Specifically, here are 2 kinds of last layer in a CNN:</p>

<pre><code>keras.layers.Dense(2, activation = 'softmax')(previousLayer)
</code></pre>

<p>or</p>

<pre><code>keras.layers.Dense(1, activation = 'softmax')(previousLayer)
</code></pre>

<p>In the first case, for every image there are 2 output values (probability of belonging to group 1 and probability of belonging to group 2). In the second case, each image has only 1 output value, which is its label (0 or 1, label=1 means it belongs to group 1).</p>

<p>Which one is correct? Is there intrinsic difference? I don't want to recognize any object in those images, just divide them into 2 groups.</p>

<p>Thanks a lot!</p>
",9775215.0,,,,,2020-03-16 12:20:29,Difference between Dense(2) and Dense(1) as the final layer of a binary classification CNN?,<tensorflow><keras><deep-learning><classification><conv-neural-network>,2,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50808593
53516662,1,53517528,,2018-11-28 09:56:20,,20,23892,"<p>Is it possible in Keras to feed both an image and a vector of values as inputs to one model? If yes, how? </p>

<p>What I want is to create a CNN with an image and a vector of 6 values on the input.</p>

<p>The output is the vector of 3 values. </p>
",10127088.0,,3442409.0,,2019-11-11 14:24:16,2021-02-24 19:16:35,Two inputs to one model in Keras,<python><image><vector><keras>,1,4,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53516662
44611325,1,45261610,,2017-06-18 02:57:13,,20,29066,"<p>I have <code>keras</code> installed with <code>devtools</code> from GitHub in R and TensorFlow installed in Python. </p>

<p>However when I run an example Keras command like:</p>

<pre><code>model &lt;- keras_model_sequential() 
</code></pre>

<p>I get the following:</p>

<blockquote>
  <p>Error: Python module tensorflow.contrib.keras.python.keras was not
  found.</p>

<pre><code>Detected Python configuration:

python:         C:\Python35\python.exe
libpython:      C:/Python35/python35.dll
pythonhome:     C:\Python35
version:        3.5.0 (v3.5.0:374f501f4567, Sep 13 2015, 02:27:37) [MSC v.1900 64 bit (AMD64)]
Architecture:   64bit
numpy:          C:\Python35\lib\site-packages\numpy
numpy_version:  1.13.0
tensorflow:     C:\Python35\lib\site-packages\tensorflow

python versions found: 
 C:\Python35\python.exe
 C:\Python27\\python.exe
 C:\Python35\\python.exe
 C:\Python36\\python.exe
</code></pre>
</blockquote>
",3604745.0,,,,,2022-05-08 04:44:20,R keras package Error: Python module tensorflow.contrib.keras.python.keras was not found,<r><tensorflow><keras>,7,3,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/44611325
46080634,1,46095279,,2017-09-06 16:54:52,,20,35417,"<p>I built the gpu version of the docker image <a href=""https://github.com/floydhub/dl-docker"" rel=""noreferrer"">https://github.com/floydhub/dl-docker</a> with keras version 2.0.0 and tensorflow version 0.12.1. I then ran the mnist tutorial <a href=""https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py"" rel=""noreferrer"">https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py</a> but realized that keras is not using GPU. Below is the output that I have</p>

<pre><code>root@b79b8a57fb1f:~/sharedfolder# python test.py
Using TensorFlow backend.
Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/12
2017-09-06 16:26:54.866833: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-06 16:26:54.866855: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-06 16:26:54.866863: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-09-06 16:26:54.866870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-09-06 16:26:54.866876: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
</code></pre>

<p>Can anyone let me know if there are some settings that need to be made before keras uses GPU ? I am very new to all these so do let me know if I need to provide more information. </p>

<p><strong>I have installed the pre-requisites as mentioned on the <a href=""https://github.com/floydhub/dl-docker#prerequisites"" rel=""noreferrer"">page</a></strong></p>

<ul>
<li>Install Docker following the installation guide for your platform: <a href=""https://docs.docker.com/engine/installation/"" rel=""noreferrer"">https://docs.docker.com/engine/installation/</a></li>
</ul>

<p>I am able to launch the docker image </p>

<pre><code>docker run -it -p 8888:8888 -p 6006:6006 -v /sharedfolder:/root/sharedfolder floydhub/dl-docker:cpu bash
</code></pre>

<ul>
<li>GPU Version Only: Install Nvidia drivers on your machine either from Nvidia directly or follow the instructions <a href=""https://github.com/floydhub/dl-setup#nvidia-drivers"" rel=""noreferrer"">here</a>. Note that you don't have to install CUDA or cuDNN. These are included in the Docker container. </li>
</ul>

<p>I am able to run the last step </p>

<pre><code>cv@cv-P15SM:~$ cat /proc/driver/nvidia/version
NVRM version: NVIDIA UNIX x86_64 Kernel Module  375.66  Mon May  1 15:29:16 PDT 2017
GCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)
</code></pre>

<ul>
<li>GPU Version Only: Install nvidia-docker: <a href=""https://github.com/NVIDIA/nvidia-docker"" rel=""noreferrer"">https://github.com/NVIDIA/nvidia-docker</a>, following the instructions here. This will install a replacement for the docker CLI. It takes care of setting up the Nvidia host driver environment inside the Docker containers and a few other things.</li>
</ul>

<p>I am able to run the step <a href=""https://github.com/NVIDIA/nvidia-docker"" rel=""noreferrer"">here</a></p>

<pre><code># Test nvidia-smi
cv@cv-P15SM:~$ nvidia-docker run --rm nvidia/cuda nvidia-smi

Thu Sep  7 00:33:06 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 780M    Off  | 0000:01:00.0     N/A |                  N/A |
| N/A   55C    P0    N/A /  N/A |    310MiB /  4036MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0                  Not Supported                                         |
+-----------------------------------------------------------------------------+
</code></pre>

<p>I am also able to run the nvidia-docker command to launch a gpu supported image.</p>

<p><strong>What I have tried</strong></p>

<p>I have tried the following suggestions below </p>

<ol>
<li>Check if you have completed step 9 of this tutorial ( <a href=""https://github.com/ignaciorlando/skinner/wiki/Keras-and-TensorFlow-installation"" rel=""noreferrer"">https://github.com/ignaciorlando/skinner/wiki/Keras-and-TensorFlow-installation</a> ). Note: Your file paths may be completely different inside that docker image, you'll have to locate them somehow. </li>
</ol>

<p>I appended the suggested lines to my bashrc and have verified that the bashrc file is updated.</p>

<pre><code>echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64' &gt;&gt; ~/.bashrc
echo 'export CUDA_HOME=/usr/local/cuda-8.0' &gt;&gt; ~/.bashrc
</code></pre>

<ol>
<li><p>To import the following commands in my python file</p>

<p><code>import os
os.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""   # see issue #152
os.environ[""CUDA_VISIBLE_DEVICES""]=""0""</code></p></li>
</ol>

<p>Both steps, done separately or together unfortunately did not solve the issue. Keras is still running with the CPU version of tensorflow as its backend. However, I might have found the possible issue. I checked the version of my tensorflow via the following commands and found two of them.</p>

<p>This is the CPU version</p>

<pre><code>root@08b5fff06800:~# pip show tensorflow
Name: tensorflow
Version: 1.3.0
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /usr/local/lib/python2.7/dist-packages
Requires: tensorflow-tensorboard, six, protobuf, mock, numpy, backports.weakref, wheel
</code></pre>

<p>And this is the GPU version</p>

<pre><code>root@08b5fff06800:~# pip show tensorflow-gpu
Name: tensorflow-gpu
Version: 0.12.1
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /usr/local/lib/python2.7/dist-packages
Requires: mock, numpy, protobuf, wheel, six
</code></pre>

<p>Interestingly, the output shows that keras is using tensorflow version 1.3.0 which is the CPU version and not 0.12.1, the GPU version</p>

<pre><code>import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

import tensorflow as tf
print('Tensorflow: ', tf.__version__)
</code></pre>

<p>Output</p>

<pre><code>root@08b5fff06800:~/sharedfolder# python test.py
Using TensorFlow backend.
Tensorflow:  1.3.0
</code></pre>

<p>I guess now I need to figure out how to have keras use the gpu version of tensorflow.</p>
",6467567.0,,6467567.0,,2017-09-07 03:48:59,2021-01-17 06:26:51,Keras with TensorFlow backend not using GPU,<docker><keras><tensorflow>,4,9,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46080634
57320371,1,57322080,,2019-08-02 05:22:20,,20,16916,"<p>In TensorFlow's offcial documentations, they always pass <code>training=True</code> when calling a Keras model in a training loop, for example, <code>logits = mnist_model(images, training=True)</code>.</p>

<p>I tried <code>help(tf.keras.Model.call)</code> and it shows that</p>

<pre><code>Help on function call in module tensorflow.python.keras.engine.network:

call(self, inputs, training=None, mask=None)
    Calls the model on new inputs.

    In this case `call` just reapplies
    all ops in the graph to the new inputs
    (e.g. build a new computational graph from the provided inputs).

    Arguments:
        inputs: A tensor or list of tensors.
        training: Boolean or boolean scalar tensor, indicating whether to run
          the `Network` in training mode or inference mode.
        mask: A mask or list of masks. A mask can be
            either a tensor or None (no mask).

    Returns:
        A tensor if there is a single output, or
        a list of tensors if there are more than one outputs.
</code></pre>

<p>It says that <code>training</code> is a Boolean or boolean scalar tensor, indicating whether to run the <code>Network</code> in <em>training mode</em> or <em>inference mode</em>. But I didn't find any information about this two modes.</p>

<p>In a nutshell, I don't know <strong>what is the influence of this argument</strong>. And what if I missed this argument when training?</p>
",8102500.0,,8102500.0,,2019-08-02 05:33:10,2021-10-07 08:00:11,What does `training=True` mean when calling a TensorFlow Keras model?,<tensorflow><keras>,2,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/57320371
52259343,1,57785739,,2018-09-10 13:53:11,,20,8778,"<p>Recently, I've started creating neural networks with Tensorflow + Keras and I would like to try the quantization feature available in Tensorflow. So far, experimenting with examples from TF tutorials worked just fine and I have this basic working example (from <a href=""https://www.tensorflow.org/tutorials/keras/basic_classification"" rel=""noreferrer"">https://www.tensorflow.org/tutorials/keras/basic_classification</a>):</p>

<pre><code>import tensorflow as tf
from tensorflow import keras

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# fashion mnist data labels (indexes related to their respective labelling in the data set)
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# preprocess the train and test images
train_images = train_images / 255.0
test_images = test_images / 255.0

# settings variables
input_shape = (train_images.shape[1], train_images.shape[2])

# create the model layers
model = keras.Sequential([
keras.layers.Flatten(input_shape=input_shape),
keras.layers.Dense(128, activation=tf.nn.relu),
keras.layers.Dense(10, activation=tf.nn.softmax)
])

# compile the model with added settings
model.compile(optimizer=tf.train.AdamOptimizer(),
          loss='sparse_categorical_crossentropy',
          metrics=['accuracy'])

# train the model
epochs = 3
model.fit(train_images, train_labels, epochs=epochs)

# evaluate the accuracy of model on test data
test_loss, test_acc = model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)
</code></pre>

<p>Now, I would like to employ quantization in the learning and classification process. The quantization documentation (<a href=""https://www.tensorflow.org/performance/quantization"" rel=""noreferrer"">https://www.tensorflow.org/performance/quantization</a>) (the page is no longer available since cca September 15, 2018) suggests to use this piece of code:</p>

<pre><code>loss = tf.losses.get_total_loss()
tf.contrib.quantize.create_training_graph(quant_delay=2000000)
optimizer = tf.train.GradientDescentOptimizer(0.00001)
optimizer.minimize(loss)
</code></pre>

<p>However, it does not contain any information about where this code should be utilized or how it should be connected to a TF code (not even mentioning a high level model created with Keras). I have no idea how this quantization part relates to the previously created neural network model. Just inserting it following the neural network code runs into the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""so.py"", line 41, in &lt;module&gt;
    loss = tf.losses.get_total_loss()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/util.py"", line 112, in get_total_loss
    return math_ops.add_n(losses, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 2119, in add_n
    raise ValueError(""inputs must be a list of at least one Tensor with the ""
ValueError: inputs must be a list of at least one Tensor with the same dtype and shape
</code></pre>

<p>Is it possible to quantize a Keras NN model in this way or am I missing something basic?
A possible solution that crossed my mind could be using low level TF API instead of Keras (needing to do quite a bit of work to construct the model), or maybe trying to extract some of the lower level methods from the Keras models.</p>
",9248378.0,,10722885.0,,2019-08-12 15:08:28,2019-10-07 07:25:34,Quantize a Keras neural network model,<python><tensorflow><neural-network><keras><quantization>,3,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52259343
54891464,1,54892165,,2019-02-26 17:56:50,,20,6486,"<p>I have a dataframe with text columns. I separated them into <code>x_train</code> and <code>x_test</code>.</p>

<p>My question is if its better to do Keras's <code>Tokenizer.fit_on_text()</code> on the entire <code>x</code> data set or just <code>x_train</code>?</p>

<p>Like this:</p>

<pre><code>tokenizer = Tokenizer()
tokenizer.fit_on_texts(x_data)
</code></pre>

<p>or</p>

<pre><code>tokenizer.fit_on_texts(x_train)        # &lt;- fixed typo
tokenizer.texts_to_sequences(x_train)
</code></pre>

<p>Does it matter? I'd also have to tokenize <code>x_test</code> later too, so can I just use the same tokenizer?</p>
",9399165.0,,6392906.0,,2019-07-08 05:30:52,2020-03-28 21:21:12,Is it better to Keras fit_to_text on the entire x_data or just the train_data?,<python><keras><tokenize>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/54891464
53190253,1,53303620,,2018-11-07 13:17:00,,20,6032,"<p>I've trained an LSTM model (built with Keras and TF) on multiple batches of 7 samples with 3 features each, with a shape the like below sample (numbers below are just placeholders for the purpose of explanation), each batch is labeled 0 or 1:</p>
<p>Data:</p>
<pre><code>[
   [[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3]]
   [[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3]]
   [[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3]]
   ...
]
</code></pre>
<p>i.e: batches of m sequences, each of length 7, whose elements are 3-dimensional vectors (so batch has shape (m<em>7</em>3))</p>
<p>Target:</p>
<pre><code>[
   [1]
   [0]
   [1]
   ...
]
</code></pre>
<p>On my production environment data is a stream of samples with 3 features (<code>[1,2,3],[1,2,3]...</code>). I would like to stream each sample as it arrives to my model and get the intermediate probability without waiting for the entire batch (7) - see the animation below.</p>
<p><a href=""https://i.stack.imgur.com/4D0yt.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4D0yt.gif"" alt=""enter image description here"" /></a></p>
<p>One of my thoughts was padding the batch with 0 for the missing samples,
<code>[[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[1,2,3]]</code> but that seems to be inefficient.</p>
<p>Will appreciate any help that will point me in the right direction of both saving the LSTM intermediate state in a persistent way, while waiting for the next sample and predicting on a model trained on a specific batch size with partial data.</p>
<hr />
<p><strong>Update,</strong> including model code:</p>
<pre class=""lang-py prettyprint-override""><code>    opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=10e-8, decay=0.001)
    model = Sequential()

    num_features = data.shape[2]
    num_samples = data.shape[1]

    first_lstm = LSTM(32, batch_input_shape=(None, num_samples, num_features), 
                      return_sequences=True, activation='tanh')
    model.add(first_lstm)
    model.add(LeakyReLU())
    model.add(Dropout(0.2))
    model.add(LSTM(16, return_sequences=True, activation='tanh'))
    model.add(Dropout(0.2))
    model.add(LeakyReLU())
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer=opt,
                  metrics=['accuracy', keras_metrics.precision(), 
                           keras_metrics.recall(), f1])
</code></pre>
<p><strong>Model Summary:</strong></p>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 100, 32)           6272      
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 100, 32)           0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100, 32)           0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 100, 16)           3136      
_________________________________________________________________
dropout_2 (Dropout)          (None, 100, 16)           0         
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 100, 16)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1600)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 1601      
=================================================================
Total params: 11,009
Trainable params: 11,009
Non-trainable params: 0
_________________________________________________________________
</code></pre>
",1115237.0,,11829398.0,,2021-11-10 10:56:44,2021-11-10 10:56:44,Stateful LSTM and stream predictions,<python><tensorflow><keras><lstm><stateful>,4,15,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/53190253
47817424,1,47819022,,2017-12-14 15:55:14,,20,10866,"<p>I am learning neural networks and I built a simple one in Keras for the iris dataset classification from the UCI machine learning repository. I used a one hidden layer network with a 8 hidden nodes. Adam optimizer is used with a learning rate of 0.0005 and is run for 200 Epochs. Softmax is used at the output with loss as catogorical-crossentropy. I am getting the following learning curves. </p>

<p><a href=""https://i.stack.imgur.com/Y9bj3.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Y9bj3.png"" alt=""Learning Curve""></a></p>

<p>As you can see, the learning curve for the accuracy has a lot of flat regions and I don't understand why. The error seems to be decreasing constantly but the accuracy doesn't seem to be increasing in the same manner. What does the flat regions in the accuracy learning curve imply? Why is the accuracy not increasing at those regions even though error seems to be decreasing? </p>

<p>Is this normal in training or it is more likely that I am doing something wrong here?</p>



<pre class=""lang-python prettyprint-override""><code>dataframe = pd.read_csv(""iris.csv"", header=None)
dataset = dataframe.values
X = dataset[:,0:4].astype(float)
y = dataset[:,4]

scalar = StandardScaler()
X = scalar.fit_transform(X)

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

encoder = OneHotEncoder()
y = encoder.fit_transform(y.reshape(-1,1)).toarray()

# create model
model = Sequential()
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))

# Compile model
adam = optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
model.compile(loss='categorical_crossentropy',
              optimizer=adam, 
              metrics=['accuracy'])

# Fit the model
log = model.fit(X, y, epochs=200, batch_size=5, validation_split=0.2)

fig = plt.figure()
fig.suptitle(""Adam, lr=0.0006, one hidden layer"")

ax = fig.add_subplot(1,2,1)
ax.set_title('Cost')
ax.plot(log.history['loss'], label='Training')
ax.plot(log.history['val_loss'], label='Validation')
ax.legend()

ax = fig.add_subplot(1,2,2)
ax.set_title('Accuracy')
ax.plot(log.history['acc'], label='Training')
ax.plot(log.history['val_acc'], label='Validation')
ax.legend()

fig.show()
</code></pre>
",5530553.0,,4685471.0,,2017-12-15 17:24:47,2020-07-14 08:29:40,Loss & accuracy - Are these reasonable learning curves?,<machine-learning><neural-network><keras><classification><loss>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/47817424
36864774,1,36872347,,2016-04-26 12:19:39,,20,15307,"<p>I'm using Keras to predict a time series. As standard I'm using 20 epochs.
I want to check if my model is learning well, by predicting for each one of the 20 epochs.</p>
<p>By using <code>model.predict()</code> I'm getting only one prediction among all epochs (not sure how Keras selects it). I want all predictions, or at least the 10 best.</p>
<p>Would anyone know how to help me?</p>
",5606352.0,,6013016.0,,2020-08-28 09:20:50,2022-02-22 04:17:41,Python/Keras - How to access each epoch prediction?,<python><machine-learning><keras><deep-learning>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/36864774
49782579,1,55483743,,2018-04-11 18:56:32,,20,5963,"<p>I'm testing out my new NVIDIA Titan V, which supports float16 operations.  I noticed that during training, float16 is much slower (~800 ms/step) than float32 (~500 ms/step).</p>

<p>To do float16 operations, I changed my keras.json file to:</p>

<pre><code>{
""backend"": ""tensorflow"",
""floatx"": ""float16"",
""image_data_format"": ""channels_last"",
""epsilon"": 1e-07
}
</code></pre>

<p>Why are the float16 operations so much slower?  Do I need to make modifications to my code and not just the keras.json file?</p>

<p>I am using CUDA 9.0, cuDNN 7.0, tensorflow 1.7.0, and keras 2.1.5 on Windows 10.
My python 3.5 code is below:</p>

<pre><code>img_width, img_height = 336, 224

train_data_dir = 'C:\\my_dir\\train'
test_data_dir = 'C:\\my_dir\\test'
batch_size=128

datagen = ImageDataGenerator(rescale=1./255,
    horizontal_flip=True,   # randomly flip the images 
    vertical_flip=True) 

train_generator = datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary')

test_generator = datagen.flow_from_directory(
    test_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='binary')

# Architecture of NN
model = Sequential()
model.add(Conv2D(32,(3, 3), input_shape=(img_height, img_width, 3),padding='same',kernel_initializer='lecun_normal'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32,(3, 3),padding='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64,(3, 3),padding='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64,(3, 3),padding='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(AveragePooling2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(1))
model.add(Activation('sigmoid'))

my_rmsprop = keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-04, decay=0.0)
model.compile(loss='binary_crossentropy',
          optimizer=my_rmsprop,
          metrics=['accuracy'])

# Training 
nb_epoch = 32
nb_train_samples = 512
nb_test_samples = 512

model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples/batch_size,
    epochs=nb_epoch,
    verbose=1,
    validation_data=test_generator,
    validation_steps=nb_test_samples/batch_size)

# Evaluating on the testing set
model.evaluate_generator(test_generator, nb_test_samples)
</code></pre>
",8819660.0,,364696.0,,2018-11-01 10:25:25,2019-07-10 07:22:33,Float16 slower than float32 in keras,<python><tensorflow><keras>,2,7,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/49782579
48082655,1,48082967,,2018-01-03 17:54:20,,20,25765,"<p>I'm trying to create a simple weighted loss function. </p>

<p>Say, I have input dimensions 100 * 5, and output dimensions also 100 * 5. I also have a weight matrix of the same dimension.</p>

<p>Something like the following:</p>

<pre><code>import numpy as np
train_X = np.random.randn(100, 5)
train_Y = np.random.randn(100, 5)*0.01 + train_X

weights = np.random.randn(*train_X.shape)
</code></pre>

<h3>Defining the custom loss function</h3>

<pre><code>def custom_loss_1(y_true, y_pred):
    return K.mean(K.abs(y_true-y_pred)*weights)
</code></pre>

<h3>Defining the model</h3>

<pre><code>from keras.layers import Dense, Input
from keras import Model
import keras.backend as K

input_layer = Input(shape=(5,))
out = Dense(5)(input_layer)
model = Model(input_layer, out)
</code></pre>

<h3>Testing with existing metrics works fine</h3>

<pre><code>model.compile('adam','mean_absolute_error')
model.fit(train_X, train_Y, epochs=1)
</code></pre>

<h3>Testing with our custom loss function doesn't work</h3>

<pre><code>model.compile('adam',custom_loss_1)
model.fit(train_X, train_Y, epochs=10)
</code></pre>

<p>It gives the following stack trace:</p>

<pre><code>InvalidArgumentError (see above for traceback): Incompatible shapes: [32,5] vs. [100,5]
 [[Node: loss_9/dense_8_loss/mul = Mul[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](loss_9/dense_8_loss/Abs, loss_9/dense_8_loss/mul/y)]]
</code></pre>

<p>Where is the number 32 coming from?</p>

<h3>Testing a loss function with weights as Keras tensors</h3>

<pre><code>def custom_loss_2(y_true, y_pred):
    return K.mean(K.abs(y_true-y_pred)*K.ones_like(y_true))
</code></pre>

<p>This function seems to do the work. So, probably suggests that a Keras tensor as a weight matrix would work. So, I created another version of the loss function.</p>

<h3>Loss function try 3</h3>

<pre><code>from functools import partial

def custom_loss_3(y_true, y_pred, weights):
    return K.mean(K.abs(y_true-y_pred)*K.variable(weights, dtype=y_true.dtype))

cl3 = partial(custom_loss_3, weights=weights)  
</code></pre>

<p>Fitting data using cl3 gives the same error as above.</p>

<pre><code>InvalidArgumentError (see above for traceback): Incompatible shapes: [32,5] vs. [100,5]
     [[Node: loss_11/dense_8_loss/mul = Mul[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](loss_11/dense_8_loss/Abs, loss_11/dense_8_loss/Variable/read)]]
</code></pre>

<p>I wonder what I'm missing! I could have used the notion of sample_weight in Keras; but then I'd have to reshape my inputs to a 3d vector. </p>

<p>I thought that this custom loss function should really have been trivial.</p>
",743775.0,,743775.0,,2018-01-03 19:16:51,2018-02-01 15:47:13,Custom weighted loss function in Keras for weighing each element,<python><tensorflow><keras><loss-function>,1,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/48082655
50649831,1,50650072,,2018-06-01 19:18:45,,20,8010,"<p>I am trying to understand why regularization syntax in Keras looks the way that it does.</p>

<p>Roughly speaking, regularization is way to reduce overfitting by adding a penalty term to the loss function proportional to some function of the model weights.  Therefore, I would expect that regularization would be defined as part of the specification of the model's loss function.</p>

<p>However, in Keras the regularization is defined on a per-layer basis.  For instance, consider this regularized DNN model:</p>

<pre><code>input = Input(name='the_input', shape=(None, input_shape))
x = Dense(units = 250, activation='tanh', name='dense_1', kernel_regularizer=l2, bias_regularizer=l2, activity_regularizer=l2)(x)
x = Dense(units = 28, name='dense_2',kernel_regularizer=l2, bias_regularizer=l2, activity_regularizer=l2)(x)
y_pred = Activation('softmax', name='softmax')(x)
mymodel= Model(inputs=input, outputs=y_pred)
mymodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
</code></pre>

<p>I would have expected that the regularization arguments in the Dense layer were not needed and I could just write the last line more like:</p>

<pre><code>mymodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'], regularization='l2')
</code></pre>

<p>This is obviously wrong syntax, but I was hoping someone could elaborate for me a bit on why the regularizes are defined this way and what is actually happening when I use layer-level regularization.</p>

<p>The other thing I don't understand is under what circumstances would I use each or all of the three regularization options: <code>(kernel_regularizer, activity_regularizer, bias_regularizer)</code>?</p>
",2690677.0,,2690677.0,,2018-06-01 19:51:39,2018-06-01 19:51:39,Understanding Regularization in Keras,<python><keras>,1,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/50649831
49127214,1,50040233,,2018-03-06 09:16:35,,20,13492,"<p>I added a callback to decay the learning rate:</p>
<pre><code> keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=100, 
                                   verbose=0, mode='auto',epsilon=0.00002, cooldown=20, min_lr=0)
</code></pre>
<p>Here is my tensorboard callback:</p>
<pre><code>keras.callbacks.TensorBoard(log_dir='./graph/rank{}'.format(hvd.rank()), histogram_freq=10, batch_size=FLAGS.batch_size,
                            write_graph=True, write_grads=True, write_images=False)
</code></pre>
<p>I want to make sure the learning rate scheduler has kicked in during training, so I want to output the learning rate onto tensorboard. But I can not find where I can set it.</p>
<p>I also checked the optimizer api, but no luck.</p>
<pre><code>keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
</code></pre>
<p>How can I output the learning rate to tensorboad?</p>
",6898439.0,,6430218.0,,2021-08-06 22:16:35,2022-02-08 11:39:06,Keras: how to output learning rate onto tensorboard,<keras><tensorboard>,5,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/49127214
51749404,1,51757012,,2018-08-08 14:38:01,,19,13206,"<p>I'm trying to develop an Encoder model in keras for timeseries. The shape of data is (5039, 28, 1), meaning that my seq_len is 28 and I have one feature. For the first layer of the encoder, I'm using 112 hunits, second layer will have 56 and to be able to get back to the input shape for decoder, I had to add 3rd layer with 28 hunits (this autoencoder is supposed to reconstruct its input). But I don't know what is the correct approach to connect the LSTM layers together. AFAIK, I can either add <code>RepeatVector</code> or <code>return_seq=True</code>. You can see both of my models in the following code. I wonder what will be the difference and which approach is the correct one? </p>

<p>First model using <code>return_sequence=True</code>:</p>

<pre><code>inputEncoder = Input(shape=(28, 1))
firstEncLayer = LSTM(112, return_sequences=True)(inputEncoder)
snd = LSTM(56, return_sequences=True)(firstEncLayer)
outEncoder = LSTM(28)(snd)

context = RepeatVector(1)(outEncoder)
context_reshaped = Reshape((28,1))(context)

encoder_model = Model(inputEncoder, outEncoder)
firstDecoder = LSTM(112, return_sequences=True)(context_reshaped)
outDecoder = LSTM(1, return_sequences=True)(firstDecoder)

autoencoder = Model(inputEncoder, outDecoder)
</code></pre>

<p>Second model with <code>RepeatVector</code>:</p>

<pre><code>inputEncoder = Input(shape=(28, 1))
firstEncLayer = LSTM(112)(inputEncoder)
firstEncLayer = RepeatVector(1)(firstEncLayer)
snd = LSTM(56)(firstEncLayer)
snd = RepeatVector(1)(snd)
outEncoder = LSTM(28)(snd)
encoder_model = Model(inputEncoder, outEncoder)

context = RepeatVector(1)(outEncoder)
context_reshaped = Reshape((28, 1))(context)

firstDecoder = LSTM(112)(context_reshaped)
firstDecoder = RepeatVector(1)(firstDecoder)
sndDecoder = LSTM(28)(firstDecoder)

outDecoder = RepeatVector(1)(sndDecoder)
outDecoder = Reshape((28, 1))(outDecoder)

autoencoder = Model(inputEncoder, outDecoder)
</code></pre>
",3711985.0,,,,,2019-10-03 14:58:00,"How to connect LSTM layers in Keras, RepeatVector or return_sequence=True?",<tensorflow><keras><deep-learning><lstm><autoencoder>,1,1,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51749404
46619869,1,46620771,,2017-10-07 11:59:31,,19,23569,"<p>I am using keras+tensorflow for the first time. I would like to specify the <a href=""https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html"" rel=""noreferrer"">correlation coefficient</a> as the loss function. It makes sense to square it so that it is a number between 0 and 1 where 0 is bad and 1 is good.</p>

<p>My basic code currently looks like:</p>

<pre><code>def baseline_model():
        model = Sequential()
        model.add(Dense(4000, input_dim=n**2, kernel_initializer='normal', activation='relu'))
        model.add(Dense(1, kernel_initializer='normal'))
        # Compile model
        model.compile(loss='mean_squared_error', optimizer='adam')
        return model

estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, verbose=2)))
pipeline = Pipeline(estimators)
kfold = KFold(n_splits=10, random_state=0)
results = cross_val_score(pipeline, X, Y, cv=kfold)
print(""Standardized: %.2f (%.2f) MSE"" % (results.mean(), results.std()))
</code></pre>

<p>How can I change this so that it optimizes to minimize the squared correlation coefficient  instead?</p>

<hr>

<p>I tried the following:</p>

<pre><code>def correlation_coefficient(y_true, y_pred):
    pearson_r, _ = tf.contrib.metrics.streaming_pearson_correlation(y_pred, y_true)
    return 1-pearson_r**2

def baseline_model():
# create model
        model = Sequential()
        model.add(Dense(4000, input_dim=n**2, kernel_initializer='normal', activation='relu'))
#        model.add(Dense(2000, kernel_initializer='normal', activation='relu'))
        model.add(Dense(1, kernel_initializer='normal'))
        # Compile model
        model.compile(loss=correlation_coefficient, optimizer='adam')
        return model
</code></pre>

<p>but this crashes with:</p>

<pre><code>Traceback (most recent call last):
  File ""deeplearning-det.py"", line 67, in &lt;module&gt;
    results = cross_val_score(pipeline, X, Y, cv=kfold)
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py"", line 321, in cross_val_score
    pre_dispatch=pre_dispatch)
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py"", line 195, in cross_validate
    for train, test in cv.split(X, y, groups))
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 779, in __call__
    while self.dispatch_one_batch(iterator):
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 625, in dispatch_one_batch
    self._dispatch(tasks)
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 588, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py"", line 111, in apply_async
    result = ImmediateResult(func)
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py"", line 332, in __init__
    self.results = batch()
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py"", line 131, in &lt;listcomp&gt;
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/model_selection/_validation.py"", line 437, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File ""/home/user/.local/lib/python3.5/site-packages/sklearn/pipeline.py"", line 259, in fit
    self._final_estimator.fit(Xt, y, **fit_params)
  File ""/home/user/.local/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py"", line 147, in fit
    history = self.model.fit(x, y, **fit_args)
  File ""/home/user/.local/lib/python3.5/site-packages/keras/models.py"", line 867, in fit
    initial_epoch=initial_epoch)
  File ""/home/user/.local/lib/python3.5/site-packages/keras/engine/training.py"", line 1575, in fit
    self._make_train_function()
  File ""/home/user/.local/lib/python3.5/site-packages/keras/engine/training.py"", line 960, in _make_train_function
    loss=self.total_loss)
  File ""/home/user/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/home/user/.local/lib/python3.5/site-packages/keras/optimizers.py"", line 432, in get_updates
    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g
  File ""/home/user/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 856, in binary_op_wrapper
    y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
  File ""/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 611, in convert_to_tensor
    as_ref=False)
  File ""/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 676, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 121, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/user/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 364, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
</code></pre>

<hr>

<p><strong>Update 1</strong></p>

<p>Following the answer below the code now runs. Unfortunately, the <code>correlation_coefficient</code> and <code>correlation_coefficient_loss</code> functions give different values from each other and I am not sure either of them is the same as you would get from 1- <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html"" rel=""noreferrer"">scipy.stats.pearsonr</a>()[0]**2.  </p>

<blockquote>
  <p>Why are loss functions giving the wrong outputs and how can they be
  corrected to give the same values as <code>1 -
  scipy.stats.pearsonr()[0]**2</code> would give?</p>
</blockquote>

<p>Here is the completely self contained code that should just run:</p>

<pre><code>import numpy as np
import sys
import math
from scipy.stats import ortho_group
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import tensorflow as tf
from keras import backend as K


def permanent(M):
    n = M.shape[0]
    d = np.ones(n)
    j = 0
    s = 1
    f = np.arange(n)
    v = M.sum(axis=0)
    p = np.prod(v)
    while (j &lt; n-1):
        v -= 2*d[j]*M[j]
        d[j] = -d[j]
        s = -s
        prod = np.prod(v)
        p += s*prod
        f[0] = 0
        f[j] = f[j+1]
        f[j+1] = j+1
        j = f[0]
    return p/2**(n-1)


def correlation_coefficient_loss(y_true, y_pred):
    x = y_true
    y = y_pred
    mx = K.mean(x)
    my = K.mean(y)
    xm, ym = x-mx, y-my
    r_num = K.sum(xm * ym)
    r_den = K.sum(K.sum(K.square(xm)) * K.sum(K.square(ym)))
    r = r_num / r_den
    return 1 - r**2


def correlation_coefficient(y_true, y_pred):
    pearson_r, update_op = tf.contrib.metrics.streaming_pearson_correlation(y_pred, y_true)
    # find all variables created for this metric
    metric_vars = [i for i in tf.local_variables() if 'correlation_coefficient' in i.name.split('/')[1]]

    # Add metric variables to GLOBAL_VARIABLES collection.
    # They will be initialized for new session.
    for v in metric_vars:
        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)

    # force to update metric values
    with tf.control_dependencies([update_op]):
        pearson_r = tf.identity(pearson_r)
        return 1-pearson_r**2


def baseline_model():
    # create model
    model = Sequential()
    model.add(Dense(4000, input_dim=no_rows**2, kernel_initializer='normal', activation='relu'))
#    model.add(Dense(2000, kernel_initializer='normal', activation='relu'))
    model.add(Dense(1, kernel_initializer='normal'))
    # Compile model
    model.compile(loss=correlation_coefficient_loss, optimizer='adam', metrics=[correlation_coefficient])
    return model


no_rows = 8

print(""Making the input data using seed 7"", file=sys.stderr)
np.random.seed(7)
U = ortho_group.rvs(no_rows**2)
U = U[:, :no_rows]
# U is a random orthogonal matrix
X = []
Y = []
print(U)
for i in range(40000):
        I = np.random.choice(no_rows**2, size = no_rows)
        A = U[I][np.lexsort(np.rot90(U[I]))]
        X.append(A.ravel())
        Y.append(-math.log(permanent(A)**2, 2))

X = np.array(X)
Y = np.array(Y)

estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, verbose=2)))
pipeline = Pipeline(estimators)
X_train, X_test, y_train, y_test = train_test_split(X, Y,
                                                    train_size=0.75, test_size=0.25)
pipeline.fit(X_train, y_train)
</code></pre>

<p><strong>Update 2</strong></p>

<p>I have given up on the <code>correlation_coefficient</code> function and am now just using the <code>correlation_coefficient_loss</code> one as given by JulioDanielReyes below.  However, either this is still wrong or keras is dramatically overfitting.  Even when I have:</p>

<pre><code>def baseline_model():
        model = Sequential()
        model.add(Dense(40, input_dim=no_rows**2, kernel_initializer='normal', activation='relu'))
        model.add(Dense(1, kernel_initializer='normal'))
        model.compile(loss=correlation_coefficient_loss, optimizer='adam', metrics=[correlation_coefficient_loss])
        return model
</code></pre>

<p>I get a loss of, for example, 0.6653 after 100 epochs but 0.857 when I test the trained model.</p>

<blockquote>
  <p>How can it be overfitting which such a tiny number of nodes in the
  hidden layer?</p>
</blockquote>
",1473517.0,,1473517.0,,2017-10-11 18:09:06,2022-04-29 05:25:07,How to specify the correlation coefficient as the loss function in keras,<python><machine-learning><tensorflow><keras>,4,13,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/46619869
51704808,1,51705639,,2018-08-06 09:47:30,,19,23175,"<p>At the end of each epoch, I am getting for example the following output:</p>

<pre><code>Epoch 1/25
2018-08-06 14:54:12.555511: 
2/2 [==============================] - 86s 43s/step - loss: 6.0767 - acc: 0.0469 - val_loss: 4.1037 - val_acc: 0.2000
Epoch 2/25
2/2 [==============================] - 26s 13s/step - loss: 3.6901 - acc: 0.0938 - val_loss: 2.5610 - val_acc: 0.0000e+00
Epoch 3/25
2/2 [==============================] - 66s 33s/step - loss: 3.1491 - acc: 0.1406 - val_loss: 2.4793 - val_acc: 0.0500
Epoch 4/25
2/2 [==============================] - 44s 22s/step - loss: 3.0686 - acc: 0.0694 - val_loss: 2.3159 - val_acc: 0.0500
Epoch 5/25
2/2 [==============================] - 62s 31s/step - loss: 2.5884 - acc: 0.1094 - val_loss: 2.4601 - val_acc: 0.1500
Epoch 6/25
2/2 [==============================] - 41s 20s/step - loss: 2.7708 - acc: 0.1493 - val_loss: 2.2542 - val_acc: 0.4000
.
.
.
.
</code></pre>

<p>Can anyone explain me what's the difference between loss, accuracy, validation loss and validation accuracy?</p>
",7017416.0,,7017416.0,,2018-08-07 18:40:14,2019-08-26 09:34:13,"What is the difference between Loss, accuracy, validation loss, Validation accuracy?",<tensorflow><keras>,3,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/51704808
55308425,1,58595177,,2019-03-22 22:10:23,,19,5102,"<p>What is the difference between using <code>model(x)</code> and <code>model.predict(x)</code> for predicting the outcome of a model in Keras?</p>
",4807022.0,,42973.0,,2021-05-20 06:02:28,2021-05-20 06:02:28,Difference between model(x) and model.predict(x) in Keras?,<python><tensorflow><keras>,1,0,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55308425
45874245,1,47282487,,2017-08-25 03:59:44,,19,21441,"<p>I'm developing a real-time object classification app for android. First I created a deep learning model using ""keras"" and I already have trained model saved as ""model.h5"" file. I would like to know how can I use that model in android for image classification.  </p>
",7660421.0,,,,,2021-10-28 14:09:54,Keras deep learning model to android,<android><tensorflow><deep-learning><keras>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/45874245
56227671,1,56227965,,2019-05-20 20:21:58,,19,13258,"<p>I have a list:</p>

<pre><code>code = ['&lt;s&gt;', 'are', 'defined', 'in', 'the', '""editable', 'parameters""', '\n', 'section.', '\n', 'A', 'larger', '`tsteps`', 'value', 'means', 'that', 'the', 'LSTM', 'will', 'need', 'more', 'memory', '\n', 'to', 'figure', 'out']
</code></pre>

<p>And I want to convert to one hot encoding. I tried:</p>

<pre><code>to_categorical(code)
</code></pre>

<p>And I get an error: <code>ValueError: invalid literal for int() with base 10: '&lt;s&gt;'</code></p>

<p>What am I doing wrong?</p>
",239879.0,,,,,2021-11-01 00:08:24,How can I one hot encode a list of strings with Keras?,<python><keras><one-hot-encoding>,4,2,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/56227671
60267911,1,60307121,,2020-02-17 17:46:20,,19,3097,"<p>I tried to get an estimate of the prediction time of my keras model and realised something strange. Apart from being fairly fast normally, every once in a while the model needs quite long to come up with a prediction. And not only that, those times also increase the longer the model runs. I added a minimal working example to reproduce the error.</p>

<pre class=""lang-py prettyprint-override""><code>import time
import numpy as np
from sklearn.datasets import make_classification
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten

# Make a dummy classification problem
X, y = make_classification()

# Make a dummy model
model = Sequential()
model.add(Dense(10, activation='relu',name='input',input_shape=(X.shape[1],)))
model.add(Dense(2, activation='softmax',name='predictions'))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(X, y, verbose=0, batch_size=20, epochs=100)

for i in range(1000):
    # Pick a random sample
    sample = np.expand_dims(X[np.random.randint(99), :], axis=0)
    # Record the prediction time 10x and then take the average
    start = time.time()
    for j in range(10):
        y_pred = model.predict_classes(sample)
    end = time.time()
    print('%d, %0.7f' % (i, (end-start)/10))
</code></pre>

<p>The time does  not depend on the sample (it is being picked randomly). If the test is repeated, the indices in the for loop where the prediction takes longer are going to be (nearly) the same again.</p>

<p><a href=""https://i.stack.imgur.com/m0alO.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/m0alO.png"" alt=""enter image description here""></a></p>

<p>I'm using:</p>

<pre><code>tensorflow 2.0.0
python 3.7.4
</code></pre>

<p>For my application I need to guarantee the execution in a certain time. This is however impossible considering that behaviour. What is going wrong? Is it a bug in Keras or a bug in the tensorflow backend?</p>

<p>EDIT:
<code>predict_on_batch</code> shows the same behavior, however, more sparse:
<a href=""https://i.stack.imgur.com/AlsJQ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/AlsJQ.png"" alt=""enter image description here""></a></p>

<p><code>y_pred = model(sample, training=False).numpy()</code> shows some heavy outliers as well, however, they are not increasing.
<a href=""https://i.stack.imgur.com/xbpyX.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/xbpyX.png"" alt=""enter image description here""></a></p>

<p>EDIT 2:
I downgraded to the latest tensorflow 1 version (1.15). Not only is the problem not existent anymore, also the ""normal"" prediction time significantly improved! I do not see the two spikes as problematic, as they didn't appear when I repeated the test (at least not at the same indices and linearly increasing) and are percentual not as large as in the first plot.
<a href=""https://i.stack.imgur.com/MlI9W.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/MlI9W.png"" alt=""enter image description here""></a></p>

<p>We can thus conclude that this seems to be a problem inherent to tensorflow 2.0, which shows similar behaviour in other situations as @OverLordGoldDragon mentions.</p>
",11250466.0,,11250466.0,,2020-02-19 20:49:31,2020-03-11 06:07:48,Keras inconsistent prediction time,<python><performance><tensorflow><keras><tensorflow2.0>,2,8,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/60267911
55268762,1,55281501,,2019-03-20 19:26:43,,19,10102,"<p>I am working with a very memory demanding CNN model for a task of classification.
This poses a big limit on the batch size that I can use during training.</p>

<p>One solution is to accumulate the gradients during training, meaning that the weights of the model are not updated after every single batch. Instead the same weights are used for several batches, while the gradients from each batch are accumulated and than averaged for a single weight-update action.</p>

<p>I'm using a Tensorflow backend Keras and I'm pretty sure that Keras has no off-the-shelf function/method to achieve this.</p>

<p>How can it be done for a Keras/tensorflow model?</p>
",9673730.0,,,,,2020-01-23 09:18:13,How to accumulate gradients for large batch sizes in Keras,<python><tensorflow><machine-learning><keras>,3,3,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/55268762
42586475,1,42587192,,2017-03-03 18:57:15,,19,12143,"<p>I have an imbalanced multi-class dataset and I want to use the <code>class_weight</code> argument from <code>fit_generator</code> to give weights to the classes according to the number of images of each class. I'm using <code>ImageDataGenerator.flow_from_directory</code> to load the dataset from a directory.</p>

<p>Is it possible to directly infer the <code>class_weight</code> argument from the <code>ImageDataGenerator</code> object?</p>
",604734.0,,604734.0,,2018-09-27 07:24:56,2023-04-17 09:36:14,Is it possible to automatically infer the class_weight from flow_from_directory in Keras?,<keras><deep-learning>,7,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42586475
42689066,1,55304690,,2017-03-09 07:20:54,,19,35118,"<p>I am trying to implement CNN by Theano. I used Keras library. My data set is 55 alphabet images, 28x28. </p>

<p>In the last part I get this error:
<a href=""https://i.stack.imgur.com/sQ0Cb.png]"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/sQ0Cb.png]"" alt=""enter image description here""></a></p>

<pre><code>train_acc=hist.history['acc']
KeyError: 'acc'
</code></pre>

<p>Any help would be much appreciated. Thanks.</p>

<p>This is part of my code:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>from keras.models import Sequential
from keras.models import Model
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD, RMSprop, adam
from keras.utils import np_utils

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from urllib.request import urlretrieve
import pickle
import os
import gzip
import numpy as np
import theano
import lasagne
from lasagne import layers
from lasagne.updates import nesterov_momentum
from nolearn.lasagne import NeuralNet
from nolearn.lasagne import visualize
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from PIL import Image
import PIL.Image
#from Image import *
import webbrowser
from numpy import *
from sklearn.utils import shuffle
from sklearn.cross_validation import train_test_split
from tkinter import *
from tkinter.ttk import *
import tkinter

from keras import backend as K
K.set_image_dim_ordering('th')
%%%%%%%%%%

batch_size = 10

# number of output classes
nb_classes = 6

# number of epochs to train
nb_epoch = 5

# input iag dimensions
img_rows, img_clos = 28,28

# number of channels
img_channels = 3

# number of convolutional filters to use
nb_filters = 32

# number of convolutional filters to use
nb_pool = 2

# convolution kernel size
nb_conv = 3

%%%%%%%%

model = Sequential()

model.add(Convolution2D(nb_filters, nb_conv, nb_conv,
                        border_mode='valid',
                        input_shape=(1, img_rows, img_clos)))
convout1 = Activation('relu')
model.add(convout1)
model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
convout2 = Activation('relu')
model.add(convout2)
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adadelta')

%%%%%%%%%%%%

hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
              show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))
            
            
hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,
              show_accuracy=True, verbose=1, validation_split=0.2)
%%%%%%%%%%%%%%

train_loss=hist.history['loss']
val_loss=hist.history['val_loss']
train_acc=hist.history['acc']
val_acc=hist.history['val_acc']
xc=range(nb_epoch)
#xc=range(on_epoch_end)

plt.figure(1,figsize=(7,5))
plt.plot(xc,train_loss)
plt.plot(xc,val_loss)
plt.xlabel('num of Epochs')
plt.ylabel('loss')
plt.title('train_loss vs val_loss')
plt.grid(True)
plt.legend(['train','val'])
print (plt.style.available) # use bmh, classic,ggplot for big pictures
plt.style.use(['classic'])

plt.figure(2,figsize=(7,5))
plt.plot(xc,train_acc)
plt.plot(xc,val_acc)
plt.xlabel('num of Epochs')
plt.ylabel('accuracy')
plt.title('train_acc vs val_acc')
plt.grid(True)
plt.legend(['train','val'],loc=4)
#print plt.style.available # use bmh, classic,ggplot for big pictures
plt.style.use(['classic'])</code></pre>
</div>
</div>
</p>
",7682122.0,,1886270.0,,2017-03-09 09:06:59,2022-12-20 14:20:03,Convolutional Neural Net-Keras-val_acc Keyerror 'acc',<python><keras>,10,0,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42689066
42815131,1,42820423,,2017-03-15 16:11:18,,19,14958,"<p>I have just install tensorflow and keras. And I have the simple demo as follow:</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense
import numpy
# fix random seed for reproducibility
seed = 7
numpy.random.seed(seed)
# load pima indians dataset
dataset = numpy.loadtxt(""pima-indians-diabetes.csv"", delimiter="","")
# split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]
# create model
model = Sequential()
model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))
model.add(Dense(8, init='uniform', activation='relu'))
model.add(Dense(1, init='uniform', activation='sigmoid'))
# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# Fit the model
model.fit(X, Y, nb_epoch=10, batch_size=10)
# evaluate the model
scores = model.evaluate(X, Y)
print(""%s: %.2f%%"" % (model.metrics_names[1], scores[1]*100))
</code></pre>

<p>And I have this warning:</p>

<pre><code>/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=""relu"", kernel_initializer=""uniform"", input_dim=8)` '` call to the Keras 2 API: ' + signature)
/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=""relu"", kernel_initializer=""uniform"")` '` call to the Keras 2 API: ' + signature)
/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=""sigmoid"", kernel_initializer=""uniform"")` '` call to the Keras 2 API: ' + signature)
/usr/local/lib/python2.7/dist-packages/keras/models.py:826: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`. warnings.warn('The `nb_epoch` argument in `fit` '
</code></pre>

<p>So, How can I handle this? </p>
",7701969.0,,216356.0,,2017-12-04 15:31:32,2020-05-22 11:48:51,Keras for implement convolution neural network,<python><deep-learning><keras>,3,1,0.0,,,CC BY-SA 3.0,https://stackoverflow.com/q/42815131
52041931,1,52042520,,2018-08-27 14:53:24,,19,12079,"<p>I am developping a segmentation neural network with only two classes, 0 and 1 (0 is the background and 1 the object that I want to find on the image). On each image, there are about 80% of 1 and 20% of 0. As you can see, the dataset is unbalanced and it makes the results wrong. My accuracy is 85% and my loss is low, but that is only because my model is good at finding the background !</p>

<p>I would like to base the optimizer on another metric, like precision or recall which is more usefull in this case.</p>

<p>Does anyone know how to implement this ?</p>
",9998692.0,,4685471.0,,2018-08-27 15:01:03,2022-01-15 23:15:49,Is there an optimizer in keras based on precision or recall instead of loss?,<machine-learning><keras><metrics>,7,14,0.0,,,CC BY-SA 4.0,https://stackoverflow.com/q/52041931
49164230,1,49179305,,2018-03-08 02:03:58,,19,12503,"<p>In deep neural network, we can implement the skip connections to help:</p>

<ul>
<li><p>Solve problem of vanishing gradient, training faster</p></li>
<li><p>The network learns a combination of low level and high level features</p></li>
<li><p>Recover info loss during downsampling like max pooling.</p></li>
</ul>

<p><a href=""https://medium.com/@mikeliao/deep-layer-aggregation-combining-layers-in-nn-architectures-2744d29cab8"" rel=""noreferrer"">https://medium.com/@mikeliao/deep-layer-aggregation-combining-layers-in-nn-architectures-2744d29cab8</a></p>

<p>However, i read some source code, some implemented skip connections as concatenation, some as summation. So my question is what are the benefits of each of these implementations?</p>
",8186293.0,,,,,2018-03-08 17:42:37,Deep neural network skip connection implemented as summation vs concatenation?,<tensorflow><computer-vision><deep-learning><keras>,1,0,0.0,2018-03-09 14:01:45,,CC BY-SA 3.0,https://stackoverflow.com/q/49164230
